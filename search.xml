<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-01-20</title>
    <url>/2020/01/20/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-01-20/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Unsupervised Learning of Camera Pose with Compositional Re-estimation <a href="https://arxiv.org/pdf/2001.06479" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Combining PRNU and noiseprint for robust and efficient device source  identification <a href="https://arxiv.org/pdf/2001.06440" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> TailorGAN: Making User-Defined Fashion Designs <a href="https://arxiv.org/pdf/2001.06427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Subjective Annotation for a Frame Interpolation Benchmark using Artifact  Amplification <a href="https://arxiv.org/pdf/2001.06409" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> GraphBGS: Background Subtraction via Recovery of Graph Signals <a href="https://arxiv.org/pdf/2001.06404" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Latency-Aware Differentiable Neural Architecture Search <a href="https://arxiv.org/pdf/2001.06392" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> BigEarthNet Deep Learning Models with A New Class-Nomenclature for  Remote Sensing Image Understanding <a href="https://arxiv.org/pdf/2001.06372" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Efficient Facial Feature Learning with Wide Ensemble-based Convolutional  Neural Networks <a href="https://arxiv.org/pdf/2001.06338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Vision Meets Drones: Past, Present and Future <a href="https://arxiv.org/pdf/2001.06303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Predicting the Physical Dynamics of Unseen 3D Objects <a href="https://arxiv.org/pdf/2001.06291" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Review: deep learning on 3D point clouds <a href="https://arxiv.org/pdf/2001.06280" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Compounding the Performance Improvements of Assembled Techniques in a  Convolutional Neural Network <a href="https://arxiv.org/pdf/2001.06268" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On <a href="https://arxiv.org/pdf/2001.06265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Two-Phase Object-Based Deep Learning for Multi-temporal SAR Image Change  Detection <a href="https://arxiv.org/pdf/2001.06252" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Registration made easy -- standalone orthopedic navigation with HoloLens <a href="https://arxiv.org/pdf/2001.06209" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for  Semi-supervised Optical Flow Estimation <a href="https://arxiv.org/pdf/2001.06171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Interpreting Galaxy Deblender GAN from the Discriminator's Perspective <a href="https://arxiv.org/pdf/2001.06151" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Learning to Augment Expressions for Few-shot Fine-grained Facial  Expression Recognition <a href="https://arxiv.org/pdf/2001.06144" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Spatio-Temporal Ranked-Attention Networks for Video Captioning <a href="https://arxiv.org/pdf/2001.06127" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Automatic Discovery of Political Meme Genres with Diverse Appearances <a href="https://arxiv.org/pdf/2001.06122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> On- Device Information Extraction from Screenshots in form of tags <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> Tracking of Micro Unmanned Aerial Vehicles: A Comparative Study <a href="https://arxiv.org/pdf/2001.06066" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Increasing the robustness of DNNs against image corruptions by playing  the Game of Noise <a href="https://arxiv.org/pdf/2001.06057" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> Modality-Balanced Models for Visual Dialogue <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> Tethered Aerial Visual Assistance <a href="https://arxiv.org/pdf/2001.06347" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<div id="title26">
<b>26.</b> DeepSUM++: Non-local Deep Neural Network for Super-Resolution of  Unregistered Multitemporal Images <a href="https://arxiv.org/pdf/2001.06342" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper26" style="color:#0000EE;">摘要</a><br></div>
<div id="title27">
<b>27.</b> Detection Method Based on Automatic Visual Shape Clustering for  Pin-Missing Defect in Transmission Lines <a href="https://arxiv.org/pdf/2001.06236" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper27" style="color:#0000EE;">摘要</a><br></div>
<div id="title28">
<b>28.</b> Sideways: Depth-Parallel Training of Video Models <a href="https://arxiv.org/pdf/2001.06232" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper28" style="color:#0000EE;">摘要</a><br></div>
<div id="title29">
<b>29.</b> FedVision: An Online Visual Object Detection Platform Powered by  Federated Learning <a href="https://arxiv.org/pdf/2001.06202" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper29" style="color:#0000EE;">摘要</a><br></div>
<div id="title30">
<b>30.</b> Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless  Approach <a href="https://arxiv.org/pdf/2001.06175" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper30" style="color:#0000EE;">摘要</a><br></div>
<div id="title31">
<b>31.</b> An adversarial learning framework for preserving users' anonymity in  face-based emotion recognition <a href="https://arxiv.org/pdf/2001.06103" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper31" style="color:#0000EE;">摘要</a><br></div>
<div id="title32">
<b>32.</b> Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for  Making a CNN Classifier Robust Against Adversarial Attacks <a href="https://arxiv.org/pdf/2001.06099" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper32" style="color:#0000EE;">摘要</a><br></div>
<div id="title33">
<b>33.</b> Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised  Learning <a href="https://arxiv.org/pdf/2001.06001" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper33" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Unsupervised Learning of Camera Pose with Compositional Re-estimation</b>  <a href="https://arxiv.org/pdf/2001.06479" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Nabavi%2C+S+S" target="_blank" rel="noopener" style="color:#0000EE;">Seyed Shahabeddin Nabavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hosseinzadeh%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mehrdad Hosseinzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fahimi%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ramin Fahimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Wang</a><br>
<font size="3">
Abstract: We consider the problem of unsupervised camera pose estimation. Given an input video sequence, our goal is to estimate the camera pose (i.e. the camera motion) between consecutive frames. Traditionally, this problem is tackled by placing strict constraints on the transformation vector or by incorporating optical flow through a complex pipeline. We propose an alternative approach that utilizes a compositional re-estimation process for camera pose estimation. Given an input, we first estimate a depth map. Our method then iteratively estimates the camera motion based on the estimated depth map. Our approach significantly improves the predicted camera motion both quantitatively and visually. Furthermore, the re-estimation resolves the problem of out-of-boundaries pixels in a novel and simple way. Another advantage of our approach is that it is adaptable to other camera pose estimation approaches. Experimental analysis on KITTI benchmark dataset demonstrates that our method outperforms existing state-of-the-art approaches in unsupervised camera ego-motion estimation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们认为监督的相机姿态估计的问题。给定的输入视频序列，我们的目标是估计连续帧之间的摄像机姿态（即，照相机运动）。传统上，这个问题是通过将严格的约束的转化载体或通过一个复杂的管道结合光流解决。我们建议，利用相机姿势估计的成分重新估计过程的替代方法。给定一个输入，我们首先估计深度图。然后，我们的迭代算法估计基于估计的深度地图上的摄像机运动。我们的方法在数量上和视觉上显著提高了预测的摄像机运动。此外，重新估计解决了一种新颖和简单的方式外的边界像素的问题。我们的方法的另一个优点是，它是适用于其他相机姿态估计方法。上KITTI基准数据集试验分析表明，我们现有的最先进的国家的方法优于在无监督照相机自运动估计方法。</font>
</div>


<hr>
<div id="paper2"> <b>2. Combining PRNU and noiseprint for robust and efficient device source  identification</b>  <a href="https://arxiv.org/pdf/2001.06440" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cozzolino%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davide Cozzolino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marra%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Francesco Marra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gragnaniello%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Diego Gragnaniello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poggi%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giovanni Poggi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Verdoliva%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luisa Verdoliva</a><br>
<font size="3">
Abstract: PRNU-based image processing is a key asset in digital multimedia forensics. It allows for reliable device identification and effective detection and localization of image forgeries, in very general conditions. However, performance impairs significantly in challenging conditions involving low quality and quantity of data. These include working on compressed and cropped images, or estimating the camera PRNU pattern based on only a few images. To boost the performance of PRNU-based analyses in such conditions we propose to leverage the image noiseprint, a recently proposed camera-model fingerprint that has proved effective for several forensic tasks. Numerical experiments on datasets widely used for source identification prove that the proposed method ensures a significant performance improvement in a wide range of challenging situations. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于PRNU图像处理是数字多媒体取证的重要资产。它允许可靠的装置识别和有效的检测和图像伪造的定位，在很一般的条件。然而，性能也妨碍显著在挑战包括低质量和数据量的条件。这些包括工作压缩和裁切图像，或估计基于只有少数图像中的相机PRNU图案。为了提高在这样的条件下基于PRNU-分析的性能，我们提出了利用图像noiseprint，已被证明有效的几个法医任务的最近提出的相机型号的指纹。上的数据集广泛用于源识别数值实验证明，该方法确保在广泛的挑战的情况一显著性能改进。</font>
</div>


<hr>
<div id="paper3"> <b>3. TailorGAN: Making User-Defined Fashion Designs</b>  <a href="https://arxiv.org/pdf/2001.06427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lele Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Justin Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cheng-Haw Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=King%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Erh-Kan King</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kuan-Ting Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsieh%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shao-Hang Hsieh</a><br>
<font size="3">
Abstract: Attribute editing has become an important and emerging topic of computer vision. In this paper, we consider a task: given a reference garment image A and another image B with target attribute (collar/sleeve), generate a photo-realistic image which combines the texture from reference A and the new attribute from reference B. The highly convoluted attributes and the lack of paired data are the main challenges to the task. To overcome those limitations, we propose a novel self-supervised model to synthesize garment images with disentangled attributes (e.g., collar and sleeves) without paired data. Our method consists of a reconstruction learning step and an adversarial learning step. The model learns texture and location information through reconstruction learning. And, the model's capability is generalized to achieve single-attribute manipulation by adversarial learning. Meanwhile, we compose a new dataset, named GarmentSet, with annotation of landmarks of collars and sleeves on clean garment images. Extensive experiments on this dataset and real-world samples demonstrate that our method can synthesize much better results than the state-of-the-art methods in both quantitative and qualitative comparisons. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：属性编辑已经成为计算机视觉的一个重要和新兴的话题。在本文中，我们考虑一个任务：给定一个参考服装图像A和与目标属性（领/套筒）另一图像B，生成结合了从参考点A的质地和从参考B的新的属性的照片般逼真的图像高度令人费解的属性和缺乏配对数据是任务的主要挑战。为了克服这些限制，我们提出了一种新型的自监督模型以合成服装图像与解缠结的属性（例如，领子和袖子），而不配对数据。我们的方法包括一个重建学习步骤和敌对学习步骤的。该模型通过学习学习重建质地和位置信息。而且，该模型的能力是广义的对抗学习，实现单属性操作。同时，我们组成一个新的数据集，名为GarmentSet，用干净的服装图像领子和袖子的地标标注。在此数据集和真实世界的样本大量的实验表明，我们的方法可以合成比国家的最先进的方法，定量和定性的比较更好的结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. Subjective Annotation for a Frame Interpolation Benchmark using Artifact  Amplification</b>  <a href="https://arxiv.org/pdf/2001.06409" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Men%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hui Men</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hosu%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vlad Hosu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hanhe Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bruhn%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrés Bruhn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Saupe%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dietmar Saupe</a><br>
<font size="3">
Abstract: Current benchmarks for optical flow algorithms evaluate the estimation either directly by comparing the predicted flow fields with the ground truth or indirectly by using the predicted flow fields for frame interpolation and then comparing the interpolated frames with the actual frames. In the latter case, objective quality measures such as the mean squared error are typically employed. However, it is well known that for image quality assessment, the actual quality experienced by the user cannot be fully deduced from such simple measures. Hence, we conducted a subjective quality assessment crowdscouring study for the interpolated frames provided by one of the optical flow benchmarks, the Middlebury benchmark. It contains interpolated frames from 155 methods applied to each of 8 contents. We collected forced choice paired comparisons between interpolated images and corresponding ground truth. To increase the sensitivity of observers when judging minute difference in paired comparisons we introduced a new method to the field of full-reference quality assessment, called artifact amplification. From the crowdsourcing data we reconstructed absolute quality scale values according to Thurstone's model. As a result, we obtained a re-ranking of the 155 participating algorithms w.r.t. the visual quality of the interpolated frames. This re-ranking not only shows the necessity of visual quality assessment as another evaluation metric for optical flow and frame interpolation benchmarks, the results also provide the ground truth for designing novel image quality assessment (IQA) methods dedicated to perceptual quality of interpolated images. As a first step, we proposed such a new full-reference method, called WAE-IQA. By weighing the local differences between an interpolated image and its ground truth WAE-IQA performed slightly better than the currently best FR-IQA approach from the literature. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：用于光学流算法电流基准通过与地面实况地或间接地通过使用所预测的流场为帧内插，然后比较实际帧中的内插帧进行比较的预测的流场评价了估计直接。在后者的情况下，客观质量的措施，如均方误差，通常采用。但是，众所周知，对于图像质量评价，用户体验到的实际质量不能完全从这些简单的措施推出。因此，我们进行了由所述光流基准之一，所述明德基准提供的内插帧主观质量评估crowdscouring研究。它包含从施加到每个8项内容155点的方法的内插帧。我们收集了强制插入图片和相应的地面实况之间选择配对比较。为了增加观察员的灵敏度，当在配对比较判断分差，我们引入了一个新的方法来全参考质量评估领域，被称为神器放大。从众包数据，我们根据瑟斯顿模型重建质量绝对刻度值。其结果是，我们获得了155种参与算法的重新排名w.r.t.内插帧的视觉质量。这个重新排序不仅示出了视觉质量评估作为另一个评价度量光流和帧插值基准的必要性，该结果也提供了设计新的图像质量评价地面实况（IQA）的方法专用于内插图像的感知质量。作为第一步，我们提出了这样一个新的全参考方法，称为WAE-IQA。通过称重插入图像和地面实况WAE-IQA之间的局部差异不是从文献中目前最好的FR-IQA方法表现稍好。</font>
</div>


<hr>
<div id="paper5"> <b>5. GraphBGS: Background Subtraction via Recovery of Graph Signals</b>  <a href="https://arxiv.org/pdf/2001.06404" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Giraldo%2C+J+H" target="_blank" rel="noopener" style="color:#0000EE;">Jhony H. Giraldo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bouwmans%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thierry Bouwmans</a><br>
<font size="3">
Abstract: Graph-based algorithms have been successful approaching the problems of unsupervised and semi-supervised learning. Recently, the theory of graph signal processing and semi-supervised learning have been combined leading to new developments and insights in the field of machine learning. In this paper, concepts of recovery of graph signals and semi-supervised learning are introduced in the problem of background subtraction. We propose a new algorithm named GraphBGS, this method uses a Mask R-CNN for instances segmentation; temporal median filter for background initialization; motion, texture, color, and structural features for representing the nodes of a graph; k-nearest neighbors for the construction of the graph; and finally a semi-supervised method inspired from the theory of recovery of graph signals to solve the problem of background subtraction. The method is evaluated on the publicly available change detection, and scene background initialization databases. Experimental results show that GraphBGS outperforms unsupervised background subtraction algorithms in some challenges of the change detection dataset. And most significantly, this method outperforms generative adversarial networks in unseen videos in some sequences of the scene background initialization database. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于图的算法已经成功逼近无监督和半监督学习的问题。近日，图形信号处理和半监督学习的理论已被合并导致新的进展和见解，在机器学习领域。在本文中，图形信号及半监督学习的恢复的概念背景减除的问题进行了介绍。我们提出了一种新的算法命名GraphBGS，这种方法使用面膜R-CNN的情况下，分割;时间中值滤波器，用于背景初始化;运动，纹理，颜色和用于表示图中的节点的结构特征; k最近的图的构造的邻居;最后一个半监督方法从图信号的恢复的理论启发解决背景减除的问题。该方法在可公开获得的变化检测评价，并现场后台初始化数据库。实验结果表明，在变化检测数据集的一些挑战GraphBGS性能优于无人监督的背景减除算法。而最显著，这种方法优于在场景后台初始化数据库的一些序列看不见的视频生成对抗性的网络。</font>
</div>


<hr>
<div id="paper6"> <b>6. Latency-Aware Differentiable Neural Architecture Search</b>  <a href="https://arxiv.org/pdf/2001.06392" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuhui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xie%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lingxi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaopeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bowen Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qi Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xiong%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongkai Xiong</a><br>
<font size="3">
Abstract: Differentiable neural architecture search methods became popular in automated machine learning, mainly due to their low search costs and flexibility in designing the search space. However, these methods suffer the difficulty in optimizing network, so that the searched network is often unfriendly to hardware. This paper deals with this problem by adding a differentiable latency loss term into optimization, so that the search process can tradeoff between accuracy and latency with a balancing coefficient. The core of latency prediction is to encode each network architecture and feed it into a multi-layer regressor, with the training data being collected from randomly sampling a number of architectures and evaluating them on the hardware. We evaluate our approach on NVIDIA Tesla-P100 GPUs. With 100K sampled architectures (requiring a few hours), the latency prediction module arrives at a relative error of lower than 10\%. Equipped with this module, the search method can reduce the latency by 20% meanwhile preserving the accuracy. Our approach also enjoys the ability of being transplanted to a wide range of hardware platforms with very few efforts, or being used to optimizing other non-differentiable factors such as power consumption. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：微的神经结构的搜索方法成为自动化机器学习流行，主要是由于其较低的搜寻成本和设计的搜索空间的灵活性。然而，这些方法在遭受网络优化的难度，使网络搜索往往是不友好的硬件。这与这个问题论文涉及通过添加微延迟损失项为优化，使之与平衡系数精度和延迟之间的搜索过程可以权衡。延迟预测的核心是编码每个网络结构和它送入多层回归，与从随机抽样的数架构和硬件评估他们被收集训练数据。我们评估我们对NVIDIA的Tesla-P100 GPU的方法。用100K采样架构（需要几个小时），等待时间预测模块到达的低于10 \％的相对误差。配备该模块，搜索方法可以通过20％的同时保持准确度降低延迟。我们的方法也享有被移植到了广泛的硬件平台用很少的努力，或者被用来优化其它非微因素，例如功耗的能力。</font>
</div>


<hr>
<div id="paper7"> <b>7. BigEarthNet Deep Learning Models with A New Class-Nomenclature for  Remote Sensing Image Understanding</b>  <a href="https://arxiv.org/pdf/2001.06372" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Sumbul%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gencer Sumbul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kreuziger%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tristan Kreuziger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marcelino%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Filipe Marcelino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Costa%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hugo Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Benevides%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pedro Benevides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Caetano%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mario Caetano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Demir%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Begüm Demir</a><br>
<font size="3">
Abstract: Success of deep neural networks in the framework of remote sensing (RS) image analysis depends on the availability of a high number of annotated images. BigEarthNet is a new large-scale Sentinel-2 benchmark archive that has been recently introduced in RS to advance deep learning (DL) studies. Each image patch in BigEarthNet is annotated with multi-labels provided by the CORINE Land Cover (CLC) map of 2018 based on its most thematic detailed Level-3 class nomenclature. BigEarthNet has enabled data-hungry DL algorithms to reach high performance in the context of multi-label RS image retrieval and classification. However, initial research demonstrates that some CLC classes are challenging to be accurately described by considering only (single-date) Sentinel-2 images. To further increase the effectiveness of BigEarthNet, in this paper we introduce an alternative class-nomenclature to allow DL models for better learning and describing the complex spatial and spectral information content of the Sentinel-2 images. This is achieved by interpreting and arranging the CLC Level-3 nomenclature based on the properties of Sentinel-2 images in a new nomenclature of 19 classes. Then, the new class-nomenclature of BigEarthNet is used within state-of-the-art DL models (namely VGG model at the depth of 16 and 19 layers [VGG16 and VGG19] and ResNet model at the depth of 50, 101 and 152 layers [ResNet50, ResNet101, ResNet152] as well as K-Branch CNN model) in the context of multi-label classification. Experimental results show that the models trained from scratch on BigEarthNet outperform those pre-trained on ImageNet, especially in relation to some complex classes including agriculture and other vegetated and natural environments. All DL models are made publicly available, offering an important resource to guide future progress on content based image retrieval and scene classification problems in RS. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：遥感（RS）图像分析的框架深神经网络的成功取决于大量的注释的图像的可用性。 BigEarthNet是已在RS最近推出深处前进学习（DL）研究提供了新的大型哨兵-2基准存档。在BigEarthNet每个图像补丁标注有基于其最详细的专题级别3级命名的2018年CORINE土地覆盖（CLC）地图提供多标签。 BigEarthNet已使大量数据的DL算法，以达到多标签遥感影像检索和分类的情况下的高性能。然而，最初的研究表明，一些CLC类是具有挑战性的通过仅考虑（单日期）被精确地描述的Sentinel-2的图像。为了进一步提高BigEarthNet的有效性，本文介绍一种替代类的术语来允许DL模型更好的学习和描述哨兵2图像的复杂的空间和光谱信息的内容。这是通过解释和布置基于哨兵-2图像的在19类的新命名法的属性CLC 3级命名法来实现的。然后，BigEarthNet的新的类命名法是国家的最先进的DL模型（即VGG模型内以16层19的层[VGG16和VGG19]和RESNET模型的深度使用在50，101和152的深度层[ResNet50，ResNet101，ResNet152]以及K-科CNN模型）在多标签分类的上下文。实验结果表明，从头开始培训了BigEarthNet跑赢车型的预先训练上ImageNet，特别是涉及到一些复杂的类，包括农业和其他植被和自然环境。所有DL型号都公之于众，提供指导在RS基于内容的图像检索及场景分类问题未来发展的重要资源。</font>
</div>


<hr>
<div id="paper8"> <b>8. Efficient Facial Feature Learning with Wide Ensemble-based Convolutional  Neural Networks</b>  <a href="https://arxiv.org/pdf/2001.06338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Siqueira%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Henrique Siqueira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Magg%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sven Magg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wermter%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stefan Wermter</a><br>
<font size="3">
Abstract: Ensemble methods, traditionally built with independently trained de-correlated models, have proven to be efficient methods for reducing the remaining residual generalization error, which results in robust and accurate methods for real-world applications. In the context of deep learning, however, training an ensemble of deep networks is costly and generates high redundancy which is inefficient. In this paper, we present experiments on Ensembles with Shared Representations (ESRs) based on convolutional networks to demonstrate, quantitatively and qualitatively, their data processing efficiency and scalability to large-scale datasets of facial expressions. We show that redundancy and computational load can be dramatically reduced by varying the branching level of the ESR without loss of diversity and generalization power, which are both important for ensemble performance. Experiments on large-scale datasets suggest that ESRs reduce the remaining residual generalization error on the AffectNet and FER+ datasets, reach human-level performance, and outperform state-of-the-art methods on facial expression recognition in the wild using emotion and affect concepts. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：集成方法，传统上与​​独立的培训去相关模型构建，已被证明是减少残留的剩余泛化误差，有效的方法，这导致对现实世界的应用健全和准确的方法。在深学习的情况下，然而，培养深网络的集合是昂贵的，并且产生高冗余这是低效的。在本文中，我们对合奏基于卷积网络证明，定量和定性地共享交涉（的ESR）本实验中，它们的数据处理效率和可扩展性的面部表情的大规模数据集。我们发现可以通过改变ESR的无分集和概括断电分支水平，这既是对合奏表演重要的急剧减少了冗余和计算负载。在大型数据集的实验表明，的ESR减少对AffectNet和FER +数据集，达到人类水平的性能，以及使用情感上的野生面部表情识别跑赢大市的国家的最先进的方法，直接影响概念的剩余的残留泛化的错误。</font>
</div>


<hr>
<div id="paper9"> <b>9. Vision Meets Drones: Past, Present and Future</b>  <a href="https://arxiv.org/pdf/2001.06303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pengfei Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wen%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Longyin Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Du%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dawei Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bian%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiao Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinghua Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ling%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haibin Ling</a><br>
<font size="3">
Abstract: Drones, or general UAVs, equipped with cameras have been fast deployed with a wide range of applications, including agriculture, aerial photography, fast delivery, and surveillance. Consequently, automatic understanding of visual data collected from drones becomes highly demanding, bringing computer vision and drones more and more closely. To promote and track the developments of object detection and tracking algorithms, we have organized two challenge workshops in conjunction with European Conference on Computer Vision (ECCV) 2018, and IEEE International Conference on Computer Vision (ICCV) 2019, attracting more than 100 teams around the world. We provide a large-scale drone captured dataset, VisDrone, which includes four tracks, i.e., (1) image object detection, (2) video object detection, (3) single object tracking, and (4) multi-object tracking. This paper first presents a thorough review of object detection and tracking datasets and benchmarks, and discuss the challenges of collecting large-scale drone-based object detection and tracking datasets with fully manual annotations. After that, we describe our VisDrone dataset, which is captured over various urban/suburban areas of $14$ different cities across China from North to South. Being the largest such dataset ever published, VisDrone enables extensive evaluation and investigation of visual analysis algorithms on the drone platform. We provide a detailed analysis of the current state of the field of large-scale object detection and tracking on drones, and conclude the challenge as well as propose future directions and improvements. We expect the benchmark largely boost the research and development in video analysis on drone platforms. All the datasets and experimental results can be downloaded from the website: this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：无人机或者一般的无人机，配备摄像头已经迅速部署具有广泛的应用，包括农业，航空摄影，交货快，和监视。因此，从无人机采集的视频数据的自动理解变得极高，将计算机视觉和无人驾驶飞机越来越紧密。为了促进和跟踪目标检测与跟踪算法的发展，我们已经组织了一起2次挑战研讨会，欧洲会议计算机视觉（ECCV）2018，以及计算机视觉（ICCV）2019 IEEE国际会议，吸引了100多个团队世界。我们提供了一个大型雄蜂捕获数据集，VisDrone，它包括四个磁道，即，（1）图像对象检测，（2）视频对象检测，（3）单目标跟踪，和（4）的多目标跟踪。本文首先介绍目标检测与跟踪数据集和基准进行彻底审查，并讨论收集大型无人机基于体检测，并与全手动注释跟踪数据集的挑战。在那之后，我们描述了我们VisDrone数据集，这是超过$ $ 14在中国不同的城市，从南到北各个城市/郊区抓获。作为最大的此类数据集出版过的，VisDrone使广泛的评估和无人机平台上的视觉分析算法调查。我们提供大型物体检测和跟踪在无人机领域的现状进行了详细分析，并得出结论以及提出未来的发展方向和改进的挑战。我们预计恒生很大程度上提高对无人机平台在视频分析的研究和开发。此HTTPS URL：所有数据集和实验结果可以从网站上下载。</font>
</div>


<hr>
<div id="paper10"> <b>10. Predicting the Physical Dynamics of Unseen 3D Objects</b>  <a href="https://arxiv.org/pdf/2001.06291" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Rempe%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davis Rempe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sridhar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Srinath Sridhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">He Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guibas%2C+L+J" target="_blank" rel="noopener" style="color:#0000EE;">Leonidas J. Guibas</a><br>
<font size="3">
Abstract: Machines that can predict the effect of physical interactions on the dynamics of previously unseen object instances are important for creating better robots and interactive virtual worlds. In this work, we focus on predicting the dynamics of 3D objects on a plane that have just been subjected to an impulsive force. In particular, we predict the changes in state - 3D position, rotation, velocities, and stability. Different from previous work, our approach can generalize dynamics predictions to object shapes and initial conditions that were unseen during training. Our method takes the 3D object's shape as a point cloud and its initial linear and angular velocities as input. We extract shape features and use a recurrent neural network to predict the full change in state at each time step. Our model can support training with data from both a physics engine or the real world. Experiments show that we can accurately predict the changes in state for unseen object geometries and initial conditions. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机器，可以预测在以前看不见的对象实例的动态物理相互作用的作用是创造更好的机器人和互动的虚拟世界重要。在这项工作中，我们侧重于预测对刚刚经受冲击力的平面3D对象的动态。特别是，我们预测状态的变化 - 三维位置，旋转，速度和稳定性。从以前的工作不同的是，我们的方法可以概括的动态预测到物体的形状和初始条件的培训过程中看不见。我们的方法利用该3D对象的形状为点云和它的初始线速度和角速度作为输入。我们提取形状特征和使用回归神经网络在每个时间步来预测状态充满变化。我们的模型可以支持从两个物理引擎或现实世界的数据训练。实验结果表明，我们可以精确地预测为看不见的对象的几何形状和初始条件状态中的变化。</font>
</div>


<hr>
<div id="paper11"> <b>11. Review: deep learning on 3D point clouds</b>  <a href="https://arxiv.org/pdf/2001.06280" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bello%2C+S+A" target="_blank" rel="noopener" style="color:#0000EE;">Saifullahi Aminu Bello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shangshu Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cheng Wang</a><br>
<font size="3">
Abstract: Point cloud is point sets defined in 3D metric space. Point cloud has become one of the most significant data format for 3D representation. Its gaining increased popularity as a result of increased availability of acquisition devices, such as LiDAR, as well as increased application in areas such as robotics, autonomous driving, augmented and virtual reality. Deep learning is now the most powerful tool for data processing in computer vision, becoming the most preferred technique for tasks such as classification, segmentation, and detection. While deep learning techniques are mainly applied to data with a structured grid, point cloud, on the other hand, is unstructured. The unstructuredness of point clouds makes use of deep learning for its processing directly very challenging. Earlier approaches overcome this challenge by preprocessing the point cloud into a structured grid format at the cost of increased computational cost or lost of depth information. Recently, however, many state-of-the-arts deep learning techniques that directly operate on point cloud are being developed. This paper contains a survey of the recent state-of-the-art deep learning techniques that mainly focused on point cloud data. We first briefly discussed the major challenges faced when using deep learning directly on point cloud, we also briefly discussed earlier approaches which overcome the challenges by preprocessing the point cloud into a structured grid. We then give the review of the various state-of-the-art deep learning approaches that directly process point cloud in its unstructured form. We introduced the popular 3D point cloud benchmark datasets. And we also further discussed the application of deep learning in popular 3D vision tasks including classification, segmentation and detection. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：点云是3D度量空间定义的点集。点云已成为3D表示最显著数据格式之一。它获得越来越多的受欢迎程度增加采集设备，如激光雷达的可用性，以及在诸如机器人，自动驾驶等领域加强应用，增强和虚拟现实的结果。现在深学习是数据在计算机视觉处理的最有力的工具，成为任务，如分类，细分和检测的最优选的技术。虽然深学习技术主要应用于数据与结构化网格，点云，在另一方面，是非结构化的。该unstructuredness点云的利用深度学习的其直接处理非常具有挑战性。早期的方法通过预处理点云成结构化的网格格式以增加计算成本的成本或丢失的深度信息克服这一挑战。然而，最近深学习直接对点云操作的技术的许多艺术国家的正在开发中。本文件包含了一个调查国家的最先进的深得知主要集中在点云数据的技术，最近的。我们首先简要讨论了使用深直接在点云学习时所面临的重大挑战，我们还简要讨论克服通过预处理点云成结构化网格的挑战，早期的方法。然后，我们给国家的最先进的各种深学习的复习方法直接处理点云中的非结构化的形式。我们引进了当前流行的三维点云标准数据集。我们还进一步讨论在流行的3D视觉任务，包括分类，分割和检测深度学习的应用。</font>
</div>


<hr>
<div id="paper12"> <b>12. Compounding the Performance Improvements of Assembled Techniques in a  Convolutional Neural Network</b>  <a href="https://arxiv.org/pdf/2001.06268" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jungkyu Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Won%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taeryun Won</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hong%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kiho Hong</a><br>
<font size="3">
Abstract: Recent studies in image classification have demonstrated a variety of techniques for improving the performance of Convolutional Neural Networks (CNNs). However, attempts to combine existing techniques to create a practical model are still uncommon. In this study, we carry out extensive experiments to validate that carefully assembling these techniques and applying them to a basic CNN model in combination can improve the accuracy and robustness of the model while minimizing the loss of throughput. For example, our proposed ResNet-50 shows an improvement in top-1 accuracy from 76.3% to 82.78%, and an mCE improvement from 76.0% to 48.9%, on the ImageNet ILSVRC2012 validation set. With these improvements, inference throughput only decreases from 536 to 312. The resulting model significantly outperforms state-of-the-art models with similar accuracy in terms of mCE and inference throughput. To verify the performance improvement in transfer learning, fine grained classification and image retrieval tasks were tested on several open datasets and showed that the improvement to backbone network performance boosted transfer learning performance significantly. Our approach achieved 1st place in the iFood Competition Fine-Grained Visual Recognition at CVPR 2019, and the source code and trained models are available at this https URL </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在图像分类最近的研究表明多种用于改善卷积神经网络（细胞神经网络）的表现技法。不过，对现有技术结合起来，创造一个实际的模型仍屡见不鲜。在这项研究中，我们进行了广泛的实验，以验证仔细组装这些技术并将它们应用到结合的基本模式CNN能提高模型的精确度和耐用性，同时最大限度地减少产量损失。例如，我们所提出的RESNET-50示出了在顶部-1精度的提高，从76.3％到82.78％，和从76.0％的MCE改善48.9％，对ImageNet ILSVRC2012验证集。有了这些改进，推理可以通过仅降低从536到312得到的模型显著优于状态的最先进的模型具有类似的精度在MCE和推理吞吐量方面。为了验证迁移学习，细粒分类和图像检索任务的性能改进上几个开放的数据集进行了测试，结果表明，提高骨干网络的性能提升传输学习表现显著。我们的方法在iFood比赛细粒度的视觉识别在CVPR 2019获得第一名，源代码和训练的模型可在此HTTPS URL</font>
</div>


<hr>
<div id="paper13"> <b>13. SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On</b>  <a href="https://arxiv.org/pdf/2001.06265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Jandial%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Surgan Jandial</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chopra%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ayush Chopra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ayush%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kumar Ayush</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hemani%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mayur Hemani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Abhijeet Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Krishnamurthy%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Balaji Krishnamurthy</a><br>
<font size="3">
Abstract: Image-based virtual try-on for fashion has gained considerable attention recently. The task requires trying on a clothing item on a target model image. An efficient framework for this is composed of two stages: (1) warping (transforming) the try-on cloth to align with the pose and shape of the target model, and (2) a texture transfer module to seamlessly integrate the warped try-on cloth onto the target model image. Existing methods suffer from artifacts and distortions in their try-on output. In this work, we present SieveNet, a framework for robust image-based virtual try-on. Firstly, we introduce a multi-stage coarse-to-fine warping network to better model fine-grained intricacies (while transforming the try-on cloth) and train it with a novel perceptual geometric matching loss. Next, we introduce a try-on cloth conditioned segmentation mask prior to improve the texture transfer network. Finally, we also introduce a dueling triplet loss strategy for training the texture translation network which further improves the quality of the generated try-on results. We present extensive qualitative and quantitative evaluations of each component of the proposed pipeline and show significant performance improvements against the current state-of-the-art method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于映像的虚拟试穿时装最近获得了相当大的关注。任务需要试穿的目标模型图像上的衣物。这种高效的框架由两个阶段组成：（1）翘曲（变换）的试穿布与目标模型的姿态和形状对齐，和（2）的纹理传送模块无缝集成翘曲试戴上布到目标模型图像。现有的方法从它们的试穿输出文物和扭曲痛苦。在这项工作中，我们提出SieveNet，对于稳健的基于图像的虚拟试穿的框架。首先，我们引入一个多级粗到细的翘曲网络，以更好地模型细粒度错综复杂（同时改造试穿布），并用新的知觉几何匹配损耗训练它。接下来，我们引入一个试穿改善质地传递网络之前布空调分割掩码。最后，我们还引进了决斗三重损失的策略训练纹理翻译网络，进一步提高了产生试穿结果的质量。我们提出了广泛的定性和建议的管道中各组分的定量评估，显示对当前国家的最先进的方法显著的性能改进。</font>
</div>


<hr>
<div id="paper14"> <b>14. Two-Phase Object-Based Deep Learning for Multi-temporal SAR Image Change  Detection</b>  <a href="https://arxiv.org/pdf/2001.06252" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinzheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Ce Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Atkinson%2C+P+M" target="_blank" rel="noopener" style="color:#0000EE;">Peter M Atkinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoheng Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jian%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Jian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xichuan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yongming Li</a><br>
<font size="3">
Abstract: Change detection is one of the fundamental applications of synthetic aperture radar (SAR) images. However, speckle noise presented in SAR images has a much negative effect on change detection. In this research, a novel two-phase object-based deep learning approach is proposed for multi-temporal SAR image change detection. Compared with traditional methods, the proposed approach brings two main innovations. One is to classify all pixels into three categories rather than two categories: unchanged pixels, changed pixels caused by strong speckle (false changes), and changed pixels formed by real terrain variation (real changes). The other is to group neighboring pixels into segmented into superpixel objects (from pixels) such as to exploit local spatial context. Two phases are designed in the methodology: 1) Generate objects based on the simple linear iterative clustering algorithm, and discriminate these objects into changed and unchanged classes using fuzzy c-means (FCM) clustering and a deep PCANet. The prediction of this Phase is the set of changed and unchanged superpixels. 2) Deep learning on the pixel sets over the changed superpixels only, obtained in the first phase, to discriminate real changes from false changes. SLIC is employed again to achieve new superpixels in the second phase. Low rank and sparse decomposition are applied to these new superpixels to suppress speckle noise significantly. A further clustering step is applied to these new superpixels via FCM. A new PCANet is then trained to classify two kinds of changed superpixels to achieve the final change maps. Numerical experiments demonstrate that, compared with benchmark methods, the proposed approach can distinguish real changes from false changes effectively with significantly reduced false alarm rates, and achieve up to 99.71% change detection accuracy using multi-temporal SAR imagery. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：变化检测是合成孔径雷达（SAR）图像的基本应用中的一个。然而，斑点的SAR图像噪声提出了变化检测更负面的影响。在这项研究中，一种新型的两相基于对象的深度学习方法提出了多时相SAR图像变化检测。与传统方法相比，该方法带来了两个主要的创新。一是所有像素分为三类，而不是两类：不变的像素，改变像素造成强烈的斑点（假的变化），并改变了像素的实际地形的变化（真正的变化）而形成。另一种是相邻像素到分割成超像素的对象（从像素），如以利用局部空间上下文组。两个相被设计成在该方法：1）基于该简单的线性迭代聚类算法的目的，并区分这些对象到使用模糊c均值（FCM）聚类和深PCANet变与不变类。这个阶段的预测是一组变与不变的超像素。 2）上的像素集在所述改变仅超像素，在第一阶段中获得的，深学习辨别从虚假变化的实际变化。 SLIC被再次用来实现第二阶段的新的超像素。低等级和稀疏分解的噪音显著应用到这些新的超像素来抑制斑点。进一步的聚类步骤被施加到通过FCM这些新的超像素。然后，新的PCANet被训练2种改变超级像素的分类，以实现最终的变化图。数值结果表明，与基准方法相比，该方法可以区分有效地降低了显著的误报率假的变化真正的变化，实现了利用多时相SAR影像99.71％的变化检测精度。</font>
</div>


<hr>
<div id="paper15"> <b>15. Registration made easy -- standalone orthopedic navigation with HoloLens</b>  <a href="https://arxiv.org/pdf/2001.06209" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liebmann%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Florentin Liebmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Roner%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Roner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=von+Atzigen%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marco von Atzigen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wanivenhaus%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Florian Wanivenhaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Neuhaus%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Caroline Neuhaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Spirig%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">José Spirig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Scaramuzza%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davide Scaramuzza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sutter%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Reto Sutter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Snedeker%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jess Snedeker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Farshad%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mazda Farshad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=F%C3%BCrnstahl%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Philipp Fürnstahl</a><br>
<font size="3">
Abstract: In surgical navigation, finding correspondence between preoperative plan and intraoperative anatomy, the so-called registration task, is imperative. One promising approach is to intraoperatively digitize anatomy and register it with the preoperative plan. State-of-the-art commercial navigation systems implement such approaches for pedicle screw placement in spinal fusion surgery. Although these systems improve surgical accuracy, they are not gold standard in clinical practice. Besides economical reasons, this may be due to their difficult integration into clinical workflows and unintuitive navigation feedback. Augmented Reality has the potential to overcome these limitations. Consequently, we propose a surgical navigation approach comprising intraoperative surface digitization for registration and intuitive holographic navigation for pedicle screw placement that runs entirely on the Microsoft HoloLens. Preliminary results from phantom experiments suggest that the method may meet clinical accuracy requirements. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在手术导航，术前计划及术中解剖，所谓的注册任务之间找到对应，势在必行。一个可行的方法是手术中数字化解剖，并与术前计划注册。国家的最先进的商用导航系统实现了对脊柱融合术椎弓根螺钉放置这些方法。虽然这些系统提高手术准确性，他们不是在临床实践中的金标准。除了经济上的原因，这可能是由于他们难以融入临床工作流程和直观的导航反馈。增强现实必须克服这些局限性的潜力。因此，我们提出了一种外科手术导航的方法，包括用于登记和直观的全息术中的导航表面的数字化椎弓根螺钉放置的是完全在Microsoft HoloLens运行。从幻像实验的初步结果表明，该方法可满足临床的精度要求。</font>
</div>


<hr>
<div id="paper16"> <b>16. FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for  Semi-supervised Optical Flow Estimation</b>  <a href="https://arxiv.org/pdf/2001.06171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaolin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cuiling Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zeng%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenjun Zeng</a><br>
<font size="3">
Abstract: Optical flow estimation is an important yet challenging problem in the field of video analytics. The features of different semantics levels/layers of a convolutional neural network can provide information of different granularity. To exploit such flexible and comprehensive information, we propose a semi-supervised Feature Pyramidal Correlation and Residual Reconstruction Network (FPCR-Net) for optical flow estimation from frame pairs. It consists of two main modules: pyramid correlation mapping and residual reconstruction. The pyramid correlation mapping module takes advantage of the multi-scale correlations of global/local patches by aggregating features of different scales to form a multi-level cost volume. The residual reconstruction module aims to reconstruct the sub-band high-frequency residuals of finer optical flow in each stage. Based on the pyramid correlation mapping, we further propose a correlation-warping-normalization (CWN) module to efficiently exploit the correlation dependency. Experiment results show that the proposed scheme achieves the state-of-the-art performance, with improvement by 0.80, 1.15 and 0.10 in terms of average end-point error (AEE) against competing baseline methods - FlowNet2, LiteFlowNet and PWC-Net on the Final pass of Sintel dataset, respectively. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：光流估计是视频分析领域的一个重要而具有挑战性的问题。不同的语义等级的特征/卷积神经网络的层可提供不同粒度的信息。为了利用这种柔性和全面的信息，我们提出了从帧双光流估计一个半监督功能锥体相关和残差重建网络（FPCR-净）。它包括两个主要模块：金字塔相关映射和残差重建。金字塔相关映射模块通过聚合不同尺度的特征，以形成多级成本体积利用全局/局部贴片的多尺度相关的。将残余的重建模块目标以重建在每个阶段中更精细的光流的子带的高频残差。基于金字塔的相关性映射，我们进一步提出的相关扭曲规范化（CWN）模块，以有效地利用的相关性依赖。实验结果表明，该方案由0.80，1.15和0.10，平均终点误差（AEE）来实现国家的最先进的性能，提高同台竞技基线方法 -  FlowNet2，LiteFlowNet和PWC-Net的上辛特尔数据集的最终道次，分别。</font>
</div>


<hr>
<div id="paper17"> <b>17. Interpreting Galaxy Deblender GAN from the Discriminator's Perspective</b>  <a href="https://arxiv.org/pdf/2001.06151" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuewei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mueller%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Klaus Mueller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Xu</a><br>
<font size="3">
Abstract: Generative adversarial networks (GANs) are well known for their unsupervised learning capabilities. A recent success in the field of astronomy is deblending two overlapping galaxy images via a branched GAN model. However, it remains a significant challenge to comprehend how the network works, which is particularly difficult for non-expert users. This research focuses on behaviors of one of the network's major components, the Discriminator, which plays a vital role but is often overlooked, Specifically, we enhance the Layer-wise Relevance Propagation (LRP) scheme to generate a heatmap-based visualization. We call this technique Polarized-LRP and it consists of two parts i.e. positive contribution heatmaps for ground truth images and negative contribution heatmaps for generated images. Using the Galaxy Zoo dataset we demonstrate that our method clearly reveals attention areas of the Discriminator when differentiating generated galaxy images from ground truth images. To connect the Discriminator's impact on the Generator, we visualize the gradual changes of the Generator across the training process. An interesting result we have achieved there is the detection of a problematic data augmentation procedure that would else have remained hidden. We find that our proposed method serves as a useful visual analytical tool for a deeper understanding of GAN models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：创成对抗网络（甘斯）是众所周知的无监督的学习能力。在天文学领域最近的成功经由支GAN模型去混合两个重叠的星系图像。然而，它仍然是一个挑战显著理解如何在网络的作品，这对非专业用户特别困难。这项研究的重点是网络的主要组成部分之一的行为，鉴别，它起着至关重要的作用，但往往被忽视，特别是，我们提高了逐层关联传播（LRP）方案来生成一个基于热图可视化。我们称这种技术偏光LRP，它由两个部分组成，即积极的贡献热图的地面真理图像和生成的图像负贡献热图。利用星系动物园的数据集，我们证明了我们的方法区分从地面实况图像生成星系图像时，清楚地表明鉴别的关注的领域。要连接鉴别对发电机的影响，我们可以形象地发电机的整个训练过程中逐渐变化。我们已经实现了有一个有趣的结果是，将其他仍然隐藏着一个问题的数据增高过程的检测。我们发现，我们提出的方法作为一个有用的可视化分析工具，GAN模式有更深的了解。</font>
</div>


<hr>
<div id="paper18"> <b>18. Learning to Augment Expressions for Few-shot Fine-grained Facial  Expression Recognition</b>  <a href="https://arxiv.org/pdf/2001.06144" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenxuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanwei Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cao%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chenjie Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zheng%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Ziqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guoqiang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yu-Gang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xue%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiangyang Xue</a><br>
<font size="3">
Abstract: Affective computing and cognitive theory are widely used in modern human-computer interaction scenarios. Human faces, as the most prominent and easily accessible features, have attracted great attention from researchers. Since humans have rich emotions and developed musculature, there exist a lot of fine-grained expressions in real-world applications. However, it is extremely time-consuming to collect and annotate a large number of facial images, of which may even require psychologists to correctly categorize them. To the best of our knowledge, the existing expression datasets are only limited to several basic facial expressions, which are not sufficient to support our ambitions in developing successful human-computer interaction systems. To this end, a novel Fine-grained Facial Expression Database - F2ED is contributed in this paper, and it includes more than 200k images with 54 facial expressions from 119 persons. Considering the phenomenon of uneven data distribution and lack of samples is common in real-world scenarios, we further evaluate several tasks of few-shot expression learning by virtue of our F2ED, which are to recognize the facial expressions given only few training instances. These tasks mimic human performance to learn robust and general representation from few examples. To address such few-shot tasks, we propose a unified task-driven framework Compositional Generative Adversarial Network (Comp-GAN) learning to synthesize facial images and thus augmenting the instances of few-shot expression classes. Extensive experiments are conducted on F2ED and existing facial expression datasets, i.e., JAFFE and FER2013, to validate the efficacy of our F2ED in pre-training facial expression recognition network and the effectiveness of our proposed approach Comp-GAN to improve the performance of few-shot recognition tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：情感计算和认知理论被广泛应用于现代的人机交互场景。人脸，作为最突出和方便的特点，从研究者的高度关注。由于人类具有丰富的情感和发达的肌肉，还存在很多现实世界的应用细粒度的表情。然而，这是非常耗时的收集和注释了大量面部图像，这甚至可能需要心理学家正确分类。据我们所知，现有的表达数据仅限于几个基本的面部表情，这是不足以支持我们的野心开发成功的人机交互系统。为此，一种新的细粒度面部表情数据库 -  F2ED在本文提供的，它包括超过200K的图像与来自119分的人54个的面部表情。考虑不均匀分布数据的现象，缺乏样品是现实世界的情景一样，我们还凭借我们F2ED，这是认识到只给出几个训练实例面部表情的评价几拍表达式学习的几个任务。这些任务模拟人类的表现从几个例子学习强大和一般的表示。为了解决这样的一些次任务，我们提出了一个统一的任务驱动的框架组成剖成对抗性网络（压缩 -  GAN）学习合成面部图像，从而增强几炮表达类的实例。大量的实验是在F2ED和现有的面部表情的数据集，即JAFFE和FER2013进行，以验证我们F2ED的功效在训练前的面部表情识别网络和我们提出的方法比较-GaN的有效性，提高few-性能镜头识别任务。</font>
</div>


<hr>
<div id="paper19"> <b>19. Spatio-Temporal Ranked-Attention Networks for Video Captioning</b>  <a href="https://arxiv.org/pdf/2001.06127" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cherian%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anoop Cherian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hori%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chiori Hori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marks%2C+T+K" target="_blank" rel="noopener" style="color:#0000EE;">Tim K. Marks</a><br>
<font size="3">
Abstract: Generating video descriptions automatically is a challenging task that involves a complex interplay between spatio-temporal visual features and language models. Given that videos consist of spatial (frame-level) features and their temporal evolutions, an effective captioning model should be able to attend to these different cues selectively. To this end, we propose a Spatio-Temporal and Temporo-Spatial (STaTS) attention model which, conditioned on the language state, hierarchically combines spatial and temporal attention to videos in two different orders: (i) a spatio-temporal (ST) sub-model, which first attends to regions that have temporal evolution, then temporally pools the features from these regions; and (ii) a temporo-spatial (TS) sub-model, which first decides a single frame to attend to, then applies spatial attention within that frame. We propose a novel LSTM-based temporal ranking function, which we call ranked attention, for the ST model to capture action dynamics. Our entire framework is trained end-to-end. We provide experiments on two benchmark datasets: MSVD and MSR-VTT. Our results demonstrate the synergy between the ST and TS modules, outperforming recent state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：生成视频描述自动是一个具有挑战性的任务，涉及到时空视觉特征和语言模型之间的复杂的相互作用。鉴于影片由空间（帧级）的功能及其时间的演化，有效的字幕模型应该能够参加到这些不同的线索选择性。为此，我们提出了时空和时间空间（STATS）注意模型，该模型，条件上的语言状态，分层结合的空间和时间关注到视频中两个不同的顺序：（I）的时空（ST）子模型，该第一照顾到具有时间演变，区域然后在时间上从池这些区域的特征;和（ii）一个时间空间（TS）的子模型，该模型首先决定单个帧出席，然后应用于的帧内的空间的关注。我们提出了一个新的基于LSTM-时间排序功能，我们称之为排名的重视，对于ST模型捕捉行动力度。我们的整个框架的培训结束到终端。我们提供了两个标准数据集实验：MSVD和MSR-VTT。我们的结果证明了ST和TS模块之间的协同作用，优于国家的最先进的最近的方法。</font>
</div>


<hr>
<div id="paper20"> <b>20. Automatic Discovery of Political Meme Genres with Diverse Appearances</b>  <a href="https://arxiv.org/pdf/2001.06122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Theisen%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">William Theisen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Brogan%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Joel Brogan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Thomas%2C+P+B" target="_blank" rel="noopener" style="color:#0000EE;">Pamela Bilo Thomas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moreira%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daniel Moreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Phoa%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pascal Phoa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weninger%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tim Weninger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Scheirer%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Walter Scheirer</a><br>
<font size="3">
Abstract: Forms of human communication are not static --- we expect some evolution in the way information is conveyed over time because of advances in technology. One example of this phenomenon is the image-based meme, which has emerged as a dominant form of political messaging in the past decade. While originally used to spread jokes on social media, memes are now having an outsized impact on public perception of world events. A significant challenge in automatic meme analysis has been the development of a strategy to match memes from within a single genre when the appearances of the images vary. Such variation is especially common in memes exhibiting mimicry. For example, when voters perform a common hand gesture to signal their support for a candidate. In this paper we introduce a scalable automated visual recognition pipeline for discovering political meme genres of diverse appearance. This pipeline can ingest meme images from a social network, apply computer vision-based techniques to extract local features and index new images into a database, and then organize the memes into related genres. To validate this approach, we perform a large case study on the 2019 Indonesian Presidential Election using a new dataset of over two million images collected from Twitter and Instagram. Results show that this approach can discover new meme genres with visually diverse images that share common stylistic elements, paving the way forward for further work in semantic analysis and content attribution. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人类的沟通方式不是一成不变的---我们期待的方式获取信息的一些变化传送随着时间的推移，因为技术的进步。这种现象的一个例子是基于图像的米姆，这已经成为过去十年政治信息的主要形式。虽然原本是用来传播的笑话在社会化媒体，模因现在不得不对世界事件的公众认知的丰厚影响。在自动梅梅分析的显著挑战是一项战略，从单一的体裁内匹配模因时图像的外观变化的发展。这种变化是中模仿记因尤其常见。例如，当执行选民一个共同的手势的信号其用于候选的支持。在本文中，我们介绍了用于发现不同外观的政治米姆流派一个可扩展的自动化视觉识别管道。这条管道可以从社交网络梅梅摄取图像，应用计算机基于视觉的技术来提取局部特征和指数新的图像到一个数据库，然后整理成模因相关流派。为了验证这种方法，我们使用从Twitter和Instagram的收集超过两百万图像的新的数据集上的2019印尼总统选举的一个大案例。结果表明，该方法可以发现新的米姆风格与有着共同的风格元素在视觉上不同的图像，铺平了道路前进为语义分析和内容属性的进一步工作。</font>
</div>


<hr>
<div id="paper21"> <b>21. On- Device Information Extraction from Screenshots in form of tags</b>  <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sumit Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manoj Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Debi Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Changmai%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benu Changmai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a><br>
<font size="3">
Abstract: We propose a method to make mobile screenshots easily searchable. In this paper, we present the workflow in which we: 1) preprocessed a collection of screenshots, 2) identified script presentin image, 3) extracted unstructured text from images, 4) identifiedlanguage of the extracted text, 5) extracted keywords from the text, 6) identified tags based on image features, 7) expanded tag set by identifying related keywords, 8) inserted image tags with relevant images after ranking and indexed them to make it searchable on device. We made the pipeline which supports multiple languages and executed it on-device, which addressed privacy concerns. We developed novel architectures for components in the pipeline, optimized performance and memory for on-device computation. We observed from experimentation that the solution developed can reduce overall user effort and improve end user experience while searching, whose results are published. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们建议让移动截图易于搜索的方法。在本文中，我们提出我们在其中工作流：1）预处理截图的集合，2）识别的脚本presentin图像，3）提取从图像非结构化文本，4）提取的文本的identifiedlanguage，5）提取的关键词从文本，6）的基础上的图像特征识别的标签，7）膨胀通过识别相关的关键字标签集，8）与相关图像插入的图像标签的排名后和索引他们，使其可检索在设备上。我们做了哪些支持多种语言流水线开始执行它的设备，其中涉及隐私问题。我们开发新的架构在管线，优化的性能和内存设备上的计算组件。我们从实验观察到，解决方案开发可降低整体用户的努力和改善最终用户体验，同时搜索，其结果公布。</font>
</div>


<hr>
<div id="paper22"> <b>22. Tracking of Micro Unmanned Aerial Vehicles: A Comparative Study</b>  <a href="https://arxiv.org/pdf/2001.06066" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title22" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=G%C3%B6k%C3%A7e%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fatih Gökçe</a><br>
<font size="3">
Abstract: Micro unmanned aerial vehicles (mUAV) became very common in recent years. As a result of their widespread usage, when they are flown by hobbyists illegally, crucial risks are imposed and such mUAVs need to be sensed by security systems. Furthermore, the sensing of mUAVs are essential for also swarm robotics research where the individuals in a flock of robots require systems to sense and localize each other for coordinated operation. In order to obtain such systems, there are studies to detect mUAVs utilizing different sensing mediums, such as vision, infrared and sound signals, and small-scale radars. However, there are still challenges that awaits to be handled in this field such as integrating tracking approaches to the vision-based detection systems to enhance accuracy and computational complexity. For this reason, in this study, we combine various tracking approaches to a vision-based mUAV detection system available in the literature, in order to evaluate different tracking approaches in terms of accuracy and as well as investigate the effect of such integration to the computational cost. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：微型无人机（mUAV）在最近几年变得很普遍。由于其广泛使用的结果，当他们被非法爱好者飞行，关键的风险强加的，这样mUAVs需要通过安全系统进行检测。此外，还群机器人研究其中机器人的羊群个人要求系统意识和本地化相互协调运行mUAVs的检测是必不可少的。为了得到这样的系统，也有研究，以检测使用不同的感测介质，如视觉，红外线和声音信号，以及小规模雷达mUAVs。然而，仍然有挑战等待着在这一领域，如集成的跟踪方法，以基于视觉的检测系统，以提高精度和计算复杂性进行处理。为此，在本研究中，我们结合各种跟踪方法，以文献中的基于视觉的mUAV检测系统，以评估不同的跟踪方法在准确性方面和以及调查这种整合的计算效果成本。</font>
</div>


<hr>
<div id="paper23"> <b>23. Increasing the robustness of DNNs against image corruptions by playing  the Game of Noise</b>  <a href="https://arxiv.org/pdf/2001.06057" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title23" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Rusak%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Evgenia Rusak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schott%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lukas Schott</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zimmermann%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roland Zimmermann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bitterwolf%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julian Bitterwolf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bringmann%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">Oliver Bringmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bethge%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matthias Bethge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Brendel%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wieland Brendel</a><br>
<font size="3">
Abstract: The human visual system is remarkably robust against a wide range of naturally occurring variations and corruptions like rain or snow. In contrast, the performance of modern image recognition models strongly degrades when evaluated on previously unseen corruptions. Here, we demonstrate that a simple but properly tuned training with additive Gaussian and Speckle noise generalizes surprisingly well to unseen corruptions, easily reaching the previous state of the art on the corruption benchmark ImageNet-C (with ResNet50) and on MNIST-C. We build on top of these strong baseline results and show that an adversarial training of the recognition model against uncorrelated worst-case noise distributions leads to an additional increase in performance. This regularization can be combined with previously proposed defense methods for further improvement. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人类视觉系统对宽范围的天然存在的变型和损坏等雨或雪非常健壮。相比之下，现代的图像识别模型的性能上前所未见的损坏进行评估时，强烈地下降。在这里，我们证明了一个简单的，但适当调整训练加性高斯和斑点噪声推广出奇地好于看不见的腐败，很容易达到艺术的腐败基准ImageNet-C（含ResNet50）对以前的状态和MNIST-C。我们依靠这些强大的基准结果的顶部，并表明对不相关的最坏情况下的噪声分布引线识别模型的对抗性训练，在性能上的额外增加。这正可以进一步改进先前提出的防御方法相结合。</font>
</div>


<hr>
<div id="paper24"> <b>24. Modality-Balanced Models for Visual Dialogue</b>  <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title24" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hyounghun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：可视对话任务需要一个模型，同时利用图像和会话的上下文信息来生成到对话的下一个响应。然而，通过人工分析，我们发现了大量的对话问题只能由看图像，而不到上下文历史上的任何访问来回答，而其他人还需要对话上下文来预测正确的答案。我们表明，由于这个原因，以往合资模式（史和图像）模式过分依赖，而且更容易记住的对话记录（例如，通过上下文信息提取的关键字或模式），而只有图象模型更加普及（因为他们无法记住或者从历史中提取的关键字），并在主要贴现归累计收益（NDCG）任务指标，它允许多个正确答案大幅更好地履行。因此，这种观察鼓励我们要明确地保持两种模式，即只有一个影像的模型和图像的历史关节模型，并结合它们的互补能力，为一个更加平衡的多模式模型。我们提出了这种整合两个模型的多种方法，通过与共享参数合奏和共识辍学融合。根据经验，我们的模型实现对视觉对话挑战2019（关于NDCG和整个指标高平衡等级3）强劲的业绩，并基本跑赢视觉对话框挑战2018的大多数指标的赢家。</font>
</div>


<hr>
<div id="paper25"> <b>25. Tethered Aerial Visual Assistance</b>  <a href="https://arxiv.org/pdf/2001.06347" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title25" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xiao%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuesu Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dufek%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jan Dufek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Murphy%2C+R+R" target="_blank" rel="noopener" style="color:#0000EE;">Robin R. Murphy</a><br>
<font size="3">
Abstract: In this paper, an autonomous tethered Unmanned Aerial Vehicle (UAV) is developed into a visual assistant in a marsupial co-robots team, collaborating with a tele-operated Unmanned Ground Vehicle (UGV) for robot operations in unstructured or confined environments. These environments pose extreme challenges to the remote tele-operator due to the lack of sufficient situational awareness, mostly caused by the unstructuredness and confinement, stationary and limited field-of-view and lack of depth perception from the robot's onboard cameras. To overcome these problems, a secondary tele-operated robot is used in current practices, who acts as a visual assistant and provides external viewpoints to overcome the perceptual limitations of the primary robot's onboard sensors. However, a second tele-operated robot requires extra manpower and teamwork demand between primary and secondary operators. The manually chosen viewpoints tend to be subjective and sub-optimal. Considering these intricacies, we develop an autonomous tethered aerial visual assistant in place of the secondary tele-operated robot and operator, to reduce human robot ratio from 2:2 to 1:2. Using a fundamental viewpoint quality theory, a formal risk reasoning framework, and a newly developed tethered motion suite, our visual assistant is able to autonomously navigate to good-quality viewpoints in a risk-aware manner through unstructured or confined spaces with a tether. The developed marsupial co-robots team could improve tele-operation efficiency in nuclear operations, bomb squad, disaster robots, and other domains with novel tasks or highly occluded environments, by reducing manpower and teamwork demand, and achieving better visual assistance quality with trustworthy risk-aware motion. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种自主拴无人机（UAV）的发展成为有袋动物共同的机器人团队视觉助理，具有远程操作的无人地面车辆（UGV），用于非结构化或狭窄的环境中机器人进行作业协作。这些环境造成由于缺乏足够的态势感知能力，主要由unstructuredness和约束，固定和有限领域的视图造成极端挑战远程远程操作，缺乏从机器人的车载摄像机的景深感知。为了克服这些问题，二次远程操作机器人在当前的实践，谁充当视觉辅助，并提供外部视点克服初级机器人的机载传感器的感知限制使用。然而，第二个远程操作机器人需要初级和次级运营商之间的额外的人力和团队需求。手动选择视点趋于主观和次优的。考虑到这些复杂性，我们开发代替二次远程操作机器人和操作员的一个自治系留空中视觉助理，从2减少人类机器人比为1:2至1:2。使用基本视点质量理论，正式的风险推理框架，和新开发的系绳运动套件，我们的视觉助手是能够通过与系绳非结构化或密闭空间自主导航至在风险意识的方式高质量的观点。所开发的有袋动物共同的机器人团队可以提高核作战远程操作效率，拆弹小组，灾难机器人，并与新的任务或非常闭塞的环境中，通过减少人力和团队协作需求，并实现更好的视觉援助质量值得信赖的风险其他领域知晓运动。</font>
</div>


<hr>
<div id="paper26"> <b>26. DeepSUM++: Non-local Deep Neural Network for Super-Resolution of  Unregistered Multitemporal Images</b>  <a href="https://arxiv.org/pdf/2001.06342" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title26" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Molini%2C+A+B" target="_blank" rel="noopener" style="color:#0000EE;">Andrea Bordone Molini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Valsesia%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Diego Valsesia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Fracastoro%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giulia Fracastoro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Magli%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Enrico Magli</a><br>
<font size="3">
Abstract: Deep learning methods for super-resolution of a remote sensing scene from multiple unregistered low-resolution images have recently gained attention thanks to a challenge proposed by the European Space Agency. This paper presents an evolution of the winner of the challenge, showing how incorporating non-local information in a convolutional neural network allows to exploit self-similar patterns that provide enhanced regularization of the super-resolution problem. Experiments on the dataset of the challenge show improved performance over the state-of-the-art, which does not exploit non-local information. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：超分辨率从多个未注册的低分辨率图像的遥感场景的深度学习方法最近获得了感谢关注欧洲航天局提出了挑战。本文介绍了挑战冠军，展示了如何在卷积神经网络将非本地信息的发展允许利用自相似的模式，提供了增强的超分辨率问题的正规化。对挑战的数据集实验表明在国家的最先进的，它并没有利用非本地信息更好的性能。</font>
</div>


<hr>
<div id="paper27"> <b>27. Detection Method Based on Automatic Visual Shape Clustering for  Pin-Missing Defect in Transmission Lines</b>  <a href="https://arxiv.org/pdf/2001.06236" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title27" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhenbing Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Qi%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongyu Qi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Qi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yincheng Qi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhang%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ke Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhai%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yongjie Zhai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhao%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenqing Zhao</a><br>
<font size="3">
Abstract: Bolts are the most numerous fasteners in transmission lines and are prone to losing their split pins. How to realize the automatic pin-missing defect detection for bolts in transmission lines so as to achieve timely and efficient trouble shooting is a difficult problem and the long-term research target of power systems. In this paper, an automatic detection model called Automatic Visual Shape Clustering Network (AVSCNet) for pin-missing defect is constructed. Firstly, an unsupervised clustering method for the visual shapes of bolts is proposed and applied to construct a defect detection model which can learn the difference of visual shape. Next, three deep convolutional neural network optimization methods are used in the model: the feature enhancement, feature fusion and region feature extraction. The defect detection results are obtained by applying the regression calculation and classification to the regional features. In this paper, the object detection model of different networks is used to test the dataset of pin-missing defect constructed by the aerial images of transmission lines from multiple locations, and it is evaluated by various indicators and is fully verified. The results show that our method can achieve considerably satisfactory detection effect. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：螺栓是输电线路最众多的紧固件，而且容易失去自己的开口销。如何实现对输电线路的螺栓自动销缺失的缺陷检测，从而及时实现高效的故障排除是一个困难的问题，电力系统的长期研究目标。在本文中，一种自动检测模型称为自动视觉形状聚类网络（AVSCNet）为销缺失缺陷构造。首先，对于螺栓的视觉形状的无监督聚类方法，并应用于构建其可以学习视觉形状的差异的缺陷检测模型。接下来，在模型中使用了三个深卷积神经网络优化方法：增强功能，特征融合和区域特征提取。缺陷检测结果通过将回归计算和分类区域特征获得。在本文中，不同网络的物体检测模型用于测试的通过的从多个位置传输线架空图像构建销缺失缺陷的数据集，并且它是由各种指示器评估并且被充分验证。结果表明，我们的方法可以达到相当满意的检测效果。</font>
</div>


<hr>
<div id="paper28"> <b>28. Sideways: Depth-Parallel Training of Video Models</b>  <a href="https://arxiv.org/pdf/2001.06232" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title28" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Malinowski%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mateusz Malinowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Swirszcz%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Grzegorz Swirszcz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Carreira%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Joao Carreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Patraucean%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Viorica Patraucean</a><br>
<font size="3">
Abstract: We propose Sideways, an approximate backpropagation scheme for training video models. In standard backpropagation, the gradients and activations at every computation step through the model are temporally synchronized. The forward activations need to be stored until the backward pass is executed, preventing inter-layer (depth) parallelization. However, can we leverage smooth, redundant input streams such as videos to develop a more efficient training scheme? Here, we explore an alternative to backpropagation; we overwrite network activations whenever new ones, i.e., from new frames, become available. Such a more gradual accumulation of information from both passes breaks the precise correspondence between gradients and activations, leading to theoretically more noisy weight updates. Counter-intuitively, we show that Sideways training of deep convolutional video networks not only still converges, but can also potentially exhibit better generalization compared to standard synchronized backpropagation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出侧身，培训视频机型的大致反向传播方案。在标准反向传播，在通过所述模型中的每个计算步骤中的梯度和激活在时间上同步。正向激活需要被存储，直到执行向后通，从而防止层间（深度）并行化。然而，我们可以利用平滑，冗余输入流，如视频，开发更有效的培训计划？在这里，我们探索反向传播的替代;我们覆盖的网络激活，每当新的，即由新的框架，变得可用。这样的来自两个信息更渐进累积通断梯度和激活之间的确切的对应，从而导致理论上更嘈杂重量的更新。与直觉相反，我们表明，与标准同步反向传播侧身培训深卷积视频网络不仅仍然收敛的，但也有可能表现出较好的泛化。</font>
</div>


<hr>
<div id="paper29"> <b>29. FedVision: An Online Visual Object Detection Platform Powered by  Federated Learning</b>  <a href="https://arxiv.org/pdf/2001.06202" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title29" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anbu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luo%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">He Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youzhi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuanyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Feng%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lican Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tianjian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Yang</a><br>
<font size="3">
Abstract: Visual object detection is a computer vision-based artificial intelligence (AI) technique which has many practical applications (e.g., fire hazard monitoring). However, due to privacy concerns and the high cost of transmitting video data, it is highly challenging to build object detection models on centrally stored large training datasets following the current approach. Federated learning (FL) is a promising approach to resolve this challenge. Nevertheless, there currently lacks an easy to use tool to enable computer vision application developers who are not experts in federated learning to conveniently leverage this technology and apply it in their systems. In this paper, we report FedVision - a machine learning engineering platform to support the development of federated learning powered computer vision applications. The platform has been deployed through a collaboration between WeBank and Extreme Vision to help customers develop computer vision-based safety monitoring solutions in smart city applications. Over four months of usage, it has achieved significant efficiency improvement and cost reduction while removing the need to transmit sensitive data for three major corporate customers. To the best of our knowledge, this is the first real application of FL in computer vision-based tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：视觉对象检测是具有许多实际应用（例如，火灾监视）一个基于计算机视觉的人工智能（AI）技术。然而，由于隐私问题和传输视频数据的成本高，这是非常具有挑战性的集中存储大量训练数据构建物体检测模式下的电流的方法。联合学习（FL）是一种很有前途的方法来解决这一难题。尽管如此，目前缺乏一个易于使用的工具，使计算机视觉应用开发商谁是不是在联合学习专家能够方便地利用这一技术，并在他们的系统应用它。在本文中，我们报告FedVision  - 机器学习技术平台支持的联合学习动力的计算机视觉应用的开发。该平台已通过帮助客户WeBank和极端视觉之间的合作开发部署在智能城市应用基于计算机视觉的安全监控解决方案。四个多月的使用，它已经取得了显著提高效率和降低成本，同时消除需要发送的敏感数据有三个主要的企业客户。据我们所知，这是计算机基于视觉的任务FL的第一个真正的应用。</font>
</div>


<hr>
<div id="paper30"> <b>30. Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless  Approach</b>  <a href="https://arxiv.org/pdf/2001.06175" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title30" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Park%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chanoh Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moghadam%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Peyman Moghadam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Soohwan Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sridharan%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sridha Sridharan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fookes%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Clinton Fookes</a><br>
<font size="3">
Abstract: The demand for multimodal sensing systems for robotics is growing due to the increase in robustness, reliability and accuracy offered by these systems. These systems also need to be spatially and temporally co-registered to be effective. In this paper, we propose a targetless and structureless spatiotemporal camera-LiDAR calibration method. Our method combines a closed-form solution with a modified structureless bundle adjustment where the coarse-to-fine approach does not {require} an initial guess on the spatiotemporal parameters. Also, as 3D features (structure) are calculated from triangulation only, there is no need to have a calibration target or to match 2D features with the 3D point cloud which provides flexibility in the calibration process and sensor configuration. We demonstrate the accuracy and robustness of the proposed method through both simulation and real data experiments using multiple sensor payload configurations mounted to hand-held, aerial and legged robot systems. Also, qualitative results are given in the form of a colorized point cloud visualization. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：多传感系统对机器人的需求正在不断增长，由于这些系统提供的耐用性，可靠性和精确度的提高。这些系统还需要在空间和时间上处于同一注册是有效的。在本文中，我们提出了一个无标的和无结构的时空相机，激光雷达校准方法。我们的方法结合了改性无结构束调整，其中粗到细的方法不要求{}上的时空参数的初始猜测的闭合形式解。另外，作为三维特征（结构）从三角测量计算只，没有必要有一个校准目标或匹配2D与3D点云，其提供在校准过程和传感器配置的灵活性的特点。我们证明了该方法的准确度和鲁棒性通过使用多个传感器的有效载荷的配置模拟和实际数据实验安装到手持式，空中和腿式机器人系统。此外，定性的结果以彩色点云可视化的形式给出。</font>
</div>


<hr>
<div id="paper31"> <b>31. An adversarial learning framework for preserving users' anonymity in  face-based emotion recognition</b>  <a href="https://arxiv.org/pdf/2001.06103" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title31" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Narula%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vansh Narula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhangyang" target="_blank" rel="noopener" style="color:#0000EE;">Zhangyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang" target="_blank" rel="noopener" style="color:#0000EE;">Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chaspari%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Theodora Chaspari</a><br>
<font size="3">
Abstract: Image and video-capturing technologies have permeated our every-day life. Such technologies can continuously monitor individuals' expressions in real-life settings, affording us new insights into their emotional states and transitions, thus paving the way to novel well-being and healthcare applications. Yet, due to the strong privacy concerns, the use of such technologies is met with strong skepticism, since current face-based emotion recognition systems relying on deep learning techniques tend to preserve substantial information related to the identity of the user, apart from the emotion-specific information. This paper proposes an adversarial learning framework which relies on a convolutional neural network (CNN) architecture trained through an iterative procedure for minimizing identity-specific information and maximizing emotion-dependent information. The proposed approach is evaluated through emotion classification and face identification metrics, and is compared against two CNNs, one trained solely for emotion recognition and the other trained solely for face identification. Experiments are performed using the Yale Face Dataset and Japanese Female Facial Expression Database. Results indicate that the proposed approach can learn a convolutional transformation for preserving emotion recognition accuracy and degrading face identity recognition, providing a foundation toward privacy-aware emotion recognition technologies. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：图像和视频捕捉技术已经渗透到我们每一天的生活。这种技术可连续监测在现实生活中设置个人的表现，获得了我们新的见解他们的情感状态和转换，从而铺平了道路新的福祉和医疗应用。然而，由于强烈的隐私问题，使用这种技术时遭到强烈的怀疑态度，因为当前面为基础的情感识别系统依托深学习技术倾向于从情感保存有关用户的身份基本信息，除了-具体信息。本文提出了一种对抗性的学习框架，它依赖于通过最小化身份的具体信息，并最大限度地提高情绪相关的信息的迭代过程，培养了卷积神经网络（CNN）架构。所提出的方法是通过情感分类和面部识别指标评估，并针对两种细胞神经网络，另一个只卖情感识别训练和其他专为面部识别训练的比较。实验使用的是Yale人脸数据集和日本女性表情数据库进行。结果表明，该方法可以学习卷积转变为维护情感识别的准确性和有辱人格的脸身份识别情况，提供秘密感知情感识别技术奠定了基础。</font>
</div>


<hr>
<div id="paper32"> <b>32. Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for  Making a CNN Classifier Robust Against Adversarial Attacks</b>  <a href="https://arxiv.org/pdf/2001.06099" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title32" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Behnia%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Farnaz Behnia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mirzaeian%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ali Mirzaeian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sabokrou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohammad Sabokrou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Manoj%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sai Manoj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohsenin%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tinoosh Mohsenin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khasawneh%2C+K+N" target="_blank" rel="noopener" style="color:#0000EE;">Khaled N. Khasawneh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Liang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Homayoun%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Houman Homayoun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sasan%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Avesta Sasan</a><br>
<font size="3">
Abstract: In this paper, we propose Code-Bridged Classifier (CBC), a framework for making a Convolutional Neural Network (CNNs) robust against adversarial attacks without increasing or even by decreasing the overall models' computational complexity. More specifically, we propose a stacked encoder-convolutional model, in which the input image is first encoded by the encoder module of a denoising auto-encoder, and then the resulting latent representation (without being decoded) is fed to a reduced complexity CNN for image classification. We illustrate that this network not only is more robust to adversarial examples but also has a significantly lower computational complexity when compared to the prior art defenses. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们提出代码桥接分类（CBC），用于进行卷积神经网络（细胞神经网络）相对抗强大的攻击不增加，甚至通过降低整体模型的计算复杂性的框架。更具体地，我们提出了一种层叠的编码器卷积模型，其中，所述输入图像首先被去噪的自动编码器的编码器模块编码，然后将得到的潜表示（没有被解码）被馈送到降低复杂度的CNN为图像分类。我们表明，该网络不仅更加坚固，以对抗的例子，但也有显著较低的计算复杂性相比，现有技术抗辩。</font>
</div>


<hr>
<div id="paper33"> <b>33. Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised  Learning</b>  <a href="https://arxiv.org/pdf/2001.06001" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title33" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cascante-Bonilla%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Paola Cascante-Bonilla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fuwen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanjun Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ordonez%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vicente Ordonez</a><br>
<font size="3">
Abstract: Semi-supervised learning aims to take advantage of a large amount of unlabeled data to improve the accuracy of a model that only has access to a small number of labeled examples. We propose curriculum labeling, an approach that exploits pseudo-labeling for propagating labels to unlabeled samples in an iterative and self-paced fashion. This approach is surprisingly simple and effective and surpasses or is comparable with the best methods proposed in the recent literature across all the standard benchmarks for image classification. Notably, we obtain 94.91% accuracy on CIFAR-10 using only 4,000 labeled samples, and 88.56% top-5 accuracy on Imagenet-ILSVRC using 128,000 labeled samples. In contrast to prior works, our approach shows improvements even in a more realistic scenario that leverages out-of-distribution unlabeled data samples. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：半监督学习的目标采取了大量的未标记数据的优势，提高了一个模型，只获得了少量的标识样本的准确性。我们建议的课程标签，它利用伪标签用于在迭代和自学的方式传播标签的未标记样本的方法。这种方法是非常简单和有效，超过或者是在最近的文献在所有标准的基准图像分类提出的最佳方法相媲美。值得注意的是，我们使用128000个标记的样品获得关于Imagenet-ILSVRC上CIFAR-10 94.91％的准确度仅使用4000标记的样品，以及88.56％顶5的精度。相较于之前的作品，我们的做法显示了改善，即使在更现实的情况下，充分利用外的分布未标记的数据样本。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-20</title>
    <url>/2020/01/20/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-20/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> A Common Semantic Space for Monolingual and Cross-Lingual  Meta-Embeddings <a href="https://arxiv.org/pdf/2001.06381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Modality-Balanced Models for Visual Dialogue <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat  Groups <a href="https://arxiv.org/pdf/2001.06350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> RobBERT: a Dutch RoBERTa-based Language Model <a href="https://arxiv.org/pdf/2001.06286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue  System <a href="https://arxiv.org/pdf/2001.06206" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Plato Dialogue System: A Flexible Conversational AI Research Platform <a href="https://arxiv.org/pdf/2001.06463" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Supervised Speaker Embedding De-Mixing in Two-Speaker Environment <a href="https://arxiv.org/pdf/2001.06397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> On- Device Information Extraction from Screenshots in form of tags <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> User-in-the-loop Adaptive Intent Detection for Instructable Digital  Assistant <a href="https://arxiv.org/pdf/2001.06007" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. A Common Semantic Space for Monolingual and Cross-Lingual  Meta-Embeddings</b>  <a href="https://arxiv.org/pdf/2001.06381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Garc%C3%ADa%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Iker García</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agerri%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rodrigo Agerri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rigau%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">German Rigau</a><br>
<font size="3">
Abstract: This paper presents a new technique for creating monolingual and cross-lingual meta-embeddings. Our method integrates multiple word embeddings created from complementary techniques, textual sources, knowledge bases and languages. Existing word vectors are projected to a common semantic space using linear transformations and averaging. With our method the resulting meta-embeddings maintain the dimensionality of the original embeddings without losing information while dealing with the out-of-vocabulary problem. An extensive empirical evaluation demonstrates the effectiveness of our technique with respect to previous work on various intrinsic and extrinsic multilingual evaluations, obtaining competitive results for Semantic Textual Similarity and state-of-the-art performance for word similarity and POS tagging (English and Spanish). The resulting cross-lingual meta-embeddings also exhibit excellent cross-lingual transfer learning capabilities. In other words, we can leverage pre-trained source embeddings from a resource-rich language in order to improve the word representations for under-resourced languages. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了创建单语和跨语言间的嵌入的新技术。我们的方法整合了互补技术，文本来源，知识库和语言创建多个字的嵌入。现有字矢量投影到使用线性变换和平均共同语义空间。随着我们的方法所产生的荟萃的嵌入保持原有的嵌入的维度，而不会丢失信息，在处理外的词汇的问题。广泛的实证评价表明了我们的技术相对于各种内在和外在的多语种评估先前的工作成效，获得了语义文本相似性和国家的最先进的性能竞争的结果词语相似度和词性标注（英语和西班牙语） 。产生的跨语种元的嵌入也表现出优异的跨语言迁移学习能力。换句话说，我们可以利用从资源丰富的语言预先训练源的嵌入，以提高资源不足的语言文字表述。</font>
</div>


<hr>
<div id="paper2"> <b>2. Modality-Balanced Models for Visual Dialogue</b>  <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hyounghun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：可视对话任务需要一个模型，同时利用图像和会话的上下文信息来生成到对话的下一个响应。然而，通过人工分析，我们发现了大量的对话问题只能由看图像，而不到上下文历史上的任何访问来回答，而其他人还需要对话上下文来预测正确的答案。我们表明，由于这个原因，以往合资模式（史和图像）模式过分依赖，而且更容易记住的对话记录（例如，通过上下文信息提取的关键字或模式），而只有图象模型更加普及（因为他们无法记住或者从历史中提取的关键字），并在主要贴现归累计收益（NDCG）任务指标，它允许多个正确答案大幅更好地履行。因此，这种观察鼓励我们要明确地保持两种模式，即只有一个影像的模型和图像的历史关节模型，并结合它们的互补能力，为一个更加平衡的多模式模型。我们提出了这种整合两个模型的多种方法，通过与共享参数合奏和共识辍学融合。根据经验，我们的模型实现对视觉对话挑战2019（关于NDCG和整个指标高平衡等级3）强劲的业绩，并基本跑赢视觉对话框挑战2018的大多数指标的赢家。</font>
</div>


<hr>
<div id="paper3"> <b>3. A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat  Groups</b>  <a href="https://arxiv.org/pdf/2001.06350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=de+Bayser%2C+M+G" target="_blank" rel="noopener" style="color:#0000EE;">Maira Gatti de Bayser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guerra%2C+M+A" target="_blank" rel="noopener" style="color:#0000EE;">Melina Alberio Guerra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cavalin%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Paulo Cavalin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pinhanez%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Claudio Pinhanez</a><br>
<font size="3">
Abstract: To predict the next most likely participant to interact in a multi-party conversation is a difficult problem. In a text-based chat group, the only information available is the sender, the content of the text and the dialogue history. In this paper we present our study on how these information can be used on the prediction task through a corpus and architecture that integrates turn-taking classifiers based on Maximum Likelihood Expectation (MLE), Convolutional Neural Networks (CNN) and Finite State Automata (FSA). The corpus is a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset (MultiWOZ) to a multiple travel service-based bots scenario with dialogue errors and was created to simulate user's interaction and evaluate the architecture. We present experimental results which show that the CNN approach achieves better performance than the baseline with an accuracy of 92.34%, but the integrated solution with MLE, CNN and FSA achieves performance even better, with 95.65%. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：为了预测下一个最有可能的参与者进行互动的多方通话是一个棘手的问题。在基于文本的聊天群，唯一可用的信息是发送者，文本和对话历史的内容。在本文中，我们介绍如何将这些信息可以在预测任务中使用通过语料库和架构，集成了转向回吐基于最大似然期望（MLE），卷积神经网络（CNN）和有限状态自动分类（我们的研究FSA ）。该语料库是多域向导的盎司数据集（MultiWOZ）与对话错误多个旅游服务为主的机器人场景的合成适应和创建来模拟用户的交互和评估体系结构。我们这表明，CNN方法实现比92.34％的准确度基准更好的性能，但与MLE，CNN和FSA集成的解决方案实现性能更为出色，有95.65％目前的实验结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. RobBERT: a Dutch RoBERTa-based Language Model</b>  <a href="https://arxiv.org/pdf/2001.06286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Delobelle%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pieter Delobelle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Winters%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Winters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Berendt%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bettina Berendt</a><br>
<font size="3">
Abstract: Pre-trained language models have been dominating the field of natural language processing in recent years, and have led to significant performance gains for various complex natural language tasks. One of the most prominent pre-trained language models is BERT (Bi-directional Encoders for Transformers), which was released as an English as well as a multilingual version. Although multilingual BERT performs well on many tasks, recent studies showed that BERT models trained on a single language significantly outperform the multilingual results. Training a Dutch BERT model thus has a lot of potential for a wide range of Dutch NLP tasks. While previous approaches have used earlier implementations of BERT to train their Dutch BERT, we used RoBERTa, a robustly optimized BERT approach, to train a Dutch language model called RobBERT. We show that RobBERT improves state of the art results in Dutch-specific language tasks, and also outperforms other existing Dutch BERT-based models in sentiment analysis. These results indicate that RobBERT is a powerful pre-trained model for fine-tuning for a large variety of Dutch language tasks. We publicly release this pre-trained model in hope of supporting further downstream Dutch NLP applications. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：预先训练语言模型已经主宰自然语言处理领域在最近几年，并导致显著的性能提升各种复杂的自然语言的任务。其中最突出的预先训练语言模型是BERT（变形金刚双向编码器），它被发布了作为一个英语和一个多语种的版本。虽然多语种BERT执行以及对许多任务，最近的研究显示，培训了一个单一的语言，BERT模型显著跑赢多种语言的结果。培训荷兰BERT模型因而具有广泛的荷兰NLP任务很大的潜力。虽然以前的方法已使用BERT的早期实现培养他们的荷兰BERT，我们使用了罗伯塔，一个稳健优化BERT的方法，培养所谓的RobBERT荷兰语言模型。我们发现，RobBERT改善状态荷兰人特有的语言任务的艺术效果，而且在情感分析优于其他现有的基于BERT荷模型。这些结果表明，RobBERT是微调功能强大的预先训练的模型种类繁多的荷兰语任务。我们在公开支持进一步的下游荷兰NLP应用希望释放此预先训练模式。</font>
</div>


<hr>
<div id="paper5"> <b>5. Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue  System</b>  <a href="https://arxiv.org/pdf/2001.06206" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun-Wei Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kuan-Yen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chao-Chun Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ku%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lun-Wei Ku</a><br>
<font size="3">
Abstract: Understanding dynamic scenes and dialogue contexts in order to converse with users has been challenging for multimodal dialogue systems. The 8-th Dialog System Technology Challenge (DSTC8) proposed an Audio Visual Scene-Aware Dialog (AVSD) task, which contains multiple modalities including audio, vision, and language, to evaluate how dialogue systems understand different modalities and response to users. In this paper, we proposed a multi-step joint-modality attention network (JMAN) based on recurrent neural network (RNN) to reason on videos. Our model performs a multi-step attention mechanism and jointly considers both visual and textual representations in each reasoning process to better integrate information from the two different modalities. Compared to the baseline released by AVSD organizers, our model achieves a relative 12.1% and 22.4% improvement over the baseline on ROUGE-L score and CIDEr score. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：了解动态场景和对话的上下文，以便与用户交谈已具有挑战性的多模态对话系统。 8个对话系统技术挑战（DSTC8）提出了一个视听场景感知对话框（AVSD）任务，其中包含多种方式，包括音频，视觉和语言，以评估对话系统是如何理解不同的方式和响应用户。在本文中，我们提出了一种基于递归神经网络（RNN）一个多步骤的联合方式关注网络（JMAN）理性上的视频。我们的模型进行多步注意机制，共同考虑在每个推理过程视觉和文本表示，以更好的信息从两种不同的方式进行整合。相比于通过AVSD主办方公布的基线，我们的模型实现了对ROUGE-L分和苹果酒得分基线相对12.1％和22.4％的改善。</font>
</div>


<hr>
<div id="paper6"> <b>6. Plato Dialogue System: A Flexible Conversational AI Research Platform</b>  <a href="https://arxiv.org/pdf/2001.06463" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Papangelis%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexandros Papangelis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Namazifar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mahdi Namazifar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatri%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chandra Khatri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yi-Chia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Molino%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piero Molino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tur%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gokhan Tur</a><br>
<font size="3">
Abstract: As the field of Spoken Dialogue Systems and Conversational AI grows, so does the need for tools and environments that abstract away implementation details in order to expedite the development process, lower the barrier of entry to the field, and offer a common test-bed for new ideas. In this paper, we present Plato, a flexible Conversational AI platform written in Python that supports any kind of conversational agent architecture, from standard architectures to architectures with jointly-trained components, single- or multi-party interactions, and offline or online training of any conversational agent component. Plato has been designed to be easy to understand and debug and is agnostic to the underlying learning frameworks that train each component. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：口语对话系统和会话人工智能领域的增长，确实需要工具和环境，为了加快开发进程，降低进入该领域的障碍，并提供一个共同的测试 - 抽象掉的实施细则床上躺了新的思路。在本文中，我们目前柏拉图，灵活的对话AI平台用Python编写的，它支持任何类型的会话代理架构，从标准架构与联合训练的成分，单或多方互动，以及离线或在线培训体系任何会话代理组件。柏拉图已经被设计成易于理解和调试，并是不可知的是培养每个组件的基础学习框架。</font>
</div>


<hr>
<div id="paper7"> <b>7. Supervised Speaker Embedding De-Mixing in Two-Speaker Environment</b>  <a href="https://arxiv.org/pdf/2001.06397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanpei Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hain%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Hain</a><br>
<font size="3">
Abstract: In this work, a speaker embedding de-mixing approach is proposed. Instead of separating two-speaker signal in signal space like speech source separation, the proposed approach separates different speaker properties from two-speaker signal in embedding space. The proposed approach contains two steps. In step one, the clean speaker embeddings are learned and collected by a residual TDNN based network. In step two, the two-speaker signal and the embedding of one of the speakers are input to a speaker embedding de-mixing network. The de-mixing network is trained to generate the embedding of the other speaker of the by reconstruction loss. Speaker identification accuracy on the de-mixed speaker embeddings is used to evaluate the quality of the obtained embeddings. Experiments are done in two kind of data: artificial augmented two-speaker data (TIMIT) and real world recording of two-speaker data (MC-WSJ). Six diffident speaker embedding de-mixing architectures are investigated. Comparing with the speaker identification accuracy on the clean speaker embeddings (98.5%), the obtained results show that one of the speaker embedding de-mixing architectures obtain close performance, reaching 96.9% test accuracy on TIMIT when the SNR between the target speaker and interfering speaker is 5 dB. More surprisingly, we found choosing a simple subtraction as the embedding de-mixing function could obtain the second best performance, reaching 95.2% test accuracy. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在这项工作中，扬声器嵌入脱混合方法提出。代替在如语音源分离的信号分离空间两个扬声器信号的，所提出的方法分离两个扬声器信号在嵌入空间中的不同扬声器的特性。所提出的方法包括两个步骤。在第一步中，清洁扬声器的嵌入被学习和由残余基于TDNN网络收集。在步骤2中，两个扬声器信号和扬声器中的一个的嵌入被输入到扬声器中嵌入解混合网络。所述去混合网络进行训练，以产生的另一个扬声器的由重建丢失的嵌入。对解混合扬声器的嵌入扬声器识别精度被用于评估所获得的嵌入的质量。实验以两种类型的数据来完成：人工增强双扬声器数据（TIMIT）和双扬声器数据的真实世界记录（MC-WSJ）。六个心虚音箱嵌入脱混合体系结构进行了研究。与在干净的扬声器的嵌入扬声器识别精度（98.5％）相比较，所获得的结果表明，该扬声器中的一个嵌入脱混合架构获得紧密的性能，上TIMIT达到96.9％测试精度当目标讲话者和干扰之间的SNR扬声器为5dB。更令人惊讶的，我们发现选择一个简单的减法作为嵌入脱混合功能可以得到第二最佳性能，达到95.2％的测试精度。</font>
</div>


<hr>
<div id="paper8"> <b>8. On- Device Information Extraction from Screenshots in form of tags</b>  <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sumit Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manoj Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Debi Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Changmai%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benu Changmai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a><br>
<font size="3">
Abstract: We propose a method to make mobile screenshots easily searchable. In this paper, we present the workflow in which we: 1) preprocessed a collection of screenshots, 2) identified script presentin image, 3) extracted unstructured text from images, 4) identifiedlanguage of the extracted text, 5) extracted keywords from the text, 6) identified tags based on image features, 7) expanded tag set by identifying related keywords, 8) inserted image tags with relevant images after ranking and indexed them to make it searchable on device. We made the pipeline which supports multiple languages and executed it on-device, which addressed privacy concerns. We developed novel architectures for components in the pipeline, optimized performance and memory for on-device computation. We observed from experimentation that the solution developed can reduce overall user effort and improve end user experience while searching, whose results are published. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们建议让移动截图易于搜索的方法。在本文中，我们提出我们在其中工作流：1）预处理截图的集合，2）识别的脚本presentin图像，3）提取从图像非结构化文本，4）提取的文本的identifiedlanguage，5）提取的关键词从文本，6）的基础上的图像特征识别的标签，7）膨胀通过识别相关的关键字标签集，8）与相关图像插入的图像标签的排名后和索引他们，使其可检索在设备上。我们做了哪些支持多种语言流水线开始执行它的设备，其中涉及隐私问题。我们开发新的架构在管线，优化的性能和内存设备上的计算组件。我们从实验观察到，解决方案开发可降低整体用户的努力和改善最终用户体验，同时搜索，其结果公布。</font>
</div>


<hr>
<div id="paper9"> <b>9. User-in-the-loop Adaptive Intent Detection for Instructable Digital  Assistant</b>  <a href="https://arxiv.org/pdf/2001.06007" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lair%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nicolas Lair</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Delgrange%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Clément Delgrange</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mugisha%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Mugisha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dussoux%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jean-Michel Dussoux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Oudeyer%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre-Yves Oudeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dominey%2C+P+F" target="_blank" rel="noopener" style="color:#0000EE;">Peter Ford Dominey</a><br>
<font size="3">
Abstract: People are becoming increasingly comfortable using Digital Assistants (DAs) to interact with services or connected objects. However, for non-programming users, the available possibilities for customizing their DA are limited and do not include the possibility of teaching the assistant new tasks. To make the most of the potential of DAs, users should be able to customize assistants by instructing them through Natural Language (NL). To provide such functionalities, NL interpretation in traditional assistants should be improved: (1) The intent identification system should be able to recognize new forms of known intents, and to acquire new intents as they are expressed by the user. (2) In order to be adaptive to novel intents, the Natural Language Understanding module should be sample efficient, and should not rely on a pretrained model. Rather, the system should continuously collect the training data as it learns new intents from the user. In this work, we propose AidMe (Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop adaptive intent detection framework that allows the assistant to adapt to its user by learning his intents as their interaction progresses. AidMe builds its repertoire of intents and collects data to train a model of semantic similarity evaluation that can discriminate between the learned intents and autonomously discover new forms of known intents. AidMe addresses two major issues - intent learning and user adaptation - for instructable digital assistants. We demonstrate the capabilities of AidMe as a standalone system by comparing it with a one-shot learning system and a pretrained NLU module through simulations of interactions with a user. We also show how AidMe can smoothly integrate to an existing instructable digital assistant. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人们使用数字助理（DAS）与服务或连接的对象进行交互变得越来越舒适。然而，对于非编程的用户，定制自己的DA可用的可能性是有限的，不包括教学助理新任务的可能性。为了充分利用的DA的潜力，用户应该能够通过自然语言（NL），指示他们定制的助手。为了提供这样的功能，在传统的助理NL解释应加以改进：（1）意图识别系统应该能够识别已知的意图的新形式，因为它们是由用户表达了收购意向新。 （2）为了适应新的意图，所述自然语言理解模块应该是样品高效，并且不应该依赖于预训练的模型。相反，因为它学习来自用户的新意图，系统应不断收集训练数据。在这项工作中，我们提出AidMe（在多域环境自适应意图检测），用户在半实物自适应意图检测框架，允许助手通过学习他的意图及其互进步，以适应其用户。 AidMe建立其意图和收集数据的剧目来训练语义相似性评价的模型，可以和所学意图区分自主发现已知意图的新形式。 AidMe地址两大问题 - 意向学习和适应用户 - 对于造说明数字助理。我们通过将其与一次性学习系统，并通过与用户的交互的模拟预训练NLU模块比较表明AidMe的能力，作为一个独立的系统。我们还表明AidMe如何平滑地集成到现有的造说明数字助理。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>python gtts 文本转语音</title>
    <url>/2020/01/19/python-gtts-%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3/</url>
    <content><![CDATA[<h1 id="安装gtts"><a href="#安装gtts" class="headerlink" title="安装gtts"></a>安装gtts</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install gTTS</span><br></pre></td></tr></table></figure><h1 id="文本转语音"><a href="#文本转语音" class="headerlink" title="文本转语音"></a>文本转语音</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gtts <span class="keyword">import</span> gTTS</span><br><span class="line">tts = gTTS(text=<span class="string">"Hello World"</span>, lang=<span class="string">'en'</span>)</span><br><span class="line">tts.save(<span class="string">"helloworld.mp3"</span>)</span><br></pre></td></tr></table></figure><h1 id="播放语音"><a href="#播放语音" class="headerlink" title="播放语音"></a>播放语音</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.system(<span class="string">"start helloworld.mp3"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>tts</tag>
      </tags>
  </entry>
  <entry>
    <title>python 调用谷歌翻译接口</title>
    <url>/2020/01/19/python-%E8%B0%83%E7%94%A8%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<p>googletrans 是一个封装了谷歌翻译接口的python代码库，可以通过googletrans实现免费、无限制调用谷歌翻译接口。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install googletrans</span><br></pre></td></tr></table></figure><h1 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> googletrans <span class="keyword">import</span> Translator</span><br><span class="line">translator = Translator(service_urls=[</span><br><span class="line">      <span class="string">'translate.google.cn'</span>,</span><br><span class="line">      <span class="string">'translate.google.com'</span>])</span><br><span class="line">trans=translator.translate(<span class="string">'Hello World'</span>, src=<span class="string">'en'</span>, dest=<span class="string">'zh-cn'</span>)</span><br><span class="line"><span class="comment"># 原文</span></span><br><span class="line">print(trans.origin)</span><br><span class="line"><span class="comment"># 译文</span></span><br><span class="line">print(trans.text)</span><br></pre></td></tr></table></figure><a id="more"></a>




<h1 id="语种识别"><a href="#语种识别" class="headerlink" title="语种识别"></a>语种识别</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">detection=translator.detect(<span class="string">'All with Love'</span>)</span><br><span class="line">print(detection.lang)</span><br></pre></td></tr></table></figure>

<h1 id="语种缩略表示"><a href="#语种缩略表示" class="headerlink" title="语种缩略表示"></a>语种缩略表示</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">LANGUAGES = &#123;</span><br><span class="line">    <span class="string">'af'</span>: <span class="string">'afrikaans'</span>,</span><br><span class="line">    <span class="string">'sq'</span>: <span class="string">'albanian'</span>,</span><br><span class="line">    <span class="string">'am'</span>: <span class="string">'amharic'</span>,</span><br><span class="line">    <span class="string">'ar'</span>: <span class="string">'arabic'</span>,</span><br><span class="line">    <span class="string">'hy'</span>: <span class="string">'armenian'</span>,</span><br><span class="line">    <span class="string">'az'</span>: <span class="string">'azerbaijani'</span>,</span><br><span class="line">    <span class="string">'eu'</span>: <span class="string">'basque'</span>,</span><br><span class="line">    <span class="string">'be'</span>: <span class="string">'belarusian'</span>,</span><br><span class="line">    <span class="string">'bn'</span>: <span class="string">'bengali'</span>,</span><br><span class="line">    <span class="string">'bs'</span>: <span class="string">'bosnian'</span>,</span><br><span class="line">    <span class="string">'bg'</span>: <span class="string">'bulgarian'</span>,</span><br><span class="line">    <span class="string">'ca'</span>: <span class="string">'catalan'</span>,</span><br><span class="line">    <span class="string">'ceb'</span>: <span class="string">'cebuano'</span>,</span><br><span class="line">    <span class="string">'ny'</span>: <span class="string">'chichewa'</span>,</span><br><span class="line">    <span class="string">'zh-cn'</span>: <span class="string">'chinese (simplified)'</span>,</span><br><span class="line">    <span class="string">'zh-tw'</span>: <span class="string">'chinese (traditional)'</span>,</span><br><span class="line">    <span class="string">'co'</span>: <span class="string">'corsican'</span>,</span><br><span class="line">    <span class="string">'hr'</span>: <span class="string">'croatian'</span>,</span><br><span class="line">    <span class="string">'cs'</span>: <span class="string">'czech'</span>,</span><br><span class="line">    <span class="string">'da'</span>: <span class="string">'danish'</span>,</span><br><span class="line">    <span class="string">'nl'</span>: <span class="string">'dutch'</span>,</span><br><span class="line">    <span class="string">'en'</span>: <span class="string">'english'</span>,</span><br><span class="line">    <span class="string">'eo'</span>: <span class="string">'esperanto'</span>,</span><br><span class="line">    <span class="string">'et'</span>: <span class="string">'estonian'</span>,</span><br><span class="line">    <span class="string">'tl'</span>: <span class="string">'filipino'</span>,</span><br><span class="line">    <span class="string">'fi'</span>: <span class="string">'finnish'</span>,</span><br><span class="line">    <span class="string">'fr'</span>: <span class="string">'french'</span>,</span><br><span class="line">    <span class="string">'fy'</span>: <span class="string">'frisian'</span>,</span><br><span class="line">    <span class="string">'gl'</span>: <span class="string">'galician'</span>,</span><br><span class="line">    <span class="string">'ka'</span>: <span class="string">'georgian'</span>,</span><br><span class="line">    <span class="string">'de'</span>: <span class="string">'german'</span>,</span><br><span class="line">    <span class="string">'el'</span>: <span class="string">'greek'</span>,</span><br><span class="line">    <span class="string">'gu'</span>: <span class="string">'gujarati'</span>,</span><br><span class="line">    <span class="string">'ht'</span>: <span class="string">'haitian creole'</span>,</span><br><span class="line">    <span class="string">'ha'</span>: <span class="string">'hausa'</span>,</span><br><span class="line">    <span class="string">'haw'</span>: <span class="string">'hawaiian'</span>,</span><br><span class="line">    <span class="string">'iw'</span>: <span class="string">'hebrew'</span>,</span><br><span class="line">    <span class="string">'hi'</span>: <span class="string">'hindi'</span>,</span><br><span class="line">    <span class="string">'hmn'</span>: <span class="string">'hmong'</span>,</span><br><span class="line">    <span class="string">'hu'</span>: <span class="string">'hungarian'</span>,</span><br><span class="line">    <span class="string">'is'</span>: <span class="string">'icelandic'</span>,</span><br><span class="line">    <span class="string">'ig'</span>: <span class="string">'igbo'</span>,</span><br><span class="line">    <span class="string">'id'</span>: <span class="string">'indonesian'</span>,</span><br><span class="line">    <span class="string">'ga'</span>: <span class="string">'irish'</span>,</span><br><span class="line">    <span class="string">'it'</span>: <span class="string">'italian'</span>,</span><br><span class="line">    <span class="string">'ja'</span>: <span class="string">'japanese'</span>,</span><br><span class="line">    <span class="string">'jw'</span>: <span class="string">'javanese'</span>,</span><br><span class="line">    <span class="string">'kn'</span>: <span class="string">'kannada'</span>,</span><br><span class="line">    <span class="string">'kk'</span>: <span class="string">'kazakh'</span>,</span><br><span class="line">    <span class="string">'km'</span>: <span class="string">'khmer'</span>,</span><br><span class="line">    <span class="string">'ko'</span>: <span class="string">'korean'</span>,</span><br><span class="line">    <span class="string">'ku'</span>: <span class="string">'kurdish (kurmanji)'</span>,</span><br><span class="line">    <span class="string">'ky'</span>: <span class="string">'kyrgyz'</span>,</span><br><span class="line">    <span class="string">'lo'</span>: <span class="string">'lao'</span>,</span><br><span class="line">    <span class="string">'la'</span>: <span class="string">'latin'</span>,</span><br><span class="line">    <span class="string">'lv'</span>: <span class="string">'latvian'</span>,</span><br><span class="line">    <span class="string">'lt'</span>: <span class="string">'lithuanian'</span>,</span><br><span class="line">    <span class="string">'lb'</span>: <span class="string">'luxembourgish'</span>,</span><br><span class="line">    <span class="string">'mk'</span>: <span class="string">'macedonian'</span>,</span><br><span class="line">    <span class="string">'mg'</span>: <span class="string">'malagasy'</span>,</span><br><span class="line">    <span class="string">'ms'</span>: <span class="string">'malay'</span>,</span><br><span class="line">    <span class="string">'ml'</span>: <span class="string">'malayalam'</span>,</span><br><span class="line">    <span class="string">'mt'</span>: <span class="string">'maltese'</span>,</span><br><span class="line">    <span class="string">'mi'</span>: <span class="string">'maori'</span>,</span><br><span class="line">    <span class="string">'mr'</span>: <span class="string">'marathi'</span>,</span><br><span class="line">    <span class="string">'mn'</span>: <span class="string">'mongolian'</span>,</span><br><span class="line">    <span class="string">'my'</span>: <span class="string">'myanmar (burmese)'</span>,</span><br><span class="line">    <span class="string">'ne'</span>: <span class="string">'nepali'</span>,</span><br><span class="line">    <span class="string">'no'</span>: <span class="string">'norwegian'</span>,</span><br><span class="line">    <span class="string">'ps'</span>: <span class="string">'pashto'</span>,</span><br><span class="line">    <span class="string">'fa'</span>: <span class="string">'persian'</span>,</span><br><span class="line">    <span class="string">'pl'</span>: <span class="string">'polish'</span>,</span><br><span class="line">    <span class="string">'pt'</span>: <span class="string">'portuguese'</span>,</span><br><span class="line">    <span class="string">'pa'</span>: <span class="string">'punjabi'</span>,</span><br><span class="line">    <span class="string">'ro'</span>: <span class="string">'romanian'</span>,</span><br><span class="line">    <span class="string">'ru'</span>: <span class="string">'russian'</span>,</span><br><span class="line">    <span class="string">'sm'</span>: <span class="string">'samoan'</span>,</span><br><span class="line">    <span class="string">'gd'</span>: <span class="string">'scots gaelic'</span>,</span><br><span class="line">    <span class="string">'sr'</span>: <span class="string">'serbian'</span>,</span><br><span class="line">    <span class="string">'st'</span>: <span class="string">'sesotho'</span>,</span><br><span class="line">    <span class="string">'sn'</span>: <span class="string">'shona'</span>,</span><br><span class="line">    <span class="string">'sd'</span>: <span class="string">'sindhi'</span>,</span><br><span class="line">    <span class="string">'si'</span>: <span class="string">'sinhala'</span>,</span><br><span class="line">    <span class="string">'sk'</span>: <span class="string">'slovak'</span>,</span><br><span class="line">    <span class="string">'sl'</span>: <span class="string">'slovenian'</span>,</span><br><span class="line">    <span class="string">'so'</span>: <span class="string">'somali'</span>,</span><br><span class="line">    <span class="string">'es'</span>: <span class="string">'spanish'</span>,</span><br><span class="line">    <span class="string">'su'</span>: <span class="string">'sundanese'</span>,</span><br><span class="line">    <span class="string">'sw'</span>: <span class="string">'swahili'</span>,</span><br><span class="line">    <span class="string">'sv'</span>: <span class="string">'swedish'</span>,</span><br><span class="line">    <span class="string">'tg'</span>: <span class="string">'tajik'</span>,</span><br><span class="line">    <span class="string">'ta'</span>: <span class="string">'tamil'</span>,</span><br><span class="line">    <span class="string">'te'</span>: <span class="string">'telugu'</span>,</span><br><span class="line">    <span class="string">'th'</span>: <span class="string">'thai'</span>,</span><br><span class="line">    <span class="string">'tr'</span>: <span class="string">'turkish'</span>,</span><br><span class="line">    <span class="string">'uk'</span>: <span class="string">'ukrainian'</span>,</span><br><span class="line">    <span class="string">'ur'</span>: <span class="string">'urdu'</span>,</span><br><span class="line">    <span class="string">'uz'</span>: <span class="string">'uzbek'</span>,</span><br><span class="line">    <span class="string">'vi'</span>: <span class="string">'vietnamese'</span>,</span><br><span class="line">    <span class="string">'cy'</span>: <span class="string">'welsh'</span>,</span><br><span class="line">    <span class="string">'xh'</span>: <span class="string">'xhosa'</span>,</span><br><span class="line">    <span class="string">'yi'</span>: <span class="string">'yiddish'</span>,</span><br><span class="line">    <span class="string">'yo'</span>: <span class="string">'yoruba'</span>,</span><br><span class="line">    <span class="string">'zu'</span>: <span class="string">'zulu'</span>,</span><br><span class="line">    <span class="string">'fil'</span>: <span class="string">'Filipino'</span>,</span><br><span class="line">    <span class="string">'he'</span>: <span class="string">'Hebrew'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>官方手册: <a href="https://py-googletrans.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://py-googletrans.readthedocs.io/en/latest/</a></p>
]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>谷歌翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-17</title>
    <url>/2020/01/18/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-17/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Lexical Sememe Prediction using Dictionary Definitions by Capturing  Local Semantic Correspondence <a href="https://arxiv.org/pdf/2001.05954" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Speech Emotion Recognition Based on Multi-feature and Multi-lingual  Fusion <a href="https://arxiv.org/pdf/2001.05908" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Comparing Rule-based, Feature-based and Deep Neural Methods for  De-identification of Dutch Medical Records <a href="https://arxiv.org/pdf/2001.05714" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> A Pilot Study on Multiple Choice Machine Reading Comprehension for  Vietnamese Texts <a href="https://arxiv.org/pdf/2001.05687" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> AandP: Utilizing Prolog for converting between active sentence and  passive sentence with three-steps conversion <a href="https://arxiv.org/pdf/2001.05672" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Schema2QA: Answering Complex Queries on the Structured Web with a Neural  Model <a href="https://arxiv.org/pdf/2001.05609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Stereotypical Bias Removal for Hate Speech Detection Task using  Knowledge-based Generalizations <a href="https://arxiv.org/pdf/2001.05495" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> AggressionNet: Generalised Multi-Modal Deep Temporal and Sequential  Learning for Aggression Identification <a href="https://arxiv.org/pdf/2001.05493" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> #MeToo on Campus: Studying College Sexual Assault at Scale Using Data  Reported on Social Media <a href="https://arxiv.org/pdf/2001.05970" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Show, Recall, and Tell: Image Captioning with Recall Mechanism <a href="https://arxiv.org/pdf/2001.05876" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> "Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials  for Humans <a href="https://arxiv.org/pdf/2001.05871" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Ensemble based discriminative models for Visual Dialog Challenge 2018 <a href="https://arxiv.org/pdf/2001.05865" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Discoverability in Satellite Imagery: A Good Sentence is Worth a  Thousand Pictures <a href="https://arxiv.org/pdf/2001.05839" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Document Network Projection in Pretrained Word Embedding Space <a href="https://arxiv.org/pdf/2001.05727" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Delving Deeper into the Decoder for Video Captioning <a href="https://arxiv.org/pdf/2001.05614" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Insertion-Deletion Transformer <a href="https://arxiv.org/pdf/2001.05540" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Lexical Sememe Prediction using Dictionary Definitions by Capturing  Local Semantic Correspondence</b>  <a href="https://arxiv.org/pdf/2001.05954" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Du%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiaju Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fanchao Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maosong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhiyuan Liu</a><br>
<font size="3">
Abstract: Sememes, defined as the minimum semantic units of human languages in linguistics, have been proven useful in many NLP tasks. Since manual construction and update of sememe knowledge bases (KBs) are costly, the task of automatic sememe prediction has been proposed to assist sememe annotation. In this paper, we explore the approach of applying dictionary definitions to predicting sememes for unannotated words. We find that sememes of each word are usually semantically matched to different words in its dictionary definition, and we name this matching relationship local semantic correspondence. Accordingly, we propose a Sememe Correspondence Pooling (SCorP) model, which is able to capture this kind of matching to predict sememes. We evaluate our model and baseline methods on a famous sememe KB HowNet and find that our model achieves state-of-the-art performance. Moreover, further quantitative analysis shows that our model can properly learn the local semantic correspondence between sememes and words in dictionary definitions, which explains the effectiveness of our model. The source codes of this paper can be obtained from this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：义位，定义为语言学人类语言的语义的最小单位，已在许多自然语言处理的任务被证明是有用的。由于人工建设和义素知识库（KBS）更新是昂贵的，自动义原预测的任务已经提出，以协助义原注释。在本文中，我们将探讨采用字典的定义为预测未注释词义位的方法。我们发现，每个词的义位通常是在语义上在其字典上的定义匹配不同的话，我们命名此匹配关系当地语义对应。因此，我们提出了一个义位对应池（SCORP）模型，它能够捕捉到这种匹配预测义原。我们评估在一个著名的义原KB知网我们的模型和基线的方法和发现，我们的模型实现了国家的最先进的性能。此外，进一步的定量分析表明，我们的模型能够正确地学习字典定义义位与词之间的本地语义对应，这说明我们的模型的有效性。本文的源代码可以从该HTTPS URL来获得。</font>
</div>


<hr>
<div id="paper2"> <b>2. Speech Emotion Recognition Based on Multi-feature and Multi-lingual  Fusion</b>  <a href="https://arxiv.org/pdf/2001.05908" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chunyi Wang</a><br>
<font size="3">
Abstract: A speech emotion recognition algorithm based on multi-feature and Multi-lingual fusion is proposed in order to resolve low recognition accuracy caused by lack of large speech dataset and low robustness of acoustic features in the recognition of speech emotion. First, handcrafted and deep automatic features are extracted from existing data in Chinese and English speech emotions. Then, the various features are fused respectively. Finally, the fused features of different languages are fused again and trained in a classification model. Distinguishing the fused features with the unfused ones, the results manifest that the fused features significantly enhance the accuracy of speech emotion recognition algorithm. The proposed solution is evaluated on the two Chinese corpus and two English corpus, and is shown to provide more accurate predictions compared to original solution. As a result of this study, the multi-feature and Multi-lingual fusion algorithm can significantly improve the speech emotion recognition accuracy when the dataset is small. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于多特征和多语种的融合语音情感识别算法是为了解决由于缺乏大型数据集的讲话和在识别语音情感的声学特征低稳健的低识别精度提出。首先，手工和自动深特征在中国和英语演讲情绪现有的数据中提取。于是，各种功能都融合分别。最后，不同语言的熔断特性再次融合，并在分类模型训练。判定，非融合的，结果清单中的融合功能，融合功能显著增强语音情感识别算法的精度。提出的解决方案是在两名中国语料库和两个英语语料库进行评估，并显示相对于原来的解决方案，以提供更精确的预测。作为这项研究的结果是，多特征和多语种的融合算法可以显著提高语音情感识别的准确性如果数据集小。</font>
</div>


<hr>
<div id="paper3"> <b>3. Comparing Rule-based, Feature-based and Deep Neural Methods for  De-identification of Dutch Medical Records</b>  <a href="https://arxiv.org/pdf/2001.05714" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Trienes%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jan Trienes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Trieschnigg%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dolf Trieschnigg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Seifert%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christin Seifert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hiemstra%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Djoerd Hiemstra</a><br>
<font size="3">
Abstract: Unstructured information in electronic health records provide an invaluable resource for medical research. To protect the confidentiality of patients and to conform to privacy regulations, de-identification methods automatically remove personally identifying information from these medical records. However, due to the unavailability of labeled data, most existing research is constrained to English medical text and little is known about the generalizability of de-identification methods across languages and domains. In this study, we construct a varied dataset consisting of the medical records of 1260 patients by sampling data from 9 institutes and three domains of Dutch healthcare. We test the generalizability of three de-identification methods across languages and domains. Our experiments show that an existing rule-based method specifically developed for the Dutch language fails to generalize to this new data. Furthermore, a state-of-the-art neural architecture performs strongly across languages and domains, even with limited training data. Compared to feature-based and rule-based methods the neural method requires significantly less configuration effort and domain-knowledge. We make all code and pre-trained de-identification models available to the research community, allowing practitioners to apply them to their datasets and to enable future benchmarks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在电子健康记录的非结构化信息提供医学研究的宝贵资源。为了保护病人的保密性和符合隐私法规，去识别方法自动删除的个人识别这些医疗记录信息。然而，由于标签的数据，大多数现有的研究被限制在英国的医疗文本和小的不可有人知道的跨语言和领域去识别方法的普遍性。在这项研究中，我们构建了一个不同的数据集从9个院所和荷兰医疗保健的三个域采样数据组成的1260例患者的医疗记录。我们测试的跨语言，跨域三个去识别方法的普遍性。我们的实验表明，专门为荷兰语言开发现有的基于规则的方法不能推广到这个新的数据。此外，一个国家的最先进的神经结构进行强烈跨语言和域，即使在有限的训练数据。相比于基于规则的基于特征和方法，神经方法需要显著较少配置工作和领域的知识。我们让所有的代码和预先训练去标识模型提供给研究界，让从业者将它们应用到自己的数据集，以使未来的基准。</font>
</div>


<hr>
<div id="paper4"> <b>4. A Pilot Study on Multiple Choice Machine Reading Comprehension for  Vietnamese Texts</b>  <a href="https://arxiv.org/pdf/2001.05687" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Van+Nguyen%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kiet Van Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tran%2C+K+V" target="_blank" rel="noopener" style="color:#0000EE;">Khiem Vinh Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luu%2C+S+T" target="_blank" rel="noopener" style="color:#0000EE;">Son T. Luu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nguyen%2C+A+G" target="_blank" rel="noopener" style="color:#0000EE;">Anh Gia-Tuan Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nguyen%2C+N+L" target="_blank" rel="noopener" style="color:#0000EE;">Ngan Luu-Thuy Nguyen</a><br>
<font size="3">
Abstract: Machine Reading Comprehension (MRC) is the task of natural language processing which studies the ability to read and understand unstructured texts and then find the correct answers for questions. Until now, we have not yet had any MRC dataset for such a low-resource language as Vietnamese. In this paper, we introduce ViMMRC, a challenging machine comprehension corpus with multiple-choice questions, intended for research on the machine comprehension of Vietnamese text. This corpus includes 2,783 multiple-choice questions and answers based on a set of 417 Vietnamese texts used for teaching reading comprehension for 1st to 5th graders. Answers may be extracted from the contents of single or multiple sentences in the corresponding reading text. A thorough analysis of the corpus and experimental results in this paper illustrate that our corpus ViMMRC demands reasoning abilities beyond simple word matching. We proposed the method of Boosted Sliding Window (BSW) that improves 5.51% in accuracy over the best baseline method. We also measured human performance on the corpus and compared it to our MRC models. The performance gap between humans and our best experimental model indicates that significant progress can be made on Vietnamese machine reading comprehension in further research. The corpus is freely available at our website for research purposes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机阅读理解（MRC）是自然语言处理的哪些研究阅读和理解非结构化的文本，然后找到问题的正确答案的能力的任务。到现在为止，我们还没有过任何MRC数据集这样的低资源语言越南。在本文中，我们介绍ViMMRC，一个具有挑战性的机器理解语料库与多项选择题，供越南文本的机器理解研究。该文集包括基于一套用于教学阅读理解的1日至5年级学生417个越南文2783多项选择题及答案。答案可以从在相应的阅读文本单个或多个句子的内容被提取。本文的语料和实验结果的深入分析表明我们的语料库ViMMRC要求超出了简单的词语匹配的推理能力。我们提出的提振推拉窗（BSW）的，超过最佳基线法提高了精度5.51％的方法。我们还测量了语料库人的表现和它相比，我们的MRC模型。人类和我们最好的实验模型之间的性能差距表明，显著的进展可以在进一步研究越南机器阅读理解进行。该语料库是免费提供的，在我们的网站用于研究目的。</font>
</div>


<hr>
<div id="paper5"> <b>5. AandP: Utilizing Prolog for converting between active sentence and  passive sentence with three-steps conversion</b>  <a href="https://arxiv.org/pdf/2001.05672" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Tran%2C+T+Q" target="_blank" rel="noopener" style="color:#0000EE;">Trung Q. Tran</a><br>
<font size="3">
Abstract: I introduce a simple but efficient method to solve one of the critical aspects of English grammar which is the relationship between active sentence and passive sentence. In fact, an active sentence and its corresponding passive sentence express the same meaning, but their structure is different. I utilized Prolog [4] along with Definite Clause Grammars (DCG) [5] for doing the conversion between active sentence and passive sentence. Some advanced techniques were also used such as Extra Arguments, Extra Goals, Lexicon, etc. I tried to solve a variety of cases of active and passive sentences such as 12 English tenses, modal verbs, negative form, etc. More details and my contributions will be presented in the following sections. The source code is available at this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我介绍一个简单的，但要解决的英语语法的关键方面是主动句和被动句之间的关系的一个有效的方法。事实上，一个主动句和其对应的被动句表达同一个意思，但它们的结构是不同的。我使用的Prolog [4]与定条款文法（DCG）[5]这样做主动句和被动句子之间的转换沿。一些先进的技术，还使用了诸如额外的参数，额外的目标，词汇，等我试图解决各种主动和被动句等12个英文时态，情态动词，否定形式等更多细节和我的贡献的情况下将在下面的章节中介绍。源代码可在此HTTPS URL。</font>
</div>


<hr>
<div id="paper6"> <b>6. Schema2QA: Answering Complex Queries on the Structured Web with a Neural  Model</b>  <a href="https://arxiv.org/pdf/2001.05609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Silei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Campagna%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giovanni Campagna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Monica S. Lam</a><br>
<font size="3">
Abstract: Virtual assistants today require every website to submit skills individually into their proprietary repositories. The skill consists of a fixed set of supported commands and the formal representation of each command. The assistants use the contributed data to create a proprietary linguistic interface, typically using an intent classifier. This paper proposes an open-source toolkit, called Schema2QA, that leverages the this http URL markup found in many websites to automatically build skills. Schema2QA has several advantages: (1) Schema2QA handles compositional queries involving multiple fields automatically, such as "find the Italian restaurant around here with the most reviews", or "what W3C employees on LinkedIn went to Oxford"; (2) Schema2QA translates natural language into executable queries on the up-to-date data from the website; (3) natural language training can be applied to one domain at a time to handle multiple websites using the same this http URL representations. We apply Schema2QA to two different domains, showing that the skills we built can answer useful queries with little manual effort. Our skills achieve an overall accuracy between 74% and 78%, and can answer questions that span three or more properties with 65% accuracy. We also show that a new domain can be supported by transferring knowledge. The open-source Schema2QA lets each website create and own its linguistic interface. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：虚拟助理都要求每一个网站提交技巧单独为他们的专利库。技能由一组固定的支持的命令和各命令的正式表示。助手用提供的数据以创建一个专有的语言接口，通常使用的意图分类器。本文提出了一种开放源代码工具包，叫做Schema2QA，即利用了这个在很多网站上找到的自动构建技术HTTP URL标记。 Schema2QA有以下几个优点：（1）Schema2QA自动处理涉及多个领域组成的查询，如“找到意大利餐厅这里与大多数评论围绕”或“去牛津大学在LinkedIn什么W3C员工”; （2）Schema2QA转换自然语言转换为可执行的查询从网站上的最新数据; （3）自然语言培训可以同时被应用到一个域中使用相同的这个HTTP URL交涉处理多个网站。我们应用Schema2QA于两个不同的领域，显示出我们建立了技能可以回答很少的手动工作有用的查询。我们的技能达到74％和78％之间的整体精度，并能回答这个跨越65％的准确率三个或更多的性能问题。我们还表明，一个新的域可以通过知识转移的支持。开源Schema2QA让每个网站创建和拥有自己的语言界面。</font>
</div>


<hr>
<div id="paper7"> <b>7. Stereotypical Bias Removal for Hate Speech Detection Task using  Knowledge-based Generalizations</b>  <a href="https://arxiv.org/pdf/2001.05495" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Badjatiya%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pinkesh Badjatiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gupta%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manish Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Varma%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vasudeva Varma</a><br>
<font size="3">
Abstract: With the ever-increasing cases of hate spread on social media platforms, it is critical to design abuse detection mechanisms to proactively avoid and control such incidents. While there exist methods for hate speech detection, they stereotype words and hence suffer from inherently biased training. Bias removal has been traditionally studied for structured datasets, but we aim at bias mitigation from unstructured text data. In this paper, we make two important contributions. First, we systematically design methods to quantify the bias for any model and propose algorithms for identifying the set of words which the model stereotypes. Second, we propose novel methods leveraging knowledge-based generalizations for bias-free learning. Knowledge-based generalization provides an effective way to encode knowledge because the abstraction they provide not only generalizes content but also facilitates retraction of information from the hate speech detection classifier, thereby reducing the imbalance. We experiment with multiple knowledge generalization policies and analyze their effect on general performance and in mitigating bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages dataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that the use of knowledge-based generalizations results in better performance by forcing the classifier to learn from generalized content. Our methods utilize existing knowledge-bases and can easily be extended to other tasks </font>
<br>
<font size="2" style="line-height:30px;">
摘要：随着不断增加的社会化媒体平台上传播仇恨的情况下，它是设计滥用检测手段，积极主动规避和控制此类事件的关键。虽然存在仇恨言论的检测方法，他们刻板印象的话，因此从本质上偏向训练受到影响。偏置消除历来被研究了结构化数据集，但我们的目标是从非结构化的文本数据缓解偏差。在本文中，我们提出两个重要的贡献。首先，我们系统的设计方法，以量化的任何模型的偏差，提出的算法识别词集该模型定型。第二，我们提出了新的方法利用知识为基础的概括为无偏差的学习。基于知识的推广提供了一个有效的方式来编码知识，因为他们提供的不只是抽象概括的内容，但也有利于信息回缩从仇恨言论检测分类，从而减少不平衡。我们与多个知识推广政策实验和分析整体性能和减轻他们的偏见的影响。我们有两个现实世界的尺寸〜96K的数据集，维基百科对话页数据集（WikiDetox）和大小的Twitter的数据集〜24K，表明通过强制分类在更好的性能使用基于知识的概括的结果，从学习实验广义的内容。我们的方法利用现有的知识基地，可以很容易地扩展到其他任务</font>
</div>


<hr>
<div id="paper8"> <b>8. AggressionNet: Generalised Multi-Modal Deep Temporal and Sequential  Learning for Aggression Identification</b>  <a href="https://arxiv.org/pdf/2001.05493" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Khandelwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anant Khandelwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Niraj Kumar</a><br>
<font size="3">
Abstract: Wide usage of social media platforms has increased the risk of aggression, which results in mental stress and affects the lives of people negatively like psychological agony, fighting behavior, and disrespect to others. Majority of such conversations contains code-mixed languages[28]. Additionally, the way used to express thought or communication style also changes from one social media plat-form to another platform (e.g., communication styles are different in twitter and Facebook). These all have increased the complexity of the problem. To solve these problems, we have introduced a unified and robust multi-modal deep learning architecture which works for English code-mixed dataset and uni-lingual English dataset both.The devised system, uses psycho-linguistic features and very ba-sic linguistic features. Our multi-modal deep learning architecture contains, Deep Pyramid CNN, Pooled BiLSTM, and Disconnected RNN(with Glove and FastText embedding, both). Finally, the system takes the decision based on model averaging. We evaluated our system on English Code-Mixed TRAC 2018 dataset and uni-lingual English dataset obtained from Kaggle. Experimental results show that our proposed system outperforms all the previous approaches on English code-mixed dataset and uni-lingual English dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：社会化媒体平台，用途广泛增加侵略的风险，这会导致精神压力和负面影响的人们的生活就像心理上的痛苦，战斗行为，和不尊重他人。这样的对话的大多数包含代码混合语言[28]。此外，该方法用来表达思想或沟通方式也从一个社交媒体平台，改变到另一个平台（例如，沟通方式是在Twitter和Facebook有所不同）。这些都增加了问题的复杂性。为了解决这些问题，我们引入了一个统一和强大的多模态深度学习架构，适用于英语代码混合数据集和单语种英语数据集both.The设计系统，采用心理语言特征和非常BA-SIC语言特征。我们的多模态深度学习架构包含，深金字塔CNN，汇集BiLSTM，并断开RNN（带手套和FastText嵌入，两者）。最后，该系统采用基于模型平均的决定。我们评估了英语代码混合TRAC 2018数据集，并从Kaggle获得单语种英语数据集我们的系统。实验结果表明，该系统优于所有英语代码混合数据集和单语种英语数据集以前的方法。</font>
</div>


<hr>
<div id="paper9"> <b>9. #MeToo on Campus: Studying College Sexual Assault at Scale Using Data  Reported on Social Media</b>  <a href="https://arxiv.org/pdf/2001.05970" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Duong%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Viet Duong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pham%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Phu Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bose%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ritwik Bose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luo%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiebo Luo</a><br>
<font size="3">
Abstract: Recently, the emergence of the #MeToo trend on social media has empowered thousands of people to share their own sexual harassment experiences. This viral trend, in conjunction with the massive personal information and content available on Twitter, presents a promising opportunity to extract data driven insights to complement the ongoing survey based studies about sexual harassment in college. In this paper, we analyze the influence of the #MeToo trend on a pool of college followers. The results show that the majority of topics embedded in those #MeToo tweets detail sexual harassment stories, and there exists a significant correlation between the prevalence of this trend and official reports on several major geographical regions. Furthermore, we discover the outstanding sentiments of the #MeToo tweets using deep semantic meaning representations and their implications on the affected users experiencing different types of sexual harassment. We hope this study can raise further awareness regarding sexual misconduct in academia. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近日，在社会化媒体的#MeToo趋势的出现已经授权成千上万的人分享自己的性骚扰经历。这种病毒发展趋势，结合大量的个人信息，并在Twitter上可用内容，提出了一个有前途的机会抽取数据的深入分析，以补充有关大学性骚扰正在进行的调查为基础的研究。在本文中，我们分析了对高校追随者池#MeToo趋势的影响。结果显示，大部分嵌入在这些#MeToo主题的鸣叫细节性骚扰的故事，并且存在几大地理区域这一趋势，官方报告的患病率之间的相关性显著。此外，我们发现使用深层语义表述及其对受影响的用户体验不同类型的性骚扰影响的#MeToo鸣叫的优秀情绪。我们希望这项研究能提高公众对学术界的性行为不端进一步的认识。</font>
</div>


<hr>
<div id="paper10"> <b>10. Show, Recall, and Tell: Image Captioning with Recall Mechanism</b>  <a href="https://arxiv.org/pdf/2001.05876" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Li Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bai%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zechen Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yonghua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongtao Lu</a><br>
<font size="3">
Abstract: Generating natural and accurate descriptions in image cap-tioning has always been a challenge. In this paper, we pro-pose a novel recall mechanism to imitate the way human con-duct captioning. There are three parts in our recall mecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS). Recall unit is a text-retrieval module designedto retrieve recalled words for images. SG and RWS are de-signed for the best use of recalled words. SG branch cangenerate a recalled context, which can guide the process ofgenerating caption. RWS branch is responsible for copyingrecalled words to the caption. Inspired by pointing mecha-nism in text summarization, we adopt a soft switch to balancethe generated-word probabilities between SG and RWS. Inthe CIDEr optimization step, we also introduce an individualrecalled-word reward (WR) to boost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr / SPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 / 22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the results of other state-of-the-artmethods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：生成自然和图像帽tioning准确的描述一直是一个挑战。在本文中，我们亲姿势模仿的方式人类CON-管字幕一种新的召回机制。有三个部分在我们的回忆机甲-NISM：召回单位，语义指南（SG），并回顾-wordslot（RWS）。召回单元是文本的检索模块designedto检索图像召回的话。 SG和RWS被解签订了最好的使用被召回的话。 SG分支cangenerate一个回顾上下文，其可以引导过程ofgenerating字幕。 RWS分公司负责copyingrecalled字标题。通过指向文本摘要机甲-NISM启发，我们采用软切换至SG和RWS之间balancethe产生字概率。在矿井苹果酒优化步骤，我们还引入individualrecalled字奖励（WR），以提升培训。我们的proposedmethods（SG + RWS + WR）实现BLEU-4 /苹果酒/ 36.6 / 116.9 / 21.3与交叉熵损失和38.7 /129.1 /苹果酒优化上MSCOCO Karpathytest分裂22.4，这超越其他状态 - 的结果SPICEscores的最artmethods。</font>
</div>


<hr>
<div id="paper11"> <b>11. "Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials  for Humans</b>  <a href="https://arxiv.org/pdf/2001.05871" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lai%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vivian Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chenhao Tan</a><br>
<font size="3">
Abstract: To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a training phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：为支持与机器学习模型人的决策，我们经常需要嵌入是unsalient的，未知的，或者违反直觉的人类模型阐发模式。虽然现有的方法重点讲解机器的预测具有实时援助，我们探讨模型驱动的教程，以帮助人们了解一个训练阶段这些模式。我们认为，从科学论文，类似于科学传播的现行做法，并从解释训练数据自动选择的例子准则都教程。我们使用欺骗性的审查检测作为测试平台，并进行大规模，随机人体学科实验来检验这种教程的效果。我们发现，确实教程改善人类的性能，使用和不使用实时的援助。特别是，虽然深度学习不是简单的模型，教程和简单模型的解释提供了卓越的预测性能对人体更有益。我们的工作提出了以人为本对人类和人工智能之间的协同作用的教程和说明未来的发展方向。</font>
</div>


<hr>
<div id="paper12"> <b>12. Ensemble based discriminative models for Visual Dialog Challenge 2018</b>  <a href="https://arxiv.org/pdf/2001.05865" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shubham Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Raghav Goyal</a><br>
<font size="3">
Abstract: This manuscript describes our approach for the Visual Dialog Challenge 2018. We use an ensemble of three discriminative models with different encoders and decoders for our final submission. Our best performing model on 'test-std' split achieves the NDCG score of 55.46 and the MRR value of 63.77, securing third position in the challenge. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本稿件描述了我们的视觉对话挑战2018年我们使用三种判别模型不同的编码器和解码器为我们最后提交的集成方法。在“测试-STD”分裂我们的最佳表现模型达到NDCG得分55.46和63.77的MRR的价值，确保在挑战第三的位置。</font>
</div>


<hr>
<div id="paper13"> <b>13. Discoverability in Satellite Imagery: A Good Sentence is Worth a  Thousand Pictures</b>  <a href="https://arxiv.org/pdf/2001.05839" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Noever%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Noever</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Regian%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wes Regian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ciolino%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matt Ciolino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kalin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Josh Kalin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hambrick%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dom Hambrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Blankenship%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kaye Blankenship</a><br>
<font size="3">
Abstract: Small satellite constellations provide daily global coverage of the earth's landmass, but image enrichment relies on automating key tasks like change detection or feature searches. For example, to extract text annotations from raw pixels requires two dependent machine learning models, one to analyze the overhead image and the other to generate a descriptive caption. We evaluate seven models on the previously largest benchmark for satellite image captions. We extend the labeled image samples five-fold, then augment, correct and prune the vocabulary to approach a rough min-max (minimum word, maximum description). This outcome compares favorably to previous work with large pre-trained image models but offers a hundred-fold reduction in model size without sacrificing overall accuracy (when measured with log entropy loss). These smaller models provide new deployment opportunities, particularly when pushed to edge processors, on-board satellites, or distributed ground stations. To quantify a caption's descriptiveness, we introduce a novel multi-class confusion or error matrix to score both human-labeled test data and never-labeled images that include bounding box detection but lack full sentence captions. This work suggests future captioning strategies, particularly ones that can enrich the class coverage beyond land use applications and that lessen color-centered and adjacency adjectives ("green", "near", "between", etc.). Many modern language transformers present novel and exploitable models with world knowledge gleaned from training from their vast online corpus. One interesting, but easy example might learn the word association between wind and waves, thus enriching a beach scene with more than just color descriptions that otherwise might be accessed from raw pixels without text annotation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：小卫星星座提供地球陆地面积的每日全球覆盖，但图像富集依赖于自动化样改变检测或功能的搜索关键任务。例如，为了从原始像素提取文本注释需要两个依赖机器学习模型，一个分析俯视图像和其他，以产生描述性标题。我们评估对卫星图片说明以前最大的基准七款车型。我们扩展了标记图像样本五倍，然后扩充的，正确的和修剪词汇接近粗糙最小 - 最大（最小字，最大的描述）。这一结果相比毫不逊色与大预先训练的图像模型，但提供的模型大小百倍还原之前的工作不牺牲整体精度（当日志熵损失测量）。这些小模型提供了新的部署机会，特别是当推到边缘处理器，板载卫星，或分布式地面站。为了量化标题的描述性，我们引入了一个新的多类混淆或错误矩阵得分人类标记的测试数据，而不会标记的图像，包括边框检测，但缺乏完整的句子标题。这项工作表明未来字幕战略，特别是那些能充实类覆盖率超过土地使用的应用程序和减轻色心和邻接的形容词（“绿色”，“近”，“间”等）。许多现代语言的变压器存在新颖性和与世界的知识利用的模型从训练中收集来自其庞大的在线语料库。一个有趣的，但简单的例子可以学习乘风破浪的词语联想，从而丰富海滩场景比，否则可能从原始像素进行访问，而不文本注释只是颜色的描述更多。</font>
</div>


<hr>
<div id="paper14"> <b>14. Document Network Projection in Pretrained Word Embedding Space</b>  <a href="https://arxiv.org/pdf/2001.05727" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gourru%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Antoine Gourru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guille%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adrien Guille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Velcin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Velcin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jacques%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Jacques</a><br>
<font size="3">
Abstract: We present Regularized Linear Embedding (RLE), a novel method that projects a collection of linked documents (e.g. citation network) into a pretrained word embedding space. In addition to the textual content, we leverage a matrix of pairwise similarities providing complementary information (e.g., the network proximity of two documents in a citation graph). We first build a simple word vector average for each document, and we use the similarities to alter this average representation. The document representations can help to solve many information retrieval tasks, such as recommendation, classification and clustering. We demonstrate that our approach outperforms or matches existing document network embedding methods on node classification and link prediction tasks. Furthermore, we show that it helps identifying relevant keywords to describe document classes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出正则线性嵌入（RLE），一种新型的方法，其项目链接的文档（例如引网络）的集合到一个预训练的字嵌入空间。除了文本内容，我们利用成对的相似性提供补充信息（例如，在引用图两个文件的网络接近）的基质中。我们首先建立每个文档的简单词汇向量平均，而我们使用的相似改变这种平均表示。该文件表示可以帮助解决许多信息检索任务，如推荐，分类和聚类。我们证明我们的方法比或匹配现有的文档嵌入网络节点上的分类和链接预测任务的方法。此外，我们表明，它可以帮助识别相关关键字来描述文档类。</font>
</div>


<hr>
<div id="paper15"> <b>15. Delving Deeper into the Decoder for Video Captioning</b>  <a href="https://arxiv.org/pdf/2001.05614" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haoran Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jianmin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaolin Hu</a><br>
<font size="3">
Abstract: Video captioning is an advanced multi-modal task which aims to describe a video clip using a natural language sentence. The encoder-decoder framework is the most popular paradigm for this task in recent years. However, there still exist some non-negligible problems in the decoder of a video captioning model. We make a thorough investigation into the decoder and adopt three techniques to improve the performance of the model. First of all, a combination of variational dropout and layer normalization is embedded into a recurrent unit to alleviate the problem of overfitting. Secondly, a new method is proposed to evaluate the performance of a model on a validation set so as to select the best checkpoint for testing. Finally, a new training strategy called \textit{professional learning} is proposed which develops the strong points of a captioning model and bypasses its weaknesses. It is demonstrated in the experiments on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to Text (MSR-VTT) datasets that our model has achieved the best results evaluated by BLEU, CIDEr, METEOR and ROUGE-L metrics with significant gains of up to 11.7% on MSVD and 5% on MSR-VTT compared with the previous state-of-the-art models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：视频字幕是一种先进的多模态的任务，目的是描述使用自然语言句子的视频剪辑。编码器，解码器框架是在最近几年，这一任务最流行的范例。但是，仍然存在着一个视频字幕模型的解码器的一些不可忽视的问题。我们做一个彻底的调查，解码器，并采用三种技术来提高模型的性能。首先，变差和层正常化的组合被嵌入到一个重复单元，以减轻过拟合问题。其次，新方法，提出了在验证集评估模型的性能，以便选择最佳的检查点进行测试。最后，新的培训战略称为\ textit {专业学习}，提出了开发一个字幕模型的长处，避开其弱点。它证明了在微软研究院的视频描述语料库（MSVD）和MSR视频的实验文本（MSR-VTT）的数据集，我们的模型已经实现由BLEU，苹果酒，流星和ROUGE-L指标评估了显著收益最好的结果高达11.7％的MSVD和5％的MSR-VTT与以前国家的最先进的机型相比。</font>
</div>


<hr>
<div id="paper16"> <b>16. Insertion-Deletion Transformer</b>  <a href="https://arxiv.org/pdf/2001.05540" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ruis%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Laura Ruis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Stern%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mitchell Stern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Proskurnia%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julia Proskurnia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">William Chan</a><br>
<font size="3">
Abstract: We propose the Insertion-Deletion Transformer, a novel transformer-based neural architecture and training method for sequence generation. The model consists of two phases that are executed iteratively, 1) an insertion phase and 2) a deletion phase. The insertion phase parameterizes a distribution of insertions on the current output hypothesis, while the deletion phase parameterizes a distribution of deletions over the current output hypothesis. The training method is a principled and simple algorithm, where the deletion model obtains its signal directly on-policy from the insertion model output. We demonstrate the effectiveness of our Insertion-Deletion Transformer on synthetic translation tasks, obtaining significant BLEU score improvement over an insertion-only model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出的插入缺失变压器，一种新型的基于变压器的神经结构和序列生成训练方法。该模型由被迭代执行两个阶段：1）的插入相位和2）的删除相。插入阶段参数化对电流输出假设插入的分布，而删除相位参数化缺失的过电流输出假设的分布。该训练方法是一个原则性和简单的算法，其中该删除模型直接获得关于策略从插入模型输出它的信号。我们证明我们的插入缺失变压器上合成翻译任务的有效性，通过一个只有插入模型取得显著BLEU评分改善。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>一些公司及高校在线翻译系统</title>
    <url>/2020/01/17/%E4%B8%80%E4%BA%9B%E5%85%AC%E5%8F%B8%E5%8F%8A%E9%AB%98%E6%A0%A1%E5%9C%A8%E7%BA%BF%E7%BF%BB%E8%AF%91%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="公司在线翻译系统"><a href="#公司在线翻译系统" class="headerlink" title="公司在线翻译系统"></a>公司在线翻译系统</h1><ul>
<li><a href="https://fanyi.baidu.com/" target="_blank" rel="noopener">百度翻译</a></li>
<li><a href="https://translate.google.cn/" target="_blank" rel="noopener">谷歌翻译</a></li>
<li><a href="http://fanyi.youdao.com/" target="_blank" rel="noopener">有道翻译</a></li>
<li><a href="https://fanyi.qq.com/" target="_blank" rel="noopener">腾讯翻译君</a></li>
<li><a href="https://fanyi.sogou.com/" target="_blank" rel="noopener">搜狗翻译</a></li>
<li><a href="https://niutrans.vip/trans" target="_blank" rel="noopener">小牛翻译</a></li>
<li><a href="https://cloudtranslation.com/online/" target="_blank" rel="noopener">云译</a></li>
</ul><h1 id="高校在线翻译系统"><a href="#高校在线翻译系统" class="headerlink" title="高校在线翻译系统"></a>高校在线翻译系统</h1><ul>
<li><a href="http://nmt.xmu.edu.cn/" target="_blank" rel="noopener">厦门大学</a></li>
</ul>]]></content>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-16</title>
    <url>/2020/01/17/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-16/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses <a href="https://arxiv.org/pdf/2001.05467" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> A BERT based Sentiment Analysis and Key Entity Detection Approach for  Online Financial Texts <a href="https://arxiv.org/pdf/2001.05326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Authorship Attribution in Bangla literature using Character-level CNN <a href="https://arxiv.org/pdf/2001.05316" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> A Continuous Space Neural Language Model for Bengali Language <a href="https://arxiv.org/pdf/2001.05315" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Embedding Compression with Isotropic Iterative Quantization <a href="https://arxiv.org/pdf/2001.05314" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Tensor Graph Convolutional Networks for Text Classification <a href="https://arxiv.org/pdf/2001.05313" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process  Approach to Linguistic Relationships <a href="https://arxiv.org/pdf/2001.05297" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Urdu-English Machine Transliteration using Neural Networks <a href="https://arxiv.org/pdf/2001.05296" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Language Models Are An Effective Patient Representation Learning  Technique For Electronic Health Record Data <a href="https://arxiv.org/pdf/2001.05295" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> The empirical structure of word frequency distributions <a href="https://arxiv.org/pdf/2001.05292" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Exploring and Improving Robustness of Multi Task Deep Neural Networks  via Domain Agnostic Defenses <a href="https://arxiv.org/pdf/2001.05286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Detecting New Word Meanings: A Comparison of Word Embedding Models in  Spanish <a href="https://arxiv.org/pdf/2001.05285" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Improving Spoken Language Understanding By Exploiting ASR N-best  Hypotheses <a href="https://arxiv.org/pdf/2001.05284" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> FGN: Fusion Glyph Network for Chinese Named Entity Recognition <a href="https://arxiv.org/pdf/2001.05272" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation <a href="https://arxiv.org/pdf/2001.05139" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Parallel Machine Translation with Disentangled Context Transformer <a href="https://arxiv.org/pdf/2001.05136" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Robust Speaker Recognition Using Speech Enhancement And Attention Model <a href="https://arxiv.org/pdf/2001.05031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> A Tree Adjoining Grammar Representation for Models Of Stochastic  Dynamical Systems <a href="https://arxiv.org/pdf/2001.05320" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Auto Completion of User Interface Layout Design Using Transformer-Based  Tree Decoders <a href="https://arxiv.org/pdf/2001.05308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Teddy: A System for Interactive Review Analysis <a href="https://arxiv.org/pdf/2001.05171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Modeling Product Search Relevance in e-Commerce <a href="https://arxiv.org/pdf/2001.04980" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses</b>  <a href="https://arxiv.org/pdf/2001.05467" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Niu%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tong Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: Many sequence-to-sequence dialogue models tend to generate safe, uninformative responses. There have been various useful efforts on trying to eliminate them. However, these approaches either improve decoding algorithms during inference, rely on hand-crafted features, or employ complex models. In our work, we build dialogue models that are dynamically aware of what utterances or tokens are dull without any feature-engineering. Specifically, we start with a simple yet effective automatic metric, AvgOut, which calculates the average output probability distribution of all time steps on the decoder side during training. This metric directly estimates which tokens are more likely to be generated, thus making it a faithful evaluation of the model diversity (i.e., for diverse models, the token probabilities should be more evenly distributed rather than peaked at a few dull tokens). We then leverage this novel metric to propose three models that promote diversity without losing relevance. The first model, MinAvgOut, directly maximizes the diversity score through the output distributions of each batch; the second model, Label Fine-Tuning (LFT), prepends to the source sequence a label continuously scaled by the diversity score to control the diversity level; the third model, RL, adopts Reinforcement Learning and treats the diversity score as a reward signal. Moreover, we experiment with a hybrid model by combining the loss terms of MinAvgOut and RL. All four models outperform their base LSTM-RNN model on both diversity and relevance by a large margin, and are comparable to or better than competitive baselines (also verified via human evaluation). Moreover, our approaches are orthogonal to the base model, making them applicable as an add-on to other emerging better dialogue models in the future. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：许多序列对序列的对话模式容易产生安全，无信息的响应。已经有上试图消除他们各种有用的努力。然而，这些方法或者改进的推理过程中的解码算法，依靠手工制作的功能，或采用复杂的模型。在我们的工作，我们建立对话模型是动态意识到什么话语或令牌是没有任何功能的工程平淡。具体而言，我们先从一个简单而有效的自动度量，AvgOut，其在训练期间计算出的解码器侧的所有时间步长的平均输出概率分布。该指标直接估计令牌更容易产生，从而使得它的型号多样的忠实评价（即，对于不同的车型，令牌的概率应该是更均匀地分布，而不是在几个沉闷的令牌见顶）。然后，我们利用这一新的指标，提出促进多样性不失相关性三种模式。第一种模式，MinAvgOut，直接通过最大化每批的输出分布的分集比分;第二个模型，标签微调（LFT），前置到源序列通过分集比分来控制分集电平连续缩放的标签;第三种模式，RL，采用强化学习和对待多样性分数作为奖励信号。此外，我们结合MinAvgOut和RL的损失方面与混合动力模型试验。所有这四种型号跑赢上都多样性和实用性大幅度的基地LSTM-RNN模型，并比竞争基准（也可以通过人工评估验证）相当或更好。此外，我们的方法是正交的示范基地，使它们适用于作为一个附加在未来其他新兴更好的对话模式。</font>
</div>


<hr>
<div id="paper2"> <b>2. A BERT based Sentiment Analysis and Key Entity Detection Approach for  Online Financial Texts</b>  <a href="https://arxiv.org/pdf/2001.05326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lingyun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zheng%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinhao Zheng</a><br>
<font size="3">
Abstract: The emergence and rapid progress of the Internet have brought ever-increasing impact on financial domain. How to rapidly and accurately mine the key information from the massive negative financial texts has become one of the key issues for investors and decision makers. Aiming at the issue, we propose a sentiment analysis and key entity detection approach based on BERT, which is applied in online financial text mining and public opinion analysis in social media. By using pre-train model, we first study sentiment analysis, and then we consider key entity detection as a sentence matching or Machine Reading Comprehension (MRC) task in different granularity. Among them, we mainly focus on negative sentimental information. We detect the specific entity by using our approach, which is different from traditional Named Entity Recognition (NER). In addition, we also use ensemble learning to improve the performance of proposed approach. Experimental results show that the performance of our approach is generally higher than SVM, LR, NBM, and BERT for two financial sentiment analysis and key entity detection datasets. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：出现和互联网的飞速进步也带来了金融领域不断增加的影响。如何快速，准确地矿从大量负面财务文本的关键信息已成为投资者和决策者的关键问题之一。针对这个问题，我们提出了一个情感分析和基于BERT，这是在网上金融文本挖掘和舆情分析社交媒体应用的关键实体检测方法。通过使用预火车模型，我们首先研究情感分析，然后我们考虑的关键实体检测在不同粒度的句子匹配或机器阅读理解（MRC）的任务。其中，我们主要集中在负感伤的信息。我们发现，通过使用我们的方法，这是从传统的命名实体识别（NER）不同的特定实体。此外，我们还可以使用集成学习，以提高该方法的性能。实验结果表明，我们的方法的性能一般比SVM，LR，NBM，和BERT较高的两个财务情绪分析和关键实体检测数据集。</font>
</div>


<hr>
<div id="paper3"> <b>3. Authorship Attribution in Bangla literature using Character-level CNN</b>  <a href="https://arxiv.org/pdf/2001.05316" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatun%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Aisha Khatun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rahman%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anisur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Islam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Md. Saiful Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marium-E-Jannat" target="_blank" rel="noopener" style="color:#0000EE;">Marium-E-Jannat</a><br>
<font size="3">
Abstract: Characters are the smallest unit of text that can extract stylometric signals to determine the author of a text. In this paper, we investigate the effectiveness of character-level signals in Authorship Attribution of Bangla Literature and show that the results are promising but improvable. The time and memory efficiency of the proposed model is much higher than the word level counterparts but accuracy is 2-5% less than the best performing word-level models. Comparison of various word-based models is performed and shown that the proposed model performs increasingly better with larger datasets. We also analyze the effect of pre-training character embedding of diverse Bangla character set in authorship attribution. It is seen that the performance is improved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors, balancing them before training and compare the results. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：字符是文本，可以提取stylometric信号来确定文本的作者的最小单位。在本文中，我们研究了字符级信号的孟加拉文学著作权归属的有效性，并表明其结果是有希望的，但改善的。该模型的时间和内存效率比字级同行高得多，但精度比表现最好的字级车型少2-5％。执行并显示各种基于词的模型比较，该模型执行越来越多地与更大的数据集更好。我们还分析了前培训字符著作权归属不同孟加拉字符集的嵌入的效果。可以看出，性能高达10％的预培训提高。我们使用的数据集2的6至14作家，训练前平衡他们并比较结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. A Continuous Space Neural Language Model for Bengali Language</b>  <a href="https://arxiv.org/pdf/2001.05315" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chowdhury%2C+H+A" target="_blank" rel="noopener" style="color:#0000EE;">Hemayet Ahmed Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Imon%2C+M+A+H" target="_blank" rel="noopener" style="color:#0000EE;">Md. Azizul Haque Imon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rahman%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anisur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatun%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Aisha Khatun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Islam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Md. Saiful Islam</a><br>
<font size="3">
Abstract: Language models are generally employed to estimate the probability distribution of various linguistic units, making them one of the fundamental parts of natural language processing. Applications of language models include a wide spectrum of tasks such as text summarization, translation and classification. For a low resource language like Bengali, the research in this area so far can be considered to be narrow at the very least, with some traditional count based models being proposed. This paper attempts to address the issue and proposes a continuous-space neural language model, or more specifically an ASGD weight dropped LSTM language model, along with techniques to efficiently train it for Bengali Language. The performance analysis with some currently existing count based models illustrated in this paper also shows that the proposed architecture outperforms its counterparts by achieving an inference perplexity as low as 51.2 on the held out data set for Bengali. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言模型通常用来估计各种语言单位的概率分布，使其自然语言处理的基本组成部分之一。语言模型的应用包括任务，如文本摘要，翻译和分类的广泛。对于像孟加拉低资源的语言，在这方面至今也算是研究是起码狭窄，而提出了一些传统的基于计数模式。本文试图解决这个问题，并提出了一个连续的空间神经语言模型，或者更准确地说是ASGD体重也下降LSTM语言模型，用技术来有效地训练它的孟加拉语一起。本文所示还显示了一些目前存在的以计数为基础的模型的性能分析，提出的架构通过实现一个推论困惑低至51.2对孟加拉的伸出数据集优于其同行。</font>
</div>


<hr>
<div id="paper5"> <b>5. Embedding Compression with Isotropic Iterative Quantization</b>  <a href="https://arxiv.org/pdf/2001.05314" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liao%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Siyu Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanzhi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinru Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yuan%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bo Yuan</a><br>
<font size="3">
Abstract: Continuous representation of words is a standard component in deep learning-based NLP models. However, representing a large vocabulary requires significant memory, which can cause problems, particularly on resource-constrained platforms. Therefore, in this paper we propose an isotropic iterative quantization (IIQ) approach for compressing embedding vectors into binary ones, leveraging the iterative quantization technique well established for image retrieval, while satisfying the desired isotropic property of PMI based models. Experiments with pre-trained embeddings (i.e., GloVe and HDC) demonstrate a more than thirty-fold compression ratio with comparable and sometimes even improved performance over the original real-valued embedding vectors. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：词的连续表示是基于深学习NLP车型的标准组件。然而，较大量的词汇需要显著的内存，这可能会导致问题，特别是在资源受限的平台。因此，在本文中，我们提出了压缩嵌入矢量成二进制的，利用图像检索完善的迭代量化技术，同时满足基于PMI模型所需的各向同性各向同性迭代量化（IIQ）的方法。与预训练的嵌入（即，手套和HDC）实验证实与在原始实值嵌入矢量可比有时甚至改善性能超过30倍的压缩比。</font>
</div>


<hr>
<div id="paper6"> <b>6. Tensor Graph Convolutional Networks for Text Classification</b>  <a href="https://arxiv.org/pdf/2001.05313" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xien Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=You%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinxin You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Ji Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lv%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Ping Lv</a><br>
<font size="3">
Abstract: Compared to sequential learning models, graph-based neural networks exhibit some excellent properties, such as ability capturing global information. In this paper, we investigate graph-based neural networks for text classification problem. A new framework TensorGCN (tensor graph convolutional networks), is presented for this task. A text graph tensor is firstly constructed to describe semantic, syntactic, and sequential contextual information. Then, two kinds of propagation learning perform on the text graph tensor. The first is intra-graph propagation used for aggregating information from neighborhood nodes in a single graph. The second is inter-graph propagation used for harmonizing heterogeneous information between graphs. Extensive experiments are conducted on benchmark datasets, and the results illustrate the effectiveness of our proposed framework. Our proposed TensorGCN presents an effective way to harmonize and integrate heterogeneous information from different kinds of graphs. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：相比于连续的学习模式，基于图形的神经网络表现出一些优异的性能，如能力捕捉全球信息。在本文中，我们研究了文本分类问题，基于图形的神经网络。一个新的框架TensorGCN（图张卷积网络），提出了这一任务。文本图形张量首先被构造来描述语义，语法，和顺序的上下文信息。然后，有两种传播学习上的文字图形张量执行。第一种是用于在单个图表聚集来自邻近节点的信息，图形的帧内传播。第二个是用于协调图之间异构信息曲线图间传播。大量的实验是在基准数据集进行，其结果说明我们提出的框架的有效性。我们提出的TensorGCN礼物协调和异构信息从不同类型的图形整合的有效途径。</font>
</div>


<hr>
<div id="paper7"> <b>7. Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process  Approach to Linguistic Relationships</b>  <a href="https://arxiv.org/pdf/2001.05297" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cathcart%2C+C+A" target="_blank" rel="noopener" style="color:#0000EE;">Chundra Aroor Cathcart</a><br>
<font size="3">
Abstract: This paper addresses a series of complex and unresolved issues in the historical phonology of West Iranian languages. The West Iranian languages (Persian, Kurdish, Balochi, and other languages) display a high degree of non-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to language contact; we argue, however, that an oversimplified view of the processes at work has prevailed in the literature on West Iranian dialectology, with specialists assuming that deviations from an expected outcome in a given non-Persian language are due to lexical borrowing from some chronological stage of Persian. It is demonstrated that this qualitative approach yields at times problematic conclusions stemming from the lack of explicit probabilistic inferences regarding the distribution of the data: Persian may not be the sole donor language; additionally, borrowing at the lexical level is not always the mechanism that introduces irregularity. In many cases, the possibility that West Iranian languages show different reflexes in different conditioning environments remains under-explored. We employ a novel Bayesian approach designed to overcome these problems and tease apart the different determinants of irregularity in patterns of West Iranian sound change. Our methodology allows us to provisionally resolve a number of outstanding questions in the literature on West Iranian dialectology concerning the dialectal affiliation of certain sound changes. We outline future directions for work of this sort. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文地址了一系列西伊朗语支的历史音韵复杂和悬而未决的问题。西伊朗语支（波斯，库尔德人，俾路支语等语种）表现出高度的非Lautgesetzlich行为。大多数这种不规则的无疑是由于语言接触;我们认为，但是，在工作流程的一个过于简单化的观点在西方的伊朗方言的文学盛行，与由于从一些时间阶段的词汇借用专家假设从给定的非波斯语的预期结果偏差波斯语。据证实，这种定性方法的产量有时有问题的结论，因为缺乏有关数据的分布概率明确推论的词干：波斯可能不是唯一的供体语言;另外，在词汇水平借用并不总是机制引入了不规则性。在许多情况下，西伊朗的语言说明了在不同的环境条件不同反射的可能性仍然充分开发。我们采用设计来克服这些问题，并梳理出不规则的西伊朗声音的变化模式的不同决定一种新的贝叶斯方法。我们的方法可以让我们暂时解决了许多文献对西方的伊朗方言有关的某些声音的变化方言隶属关系悬而未决的问题。我们为这种工作勾勒未来的发展方向。</font>
</div>


<hr>
<div id="paper8"> <b>8. Urdu-English Machine Transliteration using Neural Networks</b>  <a href="https://arxiv.org/pdf/2001.05296" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Din%2C+U+M+u" target="_blank" rel="noopener" style="color:#0000EE;">Usman Mohy ud Din</a><br>
<font size="3">
Abstract: Machine translation has gained much attention in recent years. It is a sub-field of computational linguistic which focus on translating text from one language to other language. Among different translation techniques, neural network currently leading the domain with its capabilities of providing a single large neural network with attention mechanism, sequence-to-sequence and long-short term modelling. Despite significant progress in domain of machine translation, translation of out-of-vocabulary words(OOV) which include technical terms, named-entities, foreign words are still a challenge for current state-of-art translation systems, and this situation becomes even worse while translating between low resource languages or languages having different structures. Due to morphological richness of a language, a word may have different meninges in different context. In such scenarios, translation of word is not only enough in order provide the correct/quality translation. Transliteration is a way to consider the context of word/sentence during translation. For low resource language like Urdu, it is very difficult to have/find parallel corpus for transliteration which is large enough to train the system. In this work, we presented transliteration technique based on Expectation Maximization (EM) which is un-supervised and language independent. Systems learns the pattern and out-of-vocabulary (OOV) words from parallel corpus and there is no need to train it on transliteration corpus explicitly. This approach is tested on three models of statistical machine translation (SMT) which include phrasebased, hierarchical phrase-based and factor based models and two models of neural machine translation which include LSTM and transformer model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机器翻译已经获得了广泛关注，近年来。这是着眼于从一种语言到另一种语言翻译文本计算语言学的子领域。在不同的翻译技术，目前主导其提供与注意机制，序列对序列和长短期建模一个大的神经网络的功能域的神经网络。尽管在机器翻译，出词汇的词（OOV），其中包括技术术语，命名实体翻译的领域显著进步，外来词仍然是国家的最先进的电流转换系统的挑战，而且这种情况变得更而具有不同结构的低资源语言或语言之间的转换变得更糟。由于语言的形态丰富，一个字可以有不同的上下文不同的脑膜。在这种情况下，文字的翻译不仅足以为了提供正确的/翻译质量。音译是考虑在翻译过程中字/句子的上下文的方式。对于像乌尔都语低资源语言，它是很难有/找到音译平行语料库是足够大的训练系统。在这项工作中，我们提出了基于期望最大化（EM）的音译技术，它是无监督和语言无关。系统学习的模式，从平行语料库超出词汇（OOV）的话，也没有必要训练它音译语料库明确。这种方法是在三个模型的统计机器翻译（SMT），其中包括phrasebased的测试，分层phrasebased和基于因子模型和神经机器翻译的两款车型，其中包括LSTM和变压器模型。</font>
</div>


<hr>
<div id="paper9"> <b>9. Language Models Are An Effective Patient Representation Learning  Technique For Electronic Health Record Data</b>  <a href="https://arxiv.org/pdf/2001.05295" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Steinberg%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Ethan Steinberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jung%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ken Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fries%2C+J+A" target="_blank" rel="noopener" style="color:#0000EE;">Jason A. Fries</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Corbin%2C+C+K" target="_blank" rel="noopener" style="color:#0000EE;">Conor K. Corbin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pfohl%2C+S+R" target="_blank" rel="noopener" style="color:#0000EE;">Stephen R. Pfohl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shah%2C+N+H" target="_blank" rel="noopener" style="color:#0000EE;">Nigam H. Shah</a><br>
<font size="3">
Abstract: Widespread adoption of electronic health records (EHRs) has fueled development of clinical outcome models using machine learning. However, patient EHR data are complex, and how to optimally represent them is an open question. This complexity, along with often small training set sizes available to train these clinical outcome models, are two core challenges for training high quality models. In this paper, we demonstrate that learning generic representations from the data of all the patients in the EHR enables better performing prediction models for clinical outcomes, allowing for these challenges to be overcome. We adapt common representation learning techniques used in other domains and find that representations inspired by language models enable a 3.5% mean improvement in AUROC on five clinical outcomes compared to standard baselines, with the average improvement rising to 19% when only a small number of patients are available for training a prediction model for a given clinical outcome. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：广泛采用的电子健康记录（电子病历）具有利用机器学习临床结果模型的燃料的发展。然而，患者的电子病历数据是复杂的，如何最优地表示他们是一个悬而未决的问题。这种复杂性，经常与小的训练集以及尺寸，以训练这些临床结果的模型，是培养高素质模型两个核心挑战。在本文中，我们证明了学习所有的患者在电子病历的数据一般表示为临床结果可以实现更好的进行预测模型，从而不必在克服这些挑战。我们采用通用表示学习其他领域使用的技术，并找到语言模型的启发是表示能够在AUROC五个临床结果3.5％的平均改善比标准的基线，平均提高上升到19％时，只有少数患者可用于训练预测模型对于给定的临床结果。</font>
</div>


<hr>
<div id="paper10"> <b>10. The empirical structure of word frequency distributions</b>  <a href="https://arxiv.org/pdf/2001.05292" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramscar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michael Ramscar</a><br>
<font size="3">
Abstract: The frequencies at which individual words occur across languages follow power law distributions, a pattern of findings known as Zipf's law. A vast literature argues over whether this serves to optimize the efficiency of human communication, however this claim is necessarily post hoc, and it has been suggested that Zipf's law may in fact describe mixtures of other distributions. From this perspective, recent findings that Sinosphere first (family) names are geometrically distributed are notable, because this is actually consistent with information theoretic predictions regarding optimal coding. First names form natural communicative distributions in most languages, and I show that when analyzed in relation to the communities in which they are used, first name distributions across a diverse set of languages are both geometric and, historically, remarkably similar, with power law distributions only emerging when empirical distributions are aggregated. I then show this pattern of findings replicates in communicative distributions of English nouns and verbs. These results indicate that if lexical distributions support efficient communication, they do so because their functional structures directly satisfy the constraints described by information theory, and not because of Zipf's law. Understanding the function of these information structures is likely to be key to explaining humankind's remarkable communicative capacities. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在发生个别单词跨语言服从幂律分布的频率，被称为齐普夫定律发现的模式。大量文献论证了，这是否用于优化人力沟通的效率，但这种说法必然是事后，这已经表明齐普夫定律，实际上可能描述的其他分布的混合。从这个角度来看，最近的调查结果Sinosphere第一（家庭）名称几何分布是显着的，因为这是关于最优编码信息理论预测实际上是一致的。名字形成大多数语言自然交际分布，我表明，在关系分析，在一组不同的语言中使用它们的社区，第一个名称发行时都是几何和，从历史上看，非常相似，幂律分布只有当经验分布聚集出现。然后我显示英语名词和动词的交际分布发现重复的这种模式。这些结果表明，如果词汇分布支持有效的沟通，他们这样做是因为他们的功能结构直接满足信息理论中描述的约束，并没有因为齐普夫定律。了解这些信息结构的功能很可能是关键，解释人类的非凡能力，交际。</font>
</div>


<hr>
<div id="paper11"> <b>11. Exploring and Improving Robustness of Multi Task Deep Neural Networks  via Domain Agnostic Defenses</b>  <a href="https://arxiv.org/pdf/2001.05286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Murali%2C+K+C" target="_blank" rel="noopener" style="color:#0000EE;">Kashyap Coimbatore Murali</a><br>
<font size="3">
Abstract: In this paper, we explore the robustness of the Multi-Task Deep Neural Networks (MT-DNN) against non-targeted adversarial attacks across Natural Language Understanding (NLU) tasks as well as some possible ways to defend against them. Liu et al., have shown that the Multi-Task Deep Neural Network, due to the regularization effect produced when training as a result of its cross task data, is more robust than a vanilla BERT model trained only on one task (1.1%-1.5% absolute difference). We further show that although the MT-DNN has generalized better, making it easily transferable across domains and tasks, it can still be compromised as after only 2 attacks (1-character and 2-character) the accuracy drops by 42.05% and 32.24% for the SNLI and SciTail tasks. Finally, we propose a domain agnostic defense which restores the model's accuracy (36.75% and 25.94% respectively) as opposed to a general-purpose defense or an off-the-shelf spell checker. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们探索了多任务深层神经网络（MT-DNN）的稳健性对整个自然语言理解（NLU）任务以及一些可能的方式来抵御这些非目标对抗性攻击。 Liu等人，已经表明，多任务深层的神经网络中，由于正规化效应产生当训练作为其横任务数据的结果是，比只在一个任务（1.1％培养了香草BERT模型更健壮 - 1.5％的绝对差）。进一步的研究表明，虽然MT-DNN具有更好的推广，使得它很容易跨域和任务转让的，它仍然可以作出妥协，只有2次攻击（1个字符和2个字符）的准确度42.05％和32.24％，下降后对于SNLI和SciTail任务。最后，我们提出了一个未知的领域国防其恢复模型的精确度（36.75％和25.94分别％），而不是通用的防守还是关闭的，现成的拼写检查器。</font>
</div>


<hr>
<div id="paper12"> <b>12. Detecting New Word Meanings: A Comparison of Word Embedding Models in  Spanish</b>  <a href="https://arxiv.org/pdf/2001.05285" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Torres-Rivera%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrés Torres-Rivera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Torres-Moreno%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Juan-Manuel Torres-Moreno</a><br>
<font size="3">
Abstract: Semantic neologisms (SN) are defined as words that acquire a new word meaning while maintaining their form. Given the nature of this kind of neologisms, the task of identifying these new word meanings is currently performed manually by specialists at observatories of neology. To detect SN in a semi-automatic way, we developed a system that implements a combination of the following strategies: topic modeling, keyword extraction, and word sense disambiguation. The role of topic modeling is to detect the themes that are treated in the input text. Themes within a text give clues about the particular meaning of the words that are used, for example: viral has one meaning in the context of computer science (CS) and another when talking about health. To extract keywords, we used TextRank with POS tag filtering. With this method, we can obtain relevant words that are already part of the Spanish lexicon. We use a deep learning model to determine if a given keyword could have a new meaning. Embeddings that are different from all the known meanings (or topics) indicate that a word might be a valid SN candidate. In this study, we examine the following word embedding models: Word2Vec, Sense2Vec, and FastText. The models were trained with equivalent parameters using Wikipedia in Spanish as corpora. Then we used a list of words and their concordances (obtained from our database of neologisms) to show the different embeddings that each model yields. Finally, we present a comparison of these outcomes with the concordances of each word to show how we can determine if a word could be a valid candidate for SN. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语义新词（SN）被定义为获得一个新词，同时保持其形式意义的话。鉴于这种新词的性质，目前手动专家在旧词新的天文台进行识别这些新词的意义的任务。为了检测SN以半自动化的方式，我们开发了一个系统，该系统实现了以下策略的组合：主题建模，关键词提取，以及词义消歧。主题建模的作用是检测在输入文本处理的主题。文本中的主题提供有关的被使用，例如词的特殊含义的线索：病毒只有一种含义在计算机科学（CS）和其他的方面讲卫生的时候。要提取的关键字，我们使用TextRank与POS标签过滤。通过这种方法，我们可以得到与已是西班牙词汇的一部分相关的词。我们使用了深刻的学习模式，以确定是否一个给定的关键字可能有新的意义。嵌入物是所有已知的含义（或主题）不同的指示词可能是一个有效的SN候选人。在这项研究中，我们考察以下单词嵌入型号：Word2Vec，Sense2Vec和FastText。模特们在西班牙使用维基百科语料库等效参数训练。然后我们使用的单词的列表和他们的语词（从我们的新词的数据库中获得）来显示不同的嵌入每个型号的产量。最后，我们提出这些结果与每个单词的词汇索引的比较，以显示我们如何确定一个词可能是SN有效候选人。</font>
</div>


<hr>
<div id="paper13"> <b>13. Improving Spoken Language Understanding By Exploiting ASR N-best  Hypotheses</b>  <a href="https://arxiv.org/pdf/2001.05284" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mingda Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ruan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weitong Ruan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinyue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soldaini%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luca Soldaini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hamza%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wael Hamza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Su%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chengwei Su</a><br>
<font size="3">
Abstract: In a modern spoken language understanding (SLU) system, the natural language understanding (NLU) module takes interpretations of a speech from the automatic speech recognition (ASR) module as the input. The NLU module usually uses the first best interpretation of a given speech in downstream tasks such as domain and intent classification. However, the ASR module might misrecognize some speeches and the first best interpretation could be erroneous and noisy. Solely relying on the first best interpretation could make the performance of downstream tasks non-optimal. To address this issue, we introduce a series of simple yet efficient models for improving the understanding of semantics of the input speeches by collectively exploiting the n-best speech interpretations from the ASR module. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在现代口语理解（SLU）系统，自然语言理解（NLU）模块需要一个讲话的解释从自动语音识别（ASR）模块的输入。该NLU模块通常使用一个给定的讲话在下游任务，如域名和意图分类第一最好的诠释。然而，ASR模块可能误识别的一些讲话和第一最好的诠释可能是错误的和嘈杂。仅仅依靠第一最好的诠释可以使下游任务的性能最优的。为了解决这个问题，我们引入了一系列简单而有效的模型，通过集体从ASR模块利用N条最佳演讲诠释提高输入演讲的语义的理解。</font>
</div>


<hr>
<div id="paper14"> <b>14. FGN: Fusion Glyph Network for Chinese Named Entity Recognition</b>  <a href="https://arxiv.org/pdf/2001.05272" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xuan%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhenyu Xuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bao%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rui Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chuyu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shengyi Jiang</a><br>
<font size="3">
Abstract: Chinese NER is a challenging task. As pictographs, Chinese characters contain latent glyph information, which is often overlooked. We propose the FGN, Fusion Glyph Network for Chinese NER. This method may offer glyph information for fusion representation learning with BERT. The major innovations of FGN include: (1) a novel CNN structure called CGS-CNN is proposed to capture glyph information from both character graphs and their neighboring graphs. (2) we provide a method with sliding window and Slice-Attention to extract interactive information between BERT representation and glyph representation. Experiments are conducted on four NER datasets, showing that FGN with LSTM-CRF as tagger achieves new state-of-the-arts performance for Chinese NER. Further, more experiments are conducted to investigate the influences of various components and settings in FGN. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：中国NER是一个具有挑战性的任务。作为象形文字，中国字符包含潜在的字形信息，这些信息往往被忽视。我们提出了FGN，融合雕文网中国ER。这种方法可以提供融合表示学习与BERT字形信息。 FGN的主要创新点包括：（1）所谓的CGS-CNN一种新颖的CNN结构，提出从两个字符图和其周边图形捕获字形信息。 （2）我们提供具有滑动窗口和切片-注意提取BERT表示和字形表示之间的交互信息的方法。实验是在四个NER数据集进行，显示为恶搞实现国家的最艺术的新的性能为中国NER与LSTM-CRF是FGN。此外，更多的实验以调查FGN的各种组件和设置的影响。</font>
</div>


<hr>
<div id="paper15"> <b>15. A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation</b>  <a href="https://arxiv.org/pdf/2001.05139" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Guan%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhihao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoyan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minlie Huang</a><br>
<font size="3">
Abstract: Story generation, namely generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling fluency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difficulty of associating relevant commonsense knowledge, understanding the causal relationships, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize commonsense knowledge from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we employ multi-task learning which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：故事的产生，即产生从一个领先的情况下合理的故事，是一个重要而艰巨的任务。尽管在模拟的流畅性和局部连贯，现有的神经语言生成模型的成功（例如，GPT-2）仍从重复，逻辑冲突受到影响，并且缺乏长程的在产生的故事的连贯性。我们推测，这是因为关联相关常识的知识，理解因果关系，并计划实体和事件的适当时间顺序的难度。在本文中，我们设计了常识性的故事，一代知识强化训练前的模式。我们建议利用来自外部的知识基础常识知识产生合理的故事。为了进一步捕获的因果关系，并在合理的故事句子之间的时间相关性，我们采用多任务学习相结合的具有区分客观区分微调过程中真实和虚假的故事。自动和手动评估表明，我们的模型能够产生更合理的故事，比国家的最先进的基线，特别是在逻辑和全球协调方面。</font>
</div>


<hr>
<div id="paper16"> <b>16. Parallel Machine Translation with Disentangled Context Transformer</b>  <a href="https://arxiv.org/pdf/2001.05136" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kasai%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jungo Kasai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cross%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">James Cross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ghazvininejad%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marjan Ghazvininejad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiatao Gu</a><br>
<font size="3">
Abstract: State-of-the-art neural machine translation models generate a translation from left to right and every step is conditioned on the previously generated tokens. The sequential nature of this generation process causes fundamental latency in inference since we cannot generate multiple tokens in each sentence in parallel. We propose an attention-masking based model, called Disentangled Context (DisCo) transformer, that simultaneously generates all tokens given different contexts. The DisCo transformer is trained to predict every output token given an arbitrary subset of the other reference tokens. We also develop the parallel easy-first inference algorithm, which iteratively refines every token in parallel and reduces the number of required iterations. Our extensive experiments on 7 directions with varying data sizes demonstrate that our model achieves competitive, if not better, performance compared to the state of the art in non-autoregressive machine translation while significantly reducing decoding time on average. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：国家的最先进的从左至右和每一步的前提是之前生成的令牌神经机器翻译模型生成翻译。这个生成过程的有序性导致的推论根本延迟，因为我们不能生成并行每个句子多个令牌。我们建议注意的遮蔽基于模型，称为迎刃而解上下文（迪斯科）变压器，能够同时生成给出不同的上下文中的所有令牌。迪斯科变压器训练以预测每个输出令牌给出的其它参考标记的任意子集。我们还开发并行易先推理算法，反复细化每个令牌并行，减少了所需的迭代次数。我们对7点的方向具有不同大小的数据大量的实验证明，如果没有更好的，性能比现有技术中的非自回归机器翻译的状态，而显著减少平均解码时间我们的模型实现了有竞争力的。</font>
</div>


<hr>
<div id="paper17"> <b>17. Robust Speaker Recognition Using Speech Enhancement And Attention Model</b>  <a href="https://arxiv.org/pdf/2001.05031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanpei Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hain%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Hain</a><br>
<font size="3">
Abstract: In this paper, a novel architecture for speaker recognition is proposed by cascading speech enhancement and speaker processing. Its aim is to improve speaker recognition performance when speech signals are corrupted by noise. Instead of individually processing speech enhancement and speaker recognition, the two modules are integrated into one framework by a joint optimisation using deep neural networks. Furthermore, to increase robustness against noise, a multi-stage attention mechanism is employed to highlight the speaker related features learned from context information in time and frequency domain. To evaluate speaker identification and verification performance of the proposed approach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark datasets. Moreover, the robustness of our proposed approach is also tested on VoxCeleb1 data when being corrupted by three types of interferences, general noise, music, and babble, at different signal-to-noise ratio (SNR) levels. The obtained results show that the proposed approach using speech enhancement and multi-stage attention models outperforms two strong baselines not using them in most acoustic conditions in our experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文对说话人识别一个新颖的架构通过级联语音增强和扬声器的处理建议。其目的是为了提高说话人识别性能时，语音信号被噪声干扰。而不是单独处理语音增强和说话人识别，这两个模块是通过使用深层神经网络的联合优化集成到一个框架。此外，为了增加可以有效抵抗噪声，采用多级注意机制，突出显示上下文信息在时间和频域学会了说话者相关的功能。为了评价说话人识别和建议的方法验证性能，我们测试它VoxCeleb1，大多采用标准数据集之一的数据集。此外，我们的建议的方法的稳健性上VoxCeleb1数据还测试由三种类型的干扰，一般噪声，音乐和多路重合，在不同的信噪比（SNR）水平被损坏时。得到的结果表明，该方法使用语音增强和多级车型的关注性能优于两周强的基线没有在我们的实验中最声学条件下使用它们。</font>
</div>


<hr>
<div id="paper18"> <b>18. A Tree Adjoining Grammar Representation for Models Of Stochastic  Dynamical Systems</b>  <a href="https://arxiv.org/pdf/2001.05320" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Khandelwal%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dhruv Khandelwal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Schoukens%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maarten Schoukens</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=T%C3%B3th%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roland Tóth</a><br>
<font size="3">
Abstract: Model structure and complexity selection remains a challenging problem in system identification, especially for parametric non-linear models. Many Evolutionary Algorithm (EA) based methods have been proposed in the literature for estimating model structure and complexity. In most cases, the proposed methods are devised for estimating structure and complexity within a specified model class and hence these methods do not extend to other model structures without significant changes. In this paper, we propose a Tree Adjoining Grammar (TAG) for stochastic parametric models. TAGs can be used to generate models in an EA framework while imposing desirable structural constraints and incorporating prior knowledge. In this paper, we propose a TAG that can systematically generate models ranging from FIRs to polynomial NARMAX models. Furthermore, we demonstrate that TAGs can be easily extended to more general model classes, such as the non-linear Box-Jenkins model class, enabling the realization of flexible and automatic model structure and complexity selection via EA. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：模型的结构和复杂的选择仍然在系统识别一个具有挑战性的问题，尤其是对于参数非线性模型。许多进化算法（EA）为基础的方法在文献中已经提出了用于估计模型结构和复杂性。在大多数情况下，所提出的方法被设计为在指定模型类内估计结构和复杂性，并因此这些方法不延伸到其他模型结构而不显著变化。在本文中，我们提出了一个树连接语法（TAG）为随机参数模型。标签可以用于在EA框架来生成模型，同时施加理想的结构约束和结合先验知识。在本文中，我们提出了一个标记，可以系统地生成模型，从FIR的多项式NARMAX模型。此外，我们证明，标签可以容易地扩展到更一般的模型类，诸如非线性箱Jenkins模型类，可实现灵活和自动模型结构和复杂选择经由EA实现。</font>
</div>


<hr>
<div id="paper19"> <b>19. Auto Completion of User Interface Layout Design Using Transformer-Based  Tree Decoders</b>  <a href="https://arxiv.org/pdf/2001.05308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Amelot%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Amelot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bengio%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Samy Bengio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Si%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Si Si</a><br>
<font size="3">
Abstract: It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：一直在该领域越来越多的关注，开发自动机器方便的设计过程。在本文中，我们侧重于帮助图形用户界面（UI）布局设计，在应用发展的重要任务。鉴于部分的布局，设计师已经进入，我们的模型学会通过预测与正确的位置和尺寸，其余的UI元素以及分层结构完成全国布局。这样的自动化将显著缓解UI设计师和开发人员的努力。虽然我们专注于界面布局的预测，我们的模型可以普遍适用于涉及树形结构和二维展示位置等布局预报问题。特别是，我们设计了基于变压器的树解码器的两个版本：指针和递归变压器，并与公共数据集，这些模型进行试验。我们还提出几个指标，用于测量树预测的准确性，并在用户体验领域地这些指标。这些贡献了新的任务和方法，深度学习研究。</font>
</div>


<hr>
<div id="paper20"> <b>20. Teddy: A System for Interactive Review Analysis</b>  <a href="https://arxiv.org/pdf/2001.05171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Engel%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jonathan Engel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Evensen%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sara Evensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Demiralp%2C+%C3%87" target="_blank" rel="noopener" style="color:#0000EE;">Çağatay Demiralp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wang-Chiew Tan</a><br>
<font size="3">
Abstract: Reviews are integral to e-commerce services and products. They contain a wealth of information about the opinions and experiences of users, which can help better understand consumer decisions and improve user experience with products and services. Today, data scientists analyze reviews by developing rules and models to extract, aggregate, and understand information embedded in the review text. However, working with thousands of reviews, which are typically noisy incomplete text, can be daunting without proper tools. Here we first contribute results from an interview study that we conducted with fifteen data scientists who work with review text, providing insights into their practices and challenges. Results suggest data scientists need interactive systems for many review analysis tasks. In response we introduce Teddy, an interactive system that enables data scientists to quickly obtain insights from reviews and improve their extraction and modeling pipelines. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：评论是不可或缺的电子商务服务和产品。它们包含了大量关于用户的意见和经验，这有助于更好地了解消费者的决策和提高产品和服务的用户体验信息。如今，科学家数据分析通过制定规则和模型来提取，汇总评价，并了解嵌入在审查文本信息。然而，成千上万的评论，这是典型的吵不完整的文本工作，可没有合适的工具望而生畏。在这里，我们首先从访谈研究，我们具有十五数据科学家谁的工作与评论文本进行，提供洞察到他们的做法和挑战作出贡献的结果。结果表明数据科学家需要对很多的评论分析任务的交互系统。在回应我们介绍泰迪，一个互动系统，使数据科学家能够迅速从审查获得洞察力和改善他们的提取和建模管道。</font>
</div>


<hr>
<div id="paper21"> <b>21. Modeling Product Search Relevance in e-Commerce</b>  <a href="https://arxiv.org/pdf/2001.04980" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Iyer%2C+R+R" target="_blank" rel="noopener" style="color:#0000EE;">Rahul Radhakrishnan Iyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kohli%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rohan Kohli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Prabhumoye%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shrimai Prabhumoye</a><br>
<font size="3">
Abstract: With the rapid growth of e-Commerce, online product search has emerged as a popular and effective paradigm for customers to find desired products and engage in online shopping. However, there is still a big gap between the products that customers really desire to purchase and relevance of products that are suggested in response to a query from the customer. In this paper, we propose a robust way of predicting relevance scores given a search query and a product, using techniques involving machine learning, natural language processing and information retrieval. We compare conventional information retrieval models such as BM25 and Indri with deep learning models such as word2vec, sentence2vec and paragraph2vec. We share some of our insights and findings from our experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：随着电子商务的快速发展，在线产品搜索已经成为一种流行和有效的模式，为客户找到所需的产品和从事网上购物。然而，仍然有客户真正渴望的产品的购买和相关性被提出以响应来自客户的查询产品之间有很大的差距。在本文中，我们提出了预测给定的搜索查询和产品的相关性分值，使用涉及机器学习，自然语言处理和信息检索技术的可靠方式。我们比较传统的信息检索模型如BM25和大狐猴与深度学习模式，如word2vec，sentence2vec和paragraph2vec。我们分享我们的一些见解和研究结果，从我们的实验。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-15</title>
    <url>/2020/01/16/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-15/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning <a href="https://arxiv.org/pdf/2001.04935" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Balancing the composition of word embeddings across heterogenous data  sets <a href="https://arxiv.org/pdf/2001.04693" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Bi-Decoder Augmented Network for Neural Machine Translation <a href="https://arxiv.org/pdf/2001.04586" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> On the Replicability of Combining Word Embeddings and Retrieval Models <a href="https://arxiv.org/pdf/2001.04484" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Detecting depression in dyadic conversations with multimodal narratives  and visualizations <a href="https://arxiv.org/pdf/2001.04809" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> A (Simplified) Supreme Being Necessarily Exists -- Says the Computer! <a href="https://arxiv.org/pdf/2001.04701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Improved Robust ASR for Social Robots in Public Spaces <a href="https://arxiv.org/pdf/2001.04619" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Faster Transformer Decoding: N-gram Masked Self-Attention <a href="https://arxiv.org/pdf/2001.04589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning</b>  <a href="https://arxiv.org/pdf/2001.04935" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Schuster%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roei Schuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schuster%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tal Schuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Meri%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yoav Meri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shmatikov%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vitaly Shmatikov</a><br>
<font size="3">
Abstract: Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word "meaning" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks. Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the "meaning" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another. An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：字的嵌入，即，低维向量表示，如手套和SGNS，编码字在这个意义上，词语向量之间的距离对应于它们的语义接近“意思是”。这使语义的迁移学习的各种自然语言处理任务。 Word中的嵌入通常是受过训练的大型公共语料库，如维基百科或Twitter。我们表明，攻击者谁可以修改其嵌入训练可以通过改变空间嵌入它们的位置控制的新的和现有的词“意义”的语料库。我们开发了语料库的特点，可作为单词之间距离的代理明确的表达，并建立自己的价值观和嵌入的距离之间的因果关系。然后，我们展示了如何使用两个敌对目标的这种关系：（1）做一个字一个字的世界排名第一的邻居，和（2）从一个语义集群移动一个字到另一个。在嵌入的攻击会影响不同的下游任务，这表明首次数据传输学习情境中毒的力量。我们使用这种攻击来操纵信息检索系统，如简历搜索查询扩展，使某些名字命名实体识别模型或多或少可见，并造成新词被翻译成特定的目标词无论使用什么语言。最后，我们展示了攻击者如何产生语言上可能语料库修改，从而欺骗试图难以置信的句子从使用语言模型的语料库过滤防御。</font>
</div>


<hr>
<div id="paper2"> <b>2. Balancing the composition of word embeddings across heterogenous data  sets</b>  <a href="https://arxiv.org/pdf/2001.04693" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Brandl%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stephanie Brandl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lassner%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Lassner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Alber%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maximilian Alber</a><br>
<font size="3">
Abstract: Word embeddings capture semantic relationships based on contextual information and are the basis for a wide variety of natural language processing applications. Notably these relationships are solely learned from the data and subsequently the data composition impacts the semantic of embeddings which arguably can lead to biased word vectors. Given qualitatively different data subsets, we aim to align the influence of single subsets on the resulting word vectors, while retaining their quality. In this regard we propose a criteria to measure the shift towards a single data subset and develop approaches to meet both objectives. We find that a weighted average of the two subset embeddings balances the influence of those subsets while word similarity performance decreases. We further propose a promising optimization approach to balance influences and quality of word embeddings. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于上下文信息的嵌入Word中捕捉语义关系，并且是各种各样的自然语言处理应用的基础。值得注意的是这些关系仅由数据并随后将数据组合物影响的语义的嵌入可论证可导致偏置字矢量的教训。考虑到质的不同数据子集，我们的目标是一致的最终的字向量单亚群的影响力，同时保持它们的质量。在这方面，我们提出了一个标准来衡量一个单一的数据子集的转变和发展途径，以满足这两个目标。我们发现，两个子集的嵌入的加权平均余额部分数据的影响，而单词类似性能降低。我们进一步提出了一个有前途的优化方法来平衡影响和字的嵌入质量。</font>
</div>


<hr>
<div id="paper3"> <b>3. Bi-Decoder Augmented Network for Neural Machine Translation</b>  <a href="https://arxiv.org/pdf/2001.04586" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Pan%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Boyuan Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yazheng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhou Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhuang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yueting Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cai%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Deng Cai</a><br>
<font size="3">
Abstract: Neural Machine Translation (NMT) has become a popular technology in recent years, and the encoder-decoder framework is the mainstream among all the methods. It's obvious that the quality of the semantic representations from encoding is very crucial and can significantly affect the performance of the model. However, existing unidirectional source-to-target architectures may hardly produce a language-independent representation of the text because they rely heavily on the specific relations of the given language pairs. To alleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented Network (BiDAN) for the neural machine translation task. Besides the original decoder which generates the target language sequence, we add an auxiliary decoder to generate back the source language sequence at the training time. Since each decoder transforms the representations of the input text into its corresponding language, jointly training with two target ends can make the shared encoder has the potential to produce a language-independent semantic space. We conduct extensive experiments on several NMT benchmark datasets and the results demonstrate the effectiveness of our proposed approach. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：神经机器翻译（NMT）已经成为一种流行的技术，近年来，和编码器，解码器的结构与第方法中所有的主流。很明显，从编码语义表示的质量是非常重要的，可以显著影响模型的性能。但是，现有的单向源到目标架构可以几乎不产生文本的语言无关的表示，因为他们在很大程度上依赖于特定的语言对的特定关系。为了缓解这一问题，在本文中，我们提出了一个新颖的双解码器增强网络（毕单）的神经机器翻译的任务。除了生成目标语言序列原有解码器，我们添加辅助解码器，以生成回到了训练时间的源语言序列。因为每个解码器将输入的文本的表示成其相应的语言，共同具有两个靶的端部的训练可以使共享编码器具有以产生独立于语言的语义空间的潜力。我们几个NMT基准数据集进行了广泛的实验，结果证明我们提出的方法的有效性。</font>
</div>


<hr>
<div id="paper4"> <b>4. On the Replicability of Combining Word Embeddings and Retrieval Models</b>  <a href="https://arxiv.org/pdf/2001.04484" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Papariello%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luca Papariello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bampoulidis%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexandros Bampoulidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lupu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mihai Lupu</a><br>
<font size="3">
Abstract: We replicate recent experiments attempting to demonstrate an attractive hypothesis about the use of the Fisher kernel framework and mixture models for aggregating word embeddings towards document representations and the use of these representations in document classification, clustering, and retrieval. Specifically, the hypothesis was that the use of a mixture model of von Mises-Fisher (VMF) distributions instead of Gaussian distributions would be beneficial because of the focus on cosine distances of both VMF and the vector space model traditionally used in information retrieval. Previous experiments had validated this hypothesis. Our replication was not able to validate it, despite a large parameter scan space. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近期重复实验，试图证明有关使用费的内核架构和混合模型的聚集对文档表示字的嵌入和使用文档分类，聚类和检索这些表象的一个有吸引力的假说。具体而言，假设是使用冯米塞斯-Fisher分析（VMF）的混合物模型的分布，而不是高斯分布将是因为聚焦在两个VMF和信息检索传统上使用向量空间模型的余弦距离的有益的。以前的实验已经证实了这一假设。我们的复制无法验证它，尽管大的参数扫描空间。</font>
</div>


<hr>
<div id="paper5"> <b>5. Detecting depression in dyadic conversations with multimodal narratives  and visualizations</b>  <a href="https://arxiv.org/pdf/2001.04809" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+J+Y" target="_blank" rel="noopener" style="color:#0000EE;">Joshua Y. Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+G+Y" target="_blank" rel="noopener" style="color:#0000EE;">Greyson Y. Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yacef%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kalina Yacef</a><br>
<font size="3">
Abstract: Conversations contain a wide spectrum of multimodal information that gives us hints about the emotions and moods of the speaker. In this paper, we developed a system that supports humans to analyze conversations. Our main contribution is the identification of appropriate multimodal features and the integration of such features into verbatim conversation transcripts. We demonstrate the ability of our system to take in a wide range of multimodal information and automatically generated a prediction score for the depression state of the individual. Our experiments showed that this approach yielded better performance than the baseline model. Furthermore, the multimodal narrative approach makes it easy to integrate learnings from other disciplines, such as conversational analysis and psychology. Lastly, this interdisciplinary and automated approach is a step towards emulating how practitioners record the course of treatment as well as emulating how conversational analysts have been analyzing conversations by hand. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话包含的多模式信息范围广泛，让我们有预兆说话者的情绪和心情。在本文中，我们开发了一个系统，支持人类分析的对话。我们的主要贡献是适当的多模式特征的识别和整合这些功能集成到逐字谈话笔录。我们证明我们的系统采取广泛的多模式信息，并自动生成个人的抑郁状态的预测得分的能力。我们的实验表明，这种方法取得了比基线模型更好的性能。此外，多模式的叙事方法，可以轻松集成到其他学科，如会话分析和心理学的学习收获。最后，这种跨学科的和自动化的方法是对模拟从业者如何记录治疗过程，以及如何模拟对话分析家一直用手分析对话的一个步骤。</font>
</div>


<hr>
<div id="paper6"> <b>6. A (Simplified) Supreme Being Necessarily Exists -- Says the Computer!</b>  <a href="https://arxiv.org/pdf/2001.04701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Benzm%C3%BCller%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christoph Benzmüller</a><br>
<font size="3">
Abstract: A simplified variant of Kurt Gödel's modal ontological argument is presented. Some of Gödel's, resp. Scott's, premises are modified, others are dropped, and modal collapse is avoided. The emended argument is shown valid already in quantified modal logic K. The presented simplifications have been computationally explored utilising latest knowledge representation and reasoning technology based on higher-order logic. The paper thus illustrates how modern symbolic AI technology can contribute new knowledge to formal philosophy and theology. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：哥德尔的模式本体论的简化变体显示。有些哥德尔，RESP的。斯科特的，房屋被修改，其他被丢弃，避免了模态崩溃。在仔细的校勘参数显示有效的已量化模态逻辑K.所提出的简化了计算研究利用最新的知识表示和基于高阶逻辑推理技术。因此，阐述了象征性的AI技术如何现代可以促进新知识的正式哲学和神学。</font>
</div>


<hr>
<div id="paper7"> <b>7. Improved Robust ASR for Social Robots in Public Spaces</b>  <a href="https://arxiv.org/pdf/2001.04619" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Jankowski%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Charles Jankowski</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mruthyunjaya%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vishwas Mruthyunjaya</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Lin%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruixi Lin</a><br>
<font size="3">
Abstract: Social robots deployed in public spaces present a challenging task for ASR because of a variety of factors, including noise SNR of 20 to 5 dB. Existing ASR models perform well for higher SNRs in this range, but degrade considerably with more noise. This work explores methods for providing improved ASR performance in such conditions. We use the AiShell-1 Chinese speech corpus and the Kaldi ASR toolkit for evaluations. We were able to exceed state-of-the-art ASR performance with SNR lower than 20 dB, demonstrating the feasibility of achieving relatively high performing ASR with open-source toolkits and hundreds of hours of training data, which is commonly available. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：部署在公共场所的社交机器人目前由于多种因素的影响，其中包括20至5分贝的噪音信噪比ASR一项艰巨的任务。现有ASR模型表现良好在这个范围内的较高的信噪比，但更多的噪音大大降低。这项工作探索提供在这样的条件下改善ASR性能的方法。我们使用AiShell-1中国语料库和Kaldi ASR工具包的评估。我们能够超过信噪比国家的最先进的ASR性能大于20dB低，表明达到比较高的用开源工具包和数以百计的训练数据，这是通常可以利用的时间来完成ASR的可行性。</font>
</div>


<hr>
<div id="paper8"> <b>8. Faster Transformer Decoding: N-gram Masked Self-Attention</b>  <a href="https://arxiv.org/pdf/2001.04589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chelba%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Ciprian Chelba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mia Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bapna%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Bapna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shazeer%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Noam Shazeer</a><br>
<font size="3">
Abstract: Motivated by the fact that most of the information relevant to the prediction of target tokens is drawn from the source sentence $S=s_1, \ldots, s_S$, we propose truncating the target-side window used for computing self-attention by making an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show that the $N$-gram masked self-attention model loses very little in BLEU score for $N$ values in the range $4, \ldots, 8$, depending on the task. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：事实上，大多数的相关目标令牌的预测信息从源句子$ S = S_1，\ ldots，S_S $绘制的启发，我们建议截断用于通过计算自我关注的目标侧窗做一个$ N $ -gram假设。在WMT恩德和EnFr数据集上的实验表明，$ N $ -gram掩盖自我注意模型的BLEU分数$ N $值的范围在$ 4 \ ldots，$ 8，根据任务非常小的损失。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-14</title>
    <url>/2020/01/15/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-14/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Multi-Source Domain Adaptation for Text Classification via  DistanceNet-Bandits <a href="https://arxiv.org/pdf/2001.04362" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark  for Chinese <a href="https://arxiv.org/pdf/2001.04351" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural  Architecture Search <a href="https://arxiv.org/pdf/2001.04246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Mining customer product reviews for product development: A summarization  process <a href="https://arxiv.org/pdf/2001.04200" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Joint Reasoning for Multi-Faceted Commonsense Knowledge <a href="https://arxiv.org/pdf/2001.04170" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> ProphetNet: Predicting Future N-gram for Sequence-to-Sequence  Pre-training <a href="https://arxiv.org/pdf/2001.04063" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Stochastic Natural Language Generation Using Dependency Information <a href="https://arxiv.org/pdf/2001.03897" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Rethinking Generalization of Neural Models: A Named Entity Recognition  Case Study <a href="https://arxiv.org/pdf/2001.03844" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Revisiting Challenges in Data-to-Text Generation with Fact Grounding <a href="https://arxiv.org/pdf/2001.03830" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Learning Cross-Context Entity Representations from Text <a href="https://arxiv.org/pdf/2001.03765" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> PatentTransformer-2: Controlling Patent Text Generation by Structural  Metadata <a href="https://arxiv.org/pdf/2001.03708" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Does syntax need to grow on trees? Sources of hierarchical inductive  bias in sequence-to-sequence networks <a href="https://arxiv.org/pdf/2001.03632" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Reformer: The Efficient Transformer <a href="https://arxiv.org/pdf/2001.04451" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured  Prediction <a href="https://arxiv.org/pdf/2001.04437" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Negative Statements Considered Useful <a href="https://arxiv.org/pdf/2001.04425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Asymmetrical Hierarchical Networks with Attentive Interactions for  Interpretable Review-Based Recommendation <a href="https://arxiv.org/pdf/2001.04346" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Shareable Representations for Search Query Understanding <a href="https://arxiv.org/pdf/2001.04345" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Improving Dysarthric Speech Intelligibility Using Cycle-consistent  Adversarial Training <a href="https://arxiv.org/pdf/2001.04260" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Structural Decompositions of Epistemic Logic Programs <a href="https://arxiv.org/pdf/2001.04219" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> A logic-based relational learning approach to relation extraction: The  OntoILPER system <a href="https://arxiv.org/pdf/2001.04192" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for  Language Grounding Tasks in Street View <a href="https://arxiv.org/pdf/2001.03671" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Multi-Source Domain Adaptation for Text Classification via  DistanceNet-Bandits</b>  <a href="https://arxiv.org/pdf/2001.04362" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Guo%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pasunuru%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ramakanth Pasunuru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: Domain adaptation performance of a learning algorithm on a target domain is a function of its source domain error and a divergence measure between the data distribution of these two domains. We present a study of various distance-based measures in the context of NLP tasks, that characterize the dissimilarity between domains based on sample estimates. We first conduct analysis experiments to show which of these distance measures can best differentiate samples from same versus different domains, and are correlated with empirical results. Next, we develop a DistanceNet model which uses these distance measures, or a mixture of these distance measures, as an additional loss function to be minimized jointly with the task's loss function, so as to achieve better unsupervised domain adaptation. Finally, we extend this model to a novel DistanceNet-Bandit model, which employs a multi-armed bandit controller to dynamically switch between multiple source domains and allow the model to learn an optimal trajectory and mixture of domains for transfer to the low-resource target domain. We conduct experiments on popular sentiment analysis datasets with several diverse domains and show that our DistanceNet model, as well as its dynamic bandit variant, can outperform competitive baselines in the context of unsupervised domain adaptation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对目标域学习算法的域自适应性能是它的源域误差的函数和这两个结构域的数据分布之间的偏差度量。我们提出的在NLP任务范围内各种基于距离的测量，表征根据样本估计域间的差异性进行了研究。我们首先进行分析实验表明其中的这些距离措施最好的分化样本相同与不同的域，并与实验结果是相关的。接下来，我们开发出使用这些距离的措施，或者这些距离测量的混合物DistanceNet模型，作为额外的损失函数要与任务的损失函数共同最小化，从而达到更好的无监督的领域适应性。最后，我们扩展该模型以一种新颖的DistanceNet匪模型，其采用多臂老虎控制器到多个源域之间动态开关和允许模型学习域的最佳轨迹和混合物，然后转移到低资源目标域。我们进行了对流行的情感分析数据集实验与多个不同领域，并表明我们的模型DistanceNet，以及它的动态强盗变种，可以在无人监督的领域适应性的背景下跑赢大市的竞争基准。</font>
</div>


<hr>
<div id="paper2"> <b>2. CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark  for Chinese</b>  <a href="https://arxiv.org/pdf/2001.04351" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Liang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qianqian Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cong Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yin Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weitang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanwei Zhang</a><br>
<font size="3">
Abstract: In this paper, we introduce the NER dataset from CLUE organization (CLUENER2020), a well-defined fine-grained dataset for named entity recognition in Chinese. CLUENER2020 contains 10 categories. Apart from common labels like person, organization, and location, it contains more diverse categories. It is more challenging than current other Chinese NER datasets and could better reflect real-world applications. For comparison, we implement several state-of-the-art baselines as sequence labeling tasks and report human performance, as well as its analysis. To facilitate future work on fine-grained NER for Chinese, we release our dataset, baselines, and leader-board. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们将介绍从CLUE组织NER数据集（CLUENER2020），一个明确的细粒度数据集在中国命名实体识别。 CLUENER2020包含10个类别。除了像个人，组织和位置共同的标签，它包含了更多样化的类别。它比目前的其他中国NER数据集更具挑战性，更能反映现实世界的应用。为了便于比较，我们实现国家的最先进的一些基线为序列标注任务和报告人的表现，以及它的分析。为了方便日后对中国细粒度NER的工作，我们发布的数据集，基线和领袖板。</font>
</div>


<hr>
<div id="paper3"> <b>3. AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural  Architecture Search</b>  <a href="https://arxiv.org/pdf/2001.04246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daoyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yaliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minghui Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bofang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ding%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bolin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Deng%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongbo Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingren Zhou</a><br>
<font size="3">
Abstract: Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大型预训练的语言模型，如BERT表明它们在不同的自然语言处理任务的有效性。然而，巨大的参数尺寸使得它们很难在需要快速推断资源有限的实时应用进行部署。现有的方法压缩BERT为小机型，而这种压缩是任务无关，即对所有不同的下游任务相同的压缩BERT。由必要性和面向任务的BERT压缩的好处的启发，我们提出了一种新的压缩方法，AdaBERT，它利用微神经结构的搜索自动压缩成BERT任务自适应小型号为特定的任务。我们结合了面向任务的知识蒸馏损失提供搜索提示和效率意识的损失，搜索约束，这使得任务自适应BERT压缩一个很好的权衡效率和效益之间。我们评估几个NLP任务AdaBERT，结果表明，这些任务自适应压缩模型12.7倍至29.3x比推理时间和11.5倍BERT更快17.0x参数规模而言较小，而相当的性能得以维持。</font>
</div>


<hr>
<div id="paper4"> <b>4. Mining customer product reviews for product development: A summarization  process</b>  <a href="https://arxiv.org/pdf/2001.04200" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hou%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tianjun Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yannou%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bernard Yannou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Leroy%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yann Leroy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poirson%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emilie Poirson</a><br>
<font size="3">
Abstract: This research set out to identify and structure from online reviews the words and expressions related to customers' likes and dislikes to guide product development. Previous methods were mainly focused on product features. However, reviewers express their preference not only on product features. In this paper, based on an extensive literature review in design science, the authors propose a summarization model containing multiples aspects of user preference, such as product affordances, emotions, usage conditions. Meanwhile, the linguistic patterns describing these aspects of preference are discovered and drafted as annotation guidelines. A case study demonstrates that with the proposed model and the annotation guidelines, human annotators can structure the online reviews with high inter-agreement. As high inter-agreement human annotation results are essential for automatizing the online review summarization process with the natural language processing, this study provides materials for the future study of automatization. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本研究着手从网上评论识别和结构关系到客户的好恶词语来指导产品的开发。先前的方法主要集中在产品功能。然而，评论家表达自己的喜好，不仅在产品功能。在本文的基础上，设计科学的全面的文献，作​​者提出了一个包含用户偏好的倍数方面，如产品的可供性，情绪，利用状况的总结模式。同时，描述偏好这些方面的语言模式被发现并起草作为注解的指导方针。案例研究表明，与所提出的模型和注释指引，人工注释就可以构建高之间的协议网上审查。由于采用协议间的人类标注的结果是与自然语言处理automatizing在线审核汇总过程中必不可少的，这项研究提供了自动化的未来学习材料。</font>
</div>


<hr>
<div id="paper5"> <b>5. Joint Reasoning for Multi-Faceted Commonsense Knowledge</b>  <a href="https://arxiv.org/pdf/2001.04170" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chalier%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yohan Chalier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Razniewski%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Razniewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weikum%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerhard Weikum</a><br>
<font size="3">
Abstract: Commonsense knowledge (CSK) supports a variety of AI applications, from visual understanding to chatbots. Prior works on acquiring CSK, such as ConceptNet, have compiled statements that associate concepts, like everyday objects or activities, with properties that hold for most or some instances of the concept. Each concept is treated in isolation from other concepts, and the only quantitative measure (or ranking) of properties is a confidence score that the statement is valid. This paper aims to overcome these limitations by introducing a multi-faceted model of CSK statements and methods for joint reasoning over sets of inter-related statements. Our model captures four different dimensions of CSK statements: plausibility, typicality, remarkability and salience, with scoring and ranking along each dimension. For example, hyenas drinking water is typical but not salient, whereas hyenas eating carcasses is salient. For reasoning and ranking, we develop a method with soft constraints, to couple the inference over concepts that are related in in a taxonomic hierarchy. The reasoning is cast into an integer linear programming (ILP), and we leverage the theory of reduction costs of a relaxed LP to compute informative rankings. This methodology is applied to several large CSK collections. Our evaluation shows that we can consolidate these inputs into much cleaner and more expressive knowledge. Results are available at this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：常识知识（CSK）支持多种AI应用，从视觉理解聊天机器人。在获取CSK之前的作品，如ConceptNet，编译语句关联的概念，像日常生活中的物体或活动，性质搁置了大部分或概念的若干实例。每个概念隔离治疗与其他概念和属性的唯一定量测量（或排序）是置信得分的声明是有效的。本文旨在通过引入CSK语句和方法的多面模型在台相互关联的语句联合推理来克服这些限制。我们的模型捕获CSK报表的四个维度：合理性，典型性，remarkability和显着性，与得分和沿每个维度的排名。例如，鬣狗饮用水是典型的但不显着，而鬣狗吃尸体是显着的。推理和排名，我们开发了一个方法与软约束，耦合，而忽视了在一个分类层次结构相关的概念推理。推理铸造成整数线性规划（ILP），和我们利用的轻松LP的降低成本的理论来计算信息排名。这种方法适用于几个大的CSK集合。我们的评估显示，我们可以整合这些投入更清洁，更富有表现力的知识。结果可在此HTTPS URL。</font>
</div>


<hr>
<div id="paper6"> <b>6. ProphetNet: Predicting Future N-gram for Sequence-to-Sequence  Pre-training</b>  <a href="https://arxiv.org/pdf/2001.04063" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yan%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yu Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weizhen Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gong%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yeyun Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dayiheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nan Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiusheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruofei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: In this paper, we present a new sequence-to-sequence pre-training model called ProphetNet, which introduces a novel self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism.Instead of the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time step.The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale dataset (160GB) respectively. Experimental results show ProphetNet achieves the best performance on both abstractive summarization and question generation tasks compared to the models using the same base scale pre-training dataset. For the large scale dataset pre-training, ProphetNet achieves new state-of-the-art results on Gigaword and comparable results on CNN/DailyMail using only about 1/5 pre-training epochs of the previous model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们提出名为ProphetNet一个新的序列到序列前的训练模式，它引入了一个新的自我监督的目标命名为将来的n-gram预测和建议的N流的自我关注的mechanism.Instead在传统的序列到序列模型中的一个步骤的提前预测的优化，ProphetNet由n-领先一步预测该预测下一个n各自时间step.The将来的n-gram在预测令牌同时基于先前上下文令牌明确地优化鼓励模型来规划未来的令牌，并防止过度拟合强大的本地相关性。我们使用碱规模的数据集（16GB）和分别大规模数据集（160GB）预列车ProphetNet。实验结果表明ProphetNet达到上相比，使用相同的基本预分训练数据集模型既抽象总结和询问生成任务的最佳性能。对于大规模数据集前培训，ProphetNet实现国家的最先进的新的Gigaword和使用CNN /每日邮报以前的型号只有约1/5前的训练时期比较的结果的结果。</font>
</div>


<hr>
<div id="paper7"> <b>7. Stochastic Natural Language Generation Using Dependency Information</b>  <a href="https://arxiv.org/pdf/2001.03897" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Seifossadat%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Elham Seifossadat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sameti%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hossein Sameti</a><br>
<font size="3">
Abstract: This article presents a stochastic corpus-based model for generating natural language text. Our model first encodes dependency relations from training data through a feature set, then concatenates these features to produce a new dependency tree for a given meaning representation, and finally generates a natural language utterance from the produced dependency tree. We test our model on nine domains from tabular, dialogue act and RDF format. Our model outperforms the corpus-based state-of-the-art methods trained on tabular datasets and also achieves comparable results with neural network-based approaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR evaluation metrics. Also, by reporting Human Evaluation results, we show that our model produces high-quality utterances in aspects of informativeness and naturalness as well as quality. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文介绍了生成自然语言文本随机基于语料库的模型。我们的模式首先编码的依赖性和通过功能训练数据集的关系，然后连接这些特征来产生一个给定的意思表示一个新的依赖关系树，最后产生从产生依赖关系树的自然语言语句。我们测试我们从表格，对话行为和RDF格式9个域模型。我们的模型优于训练有素的表格数据集基于语料库的国家的最先进的方法和也实现了比较的结果神经网络的基础上对话行为，E2E和WebNLG数据集的BLEU和ERR评价指标办法训练。此外，通过报告人的评价结果​​，我们表明，我们的模型在信息量和自然，以及质量方面的生产高品质的话语。</font>
</div>


<hr>
<div id="paper8"> <b>8. Rethinking Generalization of Neural Models: A Named Entity Recognition  Case Study</b>  <a href="https://arxiv.org/pdf/2001.03844" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jinlan Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pengfei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanjing Huang</a><br>
<font size="3">
Abstract: While neural network-based models have achieved impressive performance on a large body of NLP tasks, the generalization behavior of different models remains poorly understood: Does this excellent performance imply a perfect generalization model, or are there still some limitations? In this paper, we take the NER task as a testbed to analyze the generalization behavior of existing models from different perspectives and characterize the differences of their generalization abilities through the lens of our proposed measures, which guides us to better design models and training methods. Experiments with in-depth analyses diagnose the bottleneck of existing neural NER models in terms of breakdown performance analysis, annotation errors, dataset bias, and category relationships, which suggest directions for improvement. We have released the datasets: (ReCoNLL, PLONER) for the future research at our project page: this http URL. As a by-product of this paper, we have open-sourced a project that involves a comprehensive summary of recent NER papers and classifies them into different research topics: this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：尽管基于神经网络的模型已在大机构的NLP任务，取得了骄人的业绩，不同型号的遗体推广行为知之甚少：这是否出色表现意味着一个完美的泛化模型，还是有仍有一定的局限性？在本文中，我们采取了NER任务作为测试平台，分析从不同的角度现有车型的推广行为，并通过我们的建议措施的镜头，是指导我们更好地设计模型和训练方法表征其泛化能力的差异。在深入分析实验诊断现有的神经NER模型的瓶颈在击穿性能分析，标注错误，数据集偏见和类别的关系，其提出改进方向的术语。我们已经发布了数据集：（ReCoNLL，PLONER）对未来的研究，在我们的项目页面：这个HTTP URL。作为本文的副产品，我们有开源的，涉及到的最近NER文件，并将其分类，全面总结成不同的研究课题项目：该HTTPS URL。</font>
</div>


<hr>
<div id="paper9"> <b>9. Revisiting Challenges in Data-to-Text Generation with Fact Grounding</b>  <a href="https://arxiv.org/pdf/2001.03830" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongmin Wang</a><br>
<font size="3">
Abstract: Data-to-text generation models face challenges in ensuring data fidelity by referring to the correct input source. To inspire studies in this area, Wiseman et al. (2017) introduced the RotoWire corpus on generating NBA game summaries from the box- and line-score tables. However, limited attempts have been made in this direction and the challenges remain. We observe a prominent bottleneck in the corpus where only about 60% of the summary contents can be grounded to the boxscore records. Such information deficiency tends to misguide a conditioned language model to produce unconditioned random facts and thus leads to factual hallucinations. In this work, we restore the information balance and revamp this task to focus on fact-grounded data-to-text generation. We introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding), with 50% more data from the year 2017-19 and enriched input tables, hoping to attract more research focuses in this direction. Moreover, we achieve improved data fidelity over the state-of-the-art models by integrating a new form of table reconstruction as an auxiliary task to boost the generation quality. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：数据到文本代车型面临参照正确的输入源，确保数据的保真度的挑战。在这方面，怀斯曼等激励研究。 （2017）介绍了从箱 - 和线路得分表中生成的NBA比赛的摘要语料库RotoWire。然而，有限的尝试已在这方面取得和挑战依然存在。我们观察到，其中的总结内容只有约60％可以接地的技术统计记录的语料库一个突出的瓶颈。这样的信息不足往往误导了条件语言模型制作无条件随机的事实，从而导致实际的幻觉。在这项工作中，我们恢复信息平衡和改造这个任务专注于事实接地数据到文本生成。我们引进一个纯化和大规模数据集，RotoWire-FG（实况接地），从今年2017年覆盖和丰富的输入表50％以上的数据，希望能吸引更多的研究集中在这个方向。此外，我们通过表重建的一种新形式的积分作为辅助任务，以提高生成质量实现对国家的最先进的模型改进的数据的保真度。</font>
</div>


<hr>
<div id="paper10"> <b>10. Learning Cross-Context Entity Representations from Text</b>  <a href="https://arxiv.org/pdf/2001.03765" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ling%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jeffrey Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=FitzGerald%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nicholas FitzGerald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shan%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zifei Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soares%2C+L+B" target="_blank" rel="noopener" style="color:#0000EE;">Livio Baldini Soares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=F%C3%A9vry%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thibault Févry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weiss%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Weiss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kwiatkowski%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tom Kwiatkowski</a><br>
<font size="3">
Abstract: Language modeling tasks, in which words, or word-pieces, are predicted on the basis of a local context, have been very effective for learning word embeddings and context dependent representations of phrases. Motivated by the observation that efforts to code world knowledge into machine readable knowledge bases or human readable encyclopedias tend to be entity-centric, we investigate the use of a fill-in-the-blank task to learn context independent representations of entities from the text contexts in which those entities were mentioned. We show that large scale training of neural models allows us to learn high quality entity representations, and we demonstrate successful results on four domains: (1) existing entity-level typing benchmarks, including a 64% error reduction over previous work on TypeNet (Murty et al., 2018); (2) a novel few-shot category reconstruction task; (3) existing entity linking benchmarks, where we match the state-of-the-art on CoNLL-Aida without linking-specific features and obtain a score of 89.8% on TAC-KBP 2010 without using any alias table, external knowledge base or in domain training data and (4) answering trivia questions, which uniquely identify entities. Our global entity representations encode fine-grained type categories, such as Scottish footballers, and can answer trivia questions such as: Who was the last inmate of Spandau jail in Berlin? </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言建模任务，其中词或字块，在本地范围内的基础上预测，一直是学习的嵌入词和短语的背景有关的表示是非常有效的。通过观察该努力的代码世界知识转化为机器可读的知识基础或人类可读的百科全书往往是实体为中心的推动下，我们研究使用填充式的空白任务的学习实体的情况下独立表示从文本在这些实体中提到的上下文。我们展示的神经模型的规模大的培训，让我们了解高品质实体交涉，我们证明在四个主要领域成功的结果：（1）现有的实体层面打字的基准，其中包括64％的误差减少了以前的工作在键入net（穆尔蒂。等人，2018）; （2）一种新的几拍重建类别任务; （3）现有的实体连接的基准，在那里我们匹配状态的最先进的上CoNLL-阿依无需关联的特定功能，将获得于2010年05 TAC-KBP得分为89.8％，而无需使用任何别名表，外部知识库或在域训练数据和（4）回答琐事问题，唯一标识实体。我们的全球实体表示编码细粒度类型类别，如苏格兰足球运动员，并且可以回答小问题，如：谁是施潘道监狱在柏林的最后一个犯人？</font>
</div>


<hr>
<div id="paper11"> <b>11. PatentTransformer-2: Controlling Patent Text Generation by Structural  Metadata</b>  <a href="https://arxiv.org/pdf/2001.03708" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jieh-Sheng Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsiang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jieh Hsiang</a><br>
<font size="3">
Abstract: PatentTransformer is our codename for patent text generation based on Transformer-based models. Our goal is "Augmented Inventing." In this second version, we leverage more of the structural metadata in patents. The structural metadata includes patent title, abstract, and dependent claim, in addition to independent claim previously. Metadata controls what kind of patent text for the model to generate. Also, we leverage the relation between metadata to build a text-to-text generation flow, for example, from a few words to a title, the title to an abstract, the abstract to an independent claim, and the independent claim to multiple dependent claims. The text flow can go backward because the relation is trained bidirectionally. We release our GPT-2 models trained from scratch and our code for inference so that readers can verify and generate patent text on their own. As for generation quality, we measure it by both ROUGE and Google Universal Sentence Encoder. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：PatentTransformer是我们基于基于变压器的新型专利文本生成代号。我们的目标是“增强发明了。”在第二个版本中，我们利用更多的结构性元数据的专利。结构元数据包括专利标题，摘要，以及从属权利要求中，除了独立权利要求先前。元数据控制什么样的专利文本为模型来生成。此外，我们利用的元数据之间的关系，以建立一个文本到文本生成流，例如，从几话标题，标题为抽象，抽象到一个独立的权利要求，以及在独立权利要求到多个从属索赔。因为关系是双向训练文本流可以去落后。我们发布我们从头开始训练的GPT-2机型和我们推断代码，使读者可以验证并产生自己的专利文本。至于代的品质，我们双方ROUGE和谷歌万能句子编码器测量。</font>
</div>


<hr>
<div id="paper12"> <b>12. Does syntax need to grow on trees? Sources of hierarchical inductive  bias in sequence-to-sequence networks</b>  <a href="https://arxiv.org/pdf/2001.03632" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=McCoy%2C+R+T" target="_blank" rel="noopener" style="color:#0000EE;">R. Thomas McCoy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Frank%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Robert Frank</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Linzen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tal Linzen</a><br>
<font size="3">
Abstract: Learners that are exposed to the same training data might generalize differently due to differing inductive biases. In neural network models, inductive biases could in theory arise from any aspect of the model architecture. We investigate which architectural factors affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection. For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order. All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a tree-structured model rather than a model with sequential recurrence, suggesting that human-like syntactic generalization requires architectural syntactic structure. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：暴露在同样的训练数据学习者可以概括不同，由于不同的感性偏见。在神经网络模型，感性的偏见在理论上可以从模型架构的任何方面引起的。我们调查其建筑因素影响训练的两个句法任务，英语问题的形成和英语时态reinflection神经序列到序列模型的推广行为。对于这两个任务，训练集是基于层次结构和基于线性顺序的推广泛化一致。所有的建筑因素，我们调查定性的影响模型如何推广，其中包括没有明确的连接层次结构的因素。例如，LSTMs越冬和显示本质上不同的感应偏压。然而，持续推动整个任务的分层偏见的唯一因素是使用一个树形结构的模型，而不是连续的复发模型，这表明类似人类的语法概括要求的建筑句法结构。</font>
</div>


<hr>
<div id="paper13"> <b>13. Reformer: The Efficient Transformer</b>  <a href="https://arxiv.org/pdf/2001.04451" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kitaev%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nikita Kitaev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kaiser%2C+%C5%81" target="_blank" rel="noopener" style="color:#0000EE;">Łukasz Kaiser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Levskaya%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anselm Levskaya</a><br>
<font size="3">
Abstract: Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大型变压器模型通常实现多项任务的国家的最先进的成果，但训练这些模型可能极其昂贵的，特别是在长序列。我们介绍了两种技术来提高变压器的效率。首先，我们通过一个使用局部性敏感散列，从O（$ L ^ 2 $）至O（$ L \材L $），其中$ L $是的长度改变其复杂性替代点积关注顺序。此外，我们使用可逆残渣层而不是标准的残差，其允许在训练过程中，而不是$ N $倍，其中$ N $是层的数目仅一次存储激活。将得到的模型，重整器，而被更内存效率和长序列快得多与Transformer模型看齐进行。</font>
</div>


<hr>
<div id="paper14"> <b>14. LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured  Prediction</b>  <a href="https://arxiv.org/pdf/2001.04437" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Niculae%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vlad Niculae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Martins%2C+A+F+T" target="_blank" rel="noopener" style="color:#0000EE;">André F. T. Martins</a><br>
<font size="3">
Abstract: Structured prediction requires manipulating a large number of combinatorial structures, e.g., dependency trees or alignments, either as latent or output variables. Recently, the SparseMAP method has been proposed as a differentiable, sparse alternative to maximum a posteriori (MAP) and marginal inference. SparseMAP returns a combination of a small number of structures, a desirable property in some downstream applications. However, SparseMAP requires a tractable MAP inference oracle. This excludes, e.g., loopy graphical models or factor graphs with logic constraints, which generally require approximate inference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP that addresses this limitation via a local polytope relaxation. LP-SparseMAP uses the flexible and powerful domain specific language of factor graphs for defining and backpropagating through arbitrary hidden structure, supporting coarse decompositions, hard logic constraints, and higher-order correlations. We derive the forward and backward algorithms needed for using LP-SparseMAP as a hidden or output layer. Experiments in three structured prediction tasks show benefits compared to SparseMAP and Structured SVM. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：结构化预测需要操纵大量组合结构，例如，依赖树木或比对，无论是作为潜在的或输出变量。最近，SparseMAP方法已经被提出作为一个微的，稀疏替代最大后验（MAP）和边际推理。 SparseMAP返回少量的结构，在一些下游应用的期望特性的组合。然而，SparseMAP需要一个听话的地图推断预言。这不包括，例如，多圈图形模型或因子图与逻辑约束，这通常需要近似推断。在本文中，我们介绍了LP-SparseMAP，SparseMAP的扩展，地址通过本地多面体放松这一限制。 LP-SparseMAP使用用于定义和通过任意隐藏结构backpropagating，支撑粗分解，硬逻辑约束，和更高阶的相关性因子图的灵活和强大的域专用语言。我们推导需要使用LP-SparseMAP作为隐藏或输出层中的向前和向后的算法。在三个结构预测任务实验表明相比SparseMAP和结构化SVM的好处。</font>
</div>


<hr>
<div id="paper15"> <b>15. Negative Statements Considered Useful</b>  <a href="https://arxiv.org/pdf/2001.04425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Arnaout%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hiba Arnaout</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Razniewski%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Razniewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weikum%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerhard Weikum</a><br>
<font size="3">
Abstract: Knowledge bases (KBs), pragmatic collections of knowledge about notable entities, are an important asset in applications such as search, question answering and dialogue. Rooted in a long tradition in knowledge representation, all popular KBs only store positive information, while they abstain from taking any stance towards statements not contained in them. In this paper, we make the case for explicitly stating interesting statements which are not true. Negative statements would be important to overcome current limitations of question answering, yet due to their potential abundance, any effort towards compiling them needs a tight coupling with ranking. We introduce two approaches towards compiling negative statements. (i) In peer-based statistical inferences, we compare entities with highly related entities in order to derive potential negative statements, which we then rank using supervised and unsupervised features. (ii) In query-log-based text extraction, we use a pattern-based approach for harvesting search engine query logs. Experimental results show that both approaches hold promising and complementary potential. Along with this paper, we publish the first datasets on interesting negative information, containing over 1.1M statements for 100K popular Wikidata entities. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：知识库（KBS），约著名的实体知识务实的集合，是在应用程序，如搜索，问答和对话的重要资产。在知识表示有着悠久的传统根深蒂固，所有流行的知识库系统只保存正面信息，而他们从迈出不包含在他们陈述的任何立场弃权。在本文中，我们做出明确说明有趣的声明不属实的情况。克服答疑的电流限制否定陈述将是重要的，但由于其潜在的丰富，对编译他们的任何努力，需要与排名的紧密耦合。我们引入对编译否定陈述两种方法。 （一）在对等的统计推断，我们比较具有高度相关实体的实体，以得出潜在的负面陈述，然后我们使用级监督和无监督的功能。 （二）在查询日志基于文本的提取，我们用收获的搜索引擎查询日志基于模式的方法。实验结果表明，这两种方法保持承诺和互补的潜力。除了本文中，我们公布有趣的负面信息的第一数据集，包含100K流行的维基数据实体超过1.1M的语句。</font>
</div>


<hr>
<div id="paper16"> <b>16. Asymmetrical Hierarchical Networks with Attentive Interactions for  Interpretable Review-Based Recommendation</b>  <a href="https://arxiv.org/pdf/2001.04346" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ni%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingchao Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cheng%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhengzhang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zong%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bo Zong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dongjin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanchi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haifeng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=de+Melo%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerard de Melo</a><br>
<font size="3">
Abstract: Recently, recommender systems have been able to emit substantially improved recommendations by leveraging user-provided reviews. Existing methods typically merge all reviews of a given user or item into a long document, and then process user and item documents in the same manner. In practice, however, these two sets of reviews are notably different: users' reviews reflect a variety of items that they have bought and are hence very heterogeneous in their topics, while an item's reviews pertain only to that single item and are thus topically homogeneous. In this work, we develop a novel neural network model that properly accounts for this important difference by means of asymmetric attentive modules. The user module learns to attend to only those signals that are relevant with respect to the target item, whereas the item module learns to extract the most salient contents with regard to properties of the item. Our multi-hierarchical paradigm accounts for the fact that neither are all reviews equally useful, nor are all sentences within each review equally pertinent. Extensive experimental results on a variety of real datasets demonstrate the effectiveness of our method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近日，推荐系统已经能够通过利用用户提供的评论发出显着改善的建议。现有的方法通常合并给定用户或项目的所有评价为长的文档，然后处理以同样的方式用户和项目的文件。然而在实践中，这两组的评论是显着不同：用户的评价反映的各种物品，他们已经买了，并因此在其主题非常庞杂，而项目的审查只涉及到单个项目，因此是局部均匀。在这项工作中，我们开发了妥善占不对称周到模块的方式这一重要区别一个新的神经网络模型。用户模块学会照顾只有那些相关的相对于目标项目的信号，而项目模块学会了关于该项目的属性提取最突出的内容。我们的多层次模式考虑的事实是，无论是全部评论同样有用，也不是每个评论中的所有语句同样相关。在各种真实数据集的大量实验结果证明了该方法的有效性。</font>
</div>


<hr>
<div id="paper17"> <b>17. Shareable Representations for Search Query Understanding</b>  <a href="https://arxiv.org/pdf/2001.04345" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mukul Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youna Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Headden%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Will Headden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goutam%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rahul Goutam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heran Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yin%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bing Yin</a><br>
<font size="3">
Abstract: Understanding search queries is critical for shopping search engines to deliver a satisfying customer experience. Popular shopping search engines receive billions of unique queries yearly, each of which can depict any of hundreds of user preferences or intents. In order to get the right results to customers it must be known queries like "inexpensive prom dresses" are intended to not only surface results of a certain product type but also products with a low price. Referred to as query intents, examples also include preferences for author, brand, age group, or simply a need for customer service. Recent works such as BERT have demonstrated the success of a large transformer encoder architecture with language model pre-training on a variety of NLP tasks. We adapt such an architecture to learn intents for search queries and describe methods to account for the noisiness and sparseness of search query data. We also describe cost effective ways of hosting transformer encoder models in context with low latency requirements. With the right domain-specific training we can build a shareable deep learning model whose internal representation can be reused for a variety of query understanding tasks including query intent identification. Model sharing allows for fewer large models needed to be served at inference time and provides a platform to quickly build and roll out new search query classifiers. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：了解搜索查询是购物搜索引擎提供一个满意的客户体验至关重要。流行的购物搜索引擎获得数十亿年唯一的查询，每一个都可以描绘出任何数百个用户的偏好或意图的。为了得到正确的结果，必须知道像“便宜的舞会礼服”旨在不仅是某个产品类型的表面效果，也具有价格低的产品查询客户。称为查询意图，例子还包括作者，品牌，年龄组或只是需要为客户服务的偏好。最近的作品如BERT都展现了大型变压器编码器架构，拥有对各种NLP任务语言模型前培训的成功。我们采用这样的架构，以学习为搜索查询意图和描述的是占搜索查询数据的吵闹和稀疏。我们还描述在低延迟要求的背景下举办的变压器编码器模型的经济有效的方式。有了正确的特定领域的培训，我们可以建立其内部表示可以为多种查询理解任务，包括查询意图识别重复使用一个共享的深度学习模式。模型共享允许在需要推理时间送达较少的大型模型，并提供了一个平台快速构建并推出新的搜索查询的分类。</font>
</div>


<hr>
<div id="paper18"> <b>18. Improving Dysarthric Speech Intelligibility Using Cycle-consistent  Adversarial Training</b>  <a href="https://arxiv.org/pdf/2001.04260" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Yang%2C+S+H" target="_blank" rel="noopener" style="color:#0000EE;">Seung Hee Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Chung%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minhwa Chung</a><br>
<font size="3">
Abstract: Dysarthria is a motor speech impairment affecting millions of people. Dysarthric speech can be far less intelligible than those of non-dysarthric speakers, causing significant communication difficulties. The goal of our work is to develop a model for dysarthric to healthy speech conversion using Cycle-consistent GAN. Using 18,700 dysarthric and 8,610 healthy control Korean utterances that were recorded for the purpose of automatic recognition of voice keyboard in a previous study, the generator is trained to transform dysarthric to healthy speech in the spectral domain, which is then converted back to speech. Objective evaluation using automatic speech recognition of the generated utterance on a held-out test set shows that the recognition performance is improved compared with the original dysarthic speech after performing adversarial training, as the absolute WER has been lowered by 33.4%. It demonstrates that the proposed GAN-based conversion method is useful for improving dysarthric speech intelligibility. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：构音障碍是影响数百万人的电机语言障碍。构音障碍的言语可以比那些非构音障碍的扬声器远不如理解，造成显著沟通困难。我们工作的目标是开发用于构音障碍的使用周期一致甘健康语音转换模型。使用18700构音障碍，并且记录在先前的研究中自动识别语音键盘的目的8,610健康控制朝鲜的言论，发电机被训练在频域中，然后将其转换回语音转换构音障碍的健康讲话。客观评价使用上的保持输出测试组示出了识别性能与执行对抗性训练后的原始dysarthic语音相比得到改善，作为绝对WER已经被降低了33.4％的产生的话语的自动语音识别。这表明，所提出的基于GaN的转换方法是提高构音障碍的语音清晰度非常有用。</font>
</div>


<hr>
<div id="paper19"> <b>19. Structural Decompositions of Epistemic Logic Programs</b>  <a href="https://arxiv.org/pdf/2001.04219" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hecher%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Markus Hecher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Morak%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michael Morak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Woltran%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stefan Woltran</a><br>
<font size="3">
Abstract: Epistemic logic programs (ELPs) are a popular generalization of standard Answer Set Programming (ASP) providing means for reasoning over answer sets within the language. This richer formalism comes at the price of higher computational complexity reaching up to the fourth level of the polynomial hierarchy. However, in contrast to standard ASP, dedicated investigations towards tractability have not been undertaken yet. In this paper, we give first results in this direction and show that central ELP problems can be solved in linear time for ELPs exhibiting structural properties in terms of bounded treewidth. We also provide a full dynamic programming algorithm that adheres to these bounds. Finally, we show that applying treewidth to a novel dependency structure---given in terms of epistemic literals---allows to bound the number of ASP solver calls in typical ELP solving procedures. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：认知逻辑程序（电子学习）是标准的回答集编程（ASP）提供用于在语言中的推理在结果集的流行推广。这更丰富的形式主义来以较高的计算复杂性达到最高多项式层次的第四级的价格。然而，相对于标准的ASP，朝易处理专用的调查还没有进行呢。在本文中，我们让在这个方向的第一结果和表明中央ELP问题可以在线性时间内解决了在有界树宽的方面表现出结构性质电子学习。我们还提供一个完整的动态规划算法了符合这些界限。最后，我们表明，将树宽以一种新颖的依赖结构---在认识文字的形式给出---允许的ASP求解器的典型ELP解决过程的调用绑定的号码。</font>
</div>


<hr>
<div id="paper20"> <b>20. A logic-based relational learning approach to relation extraction: The  OntoILPER system</b>  <a href="https://arxiv.org/pdf/2001.04192" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lima%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rinaldo Lima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Espinasse%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bernard Espinasse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Freitas%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fred Freitas</a><br>
<font size="3">
Abstract: Relation Extraction (RE), the task of detecting and characterizing semantic relations between entities in text, has gained much importance in the last two decades, mainly in the biomedical domain. Many papers have been published on Relation Extraction using supervised machine learning techniques. Most of these techniques rely on statistical methods, such as feature-based and tree-kernels-based methods. Such statistical learning techniques are usually based on a propositional hypothesis space for representing examples, i.e., they employ an attribute-value representation of features. This kind of representation has some drawbacks, particularly in the extraction of complex relations which demand more contextual information about the involving instances, i.e., it is not able to effectively capture structural information from parse trees without loss of information. In this work, we present OntoILPER, a logic-based relational learning approach to Relation Extraction that uses Inductive Logic Programming for generating extraction models in the form of symbolic extraction rules. OntoILPER takes profit of a rich relational representation of examples, which can alleviate the aforementioned drawbacks. The proposed relational approach seems to be more suitable for Relation Extraction than statistical ones for several reasons that we argue. Moreover, OntoILPER uses a domain ontology that guides the background knowledge generation process and is used for storing the extracted relation instances. The induced extraction rules were evaluated on three protein-protein interaction datasets from the biomedical domain. The performance of OntoILPER extraction models was compared with other state-of-the-art RE systems. The encouraging results seem to demonstrate the effectiveness of the proposed solution. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：关系抽取（RE），检测和文本中的实体之间的表征语义关系的任务，获得了巨大的重要性在过去的二十年中，主要是在生物医学领域。许多论文已使用监督机器学习技术发表了关系抽取。这些技术大部分依赖于统计方法，如基于树的内核基于特征和方法。这样的统计学习的技术通常是基于用于表示实施例中，即一个命题假设空间，他们采用的特征的属性 - 值表示。这种表示法存在一些缺陷，特别是在复杂的关系，其中要求对涉及的情况下，即更多的上下文信息的提取，它不能有效地捕捉解析树结构信息不会丢失信息。在这项工作中，我们目前OntoILPER，一种基于逻辑的关系学习方法关系抽取使用归纳逻辑程序设计中的象征提取规则的形式产生的提取模式。 OntoILPER需要的例子丰富的关系表示，这可以减轻上述缺点的利润。拟议的关系的方式似乎更适合关系抽取比统计的人有几个原因，我们认为。此外，OntoILPER使用领域本体引导的背景知识生成处理，用于存储提取的关系实例。从生物医学域中的三个蛋白质 - 蛋白质相互作用数据集的感应提取规则进行评价。 OntoILPER提取模型的性能与国家的最先进的其它可再生能源系统进行了比较。令人鼓舞的结果似乎证明了该解决方案的有效性。</font>
</div>


<hr>
<div id="paper21"> <b>21. Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for  Language Grounding Tasks in Street View</b>  <a href="https://arxiv.org/pdf/2001.03671" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Mehta%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Harsh Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Artzi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yoav Artzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Baldridge%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jason Baldridge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ie%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eugene Ie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mirowski%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piotr Mirowski</a><br>
<font size="3">
Abstract: The Touchdown dataset (Chen et al., 2019) provides instructions by human annotators for navigation through New York City streets and for resolving spatial descriptions at a given location. To enable the wider research community to work effectively with the Touchdown tasks, we are publicly releasing the 29k raw Street View panoramas needed for Touchdown. We follow the process used for the StreetLearn data release (Mirowski et al., 2019) to check panoramas for personally identifiable information and blur them as necessary. These have been added to the StreetLearn dataset and can be obtained via the same process as used previously for StreetLearn. We also provide a reference implementation for both of the Touchdown tasks: vision and language navigation (VLN) and spatial description resolution (SDR). We compare our model results to those given in Chen et al. (2019) and show that the panoramas we have added to StreetLearn fully support both Touchdown tasks and can be used effectively for further research and comparison. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：（Chen等，2019）着陆数据集由通过纽约市的街道导航人工注释，并在给定的位置，解决空间的描述提供了说明。为了使更广泛的研究团体与着陆任务有效地开展工作，我们公开发布的29K原街景全景图所需的触地得分。我们遵循用于StreetLearn数据发布过程（Mirowski等，2019），以检查全景的个人身份信息，模糊它们是必要的。这些已被添加到所述数据集StreetLearn并如前面对StreetLearn使用可以通过相同的过程来获得。我们还为双方的着陆任务提供一个参考实现：视觉和语言导航（VLN）和空间分辨率描述（SDR）。我们比较我们的模型结果与陈等人给出的。 （2019），并表明我们已经添加到StreetLearn全景图完全支持着陆任务，可以进一步研究和比较有效地使用。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-13</title>
    <url>/2020/01/14/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-13/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Towards Minimal Supervision BERT-based Grammar Error Correction <a href="https://arxiv.org/pdf/2001.03521" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Co-evolution of language and agents in referential games <a href="https://arxiv.org/pdf/2001.03361" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> Machine Learning Approaches for Amharic Parts-of-speech Tagging <a href="https://arxiv.org/pdf/2001.03324" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> Learning to Multi-Task Learn for Better Neural Machine Translation <a href="https://arxiv.org/pdf/2001.03294" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> A Scalable Chatbot Platform Leveraging Online Community Posts: A  Proof-of-Concept Study <a href="https://arxiv.org/pdf/2001.03278" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Simulating Lexical Semantic Change from Sense-Annotated Data <a href="https://arxiv.org/pdf/2001.03216" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Debate Dynamics for Human-comprehensible Fact-checking on Knowledge  Graphs <a href="https://arxiv.org/pdf/2001.03436" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Inductive Document Network Embedding with Topic-Word Attention <a href="https://arxiv.org/pdf/2001.03369" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Linking Social Media Posts to News with Siamese Transformers <a href="https://arxiv.org/pdf/2001.03303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Towards Minimal Supervision BERT-based Grammar Error Correction</b>  <a href="https://arxiv.org/pdf/2001.03521" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yiyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Anastasopoulos%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Antonios Anastasopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Black%2C+A+W" target="_blank" rel="noopener" style="color:#0000EE;">Alan W Black</a><br>
<font size="3">
Abstract: Current grammatical error correction (GEC) models typically consider the task as sequence generation, which requires large amounts of annotated data and limit the applications in data-limited settings. We try to incorporate contextual information from pre-trained language model to leverage annotation and benefit multilingual scenarios. Results show strong potential of Bidirectional Encoder Representations from Transformers (BERT) in grammatical error correction task. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：当前语法纠错（GEC）模型通常考虑的任务，因为序列产生，这需要大量的注释数据，并限制在数据有限的情况下的应用程序。我们尝试从预先训练语言模型来杠杆注释结合上下文信息，有利于多语言情景。结果表明，从变形金刚（BERT）的语法纠错任务双向编码器交涉的巨大潜力。</font>
</div>


<hr>
<div id="paper2"> <b>2. Co-evolution of language and agents in referential games</b>  <a href="https://arxiv.org/pdf/2001.03361" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Dagan%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gautier Dagan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hupkes%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dieuwke Hupkes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bruni%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Elia Bruni</a><br>
<font size="3">
Abstract: Referential games offer a grounded learning environment for neural agents, that accounts for the functional aspects of language. However, they fail to account for another fundamental aspect of human language: Because languages are transmitted from generation to generation, they have to be learnable by new language users, which makes them subject to cultural evolution. Recent work has shown that incorporating cultural evolution in referential game results in considerable improvements in the properties of the languages that emerge in the game. In this work, we first substantiate this claim with a different data set and a wider array of evaluation metrics. Then, drawing inspiration from linguistic theories of human language evolution, we consider a scenario in which not only cultural but also genetic evolution is integrated. As our core contribution, we introduce the Language Transmission Engine, in which cultural evolution of the language is combined with genetic evolution of the agents' architecture. We show that this co-evolution scenario leads to across-the-board improvements on all considered metrics. These results stress that cultural evolution is important for language emergence studies, but also the suitability of the architecture itself should be considered. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：参照游戏提供接地的学习环境，为神经剂，这占了语言的功能方面。然而，他们无法解释人类语言的另一个重要方面：由于语言从代代相传，他们必须通过新的语言的用户，这使得他们受到文化的演变可以学习的。最近的研究显示，在纳入参考的比赛结果在在游戏中出现的语言的性质相当大的改善文化的演变。在这项工作中，我们首先证实这一要求与不同的数据集和评价度量的更广泛的阵列。然后，从人类语言进化的语言学理论中汲取灵感，我们认为这不仅是文化，而且基因进化集成的场景。作为我们的核心贡献，我们介绍了语言传输引擎，其中语言文化演进与代理的架构的遗传进化相结合。我们表明，这种协同进化的情况导致对所有考虑的指标，全面的板的改进。这些结果强调的是文化进化是语言出现的研究很重要，而且建筑本身的适用性应予以考虑。</font>
</div>


<hr>
<div id="paper3"> <b>3. Machine Learning Approaches for Amharic Parts-of-speech Tagging</b>  <a href="https://arxiv.org/pdf/2001.03324" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gashaw%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Ibrahim Gashaw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shashirekha%2C+H+L" target="_blank" rel="noopener" style="color:#0000EE;">H L. Shashirekha</a><br>
<font size="3">
Abstract: Part-of-speech (POS) tagging is considered as one of the basic but necessary tools which are required for many Natural Language Processing (NLP) applications such as word sense disambiguation, information retrieval, information processing, parsing, question answering, and machine translation. Performance of the current POS taggers in Amharic is not as good as that of the contemporary POS taggers available for English and other European languages. The aim of this work is to improve POS tagging performance for the Amharic language, which was never above 91%. Usage of morphological knowledge, an extension of the existing annotated data, feature extraction, parameter tuning by applying grid search and the tagging algorithms have been examined and obtained significant performance difference from the previous works. We have used three different datasets for POS experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：部分的词类（POS）标记被认为是其所需的许多自然语言处理（NLP）的应用，如词义消歧，信息检索，信息处理，分析，问题解答基本而必要的工具之一，和机器翻译。在阿姆哈拉语当前POS标注器的性能还不如说可用于英语和其他欧洲语言的当代POS标注器的。这项工作的目的是为了改进为阿姆哈拉语，这是从来没有91％以上的词性标注的性能。形态的知识，现有的注解数据的扩展，特征提取，参数整定运用网格搜索和标记算法的使用已经被检查，并从以前的作品获得显著的性能差异。我们使用了三种不同的数据集用于POS实验。</font>
</div>


<hr>
<div id="paper4"> <b>4. Learning to Multi-Task Learn for Better Neural Machine Translation</b>  <a href="https://arxiv.org/pdf/2001.03294" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zaremoodi%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Poorya Zaremoodi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Haffari%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gholamreza Haffari</a><br>
<font size="3">
Abstract: Scarcity of parallel sentence pairs is a major challenge for training high quality neural machine translation (NMT) models in bilingually low-resource scenarios, as NMT is data-hungry. Multi-task learning is an elegant approach to inject linguistic-related inductive biases into NMT, using auxiliary syntactic and semantic tasks, to improve generalisation. The challenge, however, is to devise effective training schedules, prescribing when to make use of the auxiliary tasks during the training process to fill the knowledge gaps of the main translation task, a setting referred to as biased-MTL. Current approaches for the training schedule are based on hand-engineering heuristics, whose effectiveness vary in different MTL settings. We propose a novel framework for learning the training schedule, ie learning to multi-task learn, for the MTL setting of interest. We formulate the training schedule as a Markov decision process which paves the way to employ policy learning methods to learn the scheduling policy. We effectively and efficiently learn the training schedule policy within the imitation learning framework using an oracle policy algorithm that dynamically sets the importance weights of auxiliary tasks based on their contributions to the generalisability of the main NMT task. Experiments on low-resource NMT settings show the resulting automatically learned training schedulers are competitive with the best heuristics, and lead to up to +1.1 BLEU score improvements. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：平行句对稀缺是在双语低资源方案培养高素质神经机器翻译（NMT）车型的一大挑战，因为NMT是大量数据的。多任务学习是注入语言相关的感性偏见到NMT，利用辅助句法和语义的任务，以提高泛化一个优雅的方法。我们面临的挑战，但是，是制定有效的培训计划，开处方时，在训练过程中使用的辅助任务，填补了主要翻译任务的知识差距，设定被称为偏压MTL。对于训练计划目前的做法是基于手工工程启发式，其有效性在不同MTL设置而异。我们提出了学习培训计划，即学习多任务学习，感兴趣的MTL设置一个新的框架。我们制定的训练计划为马尔可夫决策过程，铺平了道路雇用政策的学习方法来学习调度策略。我们有效地学习使用Oracle策略算法，动态设置的基础上他们的主要任务NMT的普适性贡献辅助任务的重要性权重模仿学习框架内的培训计划政策。在低资源NMT设置实验表明所产生的自动学习训练调度与最好的启发式竞争力，并导致高达+1.​​1 BLEU得分的改善。</font>
</div>


<hr>
<div id="paper5"> <b>5. A Scalable Chatbot Platform Leveraging Online Community Posts: A  Proof-of-Concept Study</b>  <a href="https://arxiv.org/pdf/2001.03278" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Jo%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sihyeon Jo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Im%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sangwon Im</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Han%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">SangWook Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+S+H" target="_blank" rel="noopener" style="color:#0000EE;">Seung Hee Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hee-Eun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Seong-Woo Kim</a><br>
<font size="3">
Abstract: The development of natural language processing algorithms and the explosive growth of conversational data are encouraging researches on the human-computer conversation. Still, getting qualified conversational data on a large scale is difficult and expensive. In this paper, we verify the feasibility of constructing a data-driven chatbot with processed online community posts by using them as pseudo-conversational data. We argue that chatbots for various purposes can be built extensively through the pipeline exploiting the common structure of community posts. Our experiment demonstrates that chatbots created along the pipeline can yield the proper responses. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：自然语言处理算法的开发和会话数据的爆炸性增长是令人鼓舞的人机对话的研究。尽管如此，越来越大规模合格的会话数据难，看病贵。在本文中，我们核实使用它们作为伪会话数据建设有处理在线社区的帖子一个数据驱动的聊天机器人的可行性。我们认为，出于各种目的聊天机器人，可以通过管道利用社区帖子的共同结构广泛建立。我们的实验表明，沿管道创建聊天机器人能得到适当的回应。</font>
</div>


<hr>
<div id="paper6"> <b>6. Simulating Lexical Semantic Change from Sense-Annotated Data</b>  <a href="https://arxiv.org/pdf/2001.03216" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Schlechtweg%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dominik Schlechtweg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Walde%2C+S+S+i" target="_blank" rel="noopener" style="color:#0000EE;">Sabine Schulte im Walde</a><br>
<font size="3">
Abstract: We present a novel procedure to simulate lexical semantic change from synchronic sense-annotated data, and demonstrate its usefulness for assessing lexical semantic change detection models. The induced dataset represents a stronger correspondence to empirically observed lexical semantic change than previous synthetic datasets, because it exploits the intimate relationship between synchronic polysemy and diachronic change. We publish the data and provide the first large-scale evaluation gold standard for LSC detection models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种新的方法来模拟从共时性意义标注的数据词汇语义变化，并展示其评估词汇语义变化检测模型有效性。感应数据集表示更强的对应于比以前的合成数据集经验观察词汇语义变化，因为它利用共时多义性和历时变化之间的亲密关系。我们发布的数据，并提供了LSC检测模型的首次大规模评估的黄金标准。</font>
</div>


<hr>
<div id="paper7"> <b>7. Debate Dynamics for Human-comprehensible Fact-checking on Knowledge  Graphs</b>  <a href="https://arxiv.org/pdf/2001.03436" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hildebrandt%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marcel Hildebrandt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Serna%2C+J+A+Q" target="_blank" rel="noopener" style="color:#0000EE;">Jorge Andres Quintero Serna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yunpu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ringsquandl%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Martin Ringsquandl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Joblin%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mitchell Joblin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tresp%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Volker Tresp</a><br>
<font size="3">
Abstract: We propose a novel method for fact-checking on knowledge graphs based on debate dynamics. The underlying idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments -- paths in the knowledge graph -- with the goal to justify the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, referred to as the judge, decides whether the fact is true or false. The two agents can be considered as sparse feature extractors that present interpretable evidence for either the thesis or the antithesis. In contrast to black-box methods, the arguments enable the user to gain an understanding for the decision of the judge. Moreover, our method allows for interactive reasoning on knowledge graphs where the users can raise additional arguments or evaluate the debate taking common sense reasoning and external information into account. Such interactive systems can increase the acceptance of various AI applications based on knowledge graphs and can further lead to higher efficiency, robustness, and fairness. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了基于辩论动力学知识图其实检查的新方法。其基本思想是将框架三重分类的任务，两个加强学习剂，其提取参数之间辩论的游戏 - 在知识图上的路径 - 用进球来证明的事实是真实的（论文）或事实是假的（对立面），分别。根据这些参数，一个二元分类，简称判断，决定是否其实是真还是假。这两种药剂可以看作是稀疏的特征提取，对于无论是论文或对立面目前可解释的证据。相较于黑箱方法，参数使用户获得了法官的决定的理解。此外，我们的方法允许对知识图，其中用户可以提出额外的参数或评估的辩论采取常识推理和外部信息纳入考虑交互推理。这样的交互系统可以增加接受的基于知识的图表各种AI应用，并进一步导致更高的效率，稳健性和公平性。</font>
</div>


<hr>
<div id="paper8"> <b>8. Inductive Document Network Embedding with Topic-Word Attention</b>  <a href="https://arxiv.org/pdf/2001.03369" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Brochier%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Robin Brochier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guille%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adrien Guille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Velcin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Velcin</a><br>
<font size="3">
Abstract: Document network embedding aims at learning representations for a structured text corpus i.e. when documents are linked to each other. Recent algorithms extend network embedding approaches by incorporating the text content associated with the nodes in their formulations. In most cases, it is hard to interpret the learned representations. Moreover, little importance is given to the generalization to new documents that are not observed within the network. In this paper, we propose an interpretable and inductive document network embedding method. We introduce a novel mechanism, the Topic-Word Attention (TWA), that generates document representations based on the interplay between word and topic representations. We train these word and topic vectors through our general model, Inductive Document Network Embedding (IDNE), by leveraging the connections in the document network. Quantitative evaluations show that our approach achieves state-of-the-art performance on various networks and we qualitatively show that our model produces meaningful and interpretable representations of the words, topics and documents. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：文档在网络学习表示了结构化文本语料库即当文档相互链接嵌入目标。最近算法扩展网络嵌入通过将在它们的制剂中的节点相关联的文本内容接近。在大多数情况下，这是很难解释学表示。此外，小的重要性是考虑到泛化到未在网络内观察到新文档。在本文中，我们提出了一个解释和归纳文档网络嵌入方法。我们引入新的机制，主题字注意（TWA），其基于字和主题陈述之间的相互文档表示。我们培养这些词和话题载体通过我们的一般模型，归纳文档网络嵌入（IDNE），通过利用文档网络中的连接。定量评估表明，我们的方法实现了各种网络上的国家的最先进的性能和我们定性地表明，我们的模型产生的话，主题和文件有意义的，可解释的表示。</font>
</div>


<hr>
<div id="paper9"> <b>9. Linking Social Media Posts to News with Siamese Transformers</b>  <a href="https://arxiv.org/pdf/2001.03303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Danovitch%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jacob Danovitch</a><br>
<font size="3">
Abstract: Many computational social science projects examine online discourse surrounding a specific trending topic. These works often involve the acquisition of large-scale corpora relevant to the event in question to analyze aspects of the response to the event. Keyword searches present a precision-recall trade-off and crowd-sourced annotations, while effective, are costly. This work aims to enable automatic and accurate ad-hoc retrieval of comments discussing a trending topic from a large corpus, using only a handful of seed news articles. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：许多计算社会科学的研究项目围绕特定热门话题的在线话语。这些作品往往涉及收购有关问题的情况下大规模语料库的分析应对事件的各个方面。关键字搜索呈现精密召回权衡和人群来源的注解，而有效的，是昂贵的。这项工作的目的在于使的意见，从大语料库讨论一个热门话题自动精确的ad-hoc检索，仅使用种子的新闻报道屈指可数。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【论文笔记】Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</title>
    <url>/2020/01/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Task-Oriented-Dialog-Systems-that-Consider-Multiple-Appropriate-Responses-under-the-Same-Context/</url>
    <content><![CDATA[<p><strong>Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</strong>. Yichi Zhang, Zhijian Ou, Zhou Yu. <a href="https://arxiv.org/abs/1911.10484" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p><img src="/images/DADL1.jpg" alt></p><p><img src="/images/DADL2.jpg" alt></p><p>在对话中，对于同一句话，可以有多种回复。但是，现有模型往往趋于生成出现概率最高的回复，而忽视了概率较低的回复。本文通过数据增强的方法，使得模型具备生成多样化回复的能力。</p><a id="more"></a>



<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p><img src="/images/DADL4.jpg" alt><br>在数据预处理阶段，在整个数据集中，找出所有的dialogue state相同的system actions，作为ground truth的补充增强。</p>
<h2 id="整体方法"><a href="#整体方法" class="headerlink" title="整体方法"></a>整体方法</h2><p><img src="/images/DADL3.jpg" alt><br>训练过程中，所有可能的回复概率都要最大，而不只需要ground truth概率最大。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>1 encoder + 3 decoder<br><img src="/images/DADL5.jpg" alt></p>
<p>作者认为通过这样训练，模型就具备了生成多样性回复的能力，在测试的时候可以通过multi beam search、top-k等方式生成多样性回复。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者本次实验主要在数据集MultiWoZ进行。<br><img src="/images/DADL7.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Dialog System</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Integrating Relation Constraints with Neural Relation Extractors</title>
    <url>/2020/01/08/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Integrating-Relation-Constraints-with-Neural-Relation-Extractors/</url>
    <content><![CDATA[<p><strong>Integrating Relation Constraints with Neural Relation Extractors</strong>. Yuan Ye, Yansong Feng, Bingfeng Luo, Yuxuan Lai, Dongyan Zhao. AAAI 2020. <a href="https://arxiv.org/abs/1911.11493" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>在关系抽取任务中，<strong>某个关系的所有subject或者object属于同一种类型</strong>（如：在“母校”的所有subject都属于“人”），或者<strong>多个关系之间往往存在依赖关系</strong>（如“城市”和“地区”的subject都是地名），但是现有模型都没有考虑这个约束，只是单独考虑每一个关系。本文工作利用这种约束以提升关系抽取任务的效果。</p><a id="more"></a>

<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文从Coherent和Semantic两个角度出发，提出两种方法。</p>
<h2 id="Coherent"><a href="#Coherent" class="headerlink" title="Coherent"></a>Coherent</h2><p>一致性：满足约束的两个关系，预测概率要同时高。</p>
<p><img src="/images/IER1.jpg" alt></p>
<p>矩阵v表示关系约束C,如果关系i和关系j满足约束，则v_ij=1。</p>
<h2 id="Semantic"><a href="#Semantic" class="headerlink" title="Semantic"></a>Semantic</h2><p>语义性：符合约束中某个规则的两个实例，至少有一个实例满足规则中的某个关系。</p>
<p><img src="/images/IER2.jpg" alt></p>
<p>矩阵u表示约束C,如果关系j和关系k满足约束i，则v_ij=1,v_ik=1.</p>
<p>最后loss由两部分构成，Lo为原始的loss，Lc为约束loss。<br><img src="/images/IER3.jpg" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在ACNN和APCNN两个模型上进行验证，均获得了提升。<br><img src="/images/IER4.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Neural Relation Extraction</tag>
        <tag>Relation Constraints</tag>
      </tags>
  </entry>
  <entry>
    <title>智源社区2019年大会PPT分享 </title>
    <url>/2020/01/08/%E6%99%BA%E6%BA%90%E7%A4%BE%E5%8C%BA2019%E5%B9%B4%E5%A4%A7%E4%BC%9APPT%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p>获取方式 <a href="https://mp.weixin.qq.com/s/zqqQVwr16EhqA2zxYUQSWQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/zqqQVwr16EhqA2zxYUQSWQ</a></p>
<a id="more"></a>

<p><img src="/images/zhiyuan2019-1.jpg" alt=""></p>
<p><img src="/images/zhiyuan2019-2.jpg" alt=""></p>
]]></content>
  </entry>
  <entry>
    <title>【shell】批量删除除了某个文件外的其他所有文件</title>
    <url>/2020/01/08/%E3%80%90shell%E3%80%91%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E9%99%A4%E4%BA%86%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%96%E7%9A%84%E5%85%B6%E4%BB%96%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -f !(no_delete_file1|no_delete_file2)</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls |grep -v no_delete_file |xargs rm -f</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>批量删除</tag>
      </tags>
  </entry>
  <entry>
    <title>AAAI2020 预讲会</title>
    <url>/2019/12/22/AAAI2020-%E9%A2%84%E8%AE%B2%E4%BC%9A/</url>
    <content><![CDATA[<p>AAAI2020 预讲会翻译对话与文本生成、文本分析与内容挖掘两个Session比较有意思的论文。</p><ul>
<li><p>Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation <a href="https://arxiv.org/abs/1911.09320" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N2-%E9%82%B5%E6%99%A8%E6%B3%BD-%E4%B8%AD%E7%A7%91%E9%99%A2%E8%AE%A1%E7%AE%97%E6%89%80.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Modeling Fluency and Faithful ness for Diverse Neural Machine Translation <a href="https://arxiv.org/abs/1912.00178" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N1-%E8%B0%A2%E5%A9%89%E8%8E%B9-%E4%B8%AD%E7%A7%91%E9%99%A2%E8%AE%A1%E7%AE%97%E6%89%80.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Task-Oriented Dialog Systems that Consider Multiple Appropriate Response under the Same Context <a href="https://arxiv.org/abs/1911.10484" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N3-%E5%BC%A0%E4%BA%A6%E5%BC%9B-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Neural Machine Translation with Joint Representation <a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N8-%E6%9D%8E%E7%82%8E%E6%B4%8B-%E4%B8%9C%E5%8C%97%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Multi-Scale Self-Attention for Text Classification <a href="https://arxiv.org/abs/1912.00544" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S2N1-%E9%83%AD%E7%90%A6%E9%B9%8F-%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Intergrating Relation Constraints with Neural Relation Extractors <a href="https://arxiv.org/abs/1911.11493" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S2N5-%E5%8F%B6%E5%85%83-%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Cross-Lingual Natural Language Generation via Pre-Training <a href="https://arxiv.org/abs/1909.10481" target="_blank" rel="noopener">[PDF]</a></p>
</li>
</ul>]]></content>
      <categories>
        <category>论文列表</category>
      </categories>
      <tags>
        <tag>AAAI</tag>
      </tags>
  </entry>
  <entry>
    <title>国内一些NLP实验室及老师主页</title>
    <url>/2019/12/21/%E5%9B%BD%E5%86%85%E4%B8%80%E4%BA%9BNLP%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8F%8A%E8%80%81%E5%B8%88%E4%B8%BB%E9%A1%B5/</url>
    <content><![CDATA[<p>以下列表只是我个人整理，随意排序，欢迎大家补充与指正。</p>
<ul>
<li><p><a href="http://nlp.csai.tsinghua.edu.cn/site2/" target="_blank" rel="noopener">清华大学自然语言处理与社会人文计算实验室</a></p>
<p><a href="http://www.cs.tsinghua.edu.cn/publish/cs/4616/2013/20130424103737386785027/20130424103737386785027_.html" target="_blank" rel="noopener">孙茂松</a> <a href="http://nlp.csai.tsinghua.edu.cn/~ly/index_cn.html" target="_blank" rel="noopener">刘洋</a> <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/" target="_blank" rel="noopener">刘知远</a></p>
</li>
<li><p><a href="http://www.wict.pku.edu.cn/" target="_blank" rel="noopener">北京大学王选计算机研究所</a></p>
<p><a href="http://www.icst.pku.edu.cn/xztd/xztd_01/1222625.htm" target="_blank" rel="noopener">万小军</a> <a href="http://www.icst.pku.edu.cn/xztd/xztd_01/1222614.htm" target="_blank" rel="noopener">严睿</a> <a href="http://www.wict.pku.edu.cn/zhaodongyan/" target="_blank" rel="noopener">赵东岩</a> <a href="https://sites.google.com/site/ysfeng/home" target="_blank" rel="noopener">冯岩松</a> <a href="https://www.cs.uic.edu/~liub/" target="_blank" rel="noopener">刘兵</a></p>
</li>
<li><p><a href="http://www.cs.tsinghua.edu.cn/publish/cs/index.html" target="_blank" rel="noopener">清华大学计算机科学与技术系</a></p>
<p><a href="http://coai.cs.tsinghua.edu.cn/hml/" target="_blank" rel="noopener">黄民烈</a></p>
</li>
</ul>
<a id="more"></a>

<ul>
<li><p><a href="http://www.icip.org.cn/zh/homepage/" target="_blank" rel="noopener">中国科学院软件研究所中文信息处理实验室</a></p>
<p><a href="http://www.icip.org.cn/team/sunle/" target="_blank" rel="noopener">孙乐</a> <a href="http://www.icip.org.cn/team/hanxianpei/" target="_blank" rel="noopener">韩先培</a></p>
</li>
<li><p><a href="http://iip.ict.ac.cn/" target="_blank" rel="noopener">中国科学院计算技术研究所智能信息处理重点实验室</a></p>
<p><a href="http://sourcedb.ict.cas.cn/cn/jssrck/201709/t20170910_4857722.html" target="_blank" rel="noopener">冯洋</a></p>
</li>
<li><p><a href="http://www.nlplab.com/niuplan/niutrans.ch.html" target="_blank" rel="noopener">东北大学自然语言处理实验室</a></p>
<p><a href="http://www.nlplab.com/members/zhujingbo.html" target="_blank" rel="noopener">朱靖波</a> <a href="http://www.nlplab.com/members/xiaotong.html" target="_blank" rel="noopener">肖桐</a></p>
</li>
<li><p><a href="http://www.cs.fudan.edu.cn/" target="_blank" rel="noopener">复旦大学计算机科学技术学院</a></p>
<p><a href="https://xpqiu.github.io/" target="_blank" rel="noopener">邱锡鹏</a></p>
</li>
<li><p><a href="http://cs.tju.edu.cn/csweb/" target="_blank" rel="noopener">天津大学计算机科学与技术学院</a></p>
<p><a href="https://zhangmeishan.github.io/chn.html" target="_blank" rel="noopener">张梅山</a> <a href="http://cs.tju.edu.cn/csweb/admin_teacher/view?id=232" target="_blank" rel="noopener">熊德意</a></p>
</li>
<li><p><a href="http://nlp.xmu.edu.cn/index.html" target="_blank" rel="noopener">厦门大学自然语言处理实验室</a></p>
<p><a href="http://121.192.180.171:8080/" target="_blank" rel="noopener">史晓东</a></p>
</li>
<li><p><a href="https://cdmc.xmu.edu.cn/index.htm" target="_blank" rel="noopener">厦门大学数字媒体计算研究中心</a></p>
<p><a href="https://cdmc.xmu.edu.cn/info/1010/1054.htm" target="_blank" rel="noopener">苏劲松</a></p>
</li>
<li><p><a href="http://bcmi.sjtu.edu.cn/index.cn.html" target="_blank" rel="noopener">上海交通大学BCMI实验室</a></p>
<p><a href="http://bcmi.sjtu.edu.cn/~zhaohai/" target="_blank" rel="noopener">赵海</a></p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>写作助手</title>
    <url>/2019/12/21/%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://www.overleaf.com/" target="_blank" rel="noopener">Overleaf</a><br>在线编辑Latex。</p>
</li>
<li><p><a href="https://www.grammarly.com/" target="_blank" rel="noopener">Grammarly</a><br>自动检测语法。</p>
</li>
<li><p><a href="http://www.esoda.org/" target="_blank" rel="noopener">易搜搭</a><br>词语搭配。</p>
</li>
</ul>
<a id="more"></a>]]></content>
      <tags>
        <tag>写作助手</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Improved Document Modelling with a Neural Discourse Parser</title>
    <url>/2019/12/21/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Improved-Document-Modelling-with-a-Neural-Discourse-Parser/</url>
    <content><![CDATA[<p><strong>Improved Document Modelling with a Neural Discourse Parser</strong>.Fajri Koto, Jey Han Lau, Timothy Baldwin. ArXiv 1911.<a href="https://arxiv.org/abs/1911.06919" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>使用篇章结构信息提高篇章建模。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>文章的关键有两点，篇章结构是什么？如何利用篇章结构？</p><a id="more"></a>


<h2 id="篇章结构是什么？"><a href="#篇章结构是什么？" class="headerlink" title="篇章结构是什么？"></a>篇章结构是什么？</h2><p><img src="/images/DMDP1.jpg" alt></p>
<p>本篇文章的篇章结构由RST分析得到，首先将篇章切分成EDU，然后再EDU基础上建立篇章分析树，树上的叶子结点为EDU，非叶子结点为其两个子节点的篇章关系，树上的边为对应子节点在该关系中的重要性。（具体可以去了解一下RST官网介绍和相关论文）</p>
<h2 id="如何利用篇章结构？"><a href="#如何利用篇章结构？" class="headerlink" title="如何利用篇章结构？"></a>如何利用篇章结构？</h2><p>如何利用篇章结构，首先是如何编码篇章结构，也就是如何抽取篇章分析树的特征。针对每个树根节点到每个叶子结点的路径，作者设计两类特征：Shallow Discourse Features 和 Latent Discourse Features。</p>
<h3 id="Shallow-Discourse-Features"><a href="#Shallow-Discourse-Features" class="headerlink" title="Shallow Discourse Features"></a>Shallow Discourse Features</h3><ul>
<li>叶子结点重要性分数</li>
</ul>
<p><img src="/images/DMDP2.jpg" alt></p>
<p>统计路径上Nucleus的比例，h(root)为根节点高度。</p>
<ul>
<li>关系重要性分数</li>
</ul>
<p><img src="/images/DMDP3.jpg" alt></p>
<p>统计路径上每个关系的加权比例，h(x)为节点x的高度。</p>
<ul>
<li><p>结点类别</p>
<p>  Nucleus or satellite</p>
<ul>
<li>兄弟结点</li>
</ul>
<h3 id="Latent-Discourse-Features"><a href="#Latent-Discourse-Features" class="headerlink" title="Latent Discourse Features"></a>Latent Discourse Features</h3></li>
</ul>
<p><img src="/images/DMDP6.jpg" alt></p>
<p>使用两个Bi-LSTM分别编码词序列和句法特征序列，avg-pool，然后拼接。</p>
<p><img src="/images/DMDP4.jpg" alt></p>
<p>拼接后的序列再过一个Bi-LSTM得到最终特征表示。</p>
<p><img src="/images/DMDP5.jpg" alt></p>
<h3 id="如何利用篇章特征"><a href="#如何利用篇章特征" class="headerlink" title="如何利用篇章特征"></a>如何利用篇章特征</h3><p> 得到两类特征后，要如何利用呢？本文提出了三种方法。</p>
<ul>
<li><p>拼接word embedding</p>
<p><img src="/images/DMDP7.jpg" alt></p>
</li>
<li><p>加一层Bi-LSTM</p>
<p><img src="/images/DMDP8.jpg" alt></p>
</li>
<li><p>作为解码attention的一个额外输入</p>
<p><img src="/images/DMDP9.jpg" alt></p>
</li>
</ul>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="Document-Summarizatoin"><a href="#Document-Summarizatoin" class="headerlink" title="Document Summarizatoin"></a>Document Summarizatoin</h2><p>  <img src="/images/DMDP10.jpg" alt></p>
<p>  第一种和第二种方法较好。</p>
<h2 id="Petition-Popularity-Prediction"><a href="#Petition-Popularity-Prediction" class="headerlink" title="Petition Popularity Prediction"></a>Petition Popularity Prediction</h2><p>  <img src="/images/DMDP11.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Summarization</tag>
        <tag>Discourse</tag>
        <tag>RST</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】linux批量杀死进程</title>
    <url>/2019/12/21/%E3%80%90shell%E3%80%91linux%E6%89%B9%E9%87%8F%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>批量杀死包含关键字“keyword1”但不包含“keyword2”的进程。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef|grep keyword1|grep -v keyword2|cut -c 9-15|xargs kill -9</span><br></pre></td></tr></table></figure><ul>
<li><strong>“ps -ef”</strong> ——查看所有进程</li>
<li><strong>“grep keyword1”</strong> ——列出所有含有关键字”keyword1”的进程</li>
<li><strong>“grep -v keyword2”</strong> ——在列出的进程中去除含有关键字”keyword2”的进程</li>
<li><strong>“cut -c 9-15″</strong> ——截取输入行的第9个字符到第15个字符，而这正好是进程号PID</li>
<li><strong>“xargs kill -9″</strong> ——xargs 命令是用来把前面命令的输出结果(PID)作为”kill -9″命令的参数，并执行该命令。”kill -9″会强行杀掉指定进程。</li>
</ul>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>批量</tag>
        <tag>杀死进程</tag>
      </tags>
  </entry>
  <entry>
    <title>好的研究想法从哪里来</title>
    <url>/2019/12/03/%E5%A5%BD%E7%9A%84%E7%A0%94%E7%A9%B6%E6%83%B3%E6%B3%95%E4%BB%8E%E5%93%AA%E9%87%8C%E6%9D%A5/</url>
    <content><![CDATA[<p>转载自：知乎专栏 NLP日知录 <a href="https://zhuanlan.zhihu.com/p/93765082" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/93765082</a></p><p>作者：刘知远 </p><p>背景说明：临近ACL 2020投稿截止时间，跟同学密集讨论，争论哪些研究想法适合投到ACL有机会命中。从自己十多年研究经历来看，如何判断一个研究想法好不好，以及这些研究想法从哪里来，对于初学者而言的确是个难题。所以，简单攒了这篇小短文，分享一些经验和想法，希望对刚进入NLP领域的新同学有用。多有舛误请指正。</p><a id="more"></a>


<p>王家卫的电影《一代宗师》中有段经典的比武桥段，宫会长对叶问说“今天我们不比武术，比想法”。其实，好的点子或者想法（idea），也是一篇优秀研究成果的灵魂。而计算机领域流行着一句话“IDEA is cheap, show me the code”，也说明对于重视实践的计算机学科而言，想法的好坏还取决于它的实际效能。这里就来谈下好的研究想法从哪里来。</p>
<h1 id="什么算是好的想法"><a href="#什么算是好的想法" class="headerlink" title="什么算是好的想法"></a>什么算是好的想法</h1><p>2015年，我在微博上写过一个调侃的小段子：</p>
<blockquote>
<p>ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。</p>
</blockquote>
<p>到了2018年，我又续了一小段：</p>
<blockquote>
<p>不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门，曰注意，曰记忆，曰对抗，曰增强。经ImageNet一役威震武林，豢Alpha犬一匹无人可近。一时家家筑丹炉，人人炼丹忙，门徒云集，依附者众，有一统江湖之势。有童谣为证：左手大数据，右手英伟达，每逢顶会炼丹忙。</p>
</blockquote>
<p>这里面提到的图模型加圈、神经网络加层、优化目标加正则，神经网络中的门、注意、记忆等，都是一些改进模型性能的创新思路，被各大NLP任务广泛使用并发表论文，也许就是因为被不同NLP任务的重复使用和发表，多少有些审美疲劳而缺少更深的创新思想，被有些网友和学者诟为“灌水”，似乎都不算好的想法。</p>
<p>那么什么才是好的想法呢？我理解这个”好“字，至少有两个层面的意义。</p>
<h2 id="学科发展角度的“好”"><a href="#学科发展角度的“好”" class="headerlink" title="学科发展角度的“好”"></a>学科发展角度的“好”</h2><p>学术研究本质是对未知领域的探索，是对开放问题的答案的追寻。所以从推动学科发展的角度，评判什么是好的研究想法的标准，首先就在一个<strong>“新”</strong>字。</p>
<p>过去有个说法，人工智能学科有个魔咒，凡是人工智能被解决（或者有解决方案）的部分，就不再被认为代表“人类智能”。计算机视觉、自然语言处理、机器学习、机器人之所以还被列为人工智能主要方向，也许正是因为它们尚未被解决，尚能代表“人类智能”的尊严。而我们要开展创新研究，就是要提出新的想法解决这些问题。这其中的”新“字，可以体现在提出新的问题和任务，探索新的解决思路，提出新的算法技术，实现新的工具系统等。</p>
<p>在保证”新“的基础上，研究想法好不好，那就看它<strong>对推动学科发展的助力有多大</strong>。深度学习之所以拥有如此显赫的影响力，就在于它对于人工智能自然语言处理、语音识别、计算机视觉等各重要方向都产生了革命性的影响，彻底改变了对无结构信号（语音、图像、文本）的语义表示的技术路线。</p>
<h2 id="研究实践角度的”好“"><a href="#研究实践角度的”好“" class="headerlink" title="研究实践角度的”好“"></a>研究实践角度的”好“</h2><p>那是不是想法只要够”新“就好呢？是不是越新越好呢？我认为应该还不是。因为，只有<strong>能做得出来的想法</strong>才有资格被分析好不好。所以，从研究实践角度，还需要考虑研究想法的<strong>可实现性</strong>和<strong>可验证性</strong>。</p>
<p>可实现性，体现在该想法是否有足够的数学或机器学习工具支持实现。可验证性，体现在该想法是否有合适的数据集合和广泛接受的评价标准。很多民间科学家的想法之所以得不到学术界的认同，就是因为这些想法往往缺乏可实现性和可验证性，只停留在天马行空的纸面，只是些虚无缥缈的理念。</p>
<h1 id="好的研究想法从哪里来"><a href="#好的研究想法从哪里来" class="headerlink" title="好的研究想法从哪里来"></a>好的研究想法从哪里来</h1><p>想法好还是不好，并不是非黑即白的二分问题，而是像光谱一样呈连续分布，因时而异，因人而宜。计算机科技领域的发展既有积累的过程，也有跃迁的奇点，积累量变才会产生质变，吃第三个馒头饱了，也是因为前面两个馒头打底。</p>
<p>现在的学术研究已经成为高度专业化的职业，有庞大的研究者群体。”Publish or Perish“，是从事学术职业（如教授、研究员、研究生）的人必须做好平衡的事情，不能要求研究者的每份工作都是“诺贝尔奖”或“图灵奖”级的才值得发表。只要对研究领域的发展有所助力，就值得发表出来，帮助同行前进。鲁迅说：天才并不是自生自长在深林荒野里的怪物，是由可以使天才生长的民众产生，长育出来的，所以没有这种民众，就没有天才。这个庞大研究者群体正是天才成长的群众基础。同时，学术新人也是在开展创新研究训练中，不断磨砺寻找好想法能力，鲁迅也说：即使天才，在生下来的时候的第一声啼哭，也和平常的儿童的一样，决不会就是一首好诗。</p>
<p>那么，好的研究想法从哪里来呢？我总结，首先要有区分研究想法好与不好的能力，这需要<strong>深入全面了解所在研究方向的历史与现状</strong>，具体就是对学科文献的全面掌握。人是最善于学习的动物，完全可以将既有文献中不同时期研究工作的想法作为学习对象，通过了解它们提出后对学科发展的影响——具体体现在论文引用、学术评价情况等各方面——建立对研究想法好与不好的评价模型。我们很难条分缕析完美地列出区分好与不好想法的所有特征向量，但人脑强大的学习能力，只要给予足够的输入数据，就可以在神经网络中自动学习建立判别的模型，鉴古知今，见微知著，这也许就是常说的学术洞察力。</p>
<p>做过一些研究的同学会有感受，仅阅读自己研究方向的文献，新想法还是不会特别多。这是因为，读到的都是该研究问题已经完成时的想法，它们本身无法启发新的想法。如何产生新的想法呢？我总结有三种可行的基本途径：</p>
<p><strong>实践法</strong>。即在研究任务上实现已有最好的算法，通过分析实验结果，例如发现这些算法计算复杂度特别高、训练收敛特别慢，或者发现该算法的错误样例呈现明显的规律，都可以启发你改进已有算法的思路。现在很多自然语言处理任务的Leaderboard上的最新算法，就是通过分析错误样例来有针对性改进算法的 [1]。</p>
<p><strong>类比法</strong>。即将研究问题与其他任务建立类比联系，调研其他相似任务上最新的有效思想、算法或工具，通过合理的转换迁移，运用到当前的研究问题上来。例如，当初注意力机制在神经网络机器翻译中大获成功，当时主要是在词级别建立注意力，后来我们课题组的林衍凯和沈世奇提出建立句子级别的注意力解决关系抽取的远程监督训练数据的标注噪音问题 [2]，这就是一种类比的做法。</p>
<p><strong>组合法</strong>。即将新的研究问题分解为若干已被较好解决的子问题，通过有机地组合这些子问题上的最好做法，建立对新的研究问题的解决方案。例如，我们提出的融合知识图谱的预训练语言模型，就是将BERT和TransE等已有算法融合起来建立的新模型 [3]。</p>
<p>正如武侠中的最高境界是无招胜有招，好的研究想法并不拘泥于以上的路径，很多时候是在研究者对研究问题深刻认知的基础上，综合丰富的研究阅历和聪明才智产生”顿悟“的结果。这对初学者而言恐怕还很难一窥门径，需要从基本功做起，经过大量科研实践训练后，才能有登堂入室之感。</p>
<p>在科研实践过程中，除了通过大量文献阅读了解历史，通过深入思考总结产生洞察力外，还有一项必不可少的工作，那就是主动开放的学术交流和合作意识。不同研究领域思想和成果交流碰撞，既为创新思想提供了新的来源，也为”类比“和”顿悟“提供了机会。了解一下历史就可以知晓，人工智能的提出，就是数学、计算机科学、控制论、信息论、脑科学等学科交叉融合的产物。而当红的深度学习的起源，1980年代的Parallel Distributed Processing （PDP），也是计算机科学、脑认知科学、心理学、生物学等领域研究者通力合作的产物。下面是1986年出版的名著《Parallel Distributed Processing: Explorations in the Microstructure of Cognition》第一卷的封面。</p>
<p><img src="https://pic2.zhimg.com/80/v2-a8d3f6e553f9f279cdafea5a3e218701_hd.jpg" alt></p>
<p>作者在前言中是这么讲他们的合作过程的，在最初长达六个月的时间里，它们每周见面交流两次讨论研究进展。</p>
<blockquote>
<p>We expected the project to take about six months. We began in January 1982 by bringing a number of our colleagues together to form a discussion group on these topics. During the first six months we met twice weekly and laid the foundation for most of the work presented in these volumes.</p>
</blockquote>
<p>而书中提供的PDP研究组的成员名单，40年后的今天仍让我惊叹其高度的跨机构、跨学科的交叉特点。所以，特别建议同学们在科研训练中，在专注研究问题的前提下，保持主动的学术交流意识，无论是听讲座报告，参加学术会议，还是选修课程，都有意识地扩宽学术交流的广度，不仅与小同行打成一片，更有看似八竿子打不着的研究领域的学术伙伴。随着研究经历的丰富，会越来越强烈地感受到，越是大跨度交叉的学术报告，越让你受到更大的启发，产生更多让自己兴奋的研究想法。</p>
<p><img src="https://pic2.zhimg.com/80/v2-404a752001300a69baabd40fb3d78b99_hd.jpg" alt></p>
<h1 id="初学者应该怎么做"><a href="#初学者应该怎么做" class="headerlink" title="初学者应该怎么做"></a>初学者应该怎么做</h1><p>与阅读论文、撰写论文、设计实验等环节相比，如何产生好的研究想法，是一个不太有章可循的环节，很难总结出固定的范式可供遵循。像小马过河，需要通过大量训练实践，来积累自己的研究经验。不过，对于初学者而言，仍然有几个简单可行的原则可以参考。</p>
<p><strong>一篇论文的可发表价值，取决于它与已有最直接相关工作间的Delta</strong>。我们大部分研究工作都是站在前人工作的基础上推进的。牛顿说：如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。在我看来，评判一篇论文研究想法的价值，就是看它站在了哪个或哪些巨人的肩膀上，以及在此基础上又向上走了多远。反过来，在准备开始一项研究工作之前，在形成研究想法的时候，也许要首先明确准备站在哪个巨人的肩膀上，以及计划通过什么方式走得更远。与已有最直接相关工作之间的Delta，决定了这个研究想法的价值有多大。</p>
<p><strong>兼顾摘果子和啃骨头</strong>。人们一般把比较容易想到的研究想法，叫做Low Hanging Fruit（低垂果实）。低垂果实容易摘，但同时摘的人也多，选择摘果子就容易受到想法撞车的困扰。例如，2018年以BERT为首的预训练语言模型取得重大突破，2019年中就出现大量改进工作，其中以跨模态预训练模型为例，短短几个月里<a href="http://arxiv.org上挂出了超过六个来自不同团队的图像与文本融合的预训练模型" target="_blank" rel="noopener">http://arxiv.org上挂出了超过六个来自不同团队的图像与文本融合的预训练模型</a> [4]。设身处地去想，进行跨模态预训练模型研究，就是一个比较容易想到的方向，你一定需要有预判能力，知道世界上肯定会有很多团队也同时开展这方面研究，这时你如果选择入场，就一定要做得更深入更有特色，有自己独特的贡献才行。相对而言，那些困难的问题，愿意碰的人就少，潜下心来啃硬骨头，也是不错的选择，当然同时就会面临做不出来的风险，或者做出来也得不到太多关注的风险。同学需要根据自身特点、经验和需求，兼顾摘果子和啃骨头两种类型的研究想法。</p>
<p><img src="https://pic1.zhimg.com/80/v2-d71aaf2b86116e3ea1e891bf9230a2c4_hd.jpg" alt></p>
<p><strong>注意多项研究工作的主题连贯性</strong>。同学的研究训练往往持续数年，需要注意前后多项研究工作的主题连贯性，保证内在逻辑统一。需要考虑，在个人简历上，在出国申请Personal Statement中，或者在各类评奖展示中，能够将这些研究成果汇总在一起，讲出自己开展这些研究工作的总目标、总设想。客观上讲，人工智能领域研究节奏很快，技术更新换代快，所以成果发表也倾向于小型化、短平快。我有商学院、社科的朋友，他们一项研究工作往往需要持续一年甚至数年以上；高性能计算、计算机网络方向的研究周期也相对较长。人工智能这种小步快跑的特点，决定了很多同学即使本科毕业时，也会有多篇论文发表，更不用说硕士生、博士生。在这种情况下，就格外需要在研究选题时，注意前后工作的连贯性和照应关系。几项研究工作放在一起，到底是互相割裂说不上话，还是在为一个统一的大目标而努力，格外反映研究的大局意识和布局能力。例如，下图是我们课题组涂存超博士2018年毕业时博士论文《面向社会计算的网络表示学习》的章节设置，整体来看就比《社会计算的若干重要问题研究》等没有内在关联的写法要更让人信服一些。当然，对于初学者而言，一开始就想清楚五年的研究计划，根本不可能。但想，还是不去想，结果还是不同的。</p>
<p><img src="https://pic1.zhimg.com/80/v2-9fbee2d16f9c05fa1cb1ec86a27d265c_hd.jpg" alt></p>
<p><strong>注意总结和把握研究动态和趋势，因时而动</strong>。2019年在知乎上有这样一个问题：”2019年在NLP领域，资源有限的个人/团队能做哪些有价值有希望的工作？“ 我当时的回答如下：</p>
<blockquote>
<p>我感觉，产业界开始集团化搞的问题，说明其中主要的开放性难题已经被解决得差不多了，如语言识别、人脸识别等，在过去20年里面都陆续被广泛商业应用。看最近的BERT、GPT-2，我理解更多的是将深度学习对大规模数据拟合的能力发挥到极致，在深度学习技术路线基本成熟的前提下，大公司有强大计算能力支持，自然可以数据用得更多，模型做得更大，效果拟合更好。<br>成熟高新技术进入商用竞争，就大致会符合摩尔定律的发展规律。现在BERT等训练看似遥不可及，但随着计算能力等因素的发展普及，说不定再过几年，人人都能轻易训练BERT和GPT-2，大家又会在同一个起跑线上，把目光转移到下一个挑战性难题上。<br>所以不如提前考虑，哪些问题是纯数据驱动技术无法解决的。NLP和AI中的困难任务，如常识和知识推理，复杂语境和跨模态理解，可解释智能，都还没有可行的解决方案，我个人也不看好数据驱动方法能够彻底解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些正是有远见的研究者们应该开始关注的方向。</p>
</blockquote>
<p>需要看到，不同时期的研究动态和趋势不同。把握这些动态和趋势，就能够做出研究社区感兴趣的成果。不然的话，即使研究成果没有变化，只是简单早几年或晚几年投稿，结果也会大不相同。例如，2013年word2vec发表，在2014-2016年之间开展词表示学习研究，就相对比较容易得到ACL、EMNLP等会议的录用；但到了2017-2018年，ACL等会议上的词表示学习的相关工作就比较少见了。</p>
<h1 id="最后的补充"><a href="#最后的补充" class="headerlink" title="最后的补充"></a>最后的补充</h1><p>这篇短文，主要是希望面向初学者，介绍一些求新过程中的经验和注意事项，希望大家少走一些弯路。但阅读文献，深入思考，接收拒稿不断改进的苦，该吃的还是要吃。学术研究和论文发表，对个人而言也许意味着高薪资和奖学金，但其最终的目的还是真正的推动学科的发展。所以，要做经得起考验的学术研究，关键就在”真“与”新“，需要我们始终恪守和孜孜以求。</p>
<p>著名历史学家、清华校友何炳棣先生曾在自传《读史阅世六十年》中提及著名数学家林家翘的一句嘱咐：“要紧的是不管搞哪一行，千万不要做第二等的题目。” 具体到每个领域，什么是一等的题目本身见仁见智，其实更指向内心“求真”的态度。</p>
<p>参考文献<br>[1] <a href="https://paperswithcode.com/" target="_blank" rel="noopener">https://paperswithcode.com/</a> &amp; <a href="http://nlpprogress.com/" target="_blank" rel="noopener">http://nlpprogress.com/</a></p>
<p>[2] Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, Maosong Sun. Neural Relation Extraction with Selective Attention over Instances. The 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016).</p>
<p>[3] Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu. ERNIE: Enhanced Language Representation with Informative Entities. The 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019).</p>
<p>[4] <a href="https://github.com/thunlp/PLMpapers" target="_blank" rel="noopener">https://github.com/thunlp/PLMpapers</a></p>
]]></content>
  </entry>
  <entry>
    <title>Keyphrase Generation任务综述</title>
    <url>/2019/12/02/Keyphrase-Generation%E4%BB%BB%E5%8A%A1%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="任务简介"><a href="#任务简介" class="headerlink" title="任务简介"></a>任务简介</h1><p>A <strong>keyphrase</strong> or keyword is a piece of short, summative content that expresses the main semantic meaning of a longer text. The typical use of a keyphrase or keyword is in scientific publications to provide the core information of a paper. </p><a id="more"></a>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><ul>
<li>F1@5</li>
<li>F1@10</li>
</ul>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><ul>
<li>KP20K</li>
<li>SemEval</li>
<li>NUS</li>
<li>Krapivin</li>
<li>Inspec</li>
</ul>
<h1 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h1><ul>
<li>2019-06-13 <strong>Title-Guided Encoding for Keyphrase Generation</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="center">Dataset</th>
<th align="center">F1@5</th>
<th align="center">F1@10</th>
</tr>
</thead>
<tbody><tr>
<td align="center">KP20K</td>
<td align="center">0.372</td>
<td align="center">0.315</td>
</tr>
</tbody></table>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ul>
<li><p><strong>Deep Keyphrase Generation</strong>. Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky, Yu Chi. ACL 2017. <a href="https://aclweb.org/anthology/papers/P/P17/P17-1054/" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/memray/seq2seq-keyphrase" target="_blank" rel="noopener">[code]</a><br>Keyphrase Generation的第一篇paper，主要框架是 seq2seq + copy.</p>
</li>
<li><p><strong>Semi-Supervised Learning for Neural Keyphrase Generation</strong>. Hai Ye, Lu Wang. EMNLP 2018. <a href="https://aclweb.org/anthology/papers/D/D18/D18-1447/" target="_blank" rel="noopener">[pdf]</a><br>解决资源不足问题，提出两个策略：<br>（1）微调，通过keyphrase extraction方式人为构造大量数据预训练模型，再通过已有数据微调；<br>（2）多任务框架，生成keyphrase的同时生成title。</p>
</li>
<li><p><strong>Title-Guided Encoding for Keyphrase Generation</strong>. Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, Michael R. Lyu1. AAAI 2019. <a href="https://arxiv.org/abs/1808.08575" target="_blank" rel="noopener">[pdf]</a><br>本文认为标题包含了文章的主要信息，通过标题来引导摘要的建模已提升模型性能。</p>
</li>
<li><p><strong>Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</strong>. Hou Pong Chan, Wang Chen, Lu Wang, Irwin King. ACL 2019. <a href="https://arxiv.org/abs/1906.04106" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/kenchan0226/keyphrase-generation-rl" target="_blank" rel="noopener">[code]</a></p>
</li>
</ul>
<ul>
<li><strong>Topic-Aware Neural Keyphrase Generation for Social Media Language. Yue Wang</strong>. Jing Li, Hou Pong Chan, Irwin King, Michael R. Lyu, Shuming Shi. ACL 2019. <a href="https://arxiv.org/abs/1906.03889" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/yuewang-cuhk/TAKG" target="_blank" rel="noopener">[code]</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【shell】截断字符串</title>
    <url>/2019/11/29/%E3%80%90shell%E3%80%91%E6%88%AA%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/fengbohello/p/5954895.html" target="_blank" rel="noopener">https://www.cnblogs.com/fengbohello/p/5954895.html</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">line='abcd&lt;SEG&gt;efg'</span><br><span class="line">newline=$&#123;line#*&lt;SEG&gt;&#125;</span><br><span class="line">echo $newline # efg</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】判断字符串是否包含子串</title>
    <url>/2019/11/29/%E3%80%90shell%E3%80%91%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/iamlihongwei/article/details/59484029" target="_blank" rel="noopener">https://blog.csdn.net/iamlihongwei/article/details/59484029</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [[ $line =~ "&lt;BEGIN&gt;" ]] </span><br><span class="line">then</span><br><span class="line">	echo "包含&lt;BEGIN&gt;"</span><br><span class="line">elif [[ $line =~ "&lt;SEG&gt;" ]]</span><br><span class="line">then</span><br><span class="line">	echo "包含&lt;SEG&gt;"</span><br><span class="line">else</span><br><span class="line">	echo "都不包含"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>使用python发送免费短信</title>
    <url>/2019/11/27/%E4%BD%BF%E7%94%A8python%E5%8F%91%E9%80%81%E5%85%8D%E8%B4%B9%E7%9F%AD%E4%BF%A1/</url>
    <content><![CDATA[<p>首先在 <a href="https://www.twilio.com/" target="_blank" rel="noopener">twilio</a> 上注册帐号，并申请一个 twilio 手机号，并认证自己的手机号，twilio只能给认证过的手机号发送短信。</p><p>使用 python 发送短信</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> twilio.rest <span class="keyword">import</span> Client</span><br><span class="line"></span><br><span class="line">account_sid = &lt;your account sid&gt;</span><br><span class="line">auth_token = &lt;your auth token&gt;</span><br><span class="line">client = Client(account_sid, auth_token)</span><br><span class="line"></span><br><span class="line">message=client.messages.create(</span><br><span class="line">	from_=&lt;your twilio phone num&gt;,</span><br><span class="line">	body=&lt;your message&gt;,</span><br><span class="line">	to=&lt;your phone num&gt;</span><br><span class="line">)</span><br><span class="line">print(message.sid)</span><br></pre></td></tr></table></figure><a id="more"></a>



<p>注：试用版免费次数有限。</p>
]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>【论文笔记】Context-Aware Learning for Neural Machine Translation</title>
    <url>/2019/11/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Context-Aware-Learning-for-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Context-Aware Learning for Neural Machine Translation</strong>. Sébastien Jean, Kyunghyun Cho. ArXiv 1903. <a href="https://arxiv.org/pdf/1903.04715.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文提出一个正则化项，鼓励模型利用上下文信息，从而提高篇章翻译结果。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>人们认为使用上下文可以提高篇章翻译，也就是使用上下文信息后译文翻译概率会更高。</p><a id="more"></a>


<p><img src="/images/context-aware1.png" alt></p>
<p>这个不等式在token、sentence、data三个层次上都成立</p>
<p><img src="/images/context-aware2.png" alt></p>
<p>本文在损失函数中加入一个正则化项，正则化项由三个max margin组成。</p>
<p><img src="/images/context-aware3.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="/images/context-aware4.png" alt></p>
<p>（a）句子级别翻译，不利用上下信息</p>
<p>（b）利用随机上下文，随机上下文的期望跟不利用上下文的期望一样，所以使用上下文没有提升</p>
<p>（c）利用前文上下文，对比随机上下文有提升，并且跟没有利用上下文相差0.4</p>
<p>（d）鼓励利用前文上下文，跟没有利用上下文相差3.74，并且比（c）有提升</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Pretrained Language Models for Document-Level Neural Machine Translation</title>
    <url>/2019/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Pretrained-Language-Models-for-Document-Level-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Pretrained Language Models for Document-Level Neural Machine Translation</strong>. Liangyou Li, Xin Jiang, Qun Liu. ArXiv. <a href="https://arxiv.org/pdf/1911.03110.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>现有篇章翻译工作大都只能有限的上下文（前面3句话），当利用更长上下文时，由于训练不稳定模型效果反而下降。理论上来说更长的上下文可以提供更多信息，更有助于翻译。本文就是希望能够在篇章翻译中利用更长的上下文。</p><a id="more"></a>

<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="BERT初始化"><a href="#BERT初始化" class="headerlink" title="BERT初始化"></a>BERT初始化</h2><p>现有有些篇章翻译工作先利用大量平行句对预训练（有些只有利用篇章语料的平行句对预训练），然后再利用平行篇章语料微调。本文不再使用平行句对预训练，而是使用别人训练好的BERT来初始化模型参数。（BERT是在大量单语篇章语料上训练得到的）</p>
<h2 id="利用上下文"><a href="#利用上下文" class="headerlink" title="利用上下文"></a>利用上下文</h2><p>本文使用的上下文为前面512个词。将上下文和当前句子拼接起来，中间有个分隔符，但是如果直接使用Encoder对拼接后的句子进行编码，生成的译文反而更差（训练不稳定）。</p>
<p><img src="/images/mlmdoc.png" alt></p>
<p>本文提出了三个改进方法：</p>
<ul>
<li><p><strong>Segment Embeddings</strong>:<br>用来标记每个词是属于当前要翻译句子，还是属于上下文。</p>
</li>
<li><p><strong>Reverse Position Embeddings</strong>:<br>先对当前要翻译句子进行编号，再对上下文进行编号。</p>
</li>
<li><p><strong>Context Masks</strong>:<br>经过编码器后，当前句子已经包含了上下文信息，对上下文的隐状态加 mask，使得解码器更加关注当前句子。（不加mask，训练不稳定）</p>
</li>
</ul>
<h2 id="多任务"><a href="#多任务" class="headerlink" title="多任务"></a>多任务</h2><p>本文引入了Mask Language Model</p>
<p><img src="/images/mlmdoc1.png" alt></p>
<p>X: 源端当前句子</p>
<p>C: 源端上下文</p>
<p>Y: 目标端当前句子</p>
<p>S: X 和 C 的拼接</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="/images/mlmdoc2.png" alt></p>
<p>可以训12层encoder还是比较 NB 的。<br><font color="#FF0000">我认为作者可以补充一个只加BERT的实验结果。</font></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础】Dropout</title>
    <url>/2019/11/15/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E3%80%91Dropout/</url>
    <content><![CDATA[<p>** Improving neural networks by preventing co-adaptation of feature detectors**. Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R. Salakhutdinov. arXiv 1207.0580. <a href="https://arxiv.org/abs/1207.0580" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="一些博客"><a href="#一些博客" class="headerlink" title="一些博客"></a>一些博客</h1><ul>
<li><a href="https://www.zhihu.com/question/61751133" target="_blank" rel="noopener">神经网络Dropout层中为什么dropout后还需要进行rescale？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/66337970" target="_blank" rel="noopener">Dropout的前世与今生</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【git 使用】分支合并</title>
    <url>/2019/11/12/%E3%80%90git-%E4%BD%BF%E7%94%A8%E3%80%91%E5%88%86%E6%94%AF%E5%90%88%E5%B9%B6/</url>
    <content><![CDATA[<ul>
<li>master发生改变，同步到feature branch</li>
</ul><p>merge master into feature branch</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout &lt;feature branch&gt;</span><br><span class="line">git merge master</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>ArXiv 论文 2019/11/2-2019/11/8</title>
    <url>/2019/11/10/ArXiv-%E8%AE%BA%E6%96%87-2019-11-2-2019-11-8/</url>
    <content><![CDATA[<ul>
<li><a href="https://arxiv.org/abs/1911.00492" target="_blank" rel="noopener">Reasoning Over Paths via Knowledge Base Completion</a></li>
<li><a href="https://arxiv.org/abs/1911.00069" target="_blank" rel="noopener">Neural Cross-Lingual Relation Extraction Based on Bilingual Word Embedding Mapping</a></li>
<li><a href="https://arxiv.org/abs/1911.00133" target="_blank" rel="noopener">Dreaddit: A Reddit Dataset for Stress Analysis in Social Media</a></li>
<li><a href="https://arxiv.org/abs/1911.00176" target="_blank" rel="noopener"><strong>Sequence Modeling with Unconstrained Generation Order</strong></a></li>
<li><a href="https://arxiv.org/abs/1911.00317" target="_blank" rel="noopener">On the Linguistic Representational Power of Neural Machine Translation Models</a></li>
<li><a href="https://arxiv.org/abs/1911.00473" target="_blank" rel="noopener">BERT Goes to Law School: Quantifying the Competitive Advantage of Access to Large Legal Corpora in Contract Understanding</a><a id="more"></a></li>
<li><a href="https://arxiv.org/abs/1911.00484" target="_blank" rel="noopener">Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents</a></li>
<li><a href="https://arxiv.org/abs/1911.00225" target="_blank" rel="noopener">When Choosing Plausible Alternatives, Clever Hans can be Clever</a></li>
<li><a href="https://arxiv.org/abs/1911.00269" target="_blank" rel="noopener">A Robust Data-Driven Approach for Dialogue State Tracking of Unseen Slot Values</a></li>
<li><a href="https://arxiv.org/abs/1911.00274" target="_blank" rel="noopener">Kernelized Bayesian Softmax for Text Generation</a></li>
<li><a href="https://arxiv.org/abs/1911.00359" target="_blank" rel="noopener">CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data</a></li>
</ul>
]]></content>
      <categories>
        <category>arxiv</category>
      </categories>
      <tags>
        <tag>ArXiv</tag>
      </tags>
  </entry>
  <entry>
    <title>【git 使用】clone、branch、add、commit、push</title>
    <url>/2019/11/08/%E3%80%90git-%E4%BD%BF%E7%94%A8%E3%80%91clone%E3%80%81branch%E3%80%81add%E3%80%81commit%E3%80%81push/</url>
    <content><![CDATA[<h1 id="克隆仓库"><a href="#克隆仓库" class="headerlink" title="克隆仓库"></a>克隆仓库</h1><ul>
<li>普通</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@xxx.git</span><br></pre></td></tr></table></figure><ul>
<li>指定branch</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@xxx.git -b &lt;branchname&gt;</span><br></pre></td></tr></table></figure><h1 id="提交修改"><a href="#提交修改" class="headerlink" title="提交修改"></a>提交修改</h1><ul>
<li>提交某个文件</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add &lt;path to file&gt;</span><br><span class="line">git commit -m '&lt;message&gt;'</span><br><span class="line">git push origin &lt;branchname&gt;</span><br></pre></td></tr></table></figure><a id="more"></a>








<ul>
<li>提交多个文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add --all</span><br><span class="line">git commit -m '&lt;message&gt;'</span><br><span class="line">git push origin &lt;branchname&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】alias设置指令别名</title>
    <url>/2019/11/08/%E3%80%90shell%E3%80%91alias%E8%AE%BE%E7%BD%AE%E6%8C%87%E4%BB%A4%E5%88%AB%E5%90%8D/</url>
    <content><![CDATA[<p>alias 可以用来将一些较长的指令进行简化，使用alias时，用户必须使用单引号’’将原来的命令引起来，防止特殊字符导致错误。</p><h1 id="alias基本使用"><a href="#alias基本使用" class="headerlink" title="alias基本使用"></a>alias基本使用</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias 新指令=‘原指令 -选项/参数’</span><br></pre></td></tr></table></figure><p>如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias myscp='scp admin@192.168.72.77'</span><br></pre></td></tr></table></figure><h1 id="查看永久已设置别名"><a href="#查看永久已设置别名" class="headerlink" title="查看永久已设置别名"></a>查看永久已设置别名</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias -p</span><br></pre></td></tr></table></figure><a id="more"></a>







<h1 id="设置永久别名"><a href="#设置永久别名" class="headerlink" title="设置永久别名"></a>设置永久别名</h1><p>修改<code>~/.bashrc</code>文件</p>
<p>参考：<a href="https://man.linuxde.net/alias" target="_blank" rel="noopener">https://man.linuxde.net/alias</a></p>
]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>alias</tag>
      </tags>
  </entry>
  <entry>
    <title>ArXiv 论文 2019/10/28-2019/11/1</title>
    <url>/2019/11/02/ArXiv-%E8%AE%BA%E6%96%87-2019-10-28-2019-11-1/</url>
    <content><![CDATA[<ul>
<li><a href="https://arxiv.org/abs/1910.13461" target="_blank" rel="noopener">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></li>
<li><a href="https://arxiv.org/abs/1910.14659" target="_blank" rel="noopener">Pseudolikelihood Reranking with Masked Language Models</a></li>
<li><a href="https://arxiv.org/abs/1910.14549" target="_blank" rel="noopener">Positional Attention-based Frame Identification with BERT: A Deep Learning Approach to Target Disambiguation and Semantic Frame Selection</a></li>
<li><a href="https://arxiv.org/abs/1910.14192" target="_blank" rel="noopener">Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</a></li>
<li><a href="https://arxiv.org/abs/1910.14176" target="_blank" rel="noopener">Predicting Discourse Structure using Distant Supervision from Sentiment</a><a id="more"></a></li>
<li><a href="https://arxiv.org/abs/1910.14142" target="_blank" rel="noopener">Discourse-Aware Neural Extractive Model for Text Summarization</a></li>
<li><a href="https://arxiv.org/abs/1910.14075" target="_blank" rel="noopener">Fill in the Blanks: Imputing Missing Sentences for Larger-Context Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.14613" target="_blank" rel="noopener">Neural Assistant: Joint Action Prediction, Response Generation, and Latent Knowledge Reasoning</a></li>
<li><a href="https://arxiv.org/abs/1910.14208" target="_blank" rel="noopener">Hidden State Guidance: Improving Image Captioning using An Image Conditioned Autoencoder</a></li>
<li><a href="https://arxiv.org/abs/1910.13890" target="_blank" rel="noopener">A Latent Morphology Model for Open-Vocabulary Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.13794" target="_blank" rel="noopener">Let Me Know What to Ask: Interrogative-Word-Aware Question Generation</a></li>
<li><a href="https://arxiv.org/abs/1910.13466" target="_blank" rel="noopener">Ordered Memory</a></li>
<li><a href="https://arxiv.org/abs/1910.13106" target="_blank" rel="noopener">Incorporating Interlocutor-Aware Context into Response Generation on Multi-Party Chatbots</a></li>
<li><a href="https://arxiv.org/abs/1910.13267" target="_blank" rel="noopener">BPE-Dropout: Simple and Effective Subword Regularization</a></li>
<li><a href="https://arxiv.org/abs/1910.13294" target="_blank" rel="noopener">Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control</a></li>
<li><a href="https://arxiv.org/abs/1910.13437" target="_blank" rel="noopener">An Empirical Study of Generation Order for Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.12708" target="_blank" rel="noopener">Evaluating Lottery Tickets Under Distributional Shifts</a></li>
<li><a href="https://arxiv.org/abs/1910.12702" target="_blank" rel="noopener">Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect Morphological Modeling</a></li>
<li><a href="https://arxiv.org/abs/1910.12698" target="_blank" rel="noopener">Adaptive Ensembling: Unsupervised Domain Adaptation for Political Document Analysis</a></li>
<li><a href="https://arxiv.org/abs/1910.12527" target="_blank" rel="noopener">RPM-Oriented Query Rewriting Framework for E-commerce Keyword-Based Sponsored Search</a></li>
<li><a href="https://arxiv.org/abs/1910.12391" target="_blank" rel="noopener">What does BERT Learn from Multiple-Choice Reading Comprehension Datasets?</a></li>
<li><a href="https://arxiv.org/abs/1910.12197" target="_blank" rel="noopener">Look-up and Adapt: A One-shot Semantic Parser</a></li>
<li><a href="https://arxiv.org/abs/1910.12196" target="_blank" rel="noopener">Open the Boxes of Words: Incorporating Sememes into Textual Adversarial Attack</a></li>
<li><a href="https://arxiv.org/abs/1910.11966" target="_blank" rel="noopener">Yall should read this! Identifying Plurality in Second-Person Personal Pronouns in English Texts</a></li>
<li><a href="https://arxiv.org/abs/1910.12038" target="_blank" rel="noopener">Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word Embeddings and Layered Attention</a></li>
<li><a href="https://arxiv.org/abs/1910.11959" target="_blank" rel="noopener">FineText: Text Classification via Attention-based Language Model Fine-tuning</a></li>
<li><a href="https://arxiv.org/abs/1910.12094" target="_blank" rel="noopener">Meta Learning for End-to-End Low-Resource Speech Recognition</a></li>
<li><a href="https://arxiv.org/abs/1910.11491" target="_blank" rel="noopener">Attention Optimization for Abstractive Document Summarization</a></li>
<li><a href="https://arxiv.org/abs/1910.11471" target="_blank" rel="noopener">Machine Translation from Natural Language to Code using Long-Short Term Memory</a></li>
<li><a href="https://arxiv.org/abs/1910.11470" target="_blank" rel="noopener">A Survey on Recent Advances in Named Entity Recognition from Deep Learning models</a></li>
<li><a href="https://arxiv.org/abs/1910.11411" target="_blank" rel="noopener">Multi-Document Summarization with Determinantal Point Processes and Contextualized Representations</a></li>
<li><a href="https://arxiv.org/abs/1910.11399" target="_blank" rel="noopener">Comparison of Quality Indicators in User-generated Content Using Social Media and Scholarly Text</a></li>
<li><a href="https://arxiv.org/abs/1910.11494" target="_blank" rel="noopener">Fast and Accurate Knowledge-Aware Document Representation Enhancement for News Recommendations</a></li>
<li><a href="https://arxiv.org/abs/1910.11455" target="_blank" rel="noopener">Recognizing long-form speech using streaming end-to-end models</a></li>
</ul>
]]></content>
      <categories>
        <category>arxiv</category>
      </categories>
      <tags>
        <tag>ArXiv</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Discourse-Aware Neural Extractive Model for Text Summarization</title>
    <url>/2019/11/02/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Discourse-Aware-Neural-Extractive-Model-for-Text-Summarization/</url>
    <content><![CDATA[<p><strong>Discourse-Aware Neural Extractive Model for Text Summarization</strong>. Jiacheng Xu, Zhe Gan, Yu Cheng, Jingjing Liu. ArXiv 1910.14142.<a href="https://arxiv.org/pdf/1910.14142.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>作者分析认为现有抽取式文档摘要存在以下两个不足：</p><a id="more"></a>

<ul>
<li>抽取式文档摘要都是以句子级别进行抽取，导致结果包含冗余或者没有用的信息。</li>
<li>BERT常被SOTA文档摘要模型用在文档编码器，但是BERT是再句对上预训练的，不能很好捕捉长距离的句间依赖关系。</li>
</ul>
<p>针对以上两个不足，作者提出了两个解决方法：</p>
<ul>
<li>按EDU进行抽取 （EDU是RST中的基本单元，具体可以去了解discourse parsing）</li>
<li>构造RST Graph和Coreference Graph建模长距离句间依赖关系。</li>
</ul>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>Discourse Segmentation: sequence to EDU</p>
<p>Discourse Parsing: EDU to RST tree</p>
<h2 id="RST-Graph"><a href="#RST-Graph" class="headerlink" title="RST Graph"></a>RST Graph</h2><p>通过篇章分析，可以在篇章上构造得到一棵树，树的叶子节点是EDU，树上的边代表的是对应子节点的重要性程度，N代表主要，S代表次要，可以认为S是N的补充。相邻两个子节点可以有三种关系，N-N,N-S,S-N。</p>
<p>作者提出假设：S依赖N,所以存在一条路径从S指向N；如果两个节点都是N，就认为是右N依赖做N。</p>
<p>根据这个假设，可以将RST discourse tree转成成RST dependence graph。</p>
<p><img src="/images/discbert1.jpg" alt></p>
<p>注：论文原图中没有标N和S，为了好理解我标了N和S。</p>
<p>如果存在一条从第i个EDU指向第j个EDU的路径，则设GR[i][j]=1，否则为0,这样就可以将RST Graph转化成GR矩阵。</p>
<p><img src="/images/discbert2.jpg" alt></p>
<h2 id="Coreference-Graph"><a href="#Coreference-Graph" class="headerlink" title="Coreference Graph"></a>Coreference Graph</h2><p>通过斯坦福的CoreNLP工具，可以得到多个共指簇（coreference clusters），每个簇中的EDU都指向同一个实体。指向同一个实体的EDU存在联系，所以同一个簇中的所有EDU之间（包括自己跟自己）存在一条边。基于这个原则，作者设计一个构造coreference graph的算法，遍历所有簇，簇中每个EDU之间存在一个边。也就得到了共指矩阵GC。</p>
<p><img src="/images/discbert3.jpg" alt></p>
<h2 id="模型框架"><a href="#模型框架" class="headerlink" title="模型框架"></a>模型框架</h2><p><img src="/images/discbert4.jpg" alt></p>
<p>首先使用BERT编码整个篇章，使用BERT得到的隐状态表示，每个EDU内部做self-attention得到EDU的表示，由得到的EDU表示和两个矩阵表示GR和GC，做GCN得到EDU新的表示，通过MLP预测EDU是否被抽取出来做EDU（0-1序列标注）。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在两个数据集上进行验证，并得到了SOTA结果。</p>
<p><img src="/images/discbert5.jpg" alt></p>
<p><img src="/images/discbert6.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Discourse Structure</tag>
        <tag>Extractive</tag>
        <tag>Summarization</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Document-level Neural Machine Translation with Inter-Sentence Attention</title>
    <url>/2019/11/02/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Document-level-Neural-Machine-Translation-with-Inter-Sentence-Attention/</url>
    <content><![CDATA[<p><strong>Document-level Neural Machine Translation with Inter-Sentence Attention</strong>. Shu Jiang, Rui Wang, Zuchao Li, Masao Utiyama, Kehai Chen, Eiichiro Sumita, Hai Zhao, Bao-liang Lu. ArXiv 1910.14528. <a href="https://arxiv.org/pdf/1910.14528.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文认为大部分篇章翻译只是引入大体的篇章上下文信息，但不是所有的上下文信息都对当前句子翻译有效，本文希望对上下文信息进行筛选。于是本文提出一个associated memory network（AMN）考虑句间关系，建模更加相关的上下文。(<em>其实 SAN 和 QCN 都有对上下文进行筛选</em>)</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><img src="/images/camn.jpg" alt></p>
<p>（1）使用RNN对previous sentences（cj）进行编码，得到每个词的隐状态表示<font color="#FF0000">(<em>不是很懂为什么要用RNN，不直接使用transformer，并且当前句子x也不用像c一样使用RNN编码</em>)</font></p>
<p>（2）MultiHead Self-Attention更新每个句子的表示<br><img src="/images/camn1.jpg" alt><br><img src="/images/camn2.jpg" alt></p>
<p>（3）当前句子x的每个词和前面每个句子cj中的每个词算一个相似度分数<br><img src="/images/camn3.jpg" alt></p>
<p>（4）对相似性分数按行做softmax作为最终的相似性分数<br><img src="/images/camn4.jpg" alt></p>
<p>（5）得到句子级别上下文表示<br><img src="/images/camn5.jpg" alt></p>
<p>（6）建模每个句子的权重<br><img src="/images/camn6.jpg" alt></p>
<p>（7）得到篇章级别上下文<br><img src="/images/camn7.jpg" alt></p>
<p>（8）在transformer encoder中融入篇章级别上下文信息<br><img src="/images/camn8.jpg" alt><br><img src="/images/camn9.jpg" alt></p>
<p><font color="#FF0000">整体上来说，这种方法略显粗暴。</font></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在TED Talks, Subtitles, News三个数据集上验证了自己的模型有效性。</p>
<p><img src="/images/camn10.jpg" alt></p>
<font color="#FF0000">
  我认为实验还是存在一些不足：（1）没有跟SAN、QCN等工作进行对比（2）按照HAN公开代码，HAN是没有做BPE的，但是本文有做BPE，而本文中报的结果是HAN中报的没有做BPE的结果。
</font>]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
        <tag>Document NMT</tag>
        <tag>Inter-Sentence</tag>
      </tags>
  </entry>
  <entry>
    <title>Accepted Papers List</title>
    <url>/2019/11/01/Accepted-Papers-List/</url>
    <content><![CDATA[<h1 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h1><ul>
<li><a href="">AAAI</a></li>
<li><a href="https://openreview.net/group?id=ICLR.cc/2020/Conference" target="_blank" rel="noopener">ICLR</a></li>
</ul>
<h1 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h1><ul>
<li><a href="https://dblp.org/db/conf/aaai/aaai2019" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2019/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2019.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://www.aclweb.org/anthology/events/emnlp-2019/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://openreview.net/group?id=ICLR.cc/2019/Conference" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai19.org/accepted-papers.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2019/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">NeurIPS</a></li>
</ul>
<a id="more"></a>

<h1 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h1><ul>
<li><a href="https://dblp.org/db/conf/aaai/aaai2018" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2018/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2018.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://aclweb.org/anthology/events/emnlp-2018/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://iclr.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai-18.org/accepted-papers/index.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2018/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">NeurIPS</a></li>
</ul>
]]></content>
      <categories>
        <category>论文列表</category>
      </categories>
      <tags>
        <tag>AAAI</tag>
        <tag>Accepted Papers</tag>
        <tag>ACL</tag>
        <tag>CVPR</tag>
        <tag>EMNLP</tag>
        <tag>ICLR</tag>
        <tag>ICML</tag>
        <tag>IJCAI</tag>
        <tag>NAACL</tag>
        <tag>NIPS</tag>
      </tags>
  </entry>
  <entry>
    <title>公开课推荐</title>
    <url>/2019/10/31/%E5%85%AC%E5%BC%80%E8%AF%BE%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h1 id="机器学习（斯坦福大学）"><a href="#机器学习（斯坦福大学）" class="headerlink" title="机器学习（斯坦福大学）"></a>机器学习（斯坦福大学）</h1><p>机器学习是一门研究在非特定编程条件下让计算机采取行动的学科。最近二十年，机器学习为我们带来了自动驾驶汽车、实用的语音识别、高效的网络搜索，让我们对人类基因的解读能力大大提高。当今机器学习技术已经非常普遍，您很可能在毫无察觉情况下每天使用几十次。许多研究者还认为机器学习是人工智能（AI）取得进展的最有效途径。</p><a id="more"></a>
<p>本课程将广泛介绍机器学习、数据挖掘和统计模式识别。相关主题包括：(i) 监督式学习（参数和非参数算法、支持向量机、核函数和神经网络）。(ii) 无监督学习（集群、降维、推荐系统和深度学习）。(iii) 机器学习实例（偏见/方差理论；机器学习和AI领域的创新）。课程将引用很多案例和应用，您还需要学习如何在不同领域应用学习算法，例如智能机器人（感知和控制）、文本理解（网络搜索和垃圾邮件过滤）、计算机视觉、医学信息学、音频、数据库挖掘等领域。</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera</a></li>
<li><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="noopener">网易公开课</a></li>
</ul>
<hr>
<h1 id="CS231n（斯坦福大学）"><a href="#CS231n（斯坦福大学）" class="headerlink" title="CS231n（斯坦福大学）"></a>CS231n（斯坦福大学）</h1><p>计算机视觉已经在我们的社会中无处不在，在搜索，图像理解，应用程序，测绘，医药，无人驾驶飞机和自动驾驶汽车中的应用。许多这些应用程序的核心是视觉识别任务，如图像分类，定位和检测。神经网络（又名“深度学习”）方法的最新发展极大地提高了这些最先进的视觉识别系统的性能。本课程深入探讨深度学习架构的细节，重点是学习这些任务的端到端模型，尤其是图像分类。在为期10周的课程中，学生将学习实施，训练和调试自己的神经网络，并获得对计算机视觉尖端研究的详细了解。最后的任务将涉及培训一个数百万参数卷积神经网络，并将其应用于最大的图像分类数据集（ImageNet）。我们将着重教授如何设置图像识别问题，学习算法（例如反向传播），用于训练和微调网络的实际工程技巧，并引导学生通过实践任务和最终课程项目。本课程的大部分背景和材料都将从ImageNet挑战中吸取。</p>
<h2 id="链接-1"><a href="#链接-1" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS20SI（斯坦福大学）"><a href="#CS20SI（斯坦福大学）" class="headerlink" title="CS20SI（斯坦福大学）"></a>CS20SI（斯坦福大学）</h1><p>Tensorflow是Google Brain研究人员开发的一个功能强大的机器学习开源软件库。它具有许多预建功能，可以简化构建不同神经网络的任务。 Tensorflow允许在不同计算机之间分配计算，以及在一台机器中分配多个CPU和GPU。 TensorFlow提供了一个Python API，以及一个较少记录的C ++ API。对于本课程，我们将使用Python。</p>
<p>本课程将涵盖深入学习研究的Tensorflow图书馆的基本原理和当代用法。帮助学生理解Tensorflow的图形计算模型，探索其提供的功能，并学习如何构建和构建最适合深度学习项目的模型。通过本课程，学生将使用Tensorflow建立不同复杂度的模型，从简单的线性/逻辑回归到卷积神经网络和带有LSTM的递归神经网络，以解决词嵌入，翻译，光学字符识别等任务。学生还将学习最佳实践来构建模型并管理研究实验。</p>
<h2 id="链接-2"><a href="#链接-2" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://web.stanford.edu/class/cs20si/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS224d（斯坦福大学）"><a href="#CS224d（斯坦福大学）" class="headerlink" title="CS224d（斯坦福大学）"></a>CS224d（斯坦福大学）</h1><p>自然语言处理（NLP）是信息时代最重要的技术之一。理解复杂的语言也是人工智能的重要组成部分。 NLP的应用无处不在，因为人们用语言沟通大多数事物：网络搜索，广告，电子邮件，客户服务，语言翻译，放射学报告等等。NLP应用背后有大量的基础任务和机器学习模型。最近，深度学习方法在许多不同的NLP任务中获得了非常高的性能。这些模型通常可以通过单一的端到端模型进行培训，而且不需要传统的，特定于任务的特征工程。在这个冬季的季度课程中，学生将学习实施，培训，调试，可视化和创造自己的神经网络模型。本课程深入介绍了深入学习NLP的前沿研究。在模型方面，我们将介绍词向量表示，基于窗口的神经网络，递归神经网络，长期 - 短期记忆模型，递归神经网络，卷积神经网络以及一些涉及存储器组件的最新模型。通过讲座和编程作业，学生将学习使神经网络适应实际问题的必要工程技巧。</p>
<h2 id="链接-3"><a href="#链接-3" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6" target="_blank" rel="noopener">YouTube</a></li>
</ul>
]]></content>
      <categories>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>CS231n</tag>
        <tag>CS20SI</tag>
        <tag>CS224d</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Hierarchical-Modeling-of-Global-Context-for-Document-Level-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</strong>. Xin Tan, Longyin Zhang, Deyi Xiong, Guodong Zhou. EMNLP 2019. <a href="https://www.aclweb.org/anthology/D19-1168.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文觉得现有篇章翻译工作基于pre-context的方法存在两个不足：</p>
<p>（1）只利用一边（one-sidedness）的上下文可能还不够</p>
<p>（2）不正确的pre-context（translation bias propagation caused by improper pre-context）可能会导致翻译错误，所以本文想要利用整个篇章建模全局上下文（global context）来提升篇章翻译。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="使用层次结构建模全局上下文"><a href="#使用层次结构建模全局上下文" class="headerlink" title="使用层次结构建模全局上下文"></a>使用层次结构建模全局上下文</h2><p><img src="/images/HM-GDC.png" alt></p>
<p>A. Sentence Encoder</p>
<p>首先对句子进行编码得到每个词的隐状态表示，</p>
<p><img src="/images/h1.png" alt></p>
<p>求和得到整个句子的表示，</p>
<p><img src="/images/h21.png" alt></p>
<p>B. Document Encoder</p>
<p>对篇章所有句子进行编码，得到拥有篇章信息的句子表示（sentence-level global context）</p>
<p><img src="/images/h22.png" alt></p>
<p>C. Backpropagation of global context</p>
<p>由sentence-level global context得到word-level global context</p>
<p><img src="/images/h3.png" alt></p>
<h2 id="将全局上下文结合到NMT中"><a href="#将全局上下文结合到NMT中" class="headerlink" title="将全局上下文结合到NMT中"></a>将全局上下文结合到NMT中</h2><p>像其他工作一样，这个global context既结合在编码阶段，也可以结合在解码阶段。</p>
<p>A. 结合在编码阶段</p>
<p>使用word-level global context更新每个词的表示，P表示残差dropout，这里为0.1。</p>
<p><img src="/images/h5.png" alt></p>
<p>B. 结合在解码阶段</p>
<p><img src="/images/h4.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>本文实验在中英和德英两个数据集上进行。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>A. 中英</p>
<p>句子级别数据（用于预训练）：2.8M news corpora (LDC 2003E14, LDC2004T07, LDC2005T06, LDC2005T10, LDC2004T08)</p>
<p>篇章级别数据: IWSLT 2017 TED (1906个文档，226K个句对 )</p>
<p>B. 德英</p>
<p>(不进行预训练，没有句子级别数据)</p>
<p>篇章级别数据：IWSLT 2014 TED (1361个文档，172个句对)</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>EMNLP</tag>
        <tag>NMT</tag>
        <tag>Context</tag>
        <tag>Document NMT</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Cross-Lingual-BERT-Transformation-for-Zero-Shot-Dependency-Parsing/</url>
    <content><![CDATA[<p><strong>Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</strong>. Yuxuan Wang, Wanxiang Che, Jiang Guo, Yijia Liu, Ting Liu. EMNLP 2019 <a href="https://arxiv.org/abs/1909.06775" target="_blank" rel="noopener">[PDF]</a>（短文）</p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前大部分cross-lingual word embedding技术存在的问题：</p><a id="more"></a>

<p>（1）依赖大量跨语言数据</p>
<p>（2）需要大量计算资源和训练时间</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文提出一种简单快捷的离线cross-lingual BERT线性映射方法：</p>
<p>（1）通过无监督词对齐方法获得上下文对齐次对（context-level，非词典）</p>
<p>（2）通过预训练好的BERT模型得到上下文对齐次对（x,y）中x,y的上下文表示</p>
<p>（3）通过SVD(奇异值分解)、GD(梯度下降)的方式求得两个表示的线性映射</p>
<p><img src="https://img-blog.csdnimg.cn/2019100320530798.png" alt></p>
<p>作者将获得的跨语言上下文词向量应用到zero-shot依存分析任务上，并获得了目前最好结果。并与XLM(利用跨语言数据重新训练BERT的方法)进行了对比，实验表明该方法在取得与XLM相近结果的情况下，需要的计算资源更少，训练速度也更快。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>EMNLP</tag>
        <tag>Cross Lingual</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Neural-Keyphrase-Generation-via-Reinforcement-Learning-with-Adaptive-Rewards/</url>
    <content><![CDATA[<p><strong>Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</strong>. Hou Pong Chan, Wang Chen, Lu Wang, Irwin King. ACL 2019. <a href="https://arxiv.org/abs/1906.04106" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前keyphrase generation任务中存在的两个不足：</p><a id="more"></a>

<p>（1）模型生成的keyphrase比真实的keyphrase个数少</p>
<p>（2）已有评价标准依赖词的完成匹配（不完全匹配就算错，如真实keyphrase为SVM，模型生成的keyphrase为support vector machine也算错）</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>keyphrase根据是否在原文中是否出现分present和absent，这里将一个document的所有keyphrase拼接成一个序列，present在前absent在后，并通过利用seq2seq编码document来生成所有的keyphrase。<br><img src="https://img-blog.csdnimg.cn/20190620092517159.png" width="55%" height="55%"></p>
<p>针对第一个不足，作者使用了reinforcement learning，</p>
<p>sample policy：<br><img src="https://img-blog.csdnimg.cn/20190620092800754.png" alt></p>
<p>reward function: RF1<br><img src="https://img-blog.csdnimg.cn/20190620091404860.png" alt></p>
<p>N为目前已生成的keyphrase个数，G为真实keyphrase个数。作者认为当生成keyphrase的个数还少于真实keyphrase个数时，应该鼓励模型去生成更多的keyphrase，所以用recall作为reward；当个数足够时，除了要求个数也要要求正确性，所以用的F1。看到这里可能也有人会有疑问，为什么前面只重视个数而忽视正确性呢？为什么不改变个数和正确性的权重呢（可以认为是F1的变形）？在这里我个人认为作者可能是实验驱动，只用recall就有效果了；如果没有效果作者可能会去设计吧。。。</p>
<p>presen keyphrase 和 absent keyphrase分别计算reward:<br><img src="https://img-blog.csdnimg.cn/20190620093050519.png" width="55%" height="55%"></p>
<p>针对第二个不足，思路也很容易理解，就是找keyphrase的各种形式，作者这里主要有三个方法</p>
<p>（1）Acronyms in the ground-truths</p>
<p>（2）Wikipedia entity titles</p>
<p>（3）Wikipedia disambiguation pages</p>
<p>然后作者在四个baseline基础上分别验证了方法的有效性，并且对生成的keyphrase的个数、RF1进行了分析。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>ACL</tag>
        <tag>Keyphrase Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 教程</title>
    <url>/2019/10/31/Hexo-%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<ul>
<li><a href="https://hexo-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">hexo指南</a></li>
<li><a href="https://ahh666.com/posts/blog_gitalk_about.html" target="_blank" rel="noopener">添加gitalk评论</a></li>
<li><a href="https://blog.yleao.com/2018/0901/hexo-next%E4%B8%BB%E9%A2%98%E4%B8%8B%E7%9A%84%E7%BE%8E%E5%8C%96.html" target="_blank" rel="noopener">hexo-next主题下的美化</a></li>
<li><a href="https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/MATH.md" target="_blank" rel="noopener">hexo-next使用公式</a></li>
<li><a href="https://io-oi.me/tech/hexo-next-optimization/" target="_blank" rel="noopener">打造个性超赞博客 Hexo + NexT + GitHub Pages 的超深度优化</a></li>
<li><a href="https://muse.theme-next.org/" target="_blank" rel="noopener">Next官方文档</a></li>
<li><a href="https://fontawesome.com/v4.7.0/icons/" target="_blank" rel="noopener">图标</a></li>
</ul>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Unsupervised%20Neural%20Single-Document%20Summarization%20of%20Reviews%20via/</url>
    <content><![CDATA[<p><strong>Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</strong>. Masaru Isonuma, Junichiro Mori, Ichiro Sakata. ACL 2019. <a href="https://arxiv.org/pdf/1906.05691.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文认为，评论（review）可以当作一个棵篇章树，树的根节点是其摘要，表示该评论的整体意思; 树的其他节点是对其父节点的细化。 也就是说这棵篇章树由摘要（根节点）与评论中所有句子（非根节点，每个非根节点代表一个句子）组成。于是本文通过学习构造这个隐式篇章树来建模得到评论摘要，并提出一种排序（rank）算法选择对生成摘要更加重要的句子。</p>
<p><img src="/images/strsum.png" alt></p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="模型整体方法"><a href="#模型整体方法" class="headerlink" title="模型整体方法"></a>模型整体方法</h2><p>（1）双向GRU+maxpooling 建模得到每个句子表示</p>
<p>（2）建模 父节点-子节点 对应关系权重（权重代表了树的关系）</p>
<p>（3）加权求和所有子节点表示，生成父节点（本文假设：子节点能够还原父节点，因为子节点包含了比父节点更多的信息。）</p>
<p>目标函数就是所有父节点生成概率最大。</p>
<p><img src="/images/strsum2.png" alt></p>
<h2 id="父节点-子节点-对应关系权重建模方法"><a href="#父节点-子节点-对应关系权重建模方法" class="headerlink" title="父节点-子节点 对应关系权重建模方法"></a>父节点-子节点 对应关系权重建模方法</h2><p>初始建模：边界概率（Marginal Probability of Dependency）</p>
<p><img src="/images/strsum3.png" alt></p>
<p>归一化（公式推导不是很懂）</p>
<p><img src="/images/strsum4.png" alt></p>
<p>调整：篇章排序（DiscourseRank）</p>
<p>受PageRank算法启发，更重要的句子有更多后代，迭代更新权重矩阵。<br><img src="/images/strsum5.png" alt></p>
<p><img src="/images/strsum6.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>ACL</tag>
        <tag>Discourse Structure</tag>
        <tag>Discourse Ranking</tag>
      </tags>
  </entry>
</search>

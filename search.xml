<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Accepted Papers List</title>
    <url>/2019/11/01/Accepted-Papers-List/</url>
    <content><![CDATA[<h1 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h1><ul>
<li><a href="https://aaai.org/Conferences/AAAI-19/wp-content/uploads/2018/11/AAAI-19_Accepted_Papers.pdf" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2019/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2019.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://www.emnlp-ijcnlp2019.org/program/accepted/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://openreview.net/group?id=ICLR.cc/2019/Conference" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai19.org/accepted-papers.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2019/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">NIPS</a></li>
</ul><h1 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h1><ul>
<li><a href="https://dblp.org/db/conf/aaai/aaai2018" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2018/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2018.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://aclweb.org/anthology/events/emnlp-2018/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://iclr.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai-18.org/accepted-papers/index.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2018/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">NIPS</a></li>
</ul>]]></content>
  </entry>
  <entry>
    <title>公开课推荐</title>
    <url>/2019/10/31/%E5%85%AC%E5%BC%80%E8%AF%BE%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h1 id="机器学习（斯坦福大学）"><a href="#机器学习（斯坦福大学）" class="headerlink" title="机器学习（斯坦福大学）"></a>机器学习（斯坦福大学）</h1><p>机器学习是一门研究在非特定编程条件下让计算机采取行动的学科。最近二十年，机器学习为我们带来了自动驾驶汽车、实用的语音识别、高效的网络搜索，让我们对人类基因的解读能力大大提高。当今机器学习技术已经非常普遍，您很可能在毫无察觉情况下每天使用几十次。许多研究者还认为机器学习是人工智能（AI）取得进展的最有效途径。</p><a id="more"></a>
<p>本课程将广泛介绍机器学习、数据挖掘和统计模式识别。相关主题包括：(i) 监督式学习（参数和非参数算法、支持向量机、核函数和神经网络）。(ii) 无监督学习（集群、降维、推荐系统和深度学习）。(iii) 机器学习实例（偏见/方差理论；机器学习和AI领域的创新）。课程将引用很多案例和应用，您还需要学习如何在不同领域应用学习算法，例如智能机器人（感知和控制）、文本理解（网络搜索和垃圾邮件过滤）、计算机视觉、医学信息学、音频、数据库挖掘等领域。</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera</a></li>
<li><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="noopener">网易公开课</a></li>
</ul>
<hr>
<h1 id="CS231n（斯坦福大学）"><a href="#CS231n（斯坦福大学）" class="headerlink" title="CS231n（斯坦福大学）"></a>CS231n（斯坦福大学）</h1><p>计算机视觉已经在我们的社会中无处不在，在搜索，图像理解，应用程序，测绘，医药，无人驾驶飞机和自动驾驶汽车中的应用。许多这些应用程序的核心是视觉识别任务，如图像分类，定位和检测。神经网络（又名“深度学习”）方法的最新发展极大地提高了这些最先进的视觉识别系统的性能。本课程深入探讨深度学习架构的细节，重点是学习这些任务的端到端模型，尤其是图像分类。在为期10周的课程中，学生将学习实施，训练和调试自己的神经网络，并获得对计算机视觉尖端研究的详细了解。最后的任务将涉及培训一个数百万参数卷积神经网络，并将其应用于最大的图像分类数据集（ImageNet）。我们将着重教授如何设置图像识别问题，学习算法（例如反向传播），用于训练和微调网络的实际工程技巧，并引导学生通过实践任务和最终课程项目。本课程的大部分背景和材料都将从ImageNet挑战中吸取。</p>
<h2 id="链接-1"><a href="#链接-1" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS20SI（斯坦福大学）"><a href="#CS20SI（斯坦福大学）" class="headerlink" title="CS20SI（斯坦福大学）"></a>CS20SI（斯坦福大学）</h1><p>Tensorflow是Google Brain研究人员开发的一个功能强大的机器学习开源软件库。它具有许多预建功能，可以简化构建不同神经网络的任务。 Tensorflow允许在不同计算机之间分配计算，以及在一台机器中分配多个CPU和GPU。 TensorFlow提供了一个Python API，以及一个较少记录的C ++ API。对于本课程，我们将使用Python。</p>
<p>本课程将涵盖深入学习研究的Tensorflow图书馆的基本原理和当代用法。帮助学生理解Tensorflow的图形计算模型，探索其提供的功能，并学习如何构建和构建最适合深度学习项目的模型。通过本课程，学生将使用Tensorflow建立不同复杂度的模型，从简单的线性/逻辑回归到卷积神经网络和带有LSTM的递归神经网络，以解决词嵌入，翻译，光学字符识别等任务。学生还将学习最佳实践来构建模型并管理研究实验。</p>
<h2 id="链接-2"><a href="#链接-2" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://web.stanford.edu/class/cs20si/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS224d（斯坦福大学）"><a href="#CS224d（斯坦福大学）" class="headerlink" title="CS224d（斯坦福大学）"></a>CS224d（斯坦福大学）</h1><p>自然语言处理（NLP）是信息时代最重要的技术之一。理解复杂的语言也是人工智能的重要组成部分。 NLP的应用无处不在，因为人们用语言沟通大多数事物：网络搜索，广告，电子邮件，客户服务，语言翻译，放射学报告等等。NLP应用背后有大量的基础任务和机器学习模型。最近，深度学习方法在许多不同的NLP任务中获得了非常高的性能。这些模型通常可以通过单一的端到端模型进行培训，而且不需要传统的，特定于任务的特征工程。在这个冬季的季度课程中，学生将学习实施，培训，调试，可视化和创造自己的神经网络模型。本课程深入介绍了深入学习NLP的前沿研究。在模型方面，我们将介绍词向量表示，基于窗口的神经网络，递归神经网络，长期 - 短期记忆模型，递归神经网络，卷积神经网络以及一些涉及存储器组件的最新模型。通过讲座和编程作业，学生将学习使神经网络适应实际问题的必要工程技巧。</p>
<h2 id="链接-3"><a href="#链接-3" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6" target="_blank" rel="noopener">YouTube</a></li>
</ul>
]]></content>
      <categories>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>CS231n</tag>
        <tag>CS20SI</tag>
        <tag>CS224d</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Hierarchical-Modeling-of-Global-Context-for-Document-Level-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</strong>. Xin Tan, Longyin Zhang, Deyi Xiong, Guodong Zhou. EMNLP 2019.</p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文觉得现有篇章翻译工作基于pre-context的方法存在两个不足：</p><a id="more"></a>

<p>（1）只利用一边（one-sidedness）的上下文可能还不够</p>
<p>（2）不正确的pre-context（translation bias propagation caused by improper pre-context）可能会导致翻译错误，所以本文想要利用整个篇章建模全局上下文（global context）来提升篇章翻译。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="使用层次结构建模全局上下文"><a href="#使用层次结构建模全局上下文" class="headerlink" title="使用层次结构建模全局上下文"></a>使用层次结构建模全局上下文</h2><p><img src="/images/HM-GDC.png" alt></p>
<p>A. Sentence Encoder</p>
<p>首先对句子进行编码得到每个词的隐状态表示，</p>
<p><img src="/images/h1.png" alt></p>
<p>求和得到整个句子的表示，</p>
<p><img src="/images/h21.png" alt></p>
<p>B. Document Encoder</p>
<p>对篇章所有句子进行编码，得到拥有篇章信息的句子表示（sentence-level global context）</p>
<p><img src="/images/h22.png" alt></p>
<p>C. Backpropagation of global context</p>
<p>由sentence-level global context得到word-level global context</p>
<p><img src="/images/h3.png" alt></p>
<h2 id="将全局上下文结合到NMT中"><a href="#将全局上下文结合到NMT中" class="headerlink" title="将全局上下文结合到NMT中"></a>将全局上下文结合到NMT中</h2><p>像其他工作一样，这个global context既结合在编码阶段，也可以结合在解码阶段。</p>
<p>A. 结合在编码阶段</p>
<p>使用word-level global context更新每个词的表示，P表示残差dropout，这里为0.1。</p>
<p><img src="/images/h5.png" alt></p>
<p>B. 结合在解码阶段</p>
<p><img src="/images/h4.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>本文实验在中英和德英两个数据集上进行。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>A. 中英</p>
<p>句子级别数据（用于预训练）：2.8M news corpora (LDC 2003E14, LDC2004T07, LDC2005T06, LDC2005T10, LDC2004T08)</p>
<p>篇章级别数据: IWSLT 2017 TED (1906个文档，226K个句对 )</p>
<p>B. 德英</p>
<p>(不进行预训练，没有句子级别数据)</p>
<p>篇章级别数据：IWSLT 2014 TED (1361个文档，172个句对)</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Document NMT</tag>
        <tag>NMT</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Cross-Lingual-BERT-Transformation-for-Zero-Shot-Dependency-Parsing/</url>
    <content><![CDATA[<p><strong>Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</strong>. Yuxuan Wang, Wanxiang Che, Jiang Guo, Yijia Liu, Ting Liu. EMNLP 2019 <a href="https://arxiv.org/abs/1909.06775" target="_blank" rel="noopener">[PDF]</a>（短文）</p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前大部分cross-lingual word embedding技术存在的问题：</p><a id="more"></a>

<p>（1）依赖大量跨语言数据</p>
<p>（2）需要大量计算资源和训练时间</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文提出一种简单快捷的离线cross-lingual BERT线性映射方法：</p>
<p>（1）通过无监督词对齐方法获得上下文对齐次对（context-level，非词典）</p>
<p>（2）通过预训练好的BERT模型得到上下文对齐次对（x,y）中x,y的上下文表示</p>
<p>（3）通过SVD(奇异值分解)、GD(梯度下降)的方式求得两个表示的线性映射</p>
<p><img src="https://img-blog.csdnimg.cn/2019100320530798.png" alt></p>
<p>作者将获得的跨语言上下文词向量应用到zero-shot依存分析任务上，并获得了目前最好结果。并与XLM(利用跨语言数据重新训练BERT的方法)进行了对比，实验表明该方法在取得与XLM相近结果的情况下，需要的计算资源更少，训练速度也更快。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Cross Lingual</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Neural-Keyphrase-Generation-via-Reinforcement-Learning-with-Adaptive-Rewards/</url>
    <content><![CDATA[<p><strong>Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</strong>. Hou Pong Chan, Wang Chen, Lu Wang, Irwin King. ACL 2019. <a href="https://arxiv.org/abs/1906.04106" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前keyphrase generation任务中存在的两个不足：</p><a id="more"></a>

<p>（1）模型生成的keyphrase比真实的keyphrase个数少</p>
<p>（2）已有评价标准依赖词的完成匹配（不完全匹配就算错，如真实keyphrase为SVM，模型生成的keyphrase为support vector machine也算错）</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>keyphrase根据是否在原文中是否出现分present和absent，这里将一个document的所有keyphrase拼接成一个序列，present在前absent在后，并通过利用seq2seq编码document来生成所有的keyphrase。<br><img src="https://img-blog.csdnimg.cn/20190620092517159.png" width="55%" height="55%"></p>
<p>针对第一个不足，作者使用了reinforcement learning，</p>
<p>sample policy：<br><img src="https://img-blog.csdnimg.cn/20190620092800754.png" alt></p>
<p>reward function: RF1<br><img src="https://img-blog.csdnimg.cn/20190620091404860.png" alt></p>
<p>N为目前已生成的keyphrase个数，G为真实keyphrase个数。作者认为当生成keyphrase的个数还少于真实keyphrase个数时，应该鼓励模型去生成更多的keyphrase，所以用recall作为reward；当个数足够时，除了要求个数也要要求正确性，所以用的F1。看到这里可能也有人会有疑问，为什么前面只重视个数而忽视正确性呢？为什么不改变个数和正确性的权重呢（可以认为是F1的变形）？在这里我个人认为作者可能是实验驱动，只用recall就有效果了；如果没有效果作者可能会去设计吧。。。</p>
<p>presen keyphrase 和 absent keyphrase分别计算reward:<br><img src="https://img-blog.csdnimg.cn/20190620093050519.png" width="55%" height="55%"></p>
<p>针对第二个不足，思路也很容易理解，就是找keyphrase的各种形式，作者这里主要有三个方法</p>
<p>（1）Acronyms in the ground-truths</p>
<p>（2）Wikipedia entity titles</p>
<p>（3）Wikipedia disambiguation pages</p>
<p>然后作者在四个baseline基础上分别验证了方法的有效性，并且对生成的keyphrase的个数、RF1进行了分析。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Keyphrase Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 教程</title>
    <url>/2019/10/31/Hexo-%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<ul>
<li><a href="https://hexo-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">hexo指南</a></li>
</ul>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>博客完善</title>
    <url>/2019/10/31/%E5%8D%9A%E5%AE%A2%E5%AE%8C%E5%96%84/</url>
    <content><![CDATA[<ul>
<li>hexo-admin 后台编辑功能完善</li>
<li><strong>多级分类</strong></li>
<li>博客阅读统计</li>
<li>标签云模块</li>
<li><strong>多级分类模块</strong></li>
<li>最新博客模块,热榜</li>
<li>评论模块</li>
<li>留言模块</li>
<li>hexo markdown 编辑语法</li>
<li>首页博客分栏</li>
<li>整理CSDN博客论文笔记 [完成]</li>
<li>google Adsense <a href>代码已经修改完成，需要等谷歌审核</a></li>
<li>部署到github page上</li>
<li>增加一个新栏目： 会议截稿</li>
<li>标签图案修改，并挪到开头位置</li>
<li><a href="https://hoxis.github.io/" target="_blank" rel="noopener">可借鉴博客</a></li>
<li>RSS订阅</li>
<li>置顶设置，Accepted Paper List</li>
<li>增加资源模块</li>
</ul>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Unsupervised%20Neural%20Single-Document%20Summarization%20of%20Reviews%20via/</url>
    <content><![CDATA[<p><strong>Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</strong>. Masaru Isonuma, Junichiro Mori, Ichiro Sakata. ACL 2019. <a href="https://arxiv.org/pdf/1906.05691.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文认为，评论（review）可以当作一个棵篇章树，树的根节点是其摘要，表示该评论的整体意思; 树的其他节点是对其父节点的细化。 也就是说这棵篇章树由摘要（根节点）与评论中所有句子（非根节点，每个非根节点代表一个句子）组成。于是本文通过学习构造这个隐式篇章树来建模得到评论摘要，并提出一种排序（rank）算法选择对生成摘要更加重要的句子。</p>
<p><img src="/images/strsum.png" alt></p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="模型整体方法"><a href="#模型整体方法" class="headerlink" title="模型整体方法"></a>模型整体方法</h2><p>（1）双向GRU+maxpooling 建模得到每个句子表示</p>
<p>（2）建模 父节点-子节点 对应关系权重（权重代表了树的关系）</p>
<p>（3）加权求和所有子节点表示，生成父节点（本文假设：子节点能够还原父节点，因为子节点包含了比父节点更多的信息。）</p>
<p>目标函数就是所有父节点生成概率最大。</p>
<p><img src="/images/strsum2.png" alt></p>
<h2 id="父节点-子节点-对应关系权重建模方法"><a href="#父节点-子节点-对应关系权重建模方法" class="headerlink" title="父节点-子节点 对应关系权重建模方法"></a>父节点-子节点 对应关系权重建模方法</h2><p>初始建模：边界概率（Marginal Probability of Dependency）</p>
<p><img src="/images/strsum3.png" alt></p>
<p>归一化（公式推导不是很懂）</p>
<p><img src="/images/strsum4.png" alt></p>
<p>调整：篇章排序（DiscourseRank）</p>
<p>受PageRank算法启发，更重要的句子有更多后代，迭代更新权重矩阵。<br><img src="/images/strsum5.png" alt></p>
<p><img src="/images/strsum6.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Discourse Structure</tag>
        <tag>Discourse Ranking</tag>
      </tags>
  </entry>
  <entry>
    <title>My New Post</title>
    <url>/2019/10/30/My-New-Post/</url>
    <content><![CDATA[<p>hello word</p>]]></content>
      <tags>
        <tag>Test</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/10/30/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hello</tag>
        <tag>你好</tag>
        <tag>World</tag>
        <tag>Chenjx</tag>
        <tag>xiaomi</tag>
        <tag>NLP</tag>
        <tag>ads</tag>
        <tag>156</tag>
        <tag>leijun</tag>
        <tag>xiaoai</tag>
        <tag>fuli</tag>
        <tag>gongsi</tag>
        <tag>ACL</tag>
        <tag>2019</tag>
        <tag>2018</tag>
        <tag>20017</tag>
        <tag>9102</tag>
      </tags>
  </entry>
</search>

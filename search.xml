<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>screen后台运行进程</title>
    <url>/2020/02/16/screen%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>我们常常需要将进程挂在后台运行，防止因关闭窗口或断开连接导致进程被杀掉。screen可以实现进程与当前窗口分离，即使断开连接了，进行仍可以继续运行；并且当我们重新连接后，仍可读取当前进程。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install screen</span><br></pre></td></tr></table></figure><h1 id="新建窗口"><a href="#新建窗口" class="headerlink" title="新建窗口"></a>新建窗口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 方法一</span></span><br><span class="line">screen # 新建一个无名窗口，断开连接后仍可以后台运行，但是无法重新连接</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方法二</span></span><br><span class="line">screen -S &lt;screen_name&gt; # 新建一个窗口并进入该窗口</span><br></pre></td></tr></table></figure><a id="more"></a>




<h1 id="运行后台程序"><a href="#运行后台程序" class="headerlink" title="运行后台程序"></a>运行后台程序</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen &lt;your_command&gt; # 在无名窗口执行命令 &lt;your_command&gt;</span><br></pre></td></tr></table></figure>
<p>或者在新建<code>&lt;screen_name&gt;</code>窗口后，直接运行相应程序就好</p>
<h1 id="会话分离"><a href="#会话分离" class="headerlink" title="会话分离"></a>会话分离</h1><p>退出该screen，让进程在后台运行，按住快捷键<strong><em>Ctrl + A + D</em></strong></p>
<h1 id="查看所有窗口"><a href="#查看所有窗口" class="headerlink" title="查看所有窗口"></a>查看所有窗口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -ls</span><br></pre></td></tr></table></figure>
<h1 id="恢复窗口"><a href="#恢复窗口" class="headerlink" title="恢复窗口"></a>恢复窗口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 方法一</span></span><br><span class="line">screen -r &lt;PID_to_screen&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方法二</span></span><br><span class="line">screen -r &lt;screen_name&gt;</span><br></pre></td></tr></table></figure>
<h1 id="杀死会话"><a href="#杀死会话" class="headerlink" title="杀死会话"></a>杀死会话</h1><h2 id="杀死当前会话窗口"><a href="#杀死当前会话窗口" class="headerlink" title="杀死当前会话窗口"></a>杀死当前会话窗口</h2><p>按住快捷键<strong><em>Ctrl + A + K</em></strong></p>
<h2 id="杀死指定会话窗口"><a href="#杀死指定会话窗口" class="headerlink" title="杀死指定会话窗口"></a>杀死指定会话窗口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -9 &lt;PID_to_screen&gt;</span><br></pre></td></tr></table></figure>
<h1 id="清除僵尸窗口"><a href="#清除僵尸窗口" class="headerlink" title="清除僵尸窗口"></a>清除僵尸窗口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -wipe</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>screen</tag>
        <tag>后台</tag>
      </tags>
  </entry>
  <entry>
    <title>tgz文件压缩&解压</title>
    <url>/2020/02/15/tgz%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9-%E8%A7%A3%E5%8E%8B/</url>
    <content><![CDATA[<h1 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h1><h2 id="压缩指定文件夹"><a href="#压缩指定文件夹" class="headerlink" title="压缩指定文件夹"></a>压缩指定文件夹</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar zcvf &lt;filename&gt;.tgz &lt;path_to_dir&gt;</span><br></pre></td></tr></table></figure><h1 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h1><h2 id="解压到当前文件夹"><a href="#解压到当前文件夹" class="headerlink" title="解压到当前文件夹"></a>解压到当前文件夹</h2><h3 id="保留原始压缩文件"><a href="#保留原始压缩文件" class="headerlink" title="保留原始压缩文件"></a>保留原始压缩文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar zxvf &lt;filename&gt;.tgz -C .</span><br></pre></td></tr></table></figure><h2 id="解压到指定文件夹"><a href="#解压到指定文件夹" class="headerlink" title="解压到指定文件夹"></a>解压到指定文件夹</h2><h3 id="保留原始压缩文件-1"><a href="#保留原始压缩文件-1" class="headerlink" title="保留原始压缩文件"></a>保留原始压缩文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar zxvf &lt;filename&gt;.tgz -C &lt;path_to_dir&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>tgz</tag>
        <tag>压缩</tag>
        <tag>解压</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Unsupervised Domain Adaptation for Neural Machine Translation with Iterative Back Translation</title>
    <url>/2020/02/13/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Unsupervised-Domain-Adaptation-for-Neural-Machine-Translation-with-Iterative-Back-Translation/</url>
    <content><![CDATA[<p><strong>Unsupervised Domain Adaptation for Neural Machine Translation with Iterative Back Translation</strong>. Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits. AAAI 2020. <a href="https://arxiv.org/pdf/2001.08140.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>构造领域平行数据成本很高，如何在没有领域平行数据的情况下训练领域翻译模型显得尤为重要。本文想要解决的就是非监督领域适应NMT问题，提出了一种新的构造领域平行数据的方法：迭代回翻。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><img src="/images/UDA_IBT_1.png" alt></p>
<p>本文提出一种基于transformer的模型框架，修改了transformer的encoder和decoder的输入，加入了language embedding，该模型具有以下特点：<br><br>1.源语言和目标语言共享bpe词表 <br><br>2.源语言和目标语言共享隐空间 <br></p>
<p>本文使用该模型用来训练语言模型、S2T翻译模型、T2S翻译模型，并且它们共享参数。<br>训练过程分三个步骤：<br>1.使用领域单语数据训练语言模型<br><img src="/images/UDA_IBT_3.png" alt></p>
<p>2.使用S2T翻译模型构造伪平行数据训练T2S模型，使用T2S翻译模型构造伪平行数据训练S2T模型<br><img src="/images/UDA_IBT_4.png" alt><br><font style="color: red">*公式中应该是作者笔误，顺序写错了。</font></p>
<p>3.使用平行数据训练模型<br><img src="/images/UDA_IBT_5.png" alt></p>
<p>不断迭代三个步骤直到参数收敛。</p>
<p>算法表示如下</p>
<p><img src="/images/UDA_IBT_2.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="/images/UDA_IBT_6.png" alt></p>
<ul>
<li><strong>COPY</strong>：混合(t_in, t_in)和(s_out, t_out)，一起训练nmt</li>
<li><strong>BACK</strong>：使用Model_out构造伪平行in-domain数据，混合out-domain数据</li>
<li><strong>DALI</strong>：使用in-domain词表翻译t_in sent，构造伪平行数据，finetune  Model_out</li>
<li><strong>DAFE</strong>：多任务，NMT_out和LM_in (insert domain and task embedding)</li>
<li><strong>IBT</strong>: 迭代回翻，但不使用out-domain数据（也就是没有步骤三，完全无监督翻译）</li>
<li><strong>IBT+OUTD</strong>: 使用out-domain数据训练步骤三</li>
<li><strong>IBT+BACK</strong>: 使用伪平行数据和out-domain数据一起训练步骤三</li>
</ul>
<p>消融实验<br><img src="/images/UDA_IBT_7.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>AAAI</tag>
        <tag>迭代回翻</tag>
        <tag>非监督</tag>
        <tag>领域适应</tag>
      </tags>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-12</title>
    <url>/2020/02/12/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-12/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> The Rumour Mill: Making Misinformation Spread Visible and Tangible <a href="https://arxiv.org/pdf/2002.04494" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning <a href="https://arxiv.org/pdf/2002.04326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Learning Coupled Policies for Simultaneous Machine Translation <a href="https://arxiv.org/pdf/2002.04306" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Non-Autoregressive Neural Dialogue Generation <a href="https://arxiv.org/pdf/2002.04250" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Performance Comparison of Crowdworkers and NLP Tools onNamed-Entity  Recognition and Sentiment Analysis of Political Tweets <a href="https://arxiv.org/pdf/2002.04181" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Training with Streaming Annotation <a href="https://arxiv.org/pdf/2002.04165" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Automatic Discourse Segmentation: an evaluation in French <a href="https://arxiv.org/pdf/2002.04095" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> An experiment exploring the theoretical and methodological challenges in  developing a semi-automated approach to analysis of small-N qualitative data <a href="https://arxiv.org/pdf/2002.04513" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> HGAT: Hierarchical Graph Attention Network for Fake News Detection <a href="https://arxiv.org/pdf/2002.04397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Convolutional Neural Networks and a Transfer Learning Strategy to  Classify Parkinson's Disease from Speech in Three Different Languages <a href="https://arxiv.org/pdf/2002.04374" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Adversarial Filters of Dataset Biases <a href="https://arxiv.org/pdf/2002.04108" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><!-- procjx-wenzhang2 --> <ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins> <script>      (adsbygoogle = window.adsbygoogle || []).push({}); </script>

<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. The Rumour Mill: Making Misinformation Spread Visible and Tangible</b>  <a href="https://arxiv.org/pdf/2002.04494" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Inie%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nanna Inie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Olesen%2C+J+F" target="_blank" rel="noopener" style="color:#0000EE;">Jeanette Falk Olesen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Derczynski%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Leon Derczynski</a><br>
<font size="3">
Abstract: The spread of misinformation presents a technological and social threat to society. With the advance of AI-based language models, automatically generated texts have become difficult to identify and easy to create at scale. We present the "Rumour Mill", a playful art piece, designed as a commentary on the spread of rumours and automatically-generated misinformation. The mill is a tabletop interactive machine, which invites a user to experience the process of creating believable text by interacting with different tangible controls on the mill. The user manipulates visible parameters to adjust the genre and type of an automatically generated text rumour. The Rumour Mill is a physical demonstration of the state of NLP technology and its ability to generate and manipulate natural language text, and of the act of starting and spreading rumours. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：误传的传播呈现给社会技术和社会的威胁。随着基于人工智能语言模型的推进，自动生成的文本已经变得难以识别，容易大规模制造。我们提出了“传闻”，一个好玩艺术片，设计为传言和自动生成的误传传播的评注。该工厂是一个桌面交互的机器，它邀请用户通过与轧机上不同的实际控制交互体验创造可信的文本的过程。用户操纵可见参数来调整体裁和键入一个自动生成的文本的传言。谣言是NLP技术状况及其产生和处理自然语言文字能力的物理演示，以及启动和传播谣言的行为。</font>
</div>


<hr>
<div id="paper2"> <b>2. ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning</b>  <a href="https://arxiv.org/pdf/2002.04326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weihao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zihang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanfei Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Feng%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiashi Feng</a><br>
<font size="3">
Abstract: Recent powerful pre-trained language models have achieved remarkable performance on most of the popular datasets for reading comprehension. It is time to introduce more challenging datasets to push the development of this field towards more comprehensive reasoning of text. In this paper, we introduce a new Reading Comprehension dataset requiring logical reasoning (ReClor) extracted from standardized graduate admission examinations. As earlier studies suggest, human-annotated datasets usually contain biases, which are often exploited by models to achieve high accuracy without truly understanding the text. In order to comprehensively evaluate the logical reasoning ability of models on ReClor, we propose to identify biased data points and separate them into EASY set while the rest as HARD set. Empirical results show that state-of-the-art models have an outstanding ability to capture biases contained in the dataset with high accuracy on EASY set. However, they struggle on HARD set with poor performance near that of random guess, indicating more research is needed to essentially enhance the logical reasoning ability of current models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近期强大的预先训练的语言模型已经达到上最流行的数据集的表现可圈可点阅读理解。现在是时候推出更多具有挑战性的数据集，以推动这一领域的发展对文本的更全面的推理。在本文中，我们介绍一种新的阅读理解数据集需要从标准化的研究生入学考试中提取的逻辑推理（ReClor）。正如之前的研究表明，人类的注解数据集通常包含的偏见，这往往是由模型利用来达到较高的精度没有真正理解课文。为了全面评估对ReClor车型的逻辑推理能力，我们建议确定偏置数据点，将它们分开成易于设置，而其余硬集。实证结果表明，国家的最先进的机型有出色的能力，包含在与EASY集高精度数据集中采集偏见。然而，他们在HARD组与斗争是附近随机猜测的表现不佳，表示需要基本上提高现有模式的逻辑推理能力进行更多的研究。</font>
</div>


<hr>
<div id="paper3"> <b>3. Learning Coupled Policies for Simultaneous Machine Translation</b>  <a href="https://arxiv.org/pdf/2002.04306" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Arthur%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Philip Arthur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cohn%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Trevor Cohn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Haffari%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gholamreza Haffari</a><br>
<font size="3">
Abstract: In simultaneous machine translation, the system needs to incrementally generate the output translation before the input sentence ends. This is a coupled decision process consisting of a programmer and interpreter. The programmer's policy decides about when to WRITE the next output or READ the next input, and the interpreter's policy decides what word to write. We present an imitation learning (IL) approach to efficiently learn effective coupled programmer-interpreter policies. To enable IL, we present an algorithmic oracle to produce oracle READ/WRITE actions for training bilingual sentence-pairs using the notion of word alignments. We attribute the effectiveness of the learned coupled policies to (i) scheduled sampling addressing the coupled exposure bias, and (ii) quality of oracle actions capturing enough information from the partial input before writing the output. Experiments show our method outperforms strong baselines in terms of translation quality and delay, when translating from German/Arabic/Czech/Bulgarian/Romanian to English. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在同时机器翻译系统需要逐步产生输入句子结束前的输出转换。这是由一个程序员和解释器的耦合决定处理。程序员的政策决定什么时候写下一个输出或读取下一个输入，而口译的政策决定写什么字。我们提出了一个模仿学习（IL）的方法来有效地学习有效耦合程序员解释政策。为了使IL，我们提出了一个算法甲骨文的Oracle产品的读/写操作训练用的词对齐的概念双语句子对。我们认为所学习的耦合政策的效力与（i）预定的采样寻址耦合曝光偏置，和（ii）的Oracle动作写入输出之前捕获来自所述部分输入足够的信息的质量。实验证明我们的方法优于在翻译质量和延迟方面强大的基线，从德国/阿拉伯文/捷克/保加利亚/罗马尼亚翻译成英文。</font>
</div>


<hr>
<div id="paper4"> <b>4. Non-Autoregressive Neural Dialogue Generation</b>  <a href="https://arxiv.org/pdf/2002.04250" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Han%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinghong Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Meng%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuxian Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiwei Li</a><br>
<font size="3">
Abstract: Maximum Mutual information (MMI), which models the bidirectional dependency between responses ($y$) and contexts ($x$), i.e., the forward probability $\log p(y|x)$ and the backward probability $\log p(x|y)$, has been widely used as the objective in the \sts model to address the dull-response issue in open-domain dialog generation. Unfortunately, under the framework of the \sts model, direct decoding from $\log p(y|x) + \log p(x|y)$ is infeasible since the second part (i.e., $p(x|y)$) requires the completion of target generation before it can be computed, and the search space for $y$ is enormous. Empirically, an N-best list is first generated given $p(y|x)$, and $p(x|y)$ is then used to rerank the N-best list, which inevitably results in non-globally-optimal solutions. In this paper, we propose to use non-autoregressive (non-AR) generation model to address this non-global optimality issue. Since target tokens are generated independently in non-AR generation, $p(x|y)$ for each target word can be computed as soon as it's generated, and does not have to wait for the completion of the whole sequence. This naturally resolves the non-global optimal issue in decoding. Experimental results demonstrate that the proposed non-AR strategy produces more diverse, coherent, and appropriate responses, yielding substantive gains in BLEU scores and in human evaluations. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：最大互信息（MMI），该款机型的响应（$ Y $）和环境（$ X $）之间，即双向依赖，前向概率$ \日志P（Y | X）$和反向概率$ \日志p（X | Y）$，已被广泛用作目标在\ STS模式，以解决开域对话生成的平淡反应的问题。不幸的是，\ STS模型的框架下，直接解码从$ \日志P（Y | X）+ \日志P（X | Y）$是因为第二部分（即，$ P（X不可行| Y）$ ）要求目标生成的完成可以计算它之前，和$ Y $的搜索空间是巨大的。根据经验，N-最佳列表首先生成给出$ P（Y | X）$和$ P（X | Y），则$用于重新排名的N最佳列表，这不可避免地导致了非全局最优解。在本文中，我们建议使用非自回归（非AR）代车型，以解决这种非全局最优的问题。由于目标令牌在非AR生成独立产生，$ P（X | Y）$每个目标词可以很快，因为它是生成的计算，而不必等待整个序列的完成。这自然解决了解码非全局最优的问题。实验结果表明，所提出的非AR战略产生更多样化的，连贯的，适当的反应，产生的BLEU分数和人类评估实质性收益。</font>
</div>


<hr>
<div id="paper5"> <b>5. Performance Comparison of Crowdworkers and NLP Tools onNamed-Entity  Recognition and Sentiment Analysis of Political Tweets</b>  <a href="https://arxiv.org/pdf/2002.04181" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Jalal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mona Jalal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mays%2C+K+K" target="_blank" rel="noopener" style="color:#0000EE;">Kate K. Mays</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guo%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Betke%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Margrit Betke</a><br>
<font size="3">
Abstract: We report results of a comparison of the accuracy of crowdworkers and seven NaturalLanguage Processing (NLP) toolkits in solving two important NLP tasks, named-entity recognition (NER) and entity-level sentiment(ELS) analysis. We here focus on a challenging dataset, 1,000 political tweets that were collected during the U.S. presidential primary election in February 2016. Each tweet refers to at least one of four presidential candidates,i.e., four named entities. The groundtruth, established by experts in political communication, has entity-level sentiment information for each candidate mentioned in the tweet. We tested several commercial and open-source tools. Our experiments show that, for our dataset of political tweets, the most accurate NER system, Google Cloud NL, performed almost on par with crowdworkers, but the most accurate ELS analysis system, TensiStrength, did not match the accuracy of crowdworkers by a large margin of more than 30 percent points. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们报告crowdworkers在解决两个重要的NLP任务，命名实体识别（NER）和公司层面的情绪（ELS）分析的准确性和七个自然语言处理（NLP）工具包的比较结果。在这里，我们专注于一个具有挑战性的数据集，1000在2016年二月，美国总统初选每个鸣叫是指四个总统候选人至少一个，即，四个命名实体期间收集政治鸣叫。真实状况，由专家在政治传播成立以来，一直在鸣叫提到的每个候选实体层面的情绪信息。我们测试了几个商业和开源工具。我们的实验表明，对于我们的政治鸣叫，最准确的命名实体识别系统，谷歌云NL，几乎堪与crowdworkers执行的数据集，但最准确的ELS分析系统，TensiStrength，并没有大幅度匹配crowdworkers的准确性超过30个百分点。</font>
</div>


<hr>
<div id="paper6"> <b>6. Training with Streaming Annotation</b>  <a href="https://arxiv.org/pdf/2002.04165" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tongtao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ji%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heng Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shih-Fu Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Freedman%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marjorie Freedman</a><br>
<font size="3">
Abstract: In this paper, we address a practical scenario where training data is released in a sequence of small-scale batches and annotation in earlier phases has lower quality than the later counterparts. To tackle the situation, we utilize a pre-trained transformer network to preserve and integrate the most salient document information from the earlier batches while focusing on the annotation (presumably with higher quality) from the current batch. Using event extraction as a case study, we demonstrate in the experiments that our proposed framework can perform better than conventional approaches (the improvement ranges from 3.6 to 14.9% absolute F-score gain), especially when there is more noise in the early annotation; and our approach spares 19.1% time with regard to the best conventional method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们要解决这里的训练数据被释放的小规模批次序列和注释在早期阶段具有比同行晚低质量的实际情况。为了应对这种情况，我们利用预先训练变压器网络维护和最显着的文档信息从早期批次集成，并重点标注（大概有更高质量的）从目前的批次。使用事件提取作为个案研究，我们证明在实验中，我们提出的架构可以比传统方法更好地履行（改善的范围从3.6到14.9％的绝对F-分数增益），尤其是当有更多的噪音在早期的注释;而我们的方法免去19.1％的时间就以最好的常规方法。</font>
</div>


<hr>
<div id="paper7"> <b>7. Automatic Discourse Segmentation: an evaluation in French</b>  <a href="https://arxiv.org/pdf/2002.04095" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Saksik%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rémy Saksik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Molina-Villegas%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alejandro Molina-Villegas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Linhares%2C+A+C" target="_blank" rel="noopener" style="color:#0000EE;">Andréa Carneiro Linhares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Torres-Moreno%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Juan-Manuel Torres-Moreno</a><br>
<font size="3">
Abstract: In this article, we describe some discursive segmentation methods as well as a preliminary evaluation of the segmentation quality. Although our experiment were carried for documents in French, we have developed three discursive segmentation models solely based on resources simultaneously available in several languages: marker lists and a statistic POS labeling. We have also carried out automatic evaluations of these systems against the Annodis corpus, which is a manually annotated reference. The results obtained are very encouraging. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在这篇文章中，我们介绍一些话语分割方法以及分割质量的初步评估。标记列表和统计POS标签：虽然我们的实验中，进行了在法国的文件中，我们基于几种语言的同时可利用的资源仅开发了三种话语分割模型。我们还进行了针对Annodis语料库，其是手动注释参考这些系统的自动评估。得到的结果是非常令人鼓舞的。</font>
</div>


<hr>
<div id="paper8"> <b>8. An experiment exploring the theoretical and methodological challenges in  developing a semi-automated approach to analysis of small-N qualitative data</b>  <a href="https://arxiv.org/pdf/2002.04513" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Tsang%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sandro Tsang</a><br>
<font size="3">
Abstract: This paper experiments with designing a semi-automated qualitative data analysis (QDA) algorithm to analyse 20 transcripts by using freeware. Text-mining (TM) and QDA were guided by frequency and association measures, because these statistics remain robust when the sample size is small. The refined TM algorithm split the text into various sizes based on a manually revised dictionary. This lemmatisation approach may reflect the context of the text better than uniformly tokenising the text into one single size. TM results were used for initial coding. Code repacking was guided by association measures and external data to implement a general inductive QDA approach. The information retrieved by TM and QDA was depicted in subgraphs for comparisons. The analyses were completed in 6-7 days. Both algorithms retrieved contextually consistent and relevant information. However, the QDA algorithm retrieved more specific information than TM alone. The QDA algorithm does not strictly comply with the convention of TM or of QDA, but becomes a more efficient, systematic and transparent text analysis approach than a conventional QDA approach. Scaling up QDA to reliably discover knowledge from text was exactly the research purpose. This paper also sheds light on understanding the relations between information technologies, theory and methodologies. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：设计一个半自动化定性数据分析（QDA）算法实验通过使用免费软件来分析20组的转录本。文本挖掘（TM）和QDA通过频率和关联的措施引导，因为这些统计信息保持稳健当样本大小是小的。精制TM算法分割文成基于手动订正字典各种尺寸。这lemmatisation做法可能反映了文本的语境比文字均匀tokenising成一个单一的大小更好。 TM结果用于初始编码。代码重新包装是由协会的措施和外部数据导入到实施一般的感应QDA方法。由TM和QDA检索的信息在子图用于比较被描绘。分析是在6-7天内完成。这两种算法检索上下文一致的相关信息。然而，QDA算法获取更具体的信息比TM孤独。该QDA算法不严格遵守TM或QDA的惯例，但比传统的QDA方法更高效，系统，透明的文本分析方法。扩大QDA可靠地发现从文本知识正是研究目的。本文还揭示了理解信息技术，理论和方法之间的关系光。</font>
</div>


<hr>
<div id="paper9"> <b>9. HGAT: Hierarchical Graph Attention Network for Fake News Detection</b>  <a href="https://arxiv.org/pdf/2002.04397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ren%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuxiang Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiawei Zhang</a><br>
<font size="3">
Abstract: The explosive growth of fake news has eroded the credibility of medias and governments. Fake news detection has become an urgent task. News articles along with other related components like news creators and news subjects can be modeled as a heterogeneous information network (HIN for short). In this paper, we focus on studying the HIN- based fake news detection problem. We propose a novel fake news detection framework, namely Hierarchical Graph Attention Network (HGAT) which employs a novel hierarchical attention mechanism to detect fake news by classifying news article nodes in the HIN. This method can effectively learn information from different types of related nodes through node-level and schema-level attention. Experiments with real-world fake news data show that our model can outperform text-based models and other network-based models. Besides, the experiments also demonstrate the expandability and potential of HGAT for heterogeneous graphs representation learning in the future. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：假新闻的爆炸性增长已经侵蚀媒体和政府的公信力。假新闻的检测已成为一项紧迫的任务。与像新闻创作者和新闻主体等相关组件一起的新闻文章可以模拟成一个异构信息网络（HIN的简称）。在本文中，我们重点研究基于HIN-假新闻的检测问题。我们提出了一个新的假新闻的检测框架，即层次图关注网络（HGAT），它采用了新的分级注意机制由HIN新闻文章分类节点检测到假新闻。这种方法可以有效地学习，通过节点级和模式的高度重视，从不同类型的相关节点的信息。与现实世界的假新闻数据实验表明，我们的模型可以超越基于文本的模型和其他基于网络的模型。此外，实验还证明HGAT的在未来的异构图形表示学习可扩展性和潜力。</font>
</div>


<hr>
<div id="paper10"> <b>10. Convolutional Neural Networks and a Transfer Learning Strategy to  Classify Parkinson's Disease from Speech in Three Different Languages</b>  <a href="https://arxiv.org/pdf/2002.04374" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=V%C3%A1squez-Correa%2C+J+C" target="_blank" rel="noopener" style="color:#0000EE;">J. C. Vásquez-Correa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Arias-Vergara%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">T. Arias-Vergara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rios-Urrego%2C+C+D" target="_blank" rel="noopener" style="color:#0000EE;">C. D. Rios-Urrego</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schuster%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">M. Schuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rusz%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">J. Rusz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Orozco-Arroyave%2C+J+R" target="_blank" rel="noopener" style="color:#0000EE;">J. R. Orozco-Arroyave</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=N%C3%B6th%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">E. Nöth</a><br>
<font size="3">
Abstract: Parkinson's disease patients develop different speech impairments that affect their communication capabilities. The automatic assessment of the speech of the patients allows the development of computer aided tools to support the diagnosis and the evaluation of the disease severity. This paper introduces a methodology to classify Parkinson's disease from speech in three different languages: Spanish, German, and Czech. The proposed approach considers convolutional neural networks trained with time frequency representations and a transfer learning strategy among the three languages. The transfer learning scheme aims to improve the accuracy of the models when the weights of the neural network are initialized with utterances from a different language than the used for the test set. The results suggest that the proposed strategy improves the accuracy of the models in up to 8\% when the base model used to initialize the weights of the classifier is robust enough. In addition, the results obtained after the transfer learning are in most cases more balanced in terms of specificity-sensitivity than those trained without the transfer learning strategy. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：帕金森氏症患者制定影响其通信能力不同的语言障碍。患者的语音的自动评估允许的计算机辅助工具的开发，以支持诊断和疾病严重程度的评估。本文介绍一种方法，帕金森氏病从语音三种语言进行分类，西班牙语，德语和捷克。所提出的方法考虑了频率随时间的陈述和三种语言之间的迁移学习策略训练的卷积神经网络。转移学习方案，目的是提高模型的准确性时，神经网络的权与话语从不同的语言不是用于测试集初始化。结果表明，该策略提高了多达8 \％的模型的准确性时使用的基础模型来初始化权重的分类是足够强大的。此外，转移学习之后得到的结果都在比那些没有转移学习策略训练的特异性，灵敏度方面更平衡大多数情况下。</font>
</div>


<hr>
<div id="paper11"> <b>11. Adversarial Filters of Dataset Biases</b>  <a href="https://arxiv.org/pdf/2002.04108" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bras%2C+R+L" target="_blank" rel="noopener" style="color:#0000EE;">Ronan Le Bras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Swayamdipta%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Swabha Swayamdipta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bhagavatula%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chandra Bhagavatula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zellers%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rowan Zellers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Peters%2C+M+E" target="_blank" rel="noopener" style="color:#0000EE;">Matthew E. Peters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sabharwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ashish Sabharwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Choi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yejin Choi</a><br>
<font size="3">
Abstract: Large neural models have demonstrated human-level performance on language and vision benchmarks such as ImageNet and Stanford Natural Language Inference (SNLI). Yet, their performance degrades considerably when tested on adversarial or out-of-distribution samples. This raises the question of whether these models have learned to solve a dataset rather than the underlying task by overfitting on spurious dataset biases. We investigate one recently proposed approach, AFLite, which adversarially filters such dataset biases, as a means to mitigate the prevalent overestimation of machine performance. We provide a theoretical understanding for AFLite, by situating it in the generalized framework for optimum bias reduction. Our experiments show that as a result of the substantial reduction of these biases, models trained on the filtered datasets yield better generalization to out-of-distribution tasks, especially when the benchmarks used for training are over-populated with biased samples. We show that AFLite is broadly applicable to a variety of both real and synthetic datasets for reduction of measurable dataset biases and provide extensive supporting analyses. Finally, filtering results in a large drop in model performance (e.g., from 92% to 63% for SNLI), while human performance still remains high. Our work thus shows that such filtered datasets can pose new research challenges for robust generalization by serving as upgraded benchmarks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大型神经模型已经证明在语言和视觉基准，如ImageNet和斯坦福大学自然语言推理（SNLI）人类水平的性能。然而，它们的性能会下降显着，当上对抗或分发外的样品进行测试。这就提出了这些模型是否已经学会对过度拟合数据集虚假偏见，解决了数据集而不是底层任务的问题。我们调查一个最近提出的方法，AFLite，这adversarially过滤器，例如数据集的偏见，作为一种手段来减轻整机性能普遍高估。我们为AFLite提供理论的理解，通过在最佳偏置降低广义框架的情境吧。我们的实验显示，这些偏见的大幅度减少的结果，训练有素的过滤数据集模型产生更好的推广到外的配送任务，特别是当用于训练的基准测试过填充偏置样品。我们表明，AFLite广泛适用于各种实际和综合数据集的减少衡量数据集的偏见，并提供广泛的支持分析。最后，过滤结果在模型的性能（例如SNLI，从92％至63％）大的下降，而人的性能仍然保持为高。因此，我们的工作表明，这种过滤的数据集可以作为升级基准构成了强大的推广新研究挑战。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-11</title>
    <url>/2020/02/11/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-02-11/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Upper, Middle and Lower Region Learning for Facial Action Unit Detection <a href="https://arxiv.org/pdf/2002.04023" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Deep Convolutional Neural Networks with Spatial Regularization, Volume  and Star-shape Priori for Image Segmentation <a href="https://arxiv.org/pdf/2002.03989" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Unconstrained Periocular Recognition: Using Generative Deep Learning  Frameworks for Attribute Normalization <a href="https://arxiv.org/pdf/2002.03985" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> StickyPillars: Robust feature matching on point clouds using Graph  Neural Networks <a href="https://arxiv.org/pdf/2002.03983" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Joint Encoding of Appearance and Motion Features with Self-supervision  for First Person Action Recognition <a href="https://arxiv.org/pdf/2002.03982" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> RePose: Learning Deep Kinematic Priors for Fast Human Pose Estimation <a href="https://arxiv.org/pdf/2002.03933" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> 6DoF Object Pose Estimation via Differentiable Proxy Voting Loss <a href="https://arxiv.org/pdf/2002.03923" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Hierarchical Multi-Process Fusion for Visual Place Recognition <a href="https://arxiv.org/pdf/2002.03895" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> CIFAR-10 Image Classification Using Feature Ensembles <a href="https://arxiv.org/pdf/2002.03846" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Exploiting Temporal Coherence for Multi-modal Video Categorization <a href="https://arxiv.org/pdf/2002.03844" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Attentive Group Equivariant Convolutional Networks <a href="https://arxiv.org/pdf/2002.03830" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Level Three Synthetic Fingerprint Generation <a href="https://arxiv.org/pdf/2002.03809" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Automatic image-based identification and biomass estimation of  invertebrates <a href="https://arxiv.org/pdf/2002.03807" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> CONVINCE: Collaborative Cross-Camera Video Analytics at the Edge <a href="https://arxiv.org/pdf/2002.03797" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Deep Learning for Classifying Food Waste <a href="https://arxiv.org/pdf/2002.03786" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Multi-stream Faster RCNN for Mitosis Counting in Breast Cancer Images <a href="https://arxiv.org/pdf/2002.03781" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Towards Deep Machine Reasoning: a Prototype-based Deep Neural Network  with Decision Tree Inference <a href="https://arxiv.org/pdf/2002.03776" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Deriving Emotions and Sentiments from Visual Content: A Disaster  Analysis Use Case <a href="https://arxiv.org/pdf/2002.03773" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Improving the Evaluation of Generative Models with Fuzzy Logic <a href="https://arxiv.org/pdf/2002.03772" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Learning Numerical Observers using Unsupervised Domain Adaptation <a href="https://arxiv.org/pdf/2002.03763" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Music2Dance: Music-driven Dance Generation using WaveNet <a href="https://arxiv.org/pdf/2002.03761" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> An Empirical Study of Person Re-Identification with Attributes <a href="https://arxiv.org/pdf/2002.03752" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Weighted Average Precision: Adversarial Example Detection in the Visual  Perception of Autonomous Vehicles <a href="https://arxiv.org/pdf/2002.03751" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> An Overview of Two Age Synthesis and Estimation Techniques <a href="https://arxiv.org/pdf/2002.03750" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> DFKI Cabin Simulator: A Test Platform for Visual In-Cabin Monitoring  Functions <a href="https://arxiv.org/pdf/2002.03749" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<div id="title26">
<b>26.</b> Black Box Explanation by Learning Image Exemplars in the Latent Feature  Space <a href="https://arxiv.org/pdf/2002.03746" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper26" style="color:#0000EE;">摘要</a><br></div>
<div id="title27">
<b>27.</b> Dynamic Error-bounded Lossy Compression (EBLC) to Reduce the Bandwidth  Requirement for Real-time Vision-based Pedestrian Safety Applications <a href="https://arxiv.org/pdf/2002.03742" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper27" style="color:#0000EE;">摘要</a><br></div>
<div id="title28">
<b>28.</b> Efficient Scene Text Detection with Textual Attention Tower <a href="https://arxiv.org/pdf/2002.03741" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper28" style="color:#0000EE;">摘要</a><br></div>
<div id="title29">
<b>29.</b> Convolutional Hierarchical Attention Network for Query-Focused Video  Summarization <a href="https://arxiv.org/pdf/2002.03740" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper29" style="color:#0000EE;">摘要</a><br></div>
<div id="title30">
<b>30.</b> Localizing Multi-scale Semantic Patches for Image Classification <a href="https://arxiv.org/pdf/2002.03737" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper30" style="color:#0000EE;">摘要</a><br></div>
<div id="title31">
<b>31.</b> Universal Semantic Segmentation for Fisheye Urban Driving Images <a href="https://arxiv.org/pdf/2002.03736" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper31" style="color:#0000EE;">摘要</a><br></div>
<div id="title32">
<b>32.</b> Real-Time Object Detection and Recognition on Low-Compute Humanoid  Robots using Deep Learning <a href="https://arxiv.org/pdf/2002.03735" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper32" style="color:#0000EE;">摘要</a><br></div>
<div id="title33">
<b>33.</b> Iterative energy-based projection on a normal data manifold for anomaly  localization <a href="https://arxiv.org/pdf/2002.03734" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper33" style="color:#0000EE;">摘要</a><br></div>
<div id="title34">
<b>34.</b> Robust Multimodal Image Registration Using Deep Recurrent Reinforcement  Learning <a href="https://arxiv.org/pdf/2002.03733" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper34" style="color:#0000EE;">摘要</a><br></div>
<div id="title35">
<b>35.</b> Impact of Data Quality on Deep Neural Network Training <a href="https://arxiv.org/pdf/2002.03732" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper35" style="color:#0000EE;">摘要</a><br></div>
<div id="title36">
<b>36.</b> RSnet: An improvement for Darknet <a href="https://arxiv.org/pdf/2002.03729" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper36" style="color:#0000EE;">摘要</a><br></div>
<div id="title37">
<b>37.</b> Driver Drowsiness Detection Model Using Convolutional Neural Networks  Techniques for Android Application <a href="https://arxiv.org/pdf/2002.03728" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper37" style="color:#0000EE;">摘要</a><br></div>
<div id="title38">
<b>38.</b> Durocmien: A deep framework for duroc skeleton extraction in constraint  environment <a href="https://arxiv.org/pdf/2002.03727" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper38" style="color:#0000EE;">摘要</a><br></div>
<div id="title39">
<b>39.</b> Deep Frequent Spatial Temporal Learning for Face Anti-Spoofing <a href="https://arxiv.org/pdf/2002.03723" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper39" style="color:#0000EE;">摘要</a><br></div>
<div id="title40">
<b>40.</b> Unsupervised deep clustering for predictive texture pattern discovery in  medical images <a href="https://arxiv.org/pdf/2002.03721" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper40" style="color:#0000EE;">摘要</a><br></div>
<div id="title41">
<b>41.</b> Fabricated Pictures Detection with Graph Matching <a href="https://arxiv.org/pdf/2002.03720" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper41" style="color:#0000EE;">摘要</a><br></div>
<div id="title42">
<b>42.</b> Knowledge Distillation for Brain Tumor Segmentation <a href="https://arxiv.org/pdf/2002.03688" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper42" style="color:#0000EE;">摘要</a><br></div>
<div id="title43">
<b>43.</b> Deep Multi-task Multi-label CNN for Effective Facial Attribute  Classification <a href="https://arxiv.org/pdf/2002.03683" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper43" style="color:#0000EE;">摘要</a><br></div>
<div id="title44">
<b>44.</b> Uncertainty Estimation for End-To-End Learned Dense Stereo Matching via  Probabilistic Deep Learning <a href="https://arxiv.org/pdf/2002.03663" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper44" style="color:#0000EE;">摘要</a><br></div>
<div id="title45">
<b>45.</b> Distribution Distillation Loss: Generic Approach for Improving Face  Recognition from Hard Samples <a href="https://arxiv.org/pdf/2002.03662" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper45" style="color:#0000EE;">摘要</a><br></div>
<div id="title46">
<b>46.</b> CRVOS: Clue Refining Network for Video Object Segmentation <a href="https://arxiv.org/pdf/2002.03651" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper46" style="color:#0000EE;">摘要</a><br></div>
<div id="title47">
<b>47.</b> Collaborative Training of Balanced Random Forests for Open Set Domain  Adaptation <a href="https://arxiv.org/pdf/2002.03642" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper47" style="color:#0000EE;">摘要</a><br></div>
<div id="title48">
<b>48.</b> End-to-End Facial Deep Learning Feature Compression with Teacher-Student  Enhancement <a href="https://arxiv.org/pdf/2002.03627" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper48" style="color:#0000EE;">摘要</a><br></div>
<div id="title49">
<b>49.</b> Post-Comparison Mitigation of Demographic Bias in Face Recognition Using  Fair Score Normalization <a href="https://arxiv.org/pdf/2002.03592" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper49" style="color:#0000EE;">摘要</a><br></div>
<div id="title50">
<b>50.</b> Prototype Refinement Network for Few-Shot Segmentation <a href="https://arxiv.org/pdf/2002.03579" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper50" style="color:#0000EE;">摘要</a><br></div>
<div id="title51">
<b>51.</b> Automatic detection and counting of retina cell nuclei using deep  learning <a href="https://arxiv.org/pdf/2002.03563" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper51" style="color:#0000EE;">摘要</a><br></div>
<div id="title52">
<b>52.</b> FAU, Facial Expressions, Valence and Arousal: A Multi-task Solution <a href="https://arxiv.org/pdf/2002.03557" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper52" style="color:#0000EE;">摘要</a><br></div>
<div id="title53">
<b>53.</b> Vehicle Driving Assistant <a href="https://arxiv.org/pdf/2002.03556" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper53" style="color:#0000EE;">摘要</a><br></div>
<div id="title54">
<b>54.</b> From Anchor Generation to Distribution Alignment: Learning a  Discriminative Embedding Space for Zero-Shot Recognition <a href="https://arxiv.org/pdf/2002.03554" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper54" style="color:#0000EE;">摘要</a><br></div>
<div id="title55">
<b>55.</b> UGRWO-Sampling: A modified random walk under-sampling approach based on  graphs to imbalanced data classification <a href="https://arxiv.org/pdf/2002.03521" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper55" style="color:#0000EE;">摘要</a><br></div>
<div id="title56">
<b>56.</b> A New Perspective for Flexible Feature Gathering in Scene Text  Recognition Via Character Anchor Pooling <a href="https://arxiv.org/pdf/2002.03509" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper56" style="color:#0000EE;">摘要</a><br></div>
<div id="title57">
<b>57.</b> Segmenting unseen industrial components in a heavy clutter using rgb-d  fusion and synthetic data <a href="https://arxiv.org/pdf/2002.03501" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper57" style="color:#0000EE;">摘要</a><br></div>
<div id="title58">
<b>58.</b> ABBA: Saliency-Regularized Motion-Based Adversarial Blur Attack <a href="https://arxiv.org/pdf/2002.03500" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper58" style="color:#0000EE;">摘要</a><br></div>
<div id="title59">
<b>59.</b> Medical Image Registration Using Deep Neural Networks: A Comprehensive  Review <a href="https://arxiv.org/pdf/2002.03401" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper59" style="color:#0000EE;">摘要</a><br></div>
<div id="title60">
<b>60.</b> Two-Stream Aural-Visual Affect Analysis in the Wild <a href="https://arxiv.org/pdf/2002.03399" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper60" style="color:#0000EE;">摘要</a><br></div>
<div id="title61">
<b>61.</b> MS-Net: Multi-Site Network for Improving Prostate Segmentation with  Heterogeneous MRI Data <a href="https://arxiv.org/pdf/2002.03366" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper61" style="color:#0000EE;">摘要</a><br></div>
<div id="title62">
<b>62.</b> Weakly Supervised Attention Pyramid Convolutional Neural Network for  Fine-Grained Visual Classification <a href="https://arxiv.org/pdf/2002.03353" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper62" style="color:#0000EE;">摘要</a><br></div>
<div id="title63">
<b>63.</b> Dynamic Inference: A New Approach Toward Efficient Video Action  Recognition <a href="https://arxiv.org/pdf/2002.03342" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper63" style="color:#0000EE;">摘要</a><br></div>
<div id="title64">
<b>64.</b> VIFB: A Visible and Infrared Image Fusion Benchmark <a href="https://arxiv.org/pdf/2002.03322" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper64" style="color:#0000EE;">摘要</a><br></div>
<div id="title65">
<b>65.</b> Unlabeled Data Deployment for Classification of Diabetic Retinopathy  Images Using Knowledge Transfer <a href="https://arxiv.org/pdf/2002.03321" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper65" style="color:#0000EE;">摘要</a><br></div>
<div id="title66">
<b>66.</b> FSD-10: A Dataset for Competitive Sports Content Analysis <a href="https://arxiv.org/pdf/2002.03312" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper66" style="color:#0000EE;">摘要</a><br></div>
<div id="title67">
<b>67.</b> Face Hallucination with Finishing Touches <a href="https://arxiv.org/pdf/2002.03308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper67" style="color:#0000EE;">摘要</a><br></div>
<div id="title68">
<b>68.</b> Splitting Convolutional Neural Network Structures for Efficient  Inference <a href="https://arxiv.org/pdf/2002.03302" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper68" style="color:#0000EE;">摘要</a><br></div>
<div id="title69">
<b>69.</b> Convolutional Neural Network Pruning Using Filter Attenuation <a href="https://arxiv.org/pdf/2002.03299" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper69" style="color:#0000EE;">摘要</a><br></div>
<div id="title70">
<b>70.</b> PointHop++: A Lightweight Learning Model on Point Sets for 3D  Classification <a href="https://arxiv.org/pdf/2002.03281" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper70" style="color:#0000EE;">摘要</a><br></div>
<div id="title71">
<b>71.</b> Asymmetric Rejection Loss for Fairer Face Recognition <a href="https://arxiv.org/pdf/2002.03276" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper71" style="color:#0000EE;">摘要</a><br></div>
<div id="title72">
<b>72.</b> Learning efficient structured dictionary for image classification <a href="https://arxiv.org/pdf/2002.03271" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper72" style="color:#0000EE;">摘要</a><br></div>
<div id="title73">
<b>73.</b> Weakly-Supervised Multi-Person Action Recognition in 360$^{\circ}$  Videos <a href="https://arxiv.org/pdf/2002.03266" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper73" style="color:#0000EE;">摘要</a><br></div>
<div id="title74">
<b>74.</b> GradMix: Multi-source Transfer across Domains and Tasks <a href="https://arxiv.org/pdf/2002.03264" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper74" style="color:#0000EE;">摘要</a><br></div>
<div id="title75">
<b>75.</b> Ensemble of Deep Convolutional Neural Networks for Automatic Pavement  Crack Detection and Measurement <a href="https://arxiv.org/pdf/2002.03241" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper75" style="color:#0000EE;">摘要</a><br></div>
<div id="title76">
<b>76.</b> Multi-Label Class Balancing Algorithm for Action Unit Detection <a href="https://arxiv.org/pdf/2002.03238" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper76" style="color:#0000EE;">摘要</a><br></div>
<div id="title77">
<b>77.</b> Intrinsic Dimension Estimation via Nearest Constrained Subspace  Classifier <a href="https://arxiv.org/pdf/2002.03228" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper77" style="color:#0000EE;">摘要</a><br></div>
<div id="title78">
<b>78.</b> Exocentric to Egocentric Image Generation via Parallel Generative  Adversarial Network <a href="https://arxiv.org/pdf/2002.03219" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper78" style="color:#0000EE;">摘要</a><br></div>
<div id="title79">
<b>79.</b> Spatial-Temporal Multi-Cue Network for Continuous Sign Language  Recognition <a href="https://arxiv.org/pdf/2002.03187" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper79" style="color:#0000EE;">摘要</a><br></div>
<div id="title80">
<b>80.</b> Sparsity-Aware Deep Learning for Automatic 4D Facial Expression  Recognition <a href="https://arxiv.org/pdf/2002.03157" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper80" style="color:#0000EE;">摘要</a><br></div>
<div id="title81">
<b>81.</b> CTM: Collaborative Temporal Modeling for Action Recognition <a href="https://arxiv.org/pdf/2002.03152" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper81" style="color:#0000EE;">摘要</a><br></div>
<div id="title82">
<b>82.</b> Multi-Modality Cascaded Fusion Technology for Autonomous Driving <a href="https://arxiv.org/pdf/2002.03138" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper82" style="color:#0000EE;">摘要</a><br></div>
<div id="title83">
<b>83.</b> Symbiotic Attention with Privileged Information for Egocentric Action  Recognition <a href="https://arxiv.org/pdf/2002.03137" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper83" style="color:#0000EE;">摘要</a><br></div>
<div id="title84">
<b>84.</b> Variable-Viewpoint Representations for 3D Object Recognition <a href="https://arxiv.org/pdf/2002.03131" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper84" style="color:#0000EE;">摘要</a><br></div>
<div id="title85">
<b>85.</b> Attacking Optical Character Recognition (OCR) Systems with Adversarial  Watermarks <a href="https://arxiv.org/pdf/2002.03095" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper85" style="color:#0000EE;">摘要</a><br></div>
<div id="title86">
<b>86.</b> Bone Suppression on Chest Radiographs With Adversarial Learning <a href="https://arxiv.org/pdf/2002.03073" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper86" style="color:#0000EE;">摘要</a><br></div>
<div id="title87">
<b>87.</b> Local Facial Attribute Transfer through Inpainting <a href="https://arxiv.org/pdf/2002.03040" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper87" style="color:#0000EE;">摘要</a><br></div>
<div id="title88">
<b>88.</b> Unsupervised Discovery of Interpretable Directions in the GAN Latent  Space <a href="https://arxiv.org/pdf/2002.03754" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper88" style="color:#0000EE;">摘要</a><br></div>
<div id="title89">
<b>89.</b> Learning End-to-End Lossy Image Compression: A Benchmark <a href="https://arxiv.org/pdf/2002.03711" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper89" style="color:#0000EE;">摘要</a><br></div>
<div id="title90">
<b>90.</b> Distributed Bayesian Matrix Decomposition for Big Data Mining and  Clustering <a href="https://arxiv.org/pdf/2002.03703" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper90" style="color:#0000EE;">摘要</a><br></div>
<div id="title91">
<b>91.</b> Adversarial TCAV -- Robust and Effective Interpretation of Intermediate  Layers in Neural Networks <a href="https://arxiv.org/pdf/2002.03549" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper91" style="color:#0000EE;">摘要</a><br></div>
<div id="title92">
<b>92.</b> Multi-object Monocular SLAM for Dynamic Environments <a href="https://arxiv.org/pdf/2002.03528" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper92" style="color:#0000EE;">摘要</a><br></div>
<div id="title93">
<b>93.</b> Ultra High Fidelity Image Compression with $\ell_\infty$-constrained  Encoding and Deep Decoding <a href="https://arxiv.org/pdf/2002.03482" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper93" style="color:#0000EE;">摘要</a><br></div>
<div id="title94">
<b>94.</b> Semi-Supervised Class Discovery <a href="https://arxiv.org/pdf/2002.03480" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper94" style="color:#0000EE;">摘要</a><br></div>
<div id="title95">
<b>95.</b> A Deep Learning Approach to Automate High-Resolution Blood Vessel  Reconstruction on Computerized Tomography Images With or Without the Use of  Contrast Agent <a href="https://arxiv.org/pdf/2002.03463" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper95" style="color:#0000EE;">摘要</a><br></div>
<div id="title96">
<b>96.</b> A Unified End-to-End Framework for Efficient Deep Image Compression <a href="https://arxiv.org/pdf/2002.03370" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper96" style="color:#0000EE;">摘要</a><br></div>
<div id="title97">
<b>97.</b> Multi-Task Learning by a Top-Down Control Network <a href="https://arxiv.org/pdf/2002.03335" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper97" style="color:#0000EE;">摘要</a><br></div>
<div id="title98">
<b>98.</b> Out-of-Distribution Detection with Distance Guarantee in Deep Generative  Models <a href="https://arxiv.org/pdf/2002.03328" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper98" style="color:#0000EE;">摘要</a><br></div>
<div id="title99">
<b>99.</b> Holographic Image Sensing <a href="https://arxiv.org/pdf/2002.03314" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper99" style="color:#0000EE;">摘要</a><br></div>
<div id="title100">
<b>100.</b> Soft Threshold Weight Reparameterization for Learnable Sparsity <a href="https://arxiv.org/pdf/2002.03231" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper100" style="color:#0000EE;">摘要</a><br></div>
<div id="title101">
<b>101.</b> Correction of Chromatic Aberration from a Single Image Using Keypoints <a href="https://arxiv.org/pdf/2002.03196" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper101" style="color:#0000EE;">摘要</a><br></div>
<div id="title102">
<b>102.</b> Deep No-reference Tone Mapped Image Quality Assessment <a href="https://arxiv.org/pdf/2002.03165" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper102" style="color:#0000EE;">摘要</a><br></div>
<div id="title103">
<b>103.</b> Ramifications and Diminution of Image Noise in Iris Recognition System <a href="https://arxiv.org/pdf/2002.03125" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper103" style="color:#0000EE;">摘要</a><br></div>
<div id="title104">
<b>104.</b> An Empirical Evaluation of Perturbation-based Defenses <a href="https://arxiv.org/pdf/2002.03080" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper104" style="color:#0000EE;">摘要</a><br></div>
<div id="title105">
<b>105.</b> Predictive online optimisation with applications to optical flow <a href="https://arxiv.org/pdf/2002.03053" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper105" style="color:#0000EE;">摘要</a><br></div>
<div id="title106">
<b>106.</b> Cognitive Anthropomorphism of AI: How Humans and Computers Classify  Images <a href="https://arxiv.org/pdf/2002.03024" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper106" style="color:#0000EE;">摘要</a><br></div>
<div id="title107">
<b>107.</b> Improving the Adversarial Robustness of Transfer Learning via Noisy  Feature Distillation <a href="https://arxiv.org/pdf/2002.02998" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper107" style="color:#0000EE;">摘要</a><br></div>
<div id="title108">
<b>108.</b> DropCluster: A structured dropout for convolutional networks <a href="https://arxiv.org/pdf/2002.02997" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper108" style="color:#0000EE;">摘要</a><br></div>
<div id="title109">
<b>109.</b> SS-Auto: A Single-Shot, Automatic Structured Weight Pruning Framework of  DNNs with Ultra-High Efficiency <a href="https://arxiv.org/pdf/2001.08839" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper109" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><!-- procjx-wenzhang2 --> <ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins> <script>      (adsbygoogle = window.adsbygoogle || []).push({}); </script>

<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Upper, Middle and Lower Region Learning for Facial Action Unit Detection</b>  <a href="https://arxiv.org/pdf/2002.04023" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xia%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yao Xia</a><br>
<font size="3">
Abstract: Facial action units (AUs) detection is fundamental to facial expression analysis. As AU occur only in a small area of face, region based learning has been widely recognized useful for AU detection. Most region based studies focus on a small region where the AU occurs. Focusing on a specific region is helpful in eliminating the influence of identity, but to be risk for losing information. It is difficult to find balance. In this study, I propose a simple strategy. I divide the face into three large regions, upper, middle and lower region, and group AUs based on where it occurs. I propose a new end-to-end deep learning framework named three regions based attention network (TRA-Net). After extracting the global feature, TRA-Net uses a hard attention module to extract three feature maps, each of which contains only a specific region. Each region-specific feature map is fed to an independent branch. For each branch, three continuous soft attention modules are used to extract higher-level features for final AU detection. In the DISFA dataset, this model achieves the highest F1 scores for the detection of AU1, AU2 and AU4, and produces the highest accuracy in comparison with the state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：面部动作单元（AU）检测是面部表情分析的基础。由于AU只发生在脸上的小区域，基于区域的学习已得到广泛认可的AU检测有用。大多数基于区域的研究重点放在非盟发生小区域。专注于一个特定的区域是在消除身份的影响力有帮助，但对信息丢失的风险。这是很难找到平衡点。在这项研究中，我提出了一个简单的策略。我划分面为三个大区域，上部，中部和下部区域，并且组的AU基于其中它发生。我建议命名为三个区域以关注网络（TRA-网）一个新的终端到终端的深度学习的框架。提取全局特征后，TRA-Net使用硬关注模块中提取三个特征的地图，每一个都包含只针对特定区域。每个区域特异性特征地图被馈送到一个独立的分支。对于每个分支，三个连续软注意模块用于提取最终AU检测较高级别的功能。在DISFA数据集，该模型获得了最高的分数F1用于检测AU1，AU2和AU4的，并产生最高的精度在与国家的最先进的方法相比。</font>
</div>


<hr>
<div id="paper2"> <b>2. Deep Convolutional Neural Networks with Spatial Regularization, Volume  and Star-shape Priori for Image Segmentation</b>  <a href="https://arxiv.org/pdf/2002.03989" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiangyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tai%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xue-cheng Tai</a><br>
<font size="3">
Abstract: We use Deep Convolutional Neural Networks (DCNNs) for image segmentation problems. DCNNs can well extract the features from natural images. However, the classification functions in the existing network architecture of CNNs are simple and lack capabilities to handle important spatial information in a way that have been done for many well-known traditional variational models. Prior such as spatial regularity, volume prior and object shapes cannot be well handled by existing DCNNs. We propose a novel Soft Threshold Dynamics (STD) framework which can easily integrate many spatial priors of the classical variational models into the DCNNs for image segmentation. The novelty of our method is to interpret the softmax activation function as a dual variable in a variational problem, and thus many spatial priors can be imposed in the dual space. From this viewpoint, we can build a STD based framework which can enable the outputs of DCNNs to have many special priors such as spatial regularity, volume constraints and star-shape priori. The proposed method is a general mathematical framework and it can be applied to any semantic segmentation DCNNs. To show the efficiency and accuracy of our method, we applied it to the popular DeepLabV3+ image segmentation network, and the experiments results show that our method can work efficiently on data-driven image segmentation DCNNs. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们使用深卷积神经网络（DCNNs）图像分割问题。 DCNNs能很好地提取自然图像的功能。然而，在细胞神经网络的现有网络架构的分类功能简单，缺乏能力来处理已为许多著名的传统模式变做一种方式重要的空间信息。现有如空间规律性，体积之前和对象的形状不能被很好地现有DCNNs处理。我们提出了一个新颖的软阈值的动力学（STD）的框架，可以很容易的经典车型变了许多空间先验融入DCNNs的图像分割。我们的方法的新颖性在于解释SOFTMAX激活函数如在变分问题双重可变，因此许多空间先验可以在对偶空间的罚款。从该观点出发，我们可以建立一个基于STD框架，可以使DCNNs的输出以有许多特殊的先验诸如空间规律性，体积限制和星形先验。所提出的方法是一般的数学框架，它可以被应用到任何语义分割DCNNs。为了显示我们的方法的效率和准确性，我们将其运用到流行DeepLabV3 +图像分割网络，实验结果表明，该方法可以在数据驱动的图像分割DCNNs提高工作效率。</font>
</div>


<hr>
<div id="paper3"> <b>3. Unconstrained Periocular Recognition: Using Generative Deep Learning  Frameworks for Attribute Normalization</b>  <a href="https://arxiv.org/pdf/2002.03985" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zanlorensi%2C+L+A" target="_blank" rel="noopener" style="color:#0000EE;">Luiz A. Zanlorensi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Proen%C3%A7a%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hugo Proença</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Menotti%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Menotti</a><br>
<font size="3">
Abstract: Ocular biometric systems working in unconstrained environments usually face the problem of small within-class compactness caused by the multiple factors that jointly degrade the quality of the obtained data. In this work, we propose an attribute normalization strategy based on deep learning generative frameworks, that reduces the variability of the samples used in pairwise comparisons, without reducing their discriminability. The proposed method can be seen as a preprocessing step that contributes for data regularization and improves the recognition accuracy, being fully agnostic to the recognition strategy used. As proof of concept, we consider the "eyeglasses" and "gaze" factors, comparing the levels of performance of five different recognition methods with/without using the proposed normalization strategy. Also, we introduce a new dataset for unconstrained periocular recognition, composed of images acquired by mobile devices, particularly suited to perceive the impact of "wearing eyeglasses" in recognition effectiveness. Our experiments were performed in two different datasets, and support the usefulness of our attribute normalization scheme to improve the recognition performance. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：眼在不受约束的环境中工作的生物识别系统通常面临所造成的多种因素共同降解所获得的数据的质量小的类内紧凑的问题。在这项工作中，我们提出了一种基于深度学习生成框架属性正常化的策略，即减少了两两比较用的样品的可变性，而不会降低他们的辨别力。所提出的方法可以被看作是一个预处理步骤，对于数据的正则化有助于，提高了识别精度，被完全不可知的使用的识别策略。作为概念验证，我们认为“眼镜”和“凝视”的因素，在不使用所提出的标准化战略比较与/五种不同的识别方法的性能水平。此外，我们介绍的无约束眼周识别一个新的数据集，由移动设备，特别适合于感知“戴眼镜”的在识别有效性的影响获取的图像所组成。我们的实验是在两个不同的数据集进行，并支持我们的属性正常化方案，以提高识别性能的实用性。</font>
</div>


<hr>
<div id="paper4"> <b>4. StickyPillars: Robust feature matching on point clouds using Graph  Neural Networks</b>  <a href="https://arxiv.org/pdf/2002.03983" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Simon%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Martin Simon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fischer%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kai Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Milz%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stefan Milz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Witt%2C+C+T" target="_blank" rel="noopener" style="color:#0000EE;">Christian Tobias Witt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gross%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Horst-Michael Gross</a><br>
<font size="3">
Abstract: StickyPillars introduces a sparse feature matching method on point clouds. It is the first approach applying Graph Neural Networks on point clouds to stick points of interest. The feature estimation and assignment relies on the optimal transport problem, where the cost is based on the neural network itself. We utilize a Graph Neural Network for context aggregation with the aid of multihead self and cross attention. In contrast to image based feature matching methods, the architecture learns feature extraction in an end-to-end manner. Hence, the approach does not rely on handcrafted features. Our method outperforms state-of-the art matching algorithms, while providing real-time capability. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：StickyPillars介绍了点云稀疏特征匹配方法。它是将点云图的神经网络坚持的兴趣点的第一种方法。该功能估计和分配依赖于最佳的交通问题，其中成本是基于神经网络本身。我们利用图的神经网络模型多头自我和交叉关注的援助范围内聚集。与基于图像特征匹配方法，该架构获悉设有在端至端的方式提取。因此，该方法不依赖于手工制作的特点。我们的方法优于国家的本领域匹配算法，同时提供实时能力。</font>
</div>


<hr>
<div id="paper5"> <b>5. Joint Encoding of Appearance and Motion Features with Self-supervision  for First Person Action Recognition</b>  <a href="https://arxiv.org/pdf/2002.03982" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Planamente%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mirco Planamente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bottino%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrea Bottino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Caputo%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Barbara Caputo</a><br>
<font size="3">
Abstract: Wearable cameras are becoming more and more popular in several applications, increasing the interest of the research community in developing approaches for recognizing actions from a first-person point of view. An open challenge is how to cope with the limited amount of motion information available about the action itself, as opposed to the more investigated third-person action recognition scenario. When focusing on manipulation tasks, videos tend to record only parts of the movement, making crucial the understanding of the objects being manipulated and of their context. Previous works addressed this issue with two-stream architectures, one dedicated to modeling the appearance of objects involved in the action, another dedicated to extracting motion features from optical flow. In this paper, we argue that features from these two information channels should be learned jointly to capture the spatio-temporal correlations between the two in a better way. To this end, we propose a single stream architecture able to do so, thanks to the addition of a self-supervised block that uses a pretext motion segmentation task to intertwine motion and appearance knowledge. Experiments on several publicly available databases show the power of our approach. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：可穿戴式摄像机正变得越来越流行在几个应用程序，增加了研究界在发展从一个第一人称的角度认识行动方案的兴趣。一个开放的挑战是如何应对提供了有关行动本身数量有限的运动信息，而不是更多的研究第三人称动作识别场景。当着眼于操作任务，视频往往只记录运动的部件，使得关键的被操纵的对象的理解和他们的背景。以前的作品中解决了这个问题有两个流架构下，一个专门用于模拟参与行动对象的外观，另一个专门用于提取运动从光流的特征。在本文中，我们认为，这两个信息渠道功能应共同学会了捕捉两者之间的时空相关性以更好的方式。为此，我们提出了一个单一的数据流架构能够这样做，由于增加使用的借口运动分割任务纠结运动和外观知识自我监督的块。几个公共数据库实验证明我们的方法的力量。</font>
</div>


<hr>
<div id="paper6"> <b>6. RePose: Learning Deep Kinematic Priors for Fast Human Pose Estimation</b>  <a href="https://arxiv.org/pdf/2002.03933" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Isack%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hossam Isack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Haene%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christian Haene</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Keskin%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cem Keskin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bouaziz%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sofien Bouaziz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Boykov%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuri Boykov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Izadi%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shahram Izadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khamis%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sameh Khamis</a><br>
<font size="3">
Abstract: We propose a novel efficient and lightweight model for human pose estimation from a single image. Our model is designed to achieve competitive results at a fraction of the number of parameters and computational cost of various state-of-the-art methods. To this end, we explicitly incorporate part-based structural and geometric priors in a hierarchical prediction framework. At the coarsest resolution, and in a manner similar to classical part-based approaches, we leverage the kinematic structure of the human body to propagate convolutional feature updates between the keypoints or body parts. Unlike classical approaches, we adopt end-to-end training to learn this geometric prior through feature updates from data. We then propagate the feature representation at the coarsest resolution up the hierarchy to refine the predicted pose in a coarse-to-fine fashion. The final network effectively models the geometric prior and intuition within a lightweight deep neural network, yielding state-of-the-art results for a model of this size on two standard datasets, Leeds Sports Pose and MPII Human Pose. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们从一个单一的形象提出了人体姿势估计一种新型高效和轻质的模型。我们的模型设计在参数和各种先进设备，最先进的方法计算成本的一小部分，以实现竞争的结果。为此，我们明确地纳入一个分层的预测基于框架部分结构和几何先验。在粗糙的分辨率，并以类似经典的基于部分的方法的方式，我们利用人体的运动结构传播的关键点或身体部位之间的卷积功能更新。不同于传统的方法，我们采用终端到终端的培训，学习这种几何之前通过功能从数据更新。然后，我们传播的特征表示，在最粗分辨率高达层次细化预测姿态在粗到精的方式。最终的网络有效地模型轻质深层神经网络内的几何之前和直觉，产生国家的最先进的结果对于该尺寸的两种标准数据集的模型，利兹体育姿和MPII人体姿势。</font>
</div>


<hr>
<div id="paper7"> <b>7. 6DoF Object Pose Estimation via Differentiable Proxy Voting Loss</b>  <a href="https://arxiv.org/pdf/2002.03923" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhuang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zheyu Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Koniusz%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piotr Koniusz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongdong Li</a><br>
<font size="3">
Abstract: Estimating a 6DOF object pose from a single image is very challenging due to occlusions or textureless appearances. Vector-field based keypoint voting has demonstrated its effectiveness and superiority on tackling those issues. However, direct regression of vector-fields neglects that the distances between pixels and keypoints also affect the deviations of hypotheses dramatically. In other words, small errors in direction vectors may generate severely deviated hypotheses when pixels are far away from a keypoint. In this paper, we aim to reduce such errors by incorporating the distances between pixels and keypoints into our objective. To this end, we develop a simple yet effective differentiable proxy voting loss (DPVL) which mimics the hypothesis selection in the voting procedure. By exploiting our voting loss, we are able to train our network in an end-to-end manner. Experiments on widely used datasets, i.e. LINEMOD and Occlusion LINEMOD, manifest that our DPVL improves pose estimation performance significantly and speeds up the training convergence. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：从估计单个图像6自由度对象姿势非常由于遮挡或无纹理出场挑战。矢量场根据关键点投票已经证明对解决这些问题，它的有效性和优越性。然而，矢量场忽略的直接回归的像素和关键点之间的距离也影响假设的偏差显着。换言之，在方向矢量小误差可能产生严重偏离假设当像素远离关键点。在本文中，我们的目标是通过将像素和关键点之间的距离为我们的目标，以减少此类错误。为此，我们开发了一个简单而有效的微代理投票损失（DPVL），它模仿了投票过程中的假设选择。通过利用我们的投票损失，我们能够训练我们的网络中的终端到终端的方式。广泛使用的数据集的实验，即LINEMOD和闭塞LINEMOD，体现我们的DPVL显著改善姿势估计性能并加快训练收敛。</font>
</div>


<hr>
<div id="paper8"> <b>8. Hierarchical Multi-Process Fusion for Visual Place Recognition</b>  <a href="https://arxiv.org/pdf/2002.03895" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hausler%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stephen Hausler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Milford%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michael Milford</a><br>
<font size="3">
Abstract: Combining multiple complementary techniques together has long been regarded as a way to improve performance. In visual localization, multi-sensor fusion, multi-process fusion of a single sensing modality, and even combinations of different localization techniques have been shown to result in improved performance. However, merely fusing together different localization techniques does not account for the varying performance characteristics of different localization techniques. In this paper we present a novel, hierarchical localization system that explicitly benefits from three varying characteristics of localization techniques: the distribution of their localization hypotheses, their appearance- and viewpoint-invariant properties, and the resulting differences in where in an environment each system works well and fails. We show how two techniques deployed hierarchically work better than in parallel fusion, how combining two different techniques works better than two levels of a single technique, even when the single technique has superior individual performance, and develop two and three-tier hierarchical structures that progressively improve localization performance. Finally, we develop a stacked hierarchical framework where localization hypotheses from techniques with complementary characteristics are concatenated at each layer, significantly improving retention of the correct hypothesis through to the final localization stage. Using two challenging datasets, we show the proposed system outperforming state-of-the-art techniques. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：结合使用多种互补技术的配合一直被认为是提高性能的一种方式。在视觉定位，多传感器融合，单个感测模态的多进程融合，和不同的定位技术，即使组合已显示导致改善的性能。然而，仅仅融合在一起不同的定位技术不考虑不同的定位技术不同的性能特点。在本文中，我们提出了一种新的分层定位系统，从定位技术3个变特征明确的好处：其本地化的假说，他们appearance-和观点不变性质的分配，并在一个环境中，其中产生的差异各系统的工作原理以及与失败。我们发现分级部署两种技术如何更好地工作比并行融合，如何结合两种不同的技术更好地工作比单一技术两个层面，即使在单一技术具有优异的个人表现和发展二，三梯队层次结构是渐进提高定位性能。最后，我们开发了一个层叠的分级框架，其中从具有互补特性的技术定位的假设，在每个层级联，通过对最终定位阶段显著提高正确假设的保持。使用两个挑战数据集，我们证明了该系统超越国家的最先进的技术。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-11</title>
    <url>/2020/02/11/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-11/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> End-to-End Multi-speaker Speech Recognition with Transformer <a href="https://arxiv.org/pdf/2002.03921" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> A Probabilistic Formulation of Unsupervised Text Style Transfer <a href="https://arxiv.org/pdf/2002.03912" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> A Study of Human Summaries of Scientific Articles <a href="https://arxiv.org/pdf/2002.03604" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> What Changed Your Mind: The Roles of Dynamic Topics and Discourse in  Argumentation Process <a href="https://arxiv.org/pdf/2002.03536" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Multilingual Alignment of Contextual Word Representations <a href="https://arxiv.org/pdf/2002.03518" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Limits of Detecting Text Generated by Large-Scale Language Models <a href="https://arxiv.org/pdf/2002.03438" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Abstractive Summarization for Low Resource Data using Domain Transfer  and Data Synthesis <a href="https://arxiv.org/pdf/2002.03407" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Attend to the beginning: A study on using bidirectional attention for  extractive summarization <a href="https://arxiv.org/pdf/2002.03405" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Short Text Classification via Knowledge powered Attention with  Similarity Matrix based CNN <a href="https://arxiv.org/pdf/2002.03350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Rough Set based Aggregate Rank Measure &amp; its Application to Supervised  Multi Document Summarization <a href="https://arxiv.org/pdf/2002.03259" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Mining Commonsense Facts from the Physical World <a href="https://arxiv.org/pdf/2002.03149" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> HHH: An Online Medical Chatbot System based on Knowledge Graph and  Hierarchical Bi-Directional Attention <a href="https://arxiv.org/pdf/2002.03140" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> LAVA NAT: A Non-Autoregressive Translation Model with Look-Around  Decoding and Vocabulary Attention <a href="https://arxiv.org/pdf/2002.03084" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Blank Language Models <a href="https://arxiv.org/pdf/2002.03079" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Description Based Text Classification with Reinforcement Learning <a href="https://arxiv.org/pdf/2002.03067" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> autoNLP: NLP Feature Recommendations for Text Analytics Applications <a href="https://arxiv.org/pdf/2002.03056" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Snippext: Semi-supervised Opinion Mining with Augmented Data <a href="https://arxiv.org/pdf/2002.03049" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Pre-training Tasks for Embedding-based Large-scale Retrieval <a href="https://arxiv.org/pdf/2002.03932" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly  Articles <a href="https://arxiv.org/pdf/2002.03531" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> SPA: Verbal Interactions between Agents and Avatars in Shared Virtual  Environments using Propositional Planning <a href="https://arxiv.org/pdf/2002.03246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Time-aware Large Kernel Convolutions <a href="https://arxiv.org/pdf/2002.03184" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. End-to-End Multi-speaker Speech Recognition with Transformer</b>  <a href="https://arxiv.org/pdf/2002.03921" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuankai Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wangyou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qian%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanmin Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Roux%2C+J+L" target="_blank" rel="noopener" style="color:#0000EE;">Jonathan Le Roux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Watanabe%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shinji Watanabe</a><br>
<font size="3">
Abstract: Recently, fully recurrent neural network (RNN) based end-to-end models have been proven to be effective for multi-speaker speech recognition in both the single-channel and multi-channel scenarios. In this work, we explore the use of Transformer models for these tasks by focusing on two aspects. First, we replace the RNN-based encoder-decoder in the speech recognition model with a Transformer architecture. Second, in order to use the Transformer in the masking network of the neural beamformer in the multi-channel case, we modify the self-attention component to be restricted to a segment rather than the whole sequence in order to reduce computation. Besides the model architecture improvements, we also incorporate an external dereverberation preprocessing, the weighted prediction error (WPE), enabling our model to handle reverberated signals. Experiments on the spatialized wsj1-2mix corpus show that the Transformer-based models achieve 40.9% and 25.6% relative WER reduction, down to 12.1% and 6.4% WER, under the anechoic condition in single-channel and multi-channel tasks, respectively, while in the reverberant case, our methods achieve 41.5% and 13.8% relative WER reduction, down to 16.5% and 15.2% WER. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近日，完全回归神经网络（RNN）的端至高端机型已被证明是有效的在单通道和多通道两种情况下多说话者声音识别。在这项工作中，我们侧重于两个方面探讨使用Transformer模型为这些任务的。首先，我们更换了变压器架构的语音识别模型基于RNN编码器，解码器。其次，为了使用Transformer在多通道情况下，神经波束形成器的屏蔽网络中，我们修改了自注意成分被限制在一个段，而不是整个序列，以减少计算量。除了模型体系结构的改进，我们还包含一个外部去混响预处理，加权预测误差（WPE），使我们的模型来处理混响信号。在空间化wsj1-2mix语料库表明，基于变压器的模型达到40.9％和25.6％的相对减少WER，下降到12.1％和6.4％WER，在单通道和多通道任务的消声条件下，分别的实验，而在混响情况下，我们的方法达到41.5％和13.8％的相对减少WER，下降到16.5％和15.2％WER。</font>
</div>


<hr>
<div id="paper2"> <b>2. A Probabilistic Formulation of Unsupervised Text Style Transfer</b>  <a href="https://arxiv.org/pdf/2002.03912" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=He%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Junxian He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Neubig%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Graham Neubig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Berg-Kirkpatrick%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taylor Berg-Kirkpatrick</a><br>
<font size="3">
Abstract: We present a deep generative model for unsupervised text style transfer that unifies previously proposed non-generative techniques. Our probabilistic approach models non-parallel data from two domains as a partially observed parallel corpus. By hypothesizing a parallel latent sequence that generates each observed sequence, our model learns to transform sequences from one domain to another in a completely unsupervised fashion. In contrast with traditional generative sequence models (e.g. the HMM), our model makes few assumptions about the data it generates: it uses a recurrent language model as a prior and an encoder-decoder as a transduction distribution. While computation of marginal data likelihood is intractable in this model class, we show that amortized variational inference admits a practical surrogate. Further, by drawing connections between our variational objective and other recent unsupervised style transfer and machine translation techniques, we show how our probabilistic view can unify some known non-generative objectives such as backtranslation and adversarial loss. Finally, we demonstrate the effectiveness of our method on a wide range of unsupervised style transfer tasks, including sentiment transfer, formality transfer, word decipherment, author imitation, and related language translation. Across all style transfer tasks, our approach yields substantial gains over state-of-the-art non-generative baselines, including the state-of-the-art unsupervised machine translation techniques that our approach generalizes. Further, we conduct experiments on a standard unsupervised machine translation task and find that our unified approach matches the current state-of-the-art. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出了统一了先前提出的非生殖技术监督的文本样式转移了深刻的生成模型。从两个结构域为部分观察到平行语料库我们的概率方法模型非并行数据。通过假设到生成每个观察到的序列的并行潜序列，我们的模型学习从一个域变换序列到另一个在完全无监督方式。与传统的生成序列的模型（例如，HMM）相比之下，我们的模型使得它生成数据一些假设：它采用的是复发性语言模型作为先验和编码器 - 解码器作为转导分布。虽然边际数据可能性的计算是在这个模型类棘手，我们表明，摊销变推理承认一个现实的替代。此外，通过我们的目标变和其他最近的无监督式的转移和机器翻译技术之间绘制连接，我们将展示我们的概率观点如何能够统一一些已知的非生成目标，如回译和对抗性的损失。最后，我们证明我们的方法对大范围的无监督式的传输任务，包括情绪转移，转让手续，文字解读，作者模仿，以及相关的语言翻译的有效性。在所有风格的传输任务，我们的做法得到了国家的最先进的非生成基线大有斩获，其中包括国家的最先进的无监督的机器翻译技术，我们的方法推广。此外，我们在标准无监督的机器翻译任务进行实验，发现我们统一的方法当前国家的最先进的匹配。</font>
</div>


<hr>
<div id="paper3"> <b>3. A Study of Human Summaries of Scientific Articles</b>  <a href="https://arxiv.org/pdf/2002.03604" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Boni%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">Odellia Boni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Feigenblat%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guy Feigenblat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cohen%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Doron Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Roitman%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haggai Roitman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Konopnicki%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Konopnicki</a><br>
<font size="3">
Abstract: Researchers and students face an explosion of newly published papers which may be relevant to their work. This led to a trend of sharing human summaries of scientific papers. We analyze the summaries shared in one of these platforms this http URL. The goal is to characterize human summaries of scientific papers, and use some of the insights obtained to improve and adapt existing automatic summarization systems to the domain of scientific papers. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：研究人员和学生面临的新发表的论文可能是与其工作相关的爆炸。这导致了共享的科学论文人类总结的趋势。我们分析在这些平台上的这个HTTP URL一个共享的摘要。我们的目标是表征的科学论文人类汇总，并使用一些得到改善和现有的自动摘要系统适应的科学论文域的见解。</font>
</div>


<hr>
<div id="paper4"> <b>4. What Changed Your Mind: The Roles of Dynamic Topics and Discourse in  Argumentation Process</b>  <a href="https://arxiv.org/pdf/2002.03536" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zeng%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jichuan Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=He%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yulan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gao%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cuiyun Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lyu%2C+M+R" target="_blank" rel="noopener" style="color:#0000EE;">Michael R. Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=King%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Irwin King</a><br>
<font size="3">
Abstract: In our world with full of uncertainty, debates and argumentation contribute to the progress of science and society. Despite of the increasing attention to characterize human arguments, most progress made so far focus on the debate outcome, largely ignoring the dynamic patterns in argumentation processes. This paper presents a study that automatically analyzes the key factors in argument persuasiveness, beyond simply predicting who will persuade whom. Specifically, we propose a novel neural model that is able to dynamically track the changes of latent topics and discourse in argumentative conversations, allowing the investigation of their roles in influencing the outcomes of persuasion. Extensive experiments have been conducted on argumentative conversations on both social media and supreme court. The results show that our model outperforms state-of-the-art models in identifying persuasive arguments via explicitly exploring dynamic factors of topic and discourse. We further analyze the effects of topics and discourse on persuasiveness, and find that they are both useful - topics provide concrete evidence while superior discourse styles may bias participants, especially in social media arguments. In addition, we draw some findings from our empirical results, which will help people better engage in future persuasive conversations. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在我们与充满不确定性，辩论和论证的世界做出贡献的科学和社会的进步。尽管日益关注人类的特征参数，大部分取得的进展至今专注于辩论结果如何，在很大程度上忽视了在论证过程中的动态模式。本文提出了一种研究一种能够自动分析的关键因素，论证的说服力，超越了简单的预测谁将会说服谁。具体来说，我们提出了一种新的神经模型，该模型能够动态跟踪的潜在主题和议论交谈变化的话语，让自己的角色的影响说服效果的调查。大量的实验已经在这两个社交媒体和最高法院议论对话进行。结果表明，我们的模型优于国家的最先进的车型在通过主题和话语的明确探索动态因素识别有说服力的论据。我们进一步分析主题和话语的影响说服力，并且发现它们都是有用的 - 主题提供了确凿的证据，而优越的话语风格可偏向的参与者，尤其是在社交媒体上的参数。此外，我们从实证结果，这将帮助人们更好地参与未来有说服力的交谈得出一些结论。</font>
</div>


<hr>
<div id="paper5"> <b>5. Multilingual Alignment of Contextual Word Representations</b>  <a href="https://arxiv.org/pdf/2002.03518" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cao%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Steven Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kitaev%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nikita Kitaev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Klein%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dan Klein</a><br>
<font size="3">
Abstract: We propose procedures for evaluating and strengthening contextual embedding alignment and show that they are useful in analyzing and improving multilingual BERT. In particular, after our proposed alignment procedure, BERT exhibits significantly improved zero-shot performance on XNLI compared to the base model, remarkably matching pseudo-fully-supervised translate-train models for Bulgarian and Greek. Further, to measure the degree of alignment, we introduce a contextual version of word retrieval and show that it correlates well with downstream zero-shot transfer. Using this word retrieval task, we also analyze BERT and find that it exhibits systematic deficiencies, e.g. worse alignment for open-class parts-of-speech and word pairs written in different scripts, that are corrected by the alignment procedure. These results support contextual alignment as a useful concept for understanding large multilingual pre-trained models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出了评估和加强情境嵌入定位，并表明他们是在分析和改善多语种BERT有用的程序。特别是，我们提出的调整过程之后，BERT展品显著上XNLI相比基本模型提高零射门的表现，非常匹配伪充分监督翻译火车模型，保加利亚和希腊。此外，测量校准的程度，我们介绍检索词的上下文版本，并表明它与下游的零次转让很好的相关性。使用这个检索词的任务，我们也分析BERT，发现它具有系统性缺陷，例如对于用不同的脚本开放类零件的词性和词的对，由校准程序纠正糟糕对齐。这些结果支持上下文定位为了解大型多语种预训练模型一个有用的概念。</font>
</div>


<hr>
<div id="paper6"> <b>6. Limits of Detecting Text Generated by Large-Scale Language Models</b>  <a href="https://arxiv.org/pdf/2002.03438" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Varshney%2C+L+R" target="_blank" rel="noopener" style="color:#0000EE;">Lav R. Varshney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Keskar%2C+N+S" target="_blank" rel="noopener" style="color:#0000EE;">Nitish Shirish Keskar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Socher%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Richard Socher</a><br>
<font size="3">
Abstract: Some consider large-scale language models that can generate long and coherent pieces of text as dangerous, since they may be used in misinformation campaigns. Here we formulate large-scale language model output detection as a hypothesis testing problem to classify text as genuine or generated. We show that error exponents for particular language models are bounded in terms of their perplexity, a standard measure of language generation performance. Under the assumption that human language is stationary and ergodic, the formulation is extended from considering specific language models to considering maximum likelihood language models, among the class of k-order Markov approximations; error probabilities are characterized. Some discussion of incorporating semantic side information is also given. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：有些人认为大型语言模型，可以产生长期而连贯的作品文本的危险，因为它们可能在误导广告系列。在这里，我们制定的大型语言模型输出检测为假设检验问题进行分类文本作为真正的或产生的。我们表明，特定的语言模型误差的指数在他们困惑的语言生成的性能衡量标准方面是有界的。在假设人类语言是固定的，并且遍历，该制剂是从考虑特定的语言模型来考虑最大似然语言模型中，类k阶马尔可夫近似值之间延伸;错误概率表征。结合语义方面信息的一些讨论也给出。</font>
</div>


<hr>
<div id="paper7"> <b>7. Abstractive Summarization for Low Resource Data using Domain Transfer  and Data Synthesis</b>  <a href="https://arxiv.org/pdf/2002.03407" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Magooda%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ahmed Magooda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Litman%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Diane Litman</a><br>
<font size="3">
Abstract: Training abstractive summarization models typically requires large amounts of data, which can be a limitation for many domains. In this paper we explore using domain transfer and data synthesis to improve the performance of recent abstractive summarization methods when applied to small corpora of student reflections. First, we explored whether tuning state of the art model trained on newspaper data could boost performance on student reflection data. Evaluations demonstrated that summaries produced by the tuned model achieved higher ROUGE scores compared to model trained on just student reflection data or just newspaper data. The tuned model also achieved higher scores compared to extractive summarization baselines, and additionally was judged to produce more coherent and readable summaries in human evaluations. Second, we explored whether synthesizing summaries of student data could additionally boost performance. We proposed a template-based model to synthesize new data, which when incorporated into training further increased ROUGE scores. Finally, we showed that combining data synthesis with domain transfer achieved higher ROUGE scores compared to only using one of the two approaches. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：培训抽象概括模型通常需要大量的数据，这可能是许多领域的限制。在本文中，我们探讨使用域传输和数据合成在应用于学生思考的小语料库提高近期抽象总结方法的性能。首先，我们探讨的培训在报纸上的数据的艺术模型的第二调谐状态是否能提高学生反映数据的表现。评估表明，通过调谐模型产生摘要相比，模型中训练的只是学生的反射数据，或只报数据来实现更高的分数ROUGE。调谐模型相比也萃取汇总基线实现较高的分数，并且还判定为产生更为一致的和人类可读的评价汇总。其次，我们探讨是否合成学生数据的汇总可以额外提高性能。我们提出了一个基于模板的模型来合成新的数据，这些数据在纳入培训进一步提高ROUGE得分。最后，我们显示，与域转移组合数据合成相比仅使用两种方法之一来实现更高ROUGE分数。</font>
</div>


<hr>
<div id="paper8"> <b>8. Attend to the beginning: A study on using bidirectional attention for  extractive summarization</b>  <a href="https://arxiv.org/pdf/2002.03405" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Magooda%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ahmed Magooda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marcjan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cezary Marcjan</a><br>
<font size="3">
Abstract: Forum discussion data differ in both structure and properties from generic form of textual data such as news. Henceforth, summarization techniques should, in turn, make use of such differences, and craft models that can benefit from the structural nature of discussion data. In this work, we propose attending to the beginning of a document, to improve the performance of extractive summarization models when applied to forum discussion data. Evaluations demonstrated that with the help of bidirectional attention mechanism, attending to the beginning of a document (initial comment/post) in a discussion thread, can introduce a consistent boost in ROUGE scores, as well as introducing a new State Of The Art (SOTA) ROUGE scores on the forum discussions dataset. Additionally, we explored whether this hypothesis is extendable to other generic forms of textual data. We make use of the tendency of introducing important information early in the text, by attending to the first few sentences in generic textual data. Evaluations demonstrated that attending to introductory sentences using bidirectional attention, improves the performance of extractive summarization models when even applied to more generic form of textual data. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：论坛讨论数据在结构和性能的文本数据的一般形式不同，如新闻。今后，概括技术应该反过来，利用这种差异，工艺模型，可以从讨论数据的结构性质中受益。在这项工作中，我们建议参加到文档的开头，当应用到论坛讨论数据，以提高采掘总结模型的性能。评估表明，随着双向注意机制的帮助下，参加到讨论线索文件（初始评论/后）的开始，也会引入ROUGE分数一致的提振，以及引入一个新的国家的艺术（SOTA在论坛上讨论的数据集）ROUGE得分。此外，我们探讨这个假设是否扩展到文本数据的其他一般形式。我们利用文本早期引进的重要信息，通过参加在通用文本数据的前几句的倾向。评估表明，使用双向注意参加到介绍性的句子，提高采掘总结机型的表现时，甚至应用于文本数据的更通用的形式。</font>
</div>


<hr>
<div id="paper9"> <b>9. Short Text Classification via Knowledge powered Attention with  Similarity Matrix based CNN</b>  <a href="https://arxiv.org/pdf/2002.03350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mingchen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Clinton%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gabtone.Clinton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Miao%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yijia Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gao%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Feng Gao</a><br>
<font size="3">
Abstract: Short text is becoming more and more popular on the web, such as Chat Message, SMS and Product Reviews. Accurately classifying short text is an important and challenging task. A number of studies have difficulties in addressing this problem because of the word ambiguity and data sparsity. To address this issue, we propose a knowledge powered attention with similarity matrix based convolutional neural network (KASM) model, which can compute comprehensive information by utilizing the knowledge and deep neural network. We use knowledge graph (KG) to enrich the semantic representation of short text, specially, the information of parent-entity is introduced in our model. Meanwhile, we consider the word interaction in the literal-level between short text and the representation of label, and utilize similarity matrix based convolutional neural network (CNN) to extract it. For the purpose of measuring the importance of knowledge, we introduce the attention mechanisms to choose the important information. Experimental results on five standard datasets show that our model significantly outperforms state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：短文本正在变得越来越流行网络，比如聊天信息，短信和产品评论的。准确分类短文本是一项重要而艰巨的任务。许多研究都在解决，因为这个词的模糊性和数据稀疏的这个问题的困难。为了解决这个问题，我们提出了基于相似矩阵卷积神经网络（KASM）模型，它可以利用的知识和深层神经网络计算的综合信息知识供电关注。我们用知识图（KG）充实简短的文字，特别是，母公司的实体的信息在我们的模型引入的语义表示。同时，我们认为短文本和标签的表示之间的文字级别的字互动，并利用相似矩阵基于卷积神经网络（CNN）将其解压。用来衡量知识的重要性的目的，我们引入注意机制选择的重要信息。五个标准数据集实验结果表明，我们的模型显著优于国家的最先进的方法。</font>
</div>


<hr>
<div id="paper10"> <b>10. Rough Set based Aggregate Rank Measure &amp; its Application to Supervised  Multi Document Summarization</b>  <a href="https://arxiv.org/pdf/2002.03259" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yadav%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nidhika Yadav</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chatterjee%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Niladri Chatterjee</a><br>
<font size="3">
Abstract: Most problems in Machine Learning cater to classification and the objects of universe are classified to a relevant class. Ranking of classified objects of universe per decision class is a challenging problem. We in this paper propose a novel Rough Set based membership called Rank Measure to solve to this problem. It shall be utilized for ranking the elements to a particular class. It differs from Pawlak Rough Set based membership function which gives an equivalent characterization of the Rough Set based approximations. It becomes paramount to look beyond the traditional approach of computing memberships while handling inconsistent, erroneous and missing data that is typically present in real world problems. This led us to propose the aggregate Rank Measure. The contribution of the paper is three fold. Firstly, it proposes a Rough Set based measure to be utilized for numerical characterization of within class ranking of objects. Secondly, it proposes and establish the properties of Rank Measure and aggregate Rank Measure based membership. Thirdly, we apply the concept of membership and aggregate ranking to the problem of supervised Multi Document Summarization wherein first the important class of sentences are determined using various supervised learning techniques and are post processed using the proposed ranking measure. The results proved to have significant improvement in accuracy. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在机器学习的大多数问题迎合分类和宇宙的对象分类的相关类别。每个决策类宇宙的分类对象的排名是一个具有挑战性的问题。我们在本文中提出了所谓的排名衡量一个新的基于粗糙集的成员来解决这个问题。它应被用于排序的元素到一个特定的类。它不同于帕夫拉克基于粗糙集的隶属度函数这给基于粗糙集近似的等价刻画。它成为极为重要的超越计算成员在处理不一致的，错误的，缺少通常存在于现实世界的问题数据的传统方式。这使我们提出的总排名措施。本文的贡献是三倍。首先，提出了将要用于的内类对象的排名数值表征粗集基于度量。其次，提出并建立等级测量和总浏览量措施的会员的属性。第三，我们申请会员资格的概念和总排名，其中第一使用各种监督学习技术确定句子的重要的一类，并利用所提出的衡量排名的后处理监督多文档文摘的问题。结果证明，在精度显著的改善。</font>
</div>


<hr>
<div id="paper11"> <b>11. Mining Commonsense Facts from the Physical World</b>  <a href="https://arxiv.org/pdf/2002.03149" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zou%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanyan Zou</a><br>
<font size="3">
Abstract: Textual descriptions of the physical world implicitly mention commonsense facts, while the commonsense knowledge bases explicitly represent such facts as triples. Compared to dramatically increased text data, the coverage of existing knowledge bases is far away from completion. Most of the prior studies on populating knowledge bases mainly focus on Freebase. To automatically complete commonsense knowledge bases to improve their coverage is under-explored. In this paper, we propose a new task of mining commonsense facts from the raw text that describes the physical world. We build an effective new model that fuses information from both sequence text and existing knowledge base resource. Then we create two large annotated datasets each with approximate 200k instances for commonsense knowledge base completion. Empirical results demonstrate that our model significantly outperforms baselines. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对物理世界的文本描述隐含提到常识的事实，而常识性的知识基础明确表示这样的事实三倍。相比大幅增加文本数据，现有的知识基础的覆盖面是远离完成。对大多数填充知识库事先研究主要集中在游离碱自动完成常识性的知识基础，提高其覆盖面是充分开发。在本文中，我们提出了从描述物理世界的原始文本挖掘常识性事实的新任务。我们构建一个融合了来自两个序列的文本和已有的知识基础资源信息的有效新模式。然后，我们创建每两个大型注释的数据集与常识的知识基础完成近似200K实例。实证结果表明，我们的模型显著优于基准。</font>
</div>


<hr>
<div id="paper12"> <b>12. HHH: An Online Medical Chatbot System based on Knowledge Graph and  Hierarchical Bi-Directional Attention</b>  <a href="https://arxiv.org/pdf/2002.03140" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bao%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiming Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ni%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lin Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiamou Liu</a><br>
<font size="3">
Abstract: This paper proposes a chatbot framework that adopts a hybrid model which consists of a knowledge graph and a text similarity model. Based on this chatbot framework, we build HHH, an online question-and-answer (QA) Healthcare Helper system for answering complex medical questions. HHH maintains a knowledge graph constructed from medical data collected from the Internet. HHH also implements a novel text representation and similarity deep learning model, Hierarchical BiLSTM Attention Model (HBAM), to find the most similar question from a large QA dataset. We compare HBAM with other state-of-the-art language models such as bidirectional encoder representation from transformers (BERT) and Manhattan LSTM Model (MaLSTM). We train and test the models with a subset of the Quora duplicate questions dataset in the medical area. The experimental results show that our model is able to achieve a superior performance than these existing methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种聊天机器人框架，采用它由一个知识图形和文本相似模型的混合模式。在此基础上聊天机器人框架，我们建立HHH，在线提问和回答（QA）医疗辅助系统是回答复杂的医学问题。 HHH保持从网上收集的医疗数据构建一个知识图谱。 HHH还实现了一个新的文本表示和相似性深度学习模型，分层BiLSTM注意力模型（HBAM），发现从大的QA数据集的最类似的问题。我们比较HBAM与国家的最先进的其他语言模型如变压器双向编码表示（BERT）和曼哈顿LSTM模型（MaLSTM）。我们培养和使用的Quora的重复问题的一个子集测试模型在医疗领域的数据集。实验结果表明，我们的模型能够实现比现有的这些方法优越的性能。</font>
</div>


<hr>
<div id="paper13"> <b>13. LAVA NAT: A Non-Autoregressive Translation Model with Look-Around  Decoding and Vocabulary Attention</b>  <a href="https://arxiv.org/pdf/2002.03084" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoya Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Meng%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuxian Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yuan%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Arianna Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiwei Li</a><br>
<font size="3">
Abstract: Non-autoregressive translation (NAT) models generate multiple tokens in one forward pass and is highly efficient at inference stage compared with autoregressive translation (AT) methods. However, NAT models often suffer from the multimodality problem, i.e., generating duplicated tokens or missing tokens. In this paper, we propose two novel methods to address this issue, the Look-Around (LA) strategy and the Vocabulary Attention (VA) mechanism. The Look-Around strategy predicts the neighbor tokens in order to predict the current token, and the Vocabulary Attention models long-term token dependencies inside the decoder by attending the whole vocabulary for each position to acquire knowledge of which token is about to generate. %We also propose a dynamic bidirectional decoding approach to accelerate the inference process of the LAVA model while preserving the high-quality of the generated output. Our proposed model uses significantly less time during inference compared with autoregressive models and most other NAT models. Our experiments on four benchmarks (WMT14 En$\rightarrow$De, WMT14 De$\rightarrow$En, WMT16 Ro$\rightarrow$En and IWSLT14 De$\rightarrow$En) show that the proposed model achieves competitive performance compared with the state-of-the-art non-autoregressive and autoregressive models while significantly reducing the time cost in inference phase. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：非自回归转换（NAT）模型生成一个直传多个令牌，并在推论阶段高效自回归转换（AT）方法相比。然而，NAT模式经常遭受来自多模式问题，即，产生重复的令牌或丢失令牌。在本文中，我们提出了两种新的方法来解决这个问题，环视（LA）策略和词汇注意（VA）的机制。环视战略，每个位置上的所有词汇主治地获取知识，其中令牌即将产生预测，以预测当前令牌邻居令牌，解码器内部的词汇注意模型的长期令牌的依赖。 ％我们也提出了一个动态的双向解码方式，加快LAVA模型的推理过程，同时保留生成的输出的高品质。我们提出的模型采用与自回归模型和其他大多数NAT车型相比推理过程中显著的时间更少。我们的四个基准试验（WMT14恩$ \ RIGHTARROW $德，WMT14德$ \ RIGHTARROW $恩，WMT16滚装$ \ RIGHTARROW $恩和IWSLT14德$ \ RIGHTARROW $恩）显示，随着国家相比，该模型实现了有竞争力的性能-of最先进的非自回归和自回归模型，同时显著降低推断阶段的时间成本。</font>
</div>


<hr>
<div id="paper14"> <b>14. Blank Language Models</b>  <a href="https://arxiv.org/pdf/2002.03079" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tianxiao Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Quach%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Victor Quach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Barzilay%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Regina Barzilay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jaakkola%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tommi Jaakkola</a><br>
<font size="3">
Abstract: We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks. Unlike previous masked language models or the Insertion Transformer, BLM uses blanks to control which part of the sequence to expand. This fine-grained control of generation is ideal for a variety of text editing and rewriting tasks. The model can start from a single blank or partially completed text with blanks at specified locations. It iteratively determines which word to place in a blank and whether to insert new blanks, and stops generating when no blanks are left to fill. BLM can be efficiently trained using a lower bound of the marginal data likelihood, and achieves perplexity comparable to traditional left-to-right language models on the Penn Treebank and WikiText datasets. On the task of filling missing text snippets, BLM significantly outperforms all other baselines in terms of both accuracy and fluency. Experiments on style transfer and damaged ancient text restoration demonstrate the potential of this framework for a wide range of applications. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出空白语言模型（BLM），通过动态地创建和填补空白生成序列模型。不同于以往的蒙面语言模型或插入变压器，BLM使用空格来控制流程的一部分，扩大它。这一代的细粒度控制是适用于各种文本编辑和重写任务。该模型可以从一个单一的空白开始或部分完成具有在指定位置空白文本。它反复确定哪些词来代替一个空白，是否插入新的空白，而当没有空格都留给填充停止发电。 BLM可以使用下界边际数据的可能性被有效的培训，并达到相当的困惑对宾州树库和数据集wikitext的传统左到右的语言模型。在填充缺失的文本片段的任务，BLM显著优于在准确性和流畅性方面的所有其他基线。款式转移和破坏古文字复原实验证明该框架为广泛的应用潜力。</font>
</div>


<hr>
<div id="paper15"> <b>15. Description Based Text Classification with Reinforcement Learning</b>  <a href="https://arxiv.org/pdf/2002.03067" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chai%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Duo Chai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Han%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinghong Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiwei Li</a><br>
<font size="3">
Abstract: The task of text classification is usually divided into two stages: {\it text feature extraction} and {\it classification}. In this standard formalization categories are merely represented as indexes in the label vocabulary, and the model lacks for explicit instructions on what to classify. Inspired by the current trend of formalizing NLP problems as question answering tasks, we propose a new framework for text classification, in which each category label is associated with a category description. Descriptions are generated by hand-crafted templates or using abstractive/extractive models from reinforcement learning. The concatenation of the description and the text is fed to the classifier to decide whether or not the current label should be assigned to the text. The proposed strategy forces the model to attend to the most salient texts with respect to the label, which can be regarded as a hard version of attention, leading to better performances. We observe significant performance boosts over strong baselines on a wide range of text classification tasks including single-label classification, multi-label classification and multi-aspect sentiment analysis. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：文本分类的任务通常分为两个阶段：{\它的文本特征提取}和{\它分类}。在这个标准形式化类别只是表示为标签的词汇索引，该模型缺少什么就分类明确的指示。通过正式NLP问题答疑任务的当前趋势的启发，我们提出了文本分类的新框架，其中每个类别标签与类别描述相关联。说明由手工制作的模板或使用抽象/采掘车型从强化学习产生。描述和文字的级联被送到分类，以决定当前标签是否应该被分配到的文本。拟议的战略力量模型出席中最突出的文字相对于标签，这可以看作是人们关注的硬的版本，从而获得更好的性能。我们观察到了一个大范围的文本分类的任务，包括单标签分类，多标签分类和多方位的情感分析强基线显著的性能提升。</font>
</div>


<hr>
<div id="paper16"> <b>16. autoNLP: NLP Feature Recommendations for Text Analytics Applications</b>  <a href="https://arxiv.org/pdf/2002.03056" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Misra%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Janardan Misra</a><br>
<font size="3">
Abstract: While designing machine learning based text analytics applications, often, NLP data scientists manually determine which NLP features to use based upon their knowledge and experience with related problems. This results in increased efforts during feature engineering process and renders automated reuse of features across semantically related applications inherently difficult. In this paper, we argue for standardization in feature specification by outlining structure of a language for specifying NLP features and present an approach for their reuse across applications to increase likelihood of identifying optimal features. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在设计基于机器学习的文本分析应用中，常，NLP数据科学家手动确定NLP功能，才能使用根据其与相关问题的知识和经验。在功能设计过程，这导致加大工作力度和渲染自动化的跨越语义相关的应用程序本身就难以功能重用。在本文中，我们通过概述用于指定NLP特征的语言的结构主张在特征规格标准化和呈现的方法用于其再利用跨应用程序以增加识别最佳特征的可能性。</font>
</div>


<hr>
<div id="paper17"> <b>17. Snippext: Semi-supervised Opinion Mining with Augmented Data</b>  <a href="https://arxiv.org/pdf/2002.03049" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Miao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhengjie Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaolan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wang-Chiew Tan</a><br>
<font size="3">
Abstract: Online services are interested in solutions to opinion mining, which is the problem of extracting aspects, opinions, and sentiments from text. One method to mine opinions is to leverage the recent success of pre-trained language models which can be fine-tuned to obtain high-quality extractions from reviews. However, fine-tuning language models still requires a non-trivial amount of training data. In this paper, we study the problem of how to significantly reduce the amount of labeled training data required in fine-tuning language models for opinion mining. We describe Snippext, an opinion mining system developed over a language model that is fine-tuned through semi-supervised learning with augmented data. A novelty of Snippext is its clever use of a two-prong approach to achieve state-of-the-art (SOTA) performance with little labeled training data through: (1) data augmentation to automatically generate more labeled training data from existing ones, and (2) a semi-supervised learning technique to leverage the massive amount of unlabeled data in addition to the (limited amount of) labeled data. We show with extensive experiments that Snippext performs comparably and can even exceed previous SOTA results on several opinion mining tasks with only half the training data required. Furthermore, it achieves new SOTA results when all training data are leveraged. By comparison to a baseline pipeline, we found that Snippext extracts significantly more fine-grained opinions which enable new opportunities of downstream applications. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在线服务，有兴趣的解决方案，意见挖掘，这是从文本中提取方面，意见和情绪的问题。一种方法矿井的意见是利用近期的预先训练语言模型，可以进行微调，以从审查获得高品质的提取成功。但是，微调语言模型仍然需要训练数据的不平凡的量。在本文中，我们研究如何显著减少微调语言模型所需的意见挖掘标记的训练数据量的问题。我们描述Snippext，发展了语言模型的意见挖掘系统进行微调，通过半监督学习与增强的数据。 Snippext的一个新的特点是其巧妙利用一个双叉方式通过与小标记的训练数据实现状态的最先进的（SOTA）性能：（1）数据的增强自动生成从现有的多个标记的训练数据，和（2）半监督学习技术来利用除了标记的数据（的限制量）的未标记数据的巨量。我们发现有大量的实验证明，Snippext执行同等而且甚至超过几个意见挖掘任务以前SOTA结果只需要训练数据的一半。此外，实现了新的SOTA结果时，所有的训练数据利用。通过比较基线管道，我们发现，Snippext提取显著更细粒度的意见这使下游应用新的机遇。</font>
</div>


<hr>
<div id="paper18"> <b>18. Pre-training Tasks for Embedding-based Large-scale Retrieval</b>  <a href="https://arxiv.org/pdf/2002.03932" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei-Cheng Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+F+X" target="_blank" rel="noopener" style="color:#0000EE;">Felix X. Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yin-Wen Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yiming Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sanjiv Kumar</a><br>
<font size="3">
Abstract: We consider the large-scale query-document retrieval problem: given a query (e.g., a question), return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. This problem is often solved in two steps. The retrieval phase first reduces the solution space, returning a subset of candidate documents. The scoring phase then re-ranks the documents. Critically, the retrieval algorithm not only desires high recall but also requires to be highly efficient, returning candidates in time sublinear to the number of documents. Unlike the scoring phase witnessing significant advances recently due to the BERT-style pre-training tasks on cross-attention models, the retrieval phase remains less well studied. Most previous works rely on classic Information Retrieval (IR) methods such as BM-25 (token matching + TF-IDF weights). These models only accept sparse handcrafted features and can not be optimized for different downstream tasks of interest. In this paper, we conduct a comprehensive study on the embedding-based retrieval models. We show that the key ingredient of learning a strong embedding-based Transformer model is the set of pre-training tasks. With adequately designed paragraph-level pre-training tasks, the Transformer models can remarkably improve over the widely-used BM-25 as well as embedding models without Transformers. The paragraph-level pre-training tasks we studied are Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of all three. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们认为大规模的查询，文献检索问题：给定一个查询（例如，一个问题），返回一组相关文件（例如，含有答案的段落）从一个大的文档语料库。这个问题往往解决了两个步骤。检索阶段一来降低解空间，返回候选文档的子集。该评价阶段再重新排名文档。重要的是，检索算法不仅欲火高涨的召回，也要求必须高效，及时次线性回归考生文件的数量。不同于评价阶段最近由于跨关注车型BERT式前培训任务目睹显著的进步，检索阶段仍不很好的研究。大多数以前的作品依靠传统的信息检索（IR）的方法，如BM-25（令牌匹配+ TF-IDF权重）。这些模型只接受稀疏手工制作的特点和利益不同的下游任务不能被优化。在本文中，我们进行的基于嵌入的检索模型的综合研究。我们证明了浓厚的学习基于嵌入变压器模型的关键成分是一组前培训任务。随着设计恰当段落级前的训练任务时，Transformer模型可以显着提高与广泛使用的BM-25以及嵌入模型没有变压器。我们研究的段落级前的训练任务是反完形填空任务（ICT），身体的第一选择（BFS），维基连结预测（WLP），三个人的组合。</font>
</div>


<hr>
<div id="paper19"> <b>19. A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly  Articles</b>  <a href="https://arxiv.org/pdf/2002.03531" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Saqr%2C+K+M" target="_blank" rel="noopener" style="color:#0000EE;">Khalid M. Saqr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Elsharawy%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Abdelrahman Elsharawy</a><br>
<font size="3">
Abstract: Thomas Kuhn proposed his paradigmatic view of scientific discovery five decades ago. The concept of paradigm has not only explained the progress of science, but has also become the central epistemic concept among STM scientists. Here, we adopt the principles of Kuhnian philosophy to construct a novel ontology aims at classifying and evaluating the impact of STM scholarly articles. First, we explain how the Kuhnian cycle of science describes research at different epistemic stages. Second, we show how the Kuhnian cycle could be reconstructed into modular ontologies which classify scholarly articles according to their contribution to paradigm-centred knowledge. The proposed ontology and its scenarios are discussed. To the best of the authors knowledge, this is the first attempt for creating an ontology for describing scholarly articles based on the Kuhnian paradigmatic view of science. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：托马斯·库恩建议他的科学发现的范式观五十年前。范式的概念不仅解释科学的进步，而且已经成为STM科学家中央认知概念。在这里，我们采用库恩的哲学原理在分类和评估STM学术文章的影响，构建了一个新的本体的目的。首先，我们解释科学的库恩的周期是如何描述在不同认知阶段的研究。其次，我们展示了库恩的周期怎么可能被重建成分类根据自己的范式为中心的知识贡献学术文章模块化本体。所提出的本体及其情景进行了讨论。为了最好的作者的知识，这是一个用于创建用于描述基于科学的范式库恩视学术文章本体的第一次尝试。</font>
</div>


<hr>
<div id="paper20"> <b>20. SPA: Verbal Interactions between Agents and Avatars in Shared Virtual  Environments using Propositional Planning</b>  <a href="https://arxiv.org/pdf/2002.03246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Best%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrew Best</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Narang%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sahil Narang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Manocha%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dinesh Manocha</a><br>
<font size="3">
Abstract: We present a novel approach for generating plausible verbal interactions between virtual human-like agents and user avatars in shared virtual environments. Sense-Plan-Ask, or SPA, extends prior work in propositional planning and natural language processing to enable agents to plan with uncertain information, and leverage question and answer dialogue with other agents and avatars to obtain the needed information and complete their goals. The agents are additionally able to respond to questions from the avatars and other agents using natural-language enabling real-time multi-agent multi-avatar communication environments. Our algorithm can simulate tens of virtual agents at interactive rates interacting, moving, communicating, planning, and replanning. We find that our algorithm creates a small runtime cost and enables agents to complete their goals more effectively than agents without the ability to leverage natural-language communication. We demonstrate quantitative results on a set of simulated benchmarks and detail the results of a preliminary user-study conducted to evaluate the plausibility of the virtual interactions generated by SPA. Overall, we find that participants prefer SPA to prior techniques in 84\% of responses including significant benefits in terms of the plausibility of natural-language interactions and the positive impact of those interactions. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出一个新的方法，用于产生之间合理的口头交互虚拟人样在共享虚拟环境代理和用户化身。感-计划-ASK，或SPA，扩展了命题规划和自然语言处理以前的工作，使代理商计划，不确定信息，并利用问题，并与其他代理和化身答案对话，以获得所需的信息，并完成自己的目标。这些代理还能够使用自然语言实现实时多Agent多具象通信环境从化身的问题和其他代理人回应。我们的算法可以在互动率模拟几十虚拟代理交互，移动，通信，规划，重新规划和。我们发现，我们的算法创建一个小的运行成本，使代理人没有充分利用自然语言交流的能力比药物更有效地完成自己的目标。我们展示了一套模拟基准和细节进行评估通过SPA生成的虚拟互动的合理性进行初步的用户研究结果的定量结果。总体而言，我们发现，参与者更喜欢SPA现有技术中的反应，包括在自然语言交互的真实性和这些交互的积极影响方面显著收益84 \％。</font>
</div>


<hr>
<div id="paper21"> <b>21. Time-aware Large Kernel Convolutions</b>  <a href="https://arxiv.org/pdf/2002.03184" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lioutas%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vasileios Lioutas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guo%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuhong Guo</a><br>
<font size="3">
Abstract: To date, most state-of-the-art sequence modelling architectures use attention to build generative models for language based tasks. Some of these models use all the available sequence tokens to generate an attention distribution which results in time complexity of $O(n^2)$. Alternatively, they utilize depthwise convolutions with softmax normalized kernels of size $k$ acting as a limited-window self-attention, resulting in time complexity of $O(k{\cdot}n)$. In this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a novel adaptive convolution operation that learns to predict the size of a summation kernel instead of using the fixed-sized kernel matrix. This method yields a time complexity of $O(n)$, effectively making the sequence encoding process linear to the number of tokens. We evaluate the proposed method on large-scale standard machine translation and language modelling datasets and show that TaLK Convolutions constitute an efficient improvement over other attention/convolution based approaches. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：到目前为止，国家的最先进最序列建模架构使用时注意建立生成模型基于语言的任务。其中一些模型使用所有可用的序列令牌来产生注意力分布，结果在时间的$ O（N ^ 2）$的复杂性。可替换地，它们利用在深度方向上与卷积归SOFTMAX大小$ $ķ的内核充当有限窗口自关注，导致时间的O- $（K {\ CDOT} N）$复杂性。在本文中，我们引入时间感知较大的内核（TALK）卷积，一个新的自适应卷积运算该学习如何预测求和内核，而不是使用固定尺寸的内核矩阵的大小。该方法得到的O- $（n）的一个$时间复杂度，有效地使编码处理线到的令牌的数量的序列。我们评估对大型标准机器翻译和语言模型的数据集，表明该方法会说话的卷积构成超越其它基于关注/卷积方法的有效改善。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-10</title>
    <url>/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-02-10/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Revisiting Spatial Invariance with Low-Rank Local Connectivity <a href="https://arxiv.org/pdf/2002.02959" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> $M^3$T: Multi-Modal Continuous Valence-Arousal Estimation in the Wild <a href="https://arxiv.org/pdf/2002.02957" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> On the Robustness of Face Recognition Algorithms Against Attacks and  Bias <a href="https://arxiv.org/pdf/2002.02942" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> How Does Gender Balance In Training Data Affect Face Recognition  Accuracy? <a href="https://arxiv.org/pdf/2002.02934" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> SPN-CNN: Boosting Sensor-Based Source Camera Attribution With Deep  Learning <a href="https://arxiv.org/pdf/2002.02927" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Subspace Capsule Network <a href="https://arxiv.org/pdf/2002.02924" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Temporal Segmentation of Surgical Sub-tasks through Deep Learning with  Multiple Data Sources <a href="https://arxiv.org/pdf/2002.02921" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge:  Hierarchical Group-wise Attention <a href="https://arxiv.org/pdf/2002.02918" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Data augmentation with Möbius transformations <a href="https://arxiv.org/pdf/2002.02917" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Domain Embedded Multi-model Generative Adversarial Networks for  Image-based Face Inpainting <a href="https://arxiv.org/pdf/2002.02909" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> An Auxiliary Task for Learning Nuclei Segmentation in 3D Microscopy  Images <a href="https://arxiv.org/pdf/2002.02857" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Input Dropout for Spatially Aligned Modalities <a href="https://arxiv.org/pdf/2002.02852" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Switchable Precision Neural Networks <a href="https://arxiv.org/pdf/2002.02815" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Fine-Grained Fashion Similarity Learning by Attribute-Specific Embedding  Network <a href="https://arxiv.org/pdf/2002.02814" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> FourierNet: Compact mask representation for instance segmentation using  differentiable shape decoders <a href="https://arxiv.org/pdf/2002.02709" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Deep Robust Multilevel Semantic Cross-Modal Hashing <a href="https://arxiv.org/pdf/2002.02698" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Learning Class Regularized Features for Action Recognition <a href="https://arxiv.org/pdf/2002.02651" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Statistical Outlier Identification in Multi-robot Visual SLAM using  Expectation Maximization <a href="https://arxiv.org/pdf/2002.02638" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> SideInfNet: A Deep Neural Network for Semi-Automatic Semantic  Segmentation with Side Information <a href="https://arxiv.org/pdf/2002.02634" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Visual search over billions of aerial and satellite images <a href="https://arxiv.org/pdf/2002.02624" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Image Fine-grained Inpainting <a href="https://arxiv.org/pdf/2002.02609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> Adaptive Deep Metric Embeddings for Person Re-Identification under  Occlusions <a href="https://arxiv.org/pdf/2002.02603" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Object-Adaptive LSTM Network for Real-time Visual Tracking with  Adversarial Data Augmentation <a href="https://arxiv.org/pdf/2002.02598" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> Poisson Kernel Avoiding Self-Smoothing in Graph Convolutional Networks <a href="https://arxiv.org/pdf/2002.02589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> Learning Hyperspectral Feature Extraction and Classification with  ResNeXt Network <a href="https://arxiv.org/pdf/2002.02585" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<div id="title26">
<b>26.</b> Impact of ImageNet Model Selection on Domain Adaptation <a href="https://arxiv.org/pdf/2002.02559" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper26" style="color:#0000EE;">摘要</a><br></div>
<div id="title27">
<b>27.</b> Opposite Structure Learning for Semi-supervised Domain Adaptation <a href="https://arxiv.org/pdf/2002.02545" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper27" style="color:#0000EE;">摘要</a><br></div>
<div id="title28">
<b>28.</b> Continuous Geodesic Convolutions for Learning on 3D Shapes <a href="https://arxiv.org/pdf/2002.02506" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper28" style="color:#0000EE;">摘要</a><br></div>
<div id="title29">
<b>29.</b> Activation Density driven Energy-Efficient Pruning in Training <a href="https://arxiv.org/pdf/2002.02949" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper29" style="color:#0000EE;">摘要</a><br></div>
<div id="title30">
<b>30.</b> AnimePose: Multi-person 3D pose estimation and animation <a href="https://arxiv.org/pdf/2002.02792" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper30" style="color:#0000EE;">摘要</a><br></div>
<div id="title31">
<b>31.</b> Trust Your Model: Iterative Label Improvement and Robust Training by  Confidence Based Filtering and Dataset Partitioning <a href="https://arxiv.org/pdf/2002.02705" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper31" style="color:#0000EE;">摘要</a><br></div>
<div id="title32">
<b>32.</b> Optimization of Structural Similarity in Mathematical Imaging <a href="https://arxiv.org/pdf/2002.02657" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper32" style="color:#0000EE;">摘要</a><br></div>
<div id="title33">
<b>33.</b> Quantifying the Value of Lateral Views in Deep Learning for Chest X-rays <a href="https://arxiv.org/pdf/2002.02582" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper33" style="color:#0000EE;">摘要</a><br></div>
<div id="title34">
<b>34.</b> Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow <a href="https://arxiv.org/pdf/2002.02547" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper34" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>



<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Revisiting Spatial Invariance with Low-Rank Local Connectivity</b>  <a href="https://arxiv.org/pdf/2002.02959" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Elsayed%2C+G+F" target="_blank" rel="noopener" style="color:#0000EE;">Gamaleldin F. Elsayed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramachandran%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prajit Ramachandran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shlens%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jonathon Shlens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kornblith%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Kornblith</a><br>
<font size="3">
Abstract: Convolutional neural networks are among the most successful architectures in deep learning. This success is at least partially attributable to the efficacy of spatial invariance as an inductive bias. Locally connected layers, which differ from convolutional layers in their lack of spatial invariance, usually perform poorly in practice. However, these observations still leave open the possibility that some degree of relaxation of spatial invariance may yield a better inductive bias than either convolution or local connectivity. To test this hypothesis, we design a method to relax the spatial invariance of a network layer in a controlled manner. In particular, we create a \textit{low-rank} locally connected layer, where the filter bank applied at each position is constructed as a linear combination of basis set of filter banks. By varying the number of filter banks in the basis set, we can control the degree of departure from spatial invariance. In our experiments, we find that relaxing spatial invariance improves classification accuracy over both convolution and locally connected layers across MNIST, CIFAR-10, and CelebA datasets. These results suggest that spatial invariance in convolution layers may be overly restrictive. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：卷积神经网络在深学习最成功的架构之中。这一成功是至少部分地归因于空间不变性的功效为感应偏压。本地连接的层，其从卷积层的区别在于它们缺少空间不变性的，通常在实践中表现不佳。然而，这些意见仍然保持打开的可能性，一定程度的空间不变性的放松可能会产生比任何回旋或本地连接更好的归纳偏置。为了检验这一假设，我们设计放松的网络层的空间不变性以受控的方式的方法。特别是，我们创建了一个\ textit {低秩}本地连接的层，其中，所述滤波器组施加在每个位置被构造为基组滤波器组的线性组合。通过改变基组滤波器组的数量，我们可以控制背离空间不变性的程度。在我们的实验中，我们发现，放松的空间不变性在两个卷积提高了分类的准确性和本地连接跨MNIST，CIFAR-10和CelebA数据集层。这些结果表明，在卷积层的空间不变性可能过于严格。</font>
</div>


<hr>
<div id="paper2"> <b>2. $M^3$T: Multi-Modal Continuous Valence-Arousal Estimation in the Wild</b>  <a href="https://arxiv.org/pdf/2002.02957" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuan-Hang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rulin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zeng%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiabei Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shan%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shiguang Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xilin Chen</a><br>
<font size="3">
Abstract: This report describes a multi-modal multi-task ($M^3$T) approach underlying our submission to the valence-arousal estimation track of the Affective Behavior Analysis in-the-wild (ABAW) Challenge, held in conjunction with the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2020. In the proposed $M^3$T framework, we fuse both visual features from videos and acoustic features from the audio tracks to estimate the valence and arousal. The spatio-temporal visual features are extracted with a 3D convolutional network and a bidirectional recurrent neural network. Considering the correlations between valence / arousal, emotions, and facial actions, we also explores mechanisms to benefit from other tasks. We evaluated the $M^3$T framework on the validation set provided by ABAW and it significantly outperforms the baseline method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：该报告描述了我们提交基本的情感行为分析的价觉醒估计轨道多模式多任务（$ M ^ 3 $ T）的方式在最狂野结合举行（ABAW）的挑战，在自动面部和手势识别（FG）2020年提出的$ M ^ 3 $ T框架的IEEE国际会议，我们融合从音轨视频和声音特征的视觉特征来估计效价和唤醒。时空视觉特征与3D卷积网络和双向回归神经网络萃取。考虑价/觉醒，情绪和面部动作之间的相关性，我们还探讨了其他的任务机制的好处。我们评估了由ABAW提供的验证集的$ M ^ 3 $ T框架，它显著优于基线法。</font>
</div>


<hr>
<div id="paper3"> <b>3. On the Robustness of Face Recognition Algorithms Against Attacks and  Bias</b>  <a href="https://arxiv.org/pdf/2002.02942" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Singh%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Richa Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Akshay Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Singh%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maneet Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nagpal%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shruti Nagpal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Vatsa%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mayank Vatsa</a><br>
<font size="3">
Abstract: Face recognition algorithms have demonstrated very high recognition performance, suggesting suitability for real world applications. Despite the enhanced accuracies, robustness of these algorithms against attacks and bias has been challenged. This paper summarizes different ways in which the robustness of a face recognition algorithm is challenged, which can severely affect its intended working. Different types of attacks such as physical presentation attacks, disguise/makeup, digital adversarial attacks, and morphing/tampering using GANs have been discussed. We also present a discussion on the effect of bias on face recognition models and showcase that factors such as age and gender variations affect the performance of modern algorithms. The paper also presents the potential reasons for these challenges and some of the future research directions for increasing the robustness of face recognition models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人脸识别算法已经证明非常高的识别性能，这对于现实世界的应用程序的适用性。尽管提高精度，这些算法受到攻击与偏见稳健性受到了挑战。本文总结了不同的方式，其中人脸识别算法的鲁棒性受到质疑，这会严重影响其预期工作。不同类型的攻击，例如物理呈现攻击，伪装/化妆，数字对抗攻击，变形/篡改使用甘斯进行了讨论。我们还提出关于面部识别模型偏差的影响的讨论，也展示了因素，如年龄和性别变化而影响的现代算法的性能。本文还介绍了这些挑战和一些未来的研究方向为增加脸部识别模型的鲁棒性的潜在原因。</font>
</div>


<hr>
<div id="paper4"> <b>4. How Does Gender Balance In Training Data Affect Face Recognition  Accuracy?</b>  <a href="https://arxiv.org/pdf/2002.02934" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Albiero%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vítor Albiero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bowyer%2C+K+W" target="_blank" rel="noopener" style="color:#0000EE;">Kevin W. Bowyer</a><br>
<font size="3">
Abstract: Even though deep learning methods have greatly increased the overall accuracy of face recognition, an old problem still persists: accuracy is higher for men than for women. Previous researchers have speculated that the difference could be due to cosmetics, head pose, or hair covering the face. It is also often speculated that the lower accuracy for women is caused by women being under-represented in the training data. This work aims to investigate if gender imbalance in the training data is actually the cause of lower accuracy for females. Using a state-of-the-art deep CNN, three different loss functions, and two training datasets, we train each on seven subsets with different male/female ratios, totaling forty two train-ings. The trained face matchers are then tested on three different testing datasets. Results show that gender-balancing the dataset has an overall positive effect, with higher accuracy for most of the combinations of loss functions and datasets when a balanced subset is used. However, for the best combination of loss function and dataset, the original training dataset shows better accuracy on 3 out of 4 times. We observe that test accuracy for males is higher when the training data is all male. However, test accuracy for females is not maximized when the training data is all female. Fora number of combinations of loss function and test dataset, accuracy for females is higher when only 75% of the train-ing data is female than when 100% of the training data is female. This suggests that lower accuracy for females is nota simple result of the fraction of female training data. By clustering face features, we show that in general, male faces are closer to other male faces than female faces, and female faces are closer to other female faces than male faces </font>
<br>
<font size="2" style="line-height:30px;">
摘要：尽管深度学习方法已经人脸识别的整体精度大大提高，一个老问题仍然存在：精度是男性高于女性。先前的研究人员推测，差异可能是由于化妆品，头部姿势，或头发遮住了脸。它也经常被推测为女性较低的精度是由妇女是在训练数据代表性不足引起的。这项工作旨在调查，如果在训练数据性别失衡实际上是低精度为女性的原因。用一个国家的最先进的深CNN，三种不同的损失函数，和两个训练数据集，我们每次训练七子集与不同的男性/女性的比例，共计42列车英格斯。训练有素的脸的匹配，然后在三个不同的测试数据集进行测试。结果表明，两性平衡数据集具有总体积极作用，以较高的精度对大多数的损失函数和数据集的组合中的，当使用平衡子集。然而，对于损失函数和数据集，3开出4次原训练数据集显示了更好的精确度的最佳组合。我们观察到，测试精度男性要高，当训练数据是所有男性。然而，当训练数据是所有女性为女性测试精度没有最大化。损失函数和测试数据集的组合的数目论坛，精度为女性更高时只有75％的训练数据的情况相比，在训练数据的100％是女女。这表明，对于女性低精度诺塔女训练数据的分数的简单的结果。通过聚类面部特征，我们表明，在一般情况下，男性的面孔更接近其他男性的脸比女性的面孔，和女性的面孔更接近其他女性的面孔比男性面孔</font>
</div>


<hr>
<div id="paper5"> <b>5. SPN-CNN: Boosting Sensor-Based Source Camera Attribution With Deep  Learning</b>  <a href="https://arxiv.org/pdf/2002.02927" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kirchner%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matthias Kirchner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Johnson%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cameron Johnson</a><br>
<font size="3">
Abstract: We explore means to advance source camera identification based on sensor noise in a data-driven framework. Our focus is on improving the sensor pattern noise (SPN) extraction from a single image at test time. Where existing works suppress nuisance content with denoising filters that are largely agnostic to the specific SPN signal of interest, we demonstrate that a~deep learning approach can yield a more suitable extractor that leads to improved source attribution. A series of extensive experiments on various public datasets confirms the feasibility of our approach and its applicability to image manipulation localization and video source attribution. A critical discussion of potential pitfalls completes the text. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于在数据驱动框架传感器噪声探索手段预先源摄像机识别。我们的重点是在测试时间改善从单个图像传感器图案噪声（SPN）萃取。如果现有的工作与抑制去噪是很大程度上不可知的感兴趣的特定SPN​​信号过滤器扰民的内容，我们证明了〜深深的学习方法可以产生更适合提取这会改善来源归属。一系列的各种公共数据集大量的实验证明我们的方法和适用于图像处理的定位和视频源归属的可行性。潜在缺陷的一个重要讨论完成的文字。</font>
</div>


<hr>
<div id="paper6"> <b>6. Subspace Capsule Network</b>  <a href="https://arxiv.org/pdf/2002.02924" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Edraki%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marzieh Edraki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rahnavard%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nazanin Rahnavard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shah%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mubarak Shah</a><br>
<font size="3">
Abstract: Convolutional neural networks (CNNs) have become a key asset to most of fields in AI. Despite their successful performance, CNNs suffer from a major drawback. They fail to capture the hierarchy of spatial relation among different parts of an entity. As a remedy to this problem, the idea of capsules was proposed by Hinton. In this paper, we propose the SubSpace Capsule Network (SCN) that exploits the idea of capsule networks to model possible variations in the appearance or implicitly defined properties of an entity through a group of capsule subspaces instead of simply grouping neurons to create capsules. A capsule is created by projecting an input feature vector from a lower layer onto the capsule subspace using a learnable transformation. This transformation finds the degree of alignment of the input with the properties modeled by the capsule subspace. We show that SCN is a general capsule network that can successfully be applied to both discriminative and generative models without incurring computational overhead compared to CNN during test time. Effectiveness of SCN is evaluated through a comprehensive set of experiments on supervised image classification, semi-supervised image classification and high-resolution image generation tasks using the generative adversarial network (GAN) framework. SCN significantly improves the performance of the baseline models in all 3 tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：卷积神经网络（细胞神经网络）已经成为一个重要的资产，以最人工智能领域。尽管他们的成功表现，细胞神经网络从一大缺点。他们并没有捕捉到一个实体的不同部分之间的空间关系的层次结构。作为补救这一问题，胶囊的想法被提出韩丁。在本文中，我们提出了子空间胶囊网络（SCN），它利用胶囊网络的想法通过一组子空间胶囊而不是简单地分组的神经元来创建胶囊以一个实体的外观或隐式地定义的属性可能的变化进行建模。胶囊是通过使用可学习变换从较低层的输入特征向量投影到子空间胶囊创建。这种转变中找到与由胶囊子空间模型化的特性输入的对准程度。我们发现，SCN是可以成功地应用到辨别和生成模型，而不会在测试时间招致相比，CNN的计算开销一般胶囊网络。 SCN的有效性是通过一套综合的有关使用生成对抗网络（GAN）框架监督图像分类，半监督图像分类和高分辨率图像生成任务实验进行评价。 SCN显著提高了基准模型中的所有3个任务的性能。</font>
</div>


<hr>
<div id="paper7"> <b>7. Temporal Segmentation of Surgical Sub-tasks through Deep Learning with  Multiple Data Sources</b>  <a href="https://arxiv.org/pdf/2002.02921" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Qin%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yidan Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pedram%2C+S+A" target="_blank" rel="noopener" style="color:#0000EE;">Sahba Aghajani Pedram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Feyzabadi%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Seyedshams Feyzabadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Allan%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Max Allan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=McLeod%2C+A+J" target="_blank" rel="noopener" style="color:#0000EE;">A. Jonathan McLeod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Burdick%2C+J+W" target="_blank" rel="noopener" style="color:#0000EE;">Joel W. Burdick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Azizian%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mahdi Azizian</a><br>
<font size="3">
Abstract: Many tasks in robot-assisted surgeries (RAS) can be represented by finite-state machines (FSMs), where each state represents either an action (such as picking up a needle) or an observation (such as bleeding). A crucial step towards the automation of such surgical tasks is the temporal perception of the current surgical scene, which requires a real-time estimation of the states in the FSMs. The objective of this work is to estimate the current state of the surgical task based on the actions performed or events occurred as the task progresses. We propose Fusion-KVE, a unified surgical state estimation model that incorporates multiple data sources including the Kinematics, Vision, and system Events. Additionally, we examine the strengths and weaknesses of different state estimation models in segmenting states with different representative features or levels of granularity. We evaluate our model on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more complex dataset involving robotic intra-operative ultrasound (RIOUS) imaging, created using the da Vinci Xi surgical system. Our model achieves a superior frame-wise state estimation accuracy up to 89.4%, which improves the state-of-the-art surgical state estimation models in both JIGSAWS suturing dataset and our RIOUS dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在机器人辅助的外科手术（RAS）的许多任务可以通过有限状态机（FSM），其中每个状态代表任一种动作（诸如拿起针）或观察（如出血）来表示。对这样的手术任务的自动化的一个关键步骤是目前的手术场景，这需要在有限状态机的状态的实时估计的时间感知。这项工作的目的是评估基础上进行的操作或事件发生的任务进展手术任务的当前状态。我们提出了Fusion-KVE，了采用多种数据源，包括运动学，视觉，和系统事件统一的手术状态估计模型。此外，我们研究不同的状态估计模型的优势和劣势在具有不同代表​​性的特征或粒度级别分割的状态。我们评估我们在约翰霍普金斯大学，ISI手势和技能评估工作组（拼图）模型，以及一个涉及机器人术中超声（RIOUS）成像更复杂的数据集，使用达芬奇手术兮系统创建。我们的模型实现了卓越的逐帧状态估计精度高达89.4％，提高了两个拼图的国家的最先进的手术状态估计模型缝合数据集，我们RIOUS数据集。</font>
</div>


<hr>
<div id="paper8"> <b>8. iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge:  Hierarchical Group-wise Attention</b>  <a href="https://arxiv.org/pdf/2002.02918" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cai%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dongyang Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ding%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nan Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Wang</a><br>
<font size="3">
Abstract: In this report, the method for the iqiyi submission to the task of ActivityNet 2019 Kinetics-700 challenge is described. Three models are involved in the model ensemble stage: TSN, HG-NL and StNet. We propose the hierarchical group-wise non-local (HG-NL) module for frame-level features aggregation for video classification. The standard non-local (NL) module is effective in aggregating frame-level features on the task of video classification but presents low parameters efficiency and high computational cost. The HG-NL method involves a hierarchical group-wise structure and generates multiple attention maps to enhance performance. Basing on this hierarchical group-wise structure, the proposed method has competitive accuracy, fewer parameters and smaller computational cost than the standard NL. For the task of ActivityNet 2019 Kinetics-700 challenge, after model ensemble, we finally obtain an averaged top-1 and top-5 error percentage 28.444% on the test set. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在这个报告中，被描述为爱奇艺提交ActivityNet 2019动力学-700挑战任务的方法。三种型号都参与模式集合阶段：TSN，HG-NL和StNet。我们提出了帧级的分级组明智的非本地（HG-NL）模块支持视频分类聚集。标准的非本地（NL）模块是有效的聚合帧级特征的视频分类，但呈现低参数效率和高的计算成本的任务。在HG-NL方法涉及分级组明智的结构和生成多个关注的地图，以提高性能。在此基础上分级组明智结构，所提出的方法具有竞争力的精确度，更少的参数和比标准NL较小的计算成本。对于ActivityNet 2019动力学-700挑战的任务，模式集合后，我们终于在测试组获得的平均最高-1和前五名误差百分比28.444％。</font>
</div>


<hr>
<div id="paper9"> <b>9. Data augmentation with Möbius transformations</b>  <a href="https://arxiv.org/pdf/2002.02917" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sharon Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiequan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lundh%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Torbjörn Lundh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ng%2C+A+Y" target="_blank" rel="noopener" style="color:#0000EE;">Andrew Y. Ng</a><br>
<font size="3">
Abstract: Data augmentation has led to substantial improvements in the performance and generalization of deep models, and remain a highly adaptable method to evolving model architectures and varying amounts of data---in particular, extremely scarce amounts of available training data. In this paper, we present a novel method of applying Möbius transformations to augment input images during training. Möbius transformations are bijective conformal maps that generalize image translation to operate over complex inversion in pixel space. As a result, Möbius transformations can operate on the sample level and preserve data labels. We show that the inclusion of Möbius transformations during training enables improved generalization over prior sample-level data augmentation techniques such as cutout and standard crop-and-flip transformations, most notably in low data regimes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：数据增强导致了深模型的性能和泛化实质性的改善，并保持高度适应性的方法来进化模型架构和不同的数据量---尤其是极为稀缺的可用金额的训练数据。在本文中，我们提出了训练期间施加莫比乌斯变换到扩充输入图像的新方法。莫比乌斯变换是双射共形映射是广义含图像平移了在像素空间复杂反转来操作。其结果是，莫比乌斯转换可以在样品上水平和操作保持数据的标签。我们发现，莫比乌斯变换的训练中列入允许超过前一个样级别的数据增强技术，如切口和标准的作物和翻动的转换，特别是在低数据制度改进的概括。</font>
</div>


<hr>
<div id="paper10"> <b>10. Domain Embedded Multi-model Generative Adversarial Networks for  Image-based Face Inpainting</b>  <a href="https://arxiv.org/pdf/2002.02909" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kong%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bin Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yin%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youbing Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qi Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lyu%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Siwei Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lv%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiancheng Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Canghong Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaojie Li</a><br>
<font size="3">
Abstract: Prior knowledge of face shape and location plays an important role in face inpainting. However, traditional facing inpainting methods mainly focus on the generated image resolution of the missing portion but without consideration of the special particularities of the human face explicitly and generally produce discordant facial parts. To solve this problem, we present a stable variational latent generative model for large inpainting of face images. We firstly represent only face regions with the latent variable space but simultaneously constraint the random vectors to offer control over the distribution of latent variables, and combine with the non-face parts textures to generate a face image with plausible contents. Two adversarial discriminators are finally used to judge whether the generated distribution is close to the real distribution or not. It can not only synthesize novel image structures but also explicitly utilize the latent space with Eigenfaces to make better predictions. Furthermore, our work better evaluates the side face impainting problem. Experiments on both CelebA and CelebA-HQ face datasets demonstrate that our proposed approach generates higher quality inpainting results than existing ones. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：脸的形状和位置的先验知识起着面修补了重要作用。然而，传统的面向图像修复方法主要集中在缺失部分的所产生的图像分辨率，但不考虑人脸的特殊特殊性明确和一般产生不和谐的面部部分。为了解决这个问题，我们提出了一个稳定的潜在变生成模型对于大修补面部图像。我们首先仅代表面孔区域与潜变量空间，但同时在潜变量的分布约束随机向量提供控制，并与非人脸部分的纹理相结合，生成具有合理内容的人脸图像。两个敌对的鉴别最终用于判断产生的分布是否接近真实分布与否。它不仅可以合成新的图像结构，而且还明确利用与特征脸的潜在空间，以做出更好的预测。此外，我们的工作更好地评估侧面impainting问题。两个CelebA和CelebA-HQ面数据集实验证明，我们提出的方法生成更高质量的图像修补效果比现有的。</font>
</div>


<hr>
<div id="paper11"> <b>11. An Auxiliary Task for Learning Nuclei Segmentation in 3D Microscopy  Images</b>  <a href="https://arxiv.org/pdf/2002.02857" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hirsch%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Peter Hirsch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kainmueller%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dagmar Kainmueller</a><br>
<font size="3">
Abstract: Segmentation of cell nuclei in microscopy images is a prevalent necessity in cell biology. Especially for three-dimensional datasets, manual segmentation is prohibitively time-consuming, motivating the need for automated methods. Learning-based methods trained on pixel-wise ground-truth segmentations have been shown to yield state-of-the-art results on 2d benchmark image data of nuclei, yet a respective benchmark is missing for 3d image data. In this work, we perform a comparative evaluation of nuclei segmentation algorithms on a database of manually segmented 3d light microscopy volumes. We propose a novel learning strategy that boosts segmentation accuracy by means of a simple auxiliary task, thereby robustly outperforming each of our baselines. Furthermore, we show that one of our baselines, the popular three-label model, when trained with our proposed auxiliary task, outperforms the recent StarDist-3D. As an additional, practical contribution, we benchmark nuclei segmentation against nuclei detection, i.e. the task of merely pinpointing individual nuclei without generating respective pixel-accurate segmentations. For learning nuclei detection, large 3d training datasets of manually annotated nuclei center points are available. However, the impact on detection accuracy caused by training on such sparse ground truth as opposed to dense pixel-wise ground truth has not yet been quantified. To this end, we compare nuclei detection accuracy yielded by training on dense vs. sparse ground truth. Our results suggest that training on sparse ground truth yields competitive nuclei detection rates. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在显微镜图像细胞核的分割是细胞生物学中普遍存在的必要性。特别是对于三维数据集，手动分割是过于费时的，激励为自动化方法的需要。基于学习训练的上逐像素地面实况分割方法已经显示出产生关于细胞核的2D基准图像数据状态的最先进的结果，但各自的基准缺少3D图像数据。在这项工作中，我们手动分割的3D光学显微镜卷的数据库上执行的细胞核分割算法的比较评价。我们提出了一种新的学习策略，提升分割精度通过简单的辅助任务的手段，从而有力跑赢我们每一个基线。此外，我们表明，我们的基准之一，流行的三标签模型，当我们提出的辅助任务的训练，优于近期StarDist-3D。作为一个附加的，实用的贡献，对细胞核检测我们基准细胞核分割，即，仅仅确定个体细胞核，而不会产生相应的像素精确的分割的任务。对于学习核检测，人工标注的核中心点大型3D训练数据是可用的。然而，由这种稀疏的地面实况训练，而不是密集的逐像素的地面实况对检测精度的影响尚未量化。为此，我们通过比较致密与稀疏地面实况训练产生的核检测精度。我们的研究结果表明，在稀疏的地面实况训练产生有竞争力的核检测率。</font>
</div>


<hr>
<div id="paper12"> <b>12. Input Dropout for Spatially Aligned Modalities</b>  <a href="https://arxiv.org/pdf/2002.02852" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=de+Blois%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sébastien de Blois</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Garon%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mathieu Garon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gagn%C3%A9%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christian Gagné</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lalonde%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jean-François Lalonde</a><br>
<font size="3">
Abstract: Computer vision datasets containing multiple modalities such as color, depth, and thermal properties are now commonly accessible and useful for solving a wide array of challenging tasks. However, deploying multi-sensor heads is not possible in many scenarios. As such many practical solutions tend to be based on simpler sensors, mostly for cost, simplicity and robustness considerations. In this work, we propose a training methodology to take advantage of these additional modalities available in datasets, even if they are not available at test time. By assuming that the modalities have a strong spatial correlation, we propose Input Dropout, a simple technique that consists in stochastic hiding of one or many input modalities at training time, while using only the canonical (e.g. RGB) modalities at test time. We demonstrate that Input Dropout trivially combines with existing deep convolutional architectures, and improves their performance on a wide range of computer vision tasks such as dehazing, 6-DOF object tracking, pedestrian detection and object classification. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：含有多种方式，如颜色，深度和热性能的计算机视觉的数据集，现在是解决了各种各样的挑战性的任务阵列通常访问并从中受益。但是，在部署多传感器头是不可能在许多情况下。因此许多切实可行的解决方案往往是基于简单的传感器，主要是出于成本，简单性和稳健性的考虑。在这项工作中，我们提出了一种培训方法采取数据集提供这些附加模式的优势，即使他们不提供测试时间。通过假设方式具有很强的空间相关性，我们建议输入差，一个简单的技术，其在于在训练时间的一个或多个输入模态随机遮盖力，而只使用的规范（例如，RGB）模式在测试时间。我们表明，输入差平凡与现有的深卷积架构相结合，并提高他们对范围广泛的计算机视觉任务，如除雾，6-DOF目标跟踪，行人检测和对象分类性能。</font>
</div>


<hr>
<div id="paper13"> <b>13. Switchable Precision Neural Networks</b>  <a href="https://arxiv.org/pdf/2002.02815" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Guerra%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luis Guerra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhuang%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bohan Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Reid%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Ian Reid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Drummond%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tom Drummond</a><br>
<font size="3">
Abstract: Instantaneous and on demand accuracy-efficiency trade-off has been recently explored in the context of neural networks slimming. In this paper, we propose a flexible quantization strategy, termed Switchable Precision neural Networks (SP-Nets), to train a shared network capable of operating at multiple quantization levels. At runtime, the network can adjust its precision on the fly according to instant memory, latency, power consumption and accuracy demands. For example, by constraining the network weights to 1-bit with switchable precision activations, our shared network spans from BinaryConnect to Binarized Neural Network, allowing to perform dot-products using only summations or bit operations. In addition, a self-distillation scheme is proposed to increase the performance of the quantized switches. We tested our approach with three different quantizers and demonstrate the performance of SP-Nets against independently trained quantized models in classification accuracy for Tiny ImageNet and ImageNet datasets using ResNet-18 and MobileNet architectures. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：瞬时和按需精度效率的权衡已经在最近减肥神经网络的环境中探索。在本文中，我们提出了一种灵活的量化策略，称为切换精密神经网络（SP-网），培养能够在多个量化等级操作的共享的网络。在运行时，网络可以根据即时记忆，延迟，功耗和精度要求在飞行中调整其精度。例如，通过限制网络的权重为1位具有可切换精度激活，我们的共享网络从跨度到BinaryConnect二值化神经网络，允许进行点副产物仅使用加法运算或位操作。此外，自蒸馏方案提出增加量化开关的性能。我们使用RESNET-18和MobileNet架构测试我们有三个不同的量化方法，并展示SP-篮网对独立训练的量化模型，分类准确率的表现为微小ImageNet和ImageNet数据集。</font>
</div>


<hr>
<div id="paper14"> <b>14. Fine-Grained Fashion Similarity Learning by Attribute-Specific Embedding  Network</b>  <a href="https://arxiv.org/pdf/2002.02814" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhe Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jianfeng Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Long%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhongzi Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=He%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xue%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hui Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ji%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shouling Ji</a><br>
<font size="3">
Abstract: This paper strives to learn fine-grained fashion similarity. In this similarity paradigm, one should pay more attention to the similarity in terms of a specific design/attribute among fashion items, which has potential values in many fashion related applications such as fashion copyright protection. To this end, we propose an Attribute-Specific Embedding Network (ASEN) to jointly learn multiple attribute-specific embeddings in an end-to-end manner, thus measure the fine-grained similarity in the corresponding space. With two attention modules, i.e., Attribute-aware Spatial Attention and Attribute-aware Channel Attention, ASEN is able to locate the related regions and capture the essential patterns under the guidance of the specified attribute, thus make the learned attribute-specific embeddings better reflect the fine-grained similarity. Extensive experiments on four fashion-related datasets show the effectiveness of ASEN for fine-grained fashion similarity learning and its potential for fashion reranking. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文力求学习细粒度的方式相似。在这种相似的模式，应该在当中的时尚单品的特定设计/属性，它在很多时尚相关的应用，如时尚版权保护的潜在价值方面更注重的相似性。为此，提出了一种属性特定嵌入网络（ASEN）共同学习多个属性特定的嵌入在端至端的方式，从而测量在相应的空间中的细粒的相似性。有两个注意模块，即属性感知空间注意和属性感知通道注意，日月能够找到相关的区域和指定属性的指导下拍摄的基本模式，从而使学习特定属性的嵌入更好地反映细粒度的相似性。在四大时装相关的数据集大量的实验表明日月的细粒度方式相似的学习和有效性及其对时尚的重新排名的潜力。</font>
</div>


<hr>
<div id="paper15"> <b>15. FourierNet: Compact mask representation for instance segmentation using  differentiable shape decoders</b>  <a href="https://arxiv.org/pdf/2002.02709" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Benbarka%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nuri Benbarka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Riaz%2C+H+u+M" target="_blank" rel="noopener" style="color:#0000EE;">Hamd ul Moqeet Riaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zell%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andreas Zell</a><br>
<font size="3">
Abstract: We present FourierNet a single shot, anchor-free, fully convolutional instance segmentation method, which predicts a shape vector that is converted into contour points using a numerical transformation. Compared to previous methods, we introduce a new training technique, where we utilize a differentiable shape decoder, which achieves automatic weight balancing of the shape vector's coefficients. Fourier series was utilized as a shape encoder because of its coefficient interpretability and fast implementation. By using its lower frequencies we were able to retrieve smooth and compact masks. FourierNet shows promising results compared to polygon representation methods, achieving 30.6 mAP on the MS COCO 2017 benchmark. At lower image resolutions, it runs at 26.6 FPS with 24.3 mAP. It achieves 23.3 mAP using just 8 parameters to represent the mask, which is double the amount of parameters to predict a bounding box. Code will be available at: this http URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出FourierNet单杆，锚自由，充分卷积实例分割方法，该方法预测，被转换成使用数字变换的轮廓点的形状向量。相比以前的方法中，我们引入一个新的训练技术，在这里我们利用微分的形状解码器，它实现了自动重平衡形状矢量的系数。傅立叶系列被用作形状编码器，因为它的系数解释性和快速实现的。通过使用它的频率较低，我们能够取得光滑紧致口罩。 FourierNet显示有希望的结果相比，多边形表示方法，实现对MS COCO 2017年基准30.6地图。在较低的图像分辨率，它运行在26.6 FPS 24.3地图。它实现只用8个参数来表示掩模，这是参数双倍量来预测的边界框23.3地图。代码将可在：这个HTTP URL。</font>
</div>


<hr>
<div id="paper16"> <b>16. Deep Robust Multilevel Semantic Cross-Modal Hashing</b>  <a href="https://arxiv.org/pdf/2002.02698" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Ge Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoyang Tan</a><br>
<font size="3">
Abstract: Hashing based cross-modal retrieval has recently made significant progress. But straightforward embedding data from different modalities into a joint Hamming space will inevitably produce false codes due to the intrinsic modality discrepancy and noises. We present a novel Robust Multilevel Semantic Hashing (RMSH) for more accurate cross-modal retrieval. It seeks to preserve fine-grained similarity among data with rich semantics, while explicitly require distances between dissimilar points to be larger than a specific value for strong robustness. For this, we give an effective bound of this value based on the information coding-theoretic analysis, and the above goals are embodied into a margin-adaptive triplet loss. Furthermore, we introduce pseudo-codes via fusing multiple hash codes to explore seldom-seen semantics, alleviating the sparsity problem of similarity information. Experiments on three benchmarks show the validity of the derived bounds, and our method achieves state-of-the-art performance. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于散列的跨模态获取最近取得显著的进展。但来自不同模态直接的数据嵌入到一个关节海明空间不可避免地会产生虚假的代码由于固有形态差异和噪声。我们提出了一个新颖的多级鲁棒语义散列（RMSH），用于更精确的跨通道检索。它旨在保护具有丰富的语义数据中细粒度的相似性，同时明确要求不同的点之间的距离比为较强的鲁棒性的特定值。对于这一点，我们给出一个有效的结合的该值的基础上，信息编码-理论分析，和上述目标被实现成一个余量自适应三重态损耗。此外，我们通过融合多个散列码来探索很少见过语义，减轻相似信息的稀疏问题引入伪代码。在三个基准实验表明派生边界的有效性，以及我们的方法实现国家的最先进的性能。</font>
</div>


<hr>
<div id="paper17"> <b>17. Learning Class Regularized Features for Action Recognition</b>  <a href="https://arxiv.org/pdf/2002.02651" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Stergiou%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexandros Stergiou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poppe%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ronald Poppe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Veltkamp%2C+R+C" target="_blank" rel="noopener" style="color:#0000EE;">Remco C. Veltkamp</a><br>
<font size="3">
Abstract: Training Deep Convolutional Neural Networks (CNNs) is based on the notion of using multiple kernels and non-linearities in their subsequent activations to extract useful features. The kernels are used as general feature extractors without specific correspondence to the target class. As a result, the extracted features do not correspond to specific classes. Subtle differences between similar classes are modeled in the same way as large differences between dissimilar classes. To overcome the class-agnostic use of kernels in CNNs, we introduce a novel method named Class Regularization that performs class-based regularization of layer activations. We demonstrate that this not only improves feature search during training, but also allows an explicit assignment of features per class during each stage of the feature extraction process. We show that using Class Regularization blocks in state-of-the-art CNN architectures for action recognition leads to systematic improvement gains of 1.8%, 1.2% and 1.4% on the Kinetics, UCF-101 and HMDB-51 datasets, respectively. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：培训深卷积神经网络（细胞神经网络）是基于使用多个内核和非线性在其随后的激活，提取有用的功能的概念。将所述核用作为一般特征提取器没有具体的对应于目标类。其结果是，所提取的特征不对应于特定的类。相似的类之间的细微差别以同样的方式被建模为不同阶层之间的巨大差异。为了克服类无关的使用在细胞神经网络内核，我们引入已命名的类的正则化，其执行基于类的层的激活的正则化的新方法。我们证明，这不仅提高了训练中的搜索功能，还允许在特征提取过程的每一个阶段，每级功能的明确任务。我们分别显示在国家的最先进的美国有线电视新闻网的架构，使用正则班块动作识别导致的1.8％，1.2％和1.4％，在动力学，UCF-101和HMDB-51数据集系统化改善收益。</font>
</div>


<hr>
<div id="paper18"> <b>18. Statistical Outlier Identification in Multi-robot Visual SLAM using  Expectation Maximization</b>  <a href="https://arxiv.org/pdf/2002.02638" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Karimian%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Arman Karimian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Ziqi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tron%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roberto Tron</a><br>
<font size="3">
Abstract: This paper introduces a novel and distributed method for detecting inter-map loop closure outliers in simultaneous localization and mapping (SLAM). The proposed algorithm does not rely on a good initialization and can handle more than two maps at a time. In multi-robot SLAM applications, maps made by different agents have nonidentical spatial frames of reference which makes initialization very difficult in the presence of outliers. This paper presents a probabilistic approach for detecting incorrect orientation measurements prior to pose graph optimization by checking the geometric consistency of rotation measurements. Expectation-Maximization is used to fine-tune the model parameters. As ancillary contributions, a new approximate discrete inference procedure is presented which uses evidence on loops in a graph and is based on optimization (Alternate Direction Method of Multipliers). This method yields superior results compared to Belief Propagation and has convergence guarantees. Simulation and experimental results are presented that evaluate the performance of the outlier detection method and the inference algorithm on synthetic and real-world data. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文介绍了一种新颖的和用于同时定位和地图创建（SLAM）检测地图间环路闭合离群值分布的方法。该算法不依赖于良好的初始化，可以同时处理两个以上的地图。在多机器人SLAM应用，地图由不同试剂制成具有不相同的参考帧的空间，这使得在异常值的存在初始化非常困难。本文提出了通过检查转动测量值的几何一致性检测姿态图形优化之前不正确的方向测量值的概率方法。期望最大化用于微调模型参数。作为辅助的贡献，提出了一种新的近似离散推理过程，它使用的环路证据的曲线图，并且基于优化（乘法器的交替方向法）。这种方法可以得到比置信传播效果出众，具有收敛的保证。仿真和实验结果都认为评估异常检测方法的性能和合成和真实数据的推理算法。</font>
</div>


<hr>
<div id="paper19"> <b>19. SideInfNet: A Deep Neural Network for Semi-Automatic Semantic  Segmentation with Side Information</b>  <a href="https://arxiv.org/pdf/2002.02634" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Koh%2C+J+Y" target="_blank" rel="noopener" style="color:#0000EE;">Jing Yu Koh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nguyen%2C+D+T" target="_blank" rel="noopener" style="color:#0000EE;">Duc Thanh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Truong%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Quang-Trung Truong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yeung%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sai-Kit Yeung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Binder%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexander Binder</a><br>
<font size="3">
Abstract: Fully-automatic execution is the ultimate goal for many Computer Vision applications. However, this objective is not always realistic in tasks associated with high failure costs, such as medical applications. For these tasks, a compromise between fully-automatic execution and user interactions is often preferred due to desirable accuracy and performance. Semi-automatic methods require minimal effort from experts by allowing them to provide cues that guide computer algorithms. Inspired by the practicality and applicability of the semi-automatic approach, this paper proposes a novel deep neural network architecture, namely SideInfNet that effectively integrates features learnt from images with side information extracted from user annotations to produce high quality semantic segmentation results. To evaluate our method, we applied the proposed network to three semantic segmentation tasks and conducted extensive experiments on benchmark datasets. Experimental results and comparison with prior work have verified the superiority of our model, suggesting the generality and effectiveness of the model in semi-automatic semantic segmentation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：全自动执行是许多计算机视觉应用的终极目标。然而，这个目标并非总是与高失败成本，如医疗应用相关的任务逼真。对于这些任务的，完全自动执行与用户的交互之间的折中通常优选的，因为所希望的精度和性能。半自动方法，让他们提供线索引导计算机算法需要专家最小的努力。本文通过实用性和半自动方法的适用性的启发，提出了一种新颖深层神经网络体系结构，即SideInfNet有效地集成了各种功能从与来自用户的注释提取以生产高品质的语义分割结果侧信息图像获知。为了评估我们的方法，我们应用所提出的网络三个语义分割任务，并进行了基准数据集广泛的实验。实验结果与以前的工作相比，已经验证了我们的模型的优势，这在半自动语义分割模型的通用性和有效性。</font>
</div>


<hr>
<div id="paper20"> <b>20. Visual search over billions of aerial and satellite images</b>  <a href="https://arxiv.org/pdf/2002.02624" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Keisler%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ryan Keisler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Skillman%2C+S+W" target="_blank" rel="noopener" style="color:#0000EE;">Samuel W. Skillman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gonnabathula%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sunny Gonnabathula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poehnelt%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Justin Poehnelt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rudelis%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xander Rudelis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Warren%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Michael S. Warren</a><br>
<font size="3">
Abstract: We present a system for performing visual search over billions of aerial and satellite images. The purpose of visual search is to find images that are visually similar to a query image. We define visual similarity using 512 abstract visual features generated by a convolutional neural network that has been trained on aerial and satellite imagery. The features are converted to binary values to reduce data and compute requirements. We employ a hash-based search using Bigtable, a scalable database service from Google Cloud. Searching the continental United States at 1-meter pixel resolution, corresponding to approximately 2 billion images, takes approximately 0.1 seconds. This system enables real-time visual search over the surface of the earth, and an interactive demo is available at this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种系统，用于超千亿航空和卫星图像，进行视觉搜索。视觉搜索的目的是找到在视觉上类似于查询图像的图像。我们定义使用经过训练的空中和卫星图像卷积神经网络产生512个抽象的视觉特征视觉相似。特征被转换为二进制值，以减少数据和计算要求。我们采用使用Bigtable的，从谷歌云可扩展的数据库服务基于散列的搜索。搜索美国大陆在1米像素的分辨率，对应于大约2十亿图像，需要大约为0.1秒。这个系统使地球表面上的实时可视化搜索和互动演示可在此HTTPS URL。</font>
</div>


<hr>
<div id="paper21"> <b>21. Image Fine-grained Inpainting</b>  <a href="https://arxiv.org/pdf/2002.02609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hui%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zheng Hui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jie Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiumei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gao%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinbo Gao</a><br>
<font size="3">
Abstract: Image inpainting techniques have shown promising improvement with the assistance of generative adversarial networks (GANs) recently. However, most of them often suffered from completed results with unreasonable structure or blurriness. To mitigate this problem, in this paper, we present a one-stage model that utilizes dense combinations of dilated convolutions to obtain larger and more effective receptive fields. Benefited from the property of this network, we can more easily recover large regions in an incomplete image. To better train this efficient generator, except for frequently-used VGG feature matching loss, we design a novel self-guided regression loss for concentrating on uncertain areas and enhancing the semantic details. Besides, we devise a geometrical alignment constraint item to compensate for the pixel-based distance between prediction features and ground-truth ones. We also employ a discriminator with local and global branches to ensure local-global contents consistency. To further improve the quality of generated images, discriminator feature matching on the local branch is introduced, which dynamically minimizes the similarity of intermediate features between synthetic and ground-truth patches. Extensive experiments on several public datasets demonstrate that our approach outperforms current state-of-the-art methods. Code is available at~\url{this https URL}. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：图像修复技术已显示出大有希望与生成对抗网络（甘斯）最近的协助改善。然而，大多数人往往是因与结构不合理或模糊完成结果遭遇。为了缓解这个问题，在该论文中，我们提出了利用扩张卷积的致密组合，以获得更大的和更有效的感受域的一阶段的模型。从这个网络的性能中受益，我们可以更容易在不完整的图像恢复大区。为了更好地培养这种高效的发电机，除了常用VGG特征匹配的损失，我们设计了一个新的自导回归亏损集中在不确定的领域，提高语义细节。此外，我们设计的几何对齐约束的项目，以弥补预测的功能和地面实况的人之间基于像素的距离。我们还采用了与本地和全球的分支机构鉴别，以确保地方 - 全球内容的一致性。为了进一步提高生成的图像的质量，对本地分支鉴别特征匹配被引入，其动态地最小化的合成的和地面实况贴片之间的中间特征的相似性。在几个公开的数据集大量的实验证明我们的方法优于国家的最先进的通用方法。代码可以在〜\ {URL这HTTPS URL}。</font>
</div>


<hr>
<div id="paper22"> <b>22. Adaptive Deep Metric Embeddings for Person Re-Identification under  Occlusions</b>  <a href="https://arxiv.org/pdf/2002.02603" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title22" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wanxiang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yan%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yan Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Si Chen</a><br>
<font size="3">
Abstract: Person re-identification (ReID) under occlusions is a challenging problem in video surveillance. Most of existing person ReID methods take advantage of local features to deal with occlusions. However, these methods usually independently extract features from the local regions of an image without considering the relationship among different local regions. In this paper, we propose a novel person ReID method, which learns the spatial dependencies between the local regions and extracts the discriminative feature representation of the pedestrian image based on Long Short-Term Memory (LSTM), dealing with the problem of occlusions. In particular, we propose a novel loss (termed the adaptive nearest neighbor loss) based on the classification uncertainty to effectively reduce intra-class variations while enlarging inter-class differences within the adaptive neighborhood of the sample. The proposed loss enables the deep neural network to adaptively learn discriminative metric embeddings, which significantly improve the generalization capability of recognizing unseen person identities. Extensive comparative evaluations on challenging person ReID datasets demonstrate the significantly improved performance of the proposed method compared with several state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人重新鉴定（里德）下闭塞是视频监控一个具有挑战性的问题。大多数现有的人里德方法利用的地方特色，以应对闭塞。然而，这些方法通常是独立地从提取的图像的局部区域的特征而没有考虑不同的局部区域之间的关系。在本文中，我们提出了一种新的人雷德法，其学习的局部区域之间的空间的依赖，并提取基于长短期记忆（LSTM）行人图像的判别特征表示，处理阻塞的问题。特别是，我们提出基于分类的不确定性，以有效地减少类内变化，同时增大样本的自适应邻域内类间差异的新型的损失（称为自适应最近邻损失）。所提出的损失使深层神经网络自适应学习判别指标的嵌入，这显著提高认识看不见人身份的泛化能力。上具有挑战性的人里德数据集广泛比较评价证明了该方法的显著改进的性能与国家的最先进的几种方法进行比较。</font>
</div>


<hr>
<div id="paper23"> <b>23. Object-Adaptive LSTM Network for Real-time Visual Tracking with  Adversarial Data Augmentation</b>  <a href="https://arxiv.org/pdf/2002.02598" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title23" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Du%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yihan Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yan%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yan Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Si Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hua%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Hua</a><br>
<font size="3">
Abstract: In recent years, deep learning based visual tracking methods have obtained great success owing to the powerful feature representation ability of Convolutional Neural Networks (CNNs). Among these methods, classification-based tracking methods exhibit excellent performance while their speeds are heavily limited by the expensive computation for massive proposal feature extraction. In contrast, matching-based tracking methods (such as Siamese networks) possess remarkable speed superiority. However, the absence of online updating renders these methods unadaptable to significant object appearance variations. In this paper, we propose a novel real-time visual tracking method, which adopts an object-adaptive LSTM network to effectively capture the video sequential dependencies and adaptively learn the object appearance variations. For high computational efficiency, we also present a fast proposal selection strategy, which utilizes the matching-based tracking method to pre-estimate dense proposals and selects high-quality ones to feed to the LSTM network for classification. This strategy efficiently filters out some irrelevant proposals and avoids the redundant computation for feature extraction, which enables our method to operate faster than conventional classification-based tracking methods. In addition, to handle the problems of sample inadequacy and class imbalance during online tracking, we adopt a data augmentation technique based on the Generative Adversarial Network (GAN) to facilitate the training of the LSTM network. Extensive experiments on four visual tracking benchmarks demonstrate the state-of-the-art performance of our method in terms of both tracking accuracy and speed, which exhibits great potentials of recurrent structures for visual tracking. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近年来，深度学习基于视觉跟踪方法已获得由于卷积神经网络（细胞神经网络）的强大功能表现能力，取得巨大成功。在这些方法中，基于分类的跟踪方法表现出优异的性能，而他们的速度很大程度上受到了大量的建议特征提取昂贵的计算限制。相反，基于匹配追踪方法（如连体网络）具有显着的速度优势。然而，不存在在线更新的呈现这些方法不能适应显著对象的外观的变化。在本文中，我们提出了一种新的实时视觉跟踪方法，即采用一个目的自适应LSTM网络有效地捕捉视频顺序依赖性和自适应学习对象的外观的变化。对于高计算效率，我们还提出了一种快速建议选择策略，其利用基于匹配追踪方法预先估计密提案和选择高品质的那些，以进料LSTM网络进行分类。这种策略有效地过滤掉一些不相关的建议，并避免了特征提取，这使得我们的方法比传统的基于分类的跟踪方法更快地操作冗余计算。此外，处理样品不足和不平衡类在线跟踪过程中的问题，我们采用了基于创成对抗性网络（GAN）的数据增强技术，以方便LSTM网络的培训。在四个视觉跟踪基准广泛的实验表明在这两种跟踪准确性和速度，其表现出对视觉跟踪复发性结构的巨大潜力方面我们的方法的状态的最先进的性能。</font>
</div>


<hr>
<div id="paper24"> <b>24. Poisson Kernel Avoiding Self-Smoothing in Graph Convolutional Networks</b>  <a href="https://arxiv.org/pdf/2002.02589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title24" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Ziqing Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Han%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shoudong Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Zhao</a><br>
<font size="3">
Abstract: Graph convolutional network (GCN) is now an effective tool to deal with non-Euclidean data, such as social networks in social behavior analysis, molecular structure analysis in the field of chemistry, and skeleton-based action recognition. Graph convolutional kernel is one of the most significant factors in GCN to extract nodes' feature, and some improvements of it have reached promising performance theoretically and experimentally. However, there is limited research about how exactly different data types and graph structures influence the performance of these kernels. Most existing methods used an adaptive convolutional kernel to deal with a given graph structure, which still not reveals the internal reasons. In this paper, we started from theoretical analysis of the spectral graph and studied the properties of existing graph convolutional kernels. While taking some designed datasets with specific parameters into consideration, we revealed the self-smoothing phenomenon of convolutional kernels. After that, we proposed the Poisson kernel that can avoid self-smoothing without training any adaptive kernel. Experimental results demonstrate that our Poisson kernel not only works well on the benchmark dataset where state-of-the-art methods work fine, but also is evidently superior to them in synthetic datasets. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：图形卷积网络（GCN）现在是处理非欧几里得数据，如社会行为分析社交网络，在化学领域的分子结构分析，以及基于骨架动作识别的有效工具。图卷积内核的GCN以提取节点的功能，最显著的因素之一，而它的一些改进，已经达到了理论和实验有前途的性能。然而，有关数据类型和图形结构究竟如何影响不同这些内核的性能有限的研究。大多数现有的方法中使用的自适应卷积内核来处理一个给定的图形结构，仍然没有揭示的内在原因。在本文中，我们从谱图的理论分析开始，研究了现有的图形内核卷积的性质。虽然采取了一些设计数据集以特定参数加以考虑，我们揭示了卷积核的自流平现象。在那之后，我们提出的泊松内核，可避免自平滑无任何训练适应核。实验结果表明，我们的泊松内核不仅行之有效的基准数据集，其中国家的最先进的方法，做工精细，而且是在合成数据集明显优于它们。</font>
</div>


<hr>
<div id="paper25"> <b>25. Learning Hyperspectral Feature Extraction and Classification with  ResNeXt Network</b>  <a href="https://arxiv.org/pdf/2002.02585" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title25" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Nyasaka%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Divinah Nyasaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tinega%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haron Tinega</a><br>
<font size="3">
Abstract: The Hyperspectral image (HSI) classification is a standard remote sensing task, in which each image pixel is given a label indicating the physical land-cover on the earth's surface. The achievements of image semantic segmentation and deep learning approaches on ordinary images have accelerated the research on hyperspectral image classification. Moreover, the utilization of both the spectral and spatial cues in hyperspectral images has shown improved classification accuracy in hyperspectral image classification. The use of only 3D Convolutional Neural Networks (3D-CNN) to extract both spatial and spectral cues from Hyperspectral images results in an explosion of parameters hence high computational cost. We propose network architecture called the MixedSN that utilizes the 3D convolutions to modeling spectral-spatial information in the early layers of the architecture and the 2D convolutions at the top layers which majorly deal with semantic abstraction. We constrain our architecture to ResNeXt block because of their performance and simplicity. Our model drastically reduced the number of parameters and achieved comparable classification performance with state-of-the-art methods on Indian Pine (IP) scene dataset, Pavia University scene (PU) dataset, Salinas (SA) Scene dataset, and Botswana (BW) dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：高光谱图像（HSI）分类是一个标准的远程感测任务，其中，每个图像像素被赋予了标签指示在地球表面上的物理土地覆盖。图像语义分割和深学习方法对普通图像的成就，加速了对高光谱影像分类研究。此外，光谱和空间线索两者在高光谱图像的利用率已经显示出在高光谱图像分类改进的分类精度。仅使用三维卷积神经网络（3D-CNN）的提取从高光谱图像的结果的空间和频谱线索在的参数因此具有高的计算成本爆炸。我们建议网络架构，名为利用三维回旋在顶层这majorly处理语义抽象建模架构的早期层和二维卷积谱空间信息MixedSN。我们限制，因为它们的性能和简单了系统架构以ResNeXt块。我们的模型大大减少参数的数量，并实现与印度的松树（IP）的场景数据集的国家的最先进的方法相同的分类性能，帕维亚大学场景（PU）的数据集，萨利纳斯（SA）场景的数据集，以及博茨瓦纳（BW ）数据集。</font>
</div>


<hr>
<div id="paper26"> <b>26. Impact of ImageNet Model Selection on Domain Adaptation</b>  <a href="https://arxiv.org/pdf/2002.02559" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title26" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youshan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Davison%2C+B+D" target="_blank" rel="noopener" style="color:#0000EE;">Brian D. Davison</a><br>
<font size="3">
Abstract: Deep neural networks are widely used in image classification problems. However, little work addresses how features from different deep neural networks affect the domain adaptation problem. Existing methods often extract deep features from one ImageNet model, without exploring other neural networks. In this paper, we investigate how different ImageNet models affect transfer accuracy on domain adaptation problems. We extract features from sixteen distinct pre-trained ImageNet models and examine the performance of twelve benchmarking methods when using the features. Extensive experimental results show that a higher accuracy ImageNet model produces better features, and leads to higher accuracy on domain adaptation problems (with a correlation coefficient of up to 0.95). We also examine the architecture of each neural network to find the best layer for feature extraction. Together, performance from our features exceeds that of the state-of-the-art in three benchmark datasets. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：深层神经网络被广泛应用于图像分类问题。然而，很少工作地址是如何从不同的深层神经网络的功能影响领域适应性问题。现有的方法常从一个ImageNet模型深的特点，没有探索其他神经网络。在本文中，我们研究了不同型号ImageNet如何影响域的适应问题传递的准确性。我们提取从16不同的预先训练ImageNet机型的功能和使用功能检查时，十二基准方法的性能。广泛的实验结果表明，较高的精度ImageNet模型产生更好的功能，并导致更高的准确度上域的适应的问题（与最多的相关系数0.95）。我们还检查每个神经网络的体系结构，以找到特征提取的最佳层。总之，从我们的特色性能超过了国家的最先进的三个地基准数据集。</font>
</div>


<hr>
<div id="paper27"> <b>27. Opposite Structure Learning for Semi-supervised Domain Adaptation</b>  <a href="https://arxiv.org/pdf/2002.02545" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title27" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Qin%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Can Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lichen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qianqian Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yin%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yu Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Huan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun Fu</a><br>
<font size="3">
Abstract: Current adversarial adaptation methods attempt to align the cross-domain features whereas two challenges remain unsolved: 1) conditional distribution mismatch between different domains and 2) the bias of decision boundary towards the source domain. To solve these challenges, we propose a novel framework for semi-supervised domain adaptation by unifying the learning of opposite structures (UODA). UODA consists of a generator and two classifiers (i.e., the source-based and the target-based classifiers respectively) which are trained with opposite forms of losses for a unified object. The target-based classifier attempts to cluster the target features to improve intra-class density and enlarge inter-class divergence. Meanwhile, the source-based classifier is designed to scatter the source features to enhance the smoothness of decision boundary. Through the alternation of source-feature expansion and target-feature clustering procedures, the target features are well-enclosed within the dilated boundary of the corresponding source features. This strategy effectively makes the cross-domain features precisely aligned. To overcome the model collapse through training, we progressively update the measurement of distance and the feature representation on both domains via an adversarial training paradigm. Extensive experiments on the benchmarks of DomainNet and Office-home datasets demonstrate the effectiveness of our approach over the state-of-the-art method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：当前对抗性适应方法试图对准跨域特征而两个挑战仍然没有解决：1）不同的结构域和2之间条件分布不匹配）决策边界的偏置朝向源域。为了解决这些难题，我们通过统一相反的结构（UODA）的学习提出了半监督领域适应一个新的框架。 UODA由发电机和两个分类器（即，基于源和分别与基于目标的分类器），其与一个统一的对象损失相对形式的训练。基于目标的分类器试图群集目标功能，以提高的类内的密度和放大级间发散性。同时，基于源代码的分类被设计成散射源功能，以提高决策边界的平滑度。通过源极 - 功能扩展和目标特征聚类程序的交替，所述目标特征的对应的源特征的扩张型边界内孔封闭。这种策略有效地使交叉域特征精确地对准。为了克服通过培训模式崩溃，我们不断更新的距离的测量，并通过对抗性训练模式在两个域的特征表示。在DomainNet和Office家庭数据集的基准广泛的实验，证明了我们在国家的最先进的方法，该方法的有效性。</font>
</div>


<hr>
<div id="paper28"> <b>28. Continuous Geodesic Convolutions for Learning on 3D Shapes</b>  <a href="https://arxiv.org/pdf/2002.02506" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title28" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhangsihao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Litany%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">Or Litany</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Birdal%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tolga Birdal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sridhar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Srinath Sridhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guibas%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Leonidas Guibas</a><br>
<font size="3">
Abstract: The majority of descriptor-based methods for geometric processing of non-rigid shape rely on hand-crafted descriptors. Recently, learning-based techniques have been shown effective, achieving state-of-the-art results in a variety of tasks. Yet, even though these methods can in principle work directly on raw data, most methods still rely on hand-crafted descriptors at the input layer. In this work, we wish to challenge this practice and use a neural network to learn descriptors directly from the raw mesh. To this end, we introduce two modules into our neural architecture. The first is a local reference frame (LRF) used to explicitly make the features invariant to rigid transformations. The second is continuous convolution kernels that provide robustness to sampling. We show the efficacy of our proposed network in learning on raw meshes using two cornerstone tasks: shape matching, and human body parts segmentation. Our results show superior results over baseline methods that use hand-crafted descriptors. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大多数的非刚性形状的几何处理基于描述符的方法依赖于手工制作的描述符。近年来，基于学习的技术已被证明有效，实现多种任务的国家的最先进的成果。然而，尽管这些方法可以直接在原始数据的原理工作的，大多数方法还是依靠在输入层手工制作的描述符。在这项工作中，我们要挑战这一做法，并用神经网络直接从原网学习描述。为此，我们引入两个模块到我们的神经结构。第一种是用于显式地使功能不变的刚性变换的本地参考帧（LRF）。第二个是连续卷积核，要采样提供鲁棒性。我们发现在学习上使用两个基石任务原料网我们提出的网络的功效：人体部位分割形状匹配和。我们的研究结果表明在基线的方法是用手工制作的描述效果出众。</font>
</div>


<hr>
<div id="paper29"> <b>29. Activation Density driven Energy-Efficient Pruning in Training</b>  <a href="https://arxiv.org/pdf/2002.02949" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title29" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Foldy-Porto%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Timothy Foldy-Porto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Panda%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Priyadarshini Panda</a><br>
<font size="3">
Abstract: The process of neural network pruning with suitable fine-tuning and retraining can yield networks with considerably fewer parameters than the original with comparable degrees of accuracy. Typically, pruning methods require large, pre-trained networks as a starting point from which they perform a time-intensive iterative pruning and retraining algorithm. We propose a novel pruning in-training method that prunes a network real-time during training, reducing the overall training time to achieve an optimal compressed network. To do so, we introduce an activation density based analysis that identifies the optimal relative sizing or compression for each layer of the network. Our method removes the need for pre-training and is architecture agnostic, allowing it to be employed on a wide variety of systems. For VGG-19 and ResNet18 on CIFAR-10, CIFAR-100, and TinyImageNet, we obtain exceedingly sparse networks (up to 200x reduction in parameters and >60x reduction in inference compute operations in the best case) with comparable accuracies (up to 2%-3% loss with respect to the baseline network). By reducing the network size periodically during training, we achieve total training times that are shorter than those of previously proposed pruning methods. Furthermore, training compressed networks at different epochs with our proposed method yields considerable reduction in training compute complexity (1.6x -3.2x lower) at near iso-accuracy as compared to a baseline network trained entirely from scratch. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：与合适的微调神经网络修剪和再培训可以产生网络具有比具有可比较的精确度的原始参数相当少的方法。典型地，修剪方法需要大的，预训练的网络与其所执行时间密集的迭代修剪和再培训算法的起点。我们提出了一个新的修剪在训练方法训练李子期间网络的实时性，降低整体的训练时间，以达到最佳的压缩网络。要做到这一点，我们引入一个激活基于密度分析标识所述最佳相对尺寸或压缩为网络的每个层。我们的方法消除了对预训练的必要性和架构是不可知的，允许它被在各种各样的系统中采用。为VGG-19和ResNet18上CIFAR-10，CIFAR-100，和TinyImageNet，我们得到极其稀疏的网络（高达参数200X减少和> 60倍的减少在推理计算操作在最佳情况下）具有可比较的精度（最多2个％-3相对于基线网络％的损失）。通过培训期间定期降低了网络规模，我们实现了总的训练时间是比那些先前提出的修剪方法更短。此外，相比于完全从头培养了基线网络训练在与我们在接近异精度提出的方法的产率显着降低在训练计算复杂度（1.6倍-3.2x降低）不同时期压缩网络。</font>
</div>


<hr>
<div id="paper30"> <b>30. AnimePose: Multi-person 3D pose estimation and animation</b>  <a href="https://arxiv.org/pdf/2002.02792" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title30" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumarapu%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Laxman Kumarapu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mukherjee%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prerana Mukherjee</a><br>
<font size="3">
Abstract: 3D animation of humans in action is quite challenging as it involves using a huge setup with several motion trackers all over the person's body to track the movements of every limb. This is time-consuming and may cause the person discomfort in wearing exoskeleton body suits with motion sensors. In this work, we present a trivial yet effective solution to generate 3D animation of multiple persons from a 2D video using deep learning. Although significant improvement has been achieved recently in 3D human pose estimation, most of the prior works work well in case of single person pose estimation and multi-person pose estimation is still a challenging problem. In this work, we firstly propose a supervised multi-person 3D pose estimation and animation framework namely AnimePose for a given input RGB video sequence. The pipeline of the proposed system consists of various modules: i) Person detection and segmentation, ii) Depth Map estimation, iii) Lifting 2D to 3D information for person localization iv) Person trajectory prediction and human pose tracking. Our proposed system produces comparable results on previous state-of-the-art 3D multi-person pose estimation methods on publicly available datasets MuCo-3DHP and MuPoTS-3D datasets and it also outperforms previous state-of-the-art human pose tracking methods by a significant margin of 11.7% performance gain on MOTA score on Posetrack 2018 dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在行动人的3D动画是相当具有挑战性的，因为它涉及到使用一个巨大的设置与几个运动跟踪器遍布人的身体来跟踪每一个肢体的运动。这是耗时的，并且可能导致人不适穿着外骨骼紧身衣与运动传感器。在这项工作中，我们提出了一个平凡而有效的解决方案以使用深度学习从2D视频多人的3D动画。虽然显著的改善已经在3D人体姿势估计最近取得，大部分之前的作品在一个人的姿态估计和多方人士的姿势估计的情况下很好地工作仍然是一个具有挑战性的问题。在这项工作中，我们首先提出了一个给定的输入RGB视频序列的监督多人3D姿态估计和动画框架，即AnimePose。所提出的系统的流水线由各种模块组成：i）人检测和分割，ⅱ）深度图估计，ⅲ）起重2D到3D信息用于人本地化ⅳ）人轨迹预测和人类姿态跟踪。我们所提出的系统产生的可公开获得的数据集以前的状态的最先进的3D多人姿势估计方法粘膜3DHP和MuPoTS-3D数据集比较的结果，同时也优于国家的最先进的前面的人体姿势的跟踪方法通过对MOTA 11.7％的性能增益显著保证金得分Posetrack 2018集。</font>
</div>


<hr>
<div id="paper31"> <b>31. Trust Your Model: Iterative Label Improvement and Robust Training by  Confidence Based Filtering and Dataset Partitioning</b>  <a href="https://arxiv.org/pdf/2002.02705" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title31" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Haase-Sch%C3%BCtz%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christian Haase-Schütz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Stal%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rainer Stal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hertlein%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heinz Hertlein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sick%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bernhard Sick</a><br>
<font size="3">
Abstract: State-of-the-art, high capacity deep neural networks not only require large amounts of labelled training data, they are also highly susceptible to label errors in this data, typically resulting in large efforts and costs and therefore limiting the applicability of deep learning. To alleviate this issue, we propose a novel meta training and labelling scheme that is able to use inexpensive unlabelled data by taking advantage of the generalization power of deep neural networks. We show experimentally that by solely relying on one network architecture and our proposed scheme of iterative training and prediction steps, both label quality and resulting model accuracy can be improved significantly. Our method achieves state-of-the-art results, while being architecture agnostic and therefore broadly applicable. Compared to other methods dealing with erroneous labels, our approach does neither require another network to be trained, nor does it necessarily need an additional, highly accurate reference label set. Instead of removing samples from a labelled set, our technique uses additional sensor data without the need for manual labelling. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：国家的最先进的，高容量的深层神经网络，不仅需要大量的标记的训练数据，他们也很容易受到标签错误，在此数据，通常会生成大量的努力和成本，并因此限制的适用性深度学习。为了缓解这一问题，我们提出了一个新颖元的培训和标签计划，能够通过利用深层神经网络的推广力量的优势，使用廉价的未标记的数据。我们实验表明，单纯依靠一个网络架构和我们所提出的迭代训练和预测的步骤方案，无论是标签质量和得到的模型精度可以提高显著。我们的方法实现状态的最先进的结果，而被架构无关，因此广泛适用的。相比于处理错误标签的其他方法，我们的做法既没有要求其他网络进行训练，也不一定需要一个额外的，高度准确的参考符号集。而不是从标记组取出样品，我们的技术使用附加的传感器数据，而无需手动标记。</font>
</div>


<hr>
<div id="paper32"> <b>32. Optimization of Structural Similarity in Mathematical Imaging</b>  <a href="https://arxiv.org/pdf/2002.02657" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title32" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/math?searchtype=author&query=Otero%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">D. Otero</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&query=La+Torre%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">D. La Torre</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&query=Michailovich%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">O. Michailovich</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&query=Vrscay%2C+E+R" target="_blank" rel="noopener" style="color:#0000EE;">E.R. Vrscay</a><br>
<font size="3">
Abstract: It is now generally accepted that Euclidean-based metrics may not always adequately represent the subjective judgement of a human observer. As a result, many image processing methodologies have been recently extended to take advantage of alternative visual quality measures, the most prominent of which is the Structural Similarity Index Measure (SSIM). The superiority of the latter over Euclidean-based metrics have been demonstrated in several studies. However, being focused on specific applications, the findings of such studies often lack generality which, if otherwise acknowledged, could have provided a useful guidance for further development of SSIM-based image processing algorithms. Accordingly, instead of focusing on a particular image processing task, in this paper, we introduce a general framework that encompasses a wide range of imaging applications in which the SSIM can be employed as a fidelity measure. Subsequently, we show how the framework can be used to cast some standard as well as original imaging tasks into optimization problems, followed by a discussion of a number of novel numerical strategies for their solution. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：现在人们普遍认为，基于欧几里得度量可以不总是充分代表人类观察者的主观判断。其结果是，许多图像处理方法已经扩展最近采取的另类视觉质量的措施，其中最突出的是结构相似度指数度量（SSIM）的优势。后者通过基于欧几里得度量的优越性已被证明在一些研究。然而，被集中在特定的应用程序，这些研究的结果往往缺乏，如果其它方法确认，可能会对基于SSIM图像处理算法的进一步发展提供了有益的指导普遍性。因此，而不是集中在一个特定的图像处理任务，在本文中，我们引入包括宽范围的，其中，SSIM可以用作一个保真度测度成像应用的一般框架。随后，我们展示了框架如何可以用来施放一些标准以及原始成像任务为优化问题，其次是一些对他们的解决方案的新的数字战略的讨论。</font>
</div>


<hr>
<div id="paper33"> <b>33. Quantifying the Value of Lateral Views in Deep Learning for Chest X-rays</b>  <a href="https://arxiv.org/pdf/2002.02582" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title33" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Hashir%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohammad Hashir</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Bertrand%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hadrien Bertrand</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Cohen%2C+J+P" target="_blank" rel="noopener" style="color:#0000EE;">Joseph Paul Cohen</a><br>
<font size="3">
Abstract: Most deep learning models in chest X-ray prediction utilize the posteroanterior (PA) view due to the lack of other views available. PadChest is a large-scale chest X-ray dataset that has almost 200 labels and multiple views available. In this work, we use PadChest to explore multiple approaches to merging the PA and lateral views for predicting the radiological labels associated with the X-ray image. We find that different methods of merging the model utilize the lateral view differently. We also find that including the lateral view increases performance for 32 labels in the dataset, while being neutral for the others. The increase in overall performance is comparable to the one obtained by using only the PA view with twice the amount of patients in the training set. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：胸片预测最深刻的学习模型，利用后前（PA）视图由于缺乏可用的其他意见。 PadChest的是，有近200个标签和多视图提供一个大型的胸部X射线数据集。在这项工作中，我们使用PadChest探索多种方法来合并PA和横向视图预测与X射线图像有关的放射性标签。我们发现合并模型利用横向视图不同的，不同的方法。我们还发现，包括横向视图提高性能，在数据集32级的标签，同时保持中立的人。整体性能的增加是与通过仅使用PA视图与在训练集中两次患者的量而得到的一个。</font>
</div>


<hr>
<div id="paper34"> <b>34. Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow</b>  <a href="https://arxiv.org/pdf/2002.02547" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title34" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Nielsen%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Didrik Nielsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Winther%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">Ole Winther</a><br>
<font size="3">
Abstract: Flow models have recently made great progress at modeling quantized sensor data such as images and audio. Due to the continuous nature of flow models, dequantization is typically applied when using them for such quantized data. In this paper, we propose subset flows, a class of flows which can tractably transform subsets of the input space in one pass. As a result, they can be applied directly to quantized data without the need for dequantization. Based on this class of flows, we present a novel interpretation of several existing autoregressive models, including WaveNet and PixelCNN, as single-layer flow models defined through an invertible transformation between uniform noise and data samples. This interpretation suggests that these existing models, 1) admit a latent representation of data and 2) can be stacked in multiple flow layers. We demonstrate this by exploring the latent space of a PixelCNN and by stacking PixelCNNs in multiple flow layers. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：流模型建模时量化传感器数据，如图像和音频最近取得了很大进展。由于流模型的连续性质，使用它们用于这种量化的数据去量化时典型地施加。在本文中，我们提议子集流动，一类可tractably将输入空间的子集在一个通流。其结果是，它们可以被直接应用到量化数据，而不需要反量化。基于此类流中，我们提出的几种现有的自回归模型，包括WaveNet和PixelCNN，作为单层流模型通过均匀噪声和数据样本之间的可逆变换中定义的新的解释。这种解释表明，这些现有的模型，1）承认数据和2的潜表示）可以在多个流动层堆叠。我们通过探讨PixelCNN的潜在空间，并通过在多个流程层层积PixelCNNs证明这一点。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-10</title>
    <url>/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> A Multilingual View of Unsupervised Machine Translation <a href="https://arxiv.org/pdf/2002.02955" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> BERT-of-Theseus: Compressing BERT by Progressive Module Replacing <a href="https://arxiv.org/pdf/2002.02925" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> Neural Machine Translation System of Indic Languages -- An Attention  based Approach <a href="https://arxiv.org/pdf/2002.02758" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> On-Device Information Extraction from SMS using Hybrid Hierarchical  Classification <a href="https://arxiv.org/pdf/2002.02755" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Incorporating Visual Semantics into Sentence Representations within a  Grounded Space <a href="https://arxiv.org/pdf/2002.02734" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Multimodal Matching Transformer for Live Commenting <a href="https://arxiv.org/pdf/2002.02649" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Translating Web Search Queries into Natural Language Questions <a href="https://arxiv.org/pdf/2002.02631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Introducing Aspects of Creativity in Automatic Poetry Generation <a href="https://arxiv.org/pdf/2002.02511" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker <a href="https://arxiv.org/pdf/2002.02450" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> I love your chain mail! Making knights smile in a fantasy game world:  Open-domain goal-orientated dialogue agents <a href="https://arxiv.org/pdf/2002.02878" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Unsupervised pretraining transfers well across languages <a href="https://arxiv.org/pdf/2002.02848" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Depressed individuals express more distorted thinking on social media <a href="https://arxiv.org/pdf/2002.02800" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> LEAP System for SRE19 Challenge -- Improvements and Error Analysis <a href="https://arxiv.org/pdf/2002.02735" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Transformer Transducer: A Streamable Speech Recognition Model with  Transformer Encoders and RNN-T Loss <a href="https://arxiv.org/pdf/2002.02562" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Robust Multi-channel Speech Recognition using Frequency Aligned Network <a href="https://arxiv.org/pdf/2002.02520" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Consistency of a Recurrent Language Model With Respect to Incomplete  Decoding <a href="https://arxiv.org/pdf/2002.02492" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. A Multilingual View of Unsupervised Machine Translation</b>  <a href="https://arxiv.org/pdf/2002.02955" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Garcia%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xavier Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Foret%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre Foret</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sellam%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thibault Sellam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Parikh%2C+A+P" target="_blank" rel="noopener" style="color:#0000EE;">Ankur P. Parikh</a><br>
<font size="3">
Abstract: We present a probabilistic framework for multilingual neural machine translation that encompasses supervised and unsupervised setups, focusing on unsupervised translation. In addition to studying the vanilla case where there is only monolingual data available, we propose a novel setup where one language in the (source, target) pair is not associated with any parallel data, but there may exist auxiliary parallel data that contains the other. This auxiliary data can naturally be utilized in our probabilistic framework via a novel cross-translation loss term. Empirically, we show that our approach results in higher BLEU scores over state-of-the-art unsupervised models on the WMT'14 English-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in most directions. In particular, we obtain a +1.65 BLEU advantage over the best-performing unsupervised model in the Romanian-English direction. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出了多语种神经机器翻译概率框架，包括监管和监督的设置，注重监督的翻译。除了仅存在单语数据可用的研究香草情况下，我们提出了其中在（源，目标）一种语言对不与任何并行数据相关联的新的设置，但也有可能存在包含其它辅助的并行数据。该辅助数据可以自然地在我们的概率框架通过一种新颖的横翻译损耗项利用。根据经验，我们表明，我们的方法得到更高的分数BLEU在国家的最先进的无人监督的车型上WMT'14英法，WMT'16英语 - 德语和英语WMT'16  - 罗马尼亚数据集在大部分方向。特别是，我们获得了在罗马尼亚英语方向表现最好的无监督模型1.65 BLEU优势。</font>
</div>


<hr>
<div id="paper2"> <b>2. BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</b>  <a href="https://arxiv.org/pdf/2002.02925" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Canwen Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wangchunshu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ge%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Furu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们建议逐步模块更换一个新的模型的压缩方式，有效压缩BERT。我们的方法首先将原始BERT分成几个模块，并建立其紧凑的替代品。然后，我们随机与他们的替代品代替原来的模块的紧凑型模块训练到原来模块的模仿行为。我们不断通过培训提高替代的可能性。这样一来，我们的方法所带来的原始和紧凑车型之间的相互作用更深层次的，和平滑的训练过程。相较于以前的知识蒸馏方法用于BERT压缩，我们的方法利用只有一个损失函数和一个超参数，释放从高参数整定人的努力。我们的方法比现有的知识蒸馏方法胶水标杆，展示模型压缩的一个新的视角。</font>
</div>


<hr>
<div id="paper3"> <b>3. Neural Machine Translation System of Indic Languages -- An Attention  based Approach</b>  <a href="https://arxiv.org/pdf/2002.02758" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shah%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Parth Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bakrola%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vishvajit Bakrola</a><br>
<font size="3">
Abstract: Neural machine translation (NMT) is a recent and effective technique which led to remarkable improvements in comparison of conventional machine translation techniques. Proposed neural machine translation model developed for the Gujarati language contains encoder-decoder with attention mechanism. In India, almost all the languages are originated from their ancestral language Sanskrit. They are having inevitable similarities including lexical and named entity similarity. Translating into Indic languages is always be a challenging task. In this paper, we have presented the neural machine translation system (NMT) that can efficiently translate Indic languages like Hindi and Gujarati that together covers more than 58.49 percentage of total speakers in the country. We have compared the performance of our NMT model with automatic evaluation matrices such as BLEU, perplexity and TER matrix. The comparison of our network with Google translate is also presented where it outperformed with a margin of 6 BLEU score on English-Gujarati translation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：神经机器翻译（NMT）是最近的和有效的技术，其导致显着改善在常规机器翻译技术相比。在古吉拉特语语言开发的建议神经机器翻译模型包含编码器，解码器，注意机制。在印度，几乎所有的语言都源于他们祖先的语言梵语。他们有着必然的相似，包括词汇和命名实体的相似性。翻译成印度语始终是一项艰巨的任务。在本文中，我们提出了神经机器翻译系统（NMT），可以有效地翻译印度语像印地文和古吉拉特一起覆盖全国总扬声器超过58.49百分比。我们比较我们与自动评估NMT模型的性能矩阵如BLEU，困惑和TER矩阵。还提出了我们与谷歌翻译网络的比较在那里与6 BLEU得分上英语翻译古吉拉特语保证金跑赢。</font>
</div>


<hr>
<div id="paper4"> <b>4. On-Device Information Extraction from SMS using Hybrid Hierarchical  Classification</b>  <a href="https://arxiv.org/pdf/2002.02755" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Vatsal%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shubham Vatsal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Purre%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Naresh Purre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D+P" target="_blank" rel="noopener" style="color:#0000EE;">Debi Prasanna Mohanty</a><br>
<font size="3">
Abstract: Cluttering of SMS inbox is one of the serious problems that users today face in the digital world where every online login, transaction, along with promotions generate multiple SMS. This problem not only prevents users from searching and navigating messages efficiently but often results in users missing out the relevant information associated with the corresponding SMS like offer codes, payment reminders etc. In this paper, we propose a unique architecture to organize and extract the appropriate information from SMS and further display it in an intuitive template. In the proposed architecture, we use a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural Network (CNN) to categorize SMS into multiple classes followed by a set of entity parsers used to extract the relevant information from the classified message. The architecture using its preprocessing techniques not only takes into account the enormous variations observed in SMS data but also makes it efficient for its on-device (mobile phone) functionalities in terms of inference timing and size. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：短信收件箱的杂波环境下是严重的问题之一是用户面对今天的数字世界里，所有的在线登录，交易，以得到提拔生成多个短信。这个问题不仅防止用户搜索和浏览效率消息，但通常会导致用户错过了与像优惠代码相应的SMS相关联的相关信息，催款等。在本文中，我们提出了一个独特的体系结构来组织和提取相应的以直观的模板从SMS，并进一步显示它的信息。在所提出的架构中，我们使用了基于分层长短期记忆（LSTM）-Convolutional神经网络（CNN）归类短信到多个类，然后一组用于提取分类信息相关的信息实体解析器。使用它的预处理技术的架构不仅考虑到了SMS数据中观察到的巨大的变化，但也使得有效用于推理定时和尺寸方面及其对设备（移动电话）的功能。</font>
</div>


<hr>
<div id="paper5"> <b>5. Incorporating Visual Semantics into Sentence Representations within a  Grounded Space</b>  <a href="https://arxiv.org/pdf/2002.02734" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bordes%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Patrick Bordes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zablocki%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eloi Zablocki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soulier%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Laure Soulier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Piwowarski%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benjamin Piwowarski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gallinari%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Patrick Gallinari</a><br>
<font size="3">
Abstract: Language grounding is an active field aiming at enriching textual representations with visual information. Generally, textual and visual elements are embedded in the same representation space, which implicitly assumes a one-to-one correspondence between modalities. This hypothesis does not hold when representing words, and becomes problematic when used to learn sentence representations --- the focus of this paper --- as a visual scene can be described by a wide variety of sentences. To overcome this limitation, we propose to transfer visual information to textual representations by learning an intermediate representation space: the grounded space. We further propose two new complementary objectives ensuring that (1) sentences associated with the same visual content are close in the grounded space and (2) similarities between related elements are preserved across modalities. We show that this model outperforms the previous state-of-the-art on classification and semantic relatedness tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言接地是一个活跃的领域，旨在丰富文本表示视觉信息。一般地，文本和视觉元素嵌入在相同的表示空间，这隐含地假设模态之间的一对一的对应关系。代表句话的时候这个假设不成立，并且在使用时要学会一句表述---本文的重点---作为一个视觉场景可以通过各种各样的句子来描述成为问题。为了克服这种局限性，我们提出通过学习中间表示空间的视觉信息传递到文本表示：接地的空间。我们进一步提出了两种新补充的目标，确保用相同的视觉内容相关：（1）句子接近接地的空间和（2）的相关要素之间的相似跨形式保留。我们表明，这种模型优于以前的分类和语义相关任务的国家的最先进的。</font>
</div>


<hr>
<div id="paper6"> <b>6. Multimodal Matching Transformer for Live Commenting</b>  <a href="https://arxiv.org/pdf/2002.02649" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chaoqun Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cui%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lei Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shuming Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Furu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Conghui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tiejun Zhao</a><br>
<font size="3">
Abstract: Automatic live commenting aims to provide real-time comments on videos for viewers. It encourages users engagement on online video sites, and is also a good benchmark for video-to-text generation. Recent work on this task adopts encoder-decoder models to generate comments. However, these methods do not model the interaction between videos and comments explicitly, so they tend to generate popular comments that are often irrelevant to the videos. In this work, we aim to improve the relevance between live comments and videos by modeling the cross-modal interactions among different modalities. To this end, we propose a multimodal matching transformer to capture the relationships among comments, vision, and audio. The proposed model is based on the transformer framework and can iteratively learn the attention-aware representations for each modality. We evaluate the model on a publicly available live commenting dataset. Experiments show that the multimodal matching transformer model outperforms the state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：自动活评论旨在对影片为观众提供实时评论。它鼓励对在线视频网站的用户参与，并且也是视频到文本生成一个很好的标杆。此任务最近的工作，采用编码器，解码器模型来生成评论。然而，这些方法没有视频和评论之间的相互作用明确建模，因此他们往往会产生流行的评论说，往往无关的视频。在这项工作中，我们的目标是通过模拟不同方式之间的跨模态的相互作用，以提高现场评论和视频之间的相关性。为此，我们提出了一种多模式匹配变压器捕捉到的意见，视觉和音频之间的关系。该模型是基于变压器的框架，并可以反复学习注意力感知表示每个模式。我们评估在公开的现场评论数据集模型。实验表明，该多模态匹配变压器模型优于国家的最先进的方法。</font>
</div>


<hr>
<div id="paper7"> <b>7. Translating Web Search Queries into Natural Language Questions</b>  <a href="https://arxiv.org/pdf/2002.02631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adarsh Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dandapat%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sandipan Dandapat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chordia%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sushil Chordia</a><br>
<font size="3">
Abstract: Users often query a search engine with a specific question in mind and often these queries are keywords or sub-sentential fragments. For example, if the users want to know the answer for "What's the capital of USA", they will most probably query "capital of USA" or "USA capital" or some keyword-based variation of this. For example, for the user entered query "capital of USA", the most probable question intent is "What's the capital of USA?". In this paper, we are proposing a method to generate well-formed natural language question from a given keyword-based query, which has the same question intent as the query. Conversion of keyword-based web query into a well-formed question has lots of applications, with some of them being in search engines, Community Question Answering (CQA) website and bots communication. We found a synergy between query-to-question problem with standard machine translation(MT) task. We have used both Statistical MT (SMT) and Neural MT (NMT) models to generate the questions from the query. We have observed that MT models perform well in terms of both automatic and human evaluation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：用户经常查询与具体问题的搜索引擎在心中，往往这些查询的关键字或子句子片段。例如，如果用户想知道的答案“什么是美国的首都”，他们将最有可能的查询“美国资本”或“美国资本”或一些这方面的基于关键字的变化。例如，用户输入查询“美国资本”，最有可能的问题，目的是“什么是美国的首都呢？”。在本文中，我们提议从给定的基于关键字的查询，其中有意向的询问同样的问题，良好的自然语言问题的方法。基于关键字的网页查询转换成一个结构良好的问题有很多的应用，在搜索引擎中的一些人是社区问答（CQA）的网站和漫游通信。我们发现查询到问题的问题，标准的机器翻译（MT）的任务之间的协同作用。我们都用了统计MT（SMT）和神经MT（NMT）模型来生成从查询的问题。我们观察到，MT车型在自动和人工评估方面表现良好。</font>
</div>


<hr>
<div id="paper8"> <b>8. Introducing Aspects of Creativity in Automatic Poetry Generation</b>  <a href="https://arxiv.org/pdf/2002.02511" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bena%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Brendan Bena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kalita%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jugal Kalita</a><br>
<font size="3">
Abstract: Poetry Generation involves teaching systems to automatically generate text that resembles poetic work. A deep learning system can learn to generate poetry on its own by training on a corpus of poems and modeling the particular style of language. In this paper, we propose taking an approach that fine-tunes GPT-2, a pre-trained language model, to our downstream task of poetry generation. We extend prior work on poetry generation by introducing creative elements. Specifically, we generate poems that express emotion and elicit the same in readers, and poems that use the language of dreams---called dream poetry. We are able to produce poems that correctly elicit the emotions of sadness and joy 87.5 and 85 percent, respectively, of the time. We produce dreamlike poetry by training on a corpus of texts that describe dreams. Poems from this model are shown to capture elements of dream poetry with scores of no less than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for all our poems. We also make use of the Coh-Metrix tool, outlining metrics we use to gauge the quality of text generated. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：诗歌生成涉及教学系统自动生成的文本类似于诗的工作。深学习系统可以学习在诗的语料库培训和建模语言的特殊风格产生对自己的诗歌。在本文中，我们建议采取的做法，微调GPT-2，预先训练的语言模型，我们的诗歌产生的下游任务。我们通过引入创意元素延长诗代前期工作。具体而言，我们产生表达情感和引发相同的读者，用梦想的语言---所谓的梦想诗诗和诗歌。我们能够产生诗歌分别是正确引起的时间悲伤和喜悦87.5％和85％，的情绪。我们通过描述梦想文本语料库培训产生梦幻般的诗意。从这个模型诗被示出为与在李克特量表的不小于3.2的分数梦想诗歌捕获元件。我们进行众包的人评价为我们所有的诗。我们还利用COH-Metrix的工具，概述我们用衡量生成的文本的质量指标。</font>
</div>


<hr>
<div id="paper9"> <b>9. Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker</b>  <a href="https://arxiv.org/pdf/2002.02450" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gulyaev%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pavel Gulyaev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Elistratova%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eugenia Elistratova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Konovalov%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vasily Konovalov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kuratov%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuri Kuratov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pugachev%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Leonid Pugachev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Burtsev%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mikhail Burtsev</a><br>
<font size="3">
Abstract: Dialogue State Tracking (DST) is a core component of virtual assistants such as Alexa or Siri. To accomplish various tasks, these assistants need to support an increasing number of services and APIs. The Schema-Guided State Tracking track of the 8th Dialogue System Technology Challenge highlighted the DST problem for unseen services. The organizers introduced the Schema-Guided Dialogue (SGD) dataset with multi-domain conversations and released a zero-shot dialogue state tracking model. In this work, we propose a GOaL-Oriented Multi-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures for reading comprehension question answering systems. The model "queries" dialogue history with descriptions of slots and services as well as possible values of slots. This allows to transfer slot values in multi-domain dialogues and have a capability to scale to unseen slot types. Our model achieves a joint goal accuracy of 53.97% on the SGD dataset, outperforming the baseline model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话状态跟踪（DST）是虚拟助理如Alexa或锡里的核心部件。要完成各种任务，这些助手需要支持服务和API的越来越多。第八对话系统技术挑战赛的模式制导状态跟踪轨迹突出了DST问题的看不见的服务。主办方引入了多领域的对话架构制导对话（SGD）数据集，并发布了零射门的对话状态跟踪模型。在这项工作中，我们建议架构的启发基于BERT面向目标的多任务对话状态追踪器（哥伦布）阅读理解问答系统。该模型“查询”对话的历史与插槽的说明和服务，以及插槽的可能值。这允许在多域的对话能力转移槽值并具有刻度以看不见的插槽类型。我们的模型实现了对SGD数据集的53.97％的合资目标的准确性，跑赢基准模型。</font>
</div>


<hr>
<div id="paper10"> <b>10. I love your chain mail! Making knights smile in a fantasy game world:  Open-domain goal-orientated dialogue agents</b>  <a href="https://arxiv.org/pdf/2002.02878" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Prabhumoye%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shrimai Prabhumoye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Margaret Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Urbanek%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jack Urbanek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dinan%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emily Dinan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kiela%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Douwe Kiela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weston%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jason Weston</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Szlam%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Arthur Szlam</a><br>
<font size="3">
Abstract: Dialogue research tends to distinguish between chit-chat and goal-oriented tasks. While the former is arguably more naturalistic and has a wider use of language, the latter has clearer metrics and a straightforward learning signal. Humans effortlessly combine the two, for example engaging in chit-chat with the goal of exchanging information or eliciting a specific response. Here, we bridge the divide between these two domains in the setting of a rich multi-player text-based fantasy environment where agents and humans engage in both actions and dialogue. Specifically, we train a goal-oriented model with reinforcement learning against an imitation-learned ``chit-chat'' model with two approaches: the policy either learns to pick a topic or learns to pick an utterance given the top-K utterances from the chit-chat model. We show that both models outperform an inverse model baseline and can converse naturally with their dialogue partner in order to achieve goals. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话研究倾向于闲聊和面向目标的任务区分。前者无疑是更自然，并具有广泛应用的语言，后者有更清晰的指标和一个简单的学习用信号。人类毫不费力地将二者结合起来，例如在闲聊从事与交换信息或引发特异性反应的目标。在这里，我们弥补了丰富的基于文本的多玩家幻想环境的设置这两个领域，其中代理和人类从事这两个动作和对话之间的鸿沟。具体来说，我们训练与强化学习面向目标的模型对模仿学习的``闲聊'模型方法有两种：政策要么学会选择一个主题或学会挑给从顶部-K话语的话语在闲聊模型。我们发现，这两种模式超越逆模型基线和为了达到目标，可以与他们的对话伙伴自然交谈。</font>
</div>


<hr>
<div id="paper11"> <b>11. Unsupervised pretraining transfers well across languages</b>  <a href="https://arxiv.org/pdf/2002.02848" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Rivi%C3%A8re%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Morgane Rivière</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Joulin%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Armand Joulin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mazar%C3%A9%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre-Emmanuel Mazaré</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Dupoux%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emmanuel Dupoux</a><br>
<font size="3">
Abstract: Cross-lingual and multi-lingual training of Automatic Speech Recognition (ASR) has been extensively investigated in the supervised setting. This assumes the existence of a parallel corpus of speech and orthographic transcriptions. Recently, contrastive predictive coding (CPC) algorithms have been proposed to pretrain ASR systems with unlabelled data. In this work, we investigate whether unsupervised pretraining transfers well across languages. We show that a slight modification of the CPC pretraining extracts features that transfer well to other languages, being on par or even outperforming supervised pretraining. This shows the potential of unsupervised methods for languages with few linguistic resources. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：跨语言和自动语音识别（ASR）的多语种培训的监督设置了广泛的研究。这是假设的语音和正字改编的平行语料库的存在。近日，对比预测编码（CPC）算法被提出来与未标记的数据pretrain ASR系统。在这项工作中，我们调查是否无监督的训练前转移以及跨语言。我们表明，训练前中共提取物的稍微修改的特点是传输以及其他语言，是媲美甚至超越监督训练前。这显示了与一些语言资源语言的无监督方法的潜力。</font>
</div>


<hr>
<div id="paper12"> <b>12. Depressed individuals express more distorted thinking on social media</b>  <a href="https://arxiv.org/pdf/2002.02800" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bathina%2C+K+C" target="_blank" rel="noopener" style="color:#0000EE;">Krishna C. Bathina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Thij%2C+M+t" target="_blank" rel="noopener" style="color:#0000EE;">Marijn ten Thij</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lorenzo-Luaces%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lorenzo Lorenzo-Luaces</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rutter%2C+L+A" target="_blank" rel="noopener" style="color:#0000EE;">Lauren A. Rutter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bollen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Johan Bollen</a><br>
<font size="3">
Abstract: Depression is a leading cause of disability worldwide, but is often under-diagnosed and under-treated. One of the tenets of cognitive-behavioral therapy (CBT) is that individuals who are depressed exhibit distorted modes of thinking, so-called cognitive distortions, which can negatively affect their emotions and motivation. Here, we show that individuals with a self-reported diagnosis of depression on social media express higher levels of distorted thinking than a random sample. Some types of distorted thinking were found to be more than twice as prevalent in our depressed cohort, in particular Personalizing and Emotional Reasoning. This effect is specific to the distorted content of the expression and can not be explained by the presence of specific topics, sentiment, or first-person pronouns. Our results point towards the detection, and possibly mitigation, of patterns of online language that are generally deemed depressogenic. They may also provide insight into recent observations that social media usage can have a negative impact on mental health. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：抑郁症是全世界残疾的主要原因，但往往没有得到诊断和治疗不足。一个认知行为疗法（CBT）的原则之一是，谁是抑郁个体表现出扭曲的思维方式，所谓的认知扭曲，可自己的情绪和动机产生负面影响。在这里，我们表明，抑郁对社交媒体的自我报告诊断的个体表达较高水平的扭曲的思维不是随机抽样的。发现某些类型的扭曲的思维方式是在我们的沮丧人群普遍两倍以上，尤其是个性化和情感推理。这种效果是特定于表达的失真内容，并且不能由特定的主题，情绪，或第一人称代词的存在来解释。我们的研究结果指向了检测，并可能减缓，那一般都认为depressogenic在线语言模式。他们还可以提供洞察到最近的观察，社交媒体的使用会对心理健康产生负面影响。</font>
</div>


<hr>
<div id="paper13"> <b>13. LEAP System for SRE19 Challenge -- Improvements and Error Analysis</b>  <a href="https://arxiv.org/pdf/2002.02735" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Ramoji%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shreyas Ramoji</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Krishnan%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prashant Krishnan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mysore%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bhargavram Mysore</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Singh%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prachi Singh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Ganapathy%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sriram Ganapathy</a><br>
<font size="3">
Abstract: The NIST Speaker Recognition Evaluation - Conversational Telephone Speech (CTS) challenge 2019 was an open evaluation for the task of speaker verification in challenging conditions. In this paper, we provide a detailed account of the LEAP SRE system submitted to the CTS challenge focusing on the novel components in the back-end system modeling. All the systems used the time-delay neural network (TDNN) based x-vector embeddings. The x-vector system in our SRE19 submission used a large pool of training speakers (about 14k speakers). Following the x-vector extraction, we explored a neural network approach to backend score computation that was optimized for a speaker verification cost. The system combination of generative and neural PLDA models resulted in significant improvements for the SRE evaluation dataset. We also found additional gains for the SRE systems based on score normalization and calibration. Subsequent to the evaluations, we have performed a detailed analysis of the submitted systems. The analysis revealed the incremental gains obtained for different training dataset combinations as well as the modeling methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：NIST说话人识别评估 - 会话电话语音（CTS）挑战2019是为在艰难条件下的说话人确认的任务一个开放的评价。在本文中，我们提供了一个详细的帐户提交CTS挑战着眼于后端系统建模的新组件的LEAP SRE系统。所有的系统中使用的时间延迟神经网络（TDNN）基于X的矢量的嵌入。在我们SRE19提交的X-载体系统使用的培训扬声器（约14K扬声器）的大型游泳池。继X向量提取，我们探讨了神经网络的方法来后端分数计算这是该扬声器核查成本优化。生成和神经PLDA模型的系统组合导致的SRE评估数据集显著的改善。我们还发现基于分数标准化和校准SRE系统的额外收益。继评估，我们已经完成了提交系统的详细分析。分析揭示了不同的训练数据集组合以及建模方法获得的增量收益。</font>
</div>


<hr>
<div id="paper14"> <b>14. Transformer Transducer: A Streamable Speech Recognition Model with  Transformer Encoders and RNN-T Loss</b>  <a href="https://arxiv.org/pdf/2002.02562" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qian Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Lu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Sak%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hasim Sak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Tripathi%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anshuman Tripathi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=McDermott%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Erik McDermott</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Koo%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stephen Koo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shankar Kumar</a><br>
<font size="3">
Abstract: In this paper we present an end-to-end speech recognition model with Transformer encoders that can be used in a streaming speech recognition system. Transformer computation blocks based on self-attention are used to encode both audio and label sequences independently. The activations from both audio and label encoders are combined with a feed-forward layer to compute a probability distribution over the label space for every combination of acoustic frame position and label history. This is similar to the Recurrent Neural Network Transducer (RNN-T) model, which uses RNNs for information encoding instead of Transformer encoders. The model is trained with a monotonic RNN-T loss well-suited to frame-synchronous, streaming decoding. We present results on the LibriSpeech dataset showing that limiting the left context for self-attention in the Transformer layers makes decoding computationally tractable for streaming, with only a slight degradation in accuracy. We also show that the full attention version of our model achieves competitive performance compared to existing LibriSpeech benchmarks for attention-based models trained with cross-entropy loss. Our results also show that we can bridge the gap between full attention and limited attention versions of our model by attending to a limited number of future frames. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了具有可在流式语音识别系统中使用的变压器编码器的终端到终端的语音识别模型。基于自我关注变压器计算块用于独立编码音频和标签序列。从音频和标签编码器的激活相结合，与前馈层，以计算在所述标签空间上的概率分布的声学帧位置和标签历史的每个组合。这是类似于回归神经网络传感器（RNN-T）模型，它使用RNNs用于编码代替变压器的编码器的信息。该模型被训练以单调RNN-T损耗非常适用于帧同步，流解码。我们上显示，限制自我关注的左上下文变压器层使得解码流媒体，只有在准确度稍有下降，易于计算的LibriSpeech数据集目前的结果。我们还表明，相对于现有的LibriSpeech基准注意力基础的模式与交叉熵损失训练的我们的模型的充分重视版本实现了有竞争力的表现。我们的研究结果还表明我们可以通过参加未来的帧数量有限弥合充分重视和关注有限的版本我们的模型之间的差距。</font>
</div>


<hr>
<div id="paper15"> <b>15. Robust Multi-channel Speech Recognition using Frequency Aligned Network</b>  <a href="https://arxiv.org/pdf/2002.02520" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Park%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taejin Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumatani%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kenichi Kumatani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minhua Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sundaram%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shiva Sundaram</a><br>
<font size="3">
Abstract: Conventional speech enhancement technique such as beamforming has known benefits for far-field speech recognition. Our own work in frequency-domain multi-channel acoustic modeling has shown additional improvements by training a spatial filtering layer jointly within an acoustic model. In this paper, we further develop this idea and use frequency aligned network for robust multi-channel automatic speech recognition (ASR). Unlike an affine layer in the frequency domain, the proposed frequency aligned component prevents one frequency bin influencing other frequency bins. We show that this modification not only reduces the number of parameters in the model but also significantly and improves the ASR performance. We investigate effects of frequency aligned network through ASR experiments on the real-world far-field data where users are interacting with an ASR system in uncontrolled acoustic environments. We show that our multi-channel acoustic model with a frequency aligned network shows up to 18% relative reduction in word error rate. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：传统的语音增强技术，如波束赋形已经知道好处远场语音识别。我们自己的在频域多通道声学建模工作已经由声学模型内共同培养了空间滤波层示出的额外的改进。在本文中，我们进一步发展为强大的多通道自动语音识别（ASR）这个想法，并使用频率对准网络。不像在频域中的仿射层，所提出的频率对准部件防止一个频率窗口影响其它频率仓。我们表明，这种修改不仅显著减少了参数的数量模型，而且，提高了ASR性能。我们调查通过ASR实验上，用户与失控的声学环境ASR系统交互的真实世界的远场数据的频率对准网络的影响。我们表明，在字差错率我们与频率对准网络显示多通道声学模型高达18％的相对减少。</font>
</div>


<hr>
<div id="paper16"> <b>16. Consistency of a Recurrent Language Model With Respect to Incomplete  Decoding</b>  <a href="https://arxiv.org/pdf/2002.02492" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Welleck%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sean Welleck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kulikov%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Ilia Kulikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jaedeok Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pang%2C+R+Y" target="_blank" rel="noopener" style="color:#0000EE;">Richard Yuanzhe Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cho%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kyunghyun Cho</a><br>
<font size="3">
Abstract: Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms - greedy search, beam search, top-k sampling, and nucleus sampling - are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：尽管在各种任务的强大的性能，具有最大似然训练的神经序列模型已显示表现出的问题，如长度偏差和退化重复。我们研究使用常见的解码算法时，从经常性的语言模型接收无限长序列的相关问题。为了分析这个问题，我们首先定义的解码算法的不一致，这意味着该算法可以产生一个具有模型下零概率无限长度的序列。我们证明了常用的不完整的解码算法 - 贪婪搜索，波束搜索，前k个采样，和细胞核采样 - 不一致，尽管事实上，经常性的语言模型被训练来有限长度的生产序列。根据这些分析，我们提出了两种补救措施，地址不一致：前k和核取样，并自终止复发语言模型的一致变种。实证结果表明，发生矛盾的做法，而且所提出的方法防止不一致。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>综述类论文</title>
    <url>/2020/02/08/%E7%BB%BC%E8%BF%B0%E7%B1%BB%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="综述类论文"><a href="#综述类论文" class="headerlink" title="综述类论文"></a>综述类论文</h1><h2 id="领域自适应翻译"><a href="#领域自适应翻译" class="headerlink" title="领域自适应翻译"></a>领域自适应翻译</h2><ul>
<li>A Survey of Domain Adaptation for Neural Machine Translation. Chenhui Chu, Rui Wang. COLING 2018. <a href="https://arxiv.org/pdf/1806.00258" target="_blank" rel="noopener">[PDF]</a></li>
</ul><h2 id="篇章翻译"><a href="#篇章翻译" class="headerlink" title="篇章翻译"></a>篇章翻译</h2><ul>
<li>A Survey on Document-level Machine Translation: Methods and Evaluation. Sameen Maruf, Fahimeh Saleh, Gholamreza Haffari. arXiv 1912. <a href="https://arxiv.org/pdf/1912.08494" target="_blank" rel="noopener">[PDF]</a></li>
</ul><a id="more"></a>

<h2 id="多语言翻译"><a href="#多语言翻译" class="headerlink" title="多语言翻译"></a>多语言翻译</h2><ul>
<li>A Comprehensive Survey of Multilingual Neural Machine Translation. Raj Dabre, Chenhui Chu, Anoop Kunchukuttan. arXiv 2001. <a href="https://arxiv.org/pdf/2001.01115" target="_blank" rel="noopener">[PDF]</a></li>
</ul>
]]></content>
      <categories>
        <category>论文列表</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-07</title>
    <url>/2020/02/07/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-07/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Irony Detection in a Multilingual Context <a href="https://arxiv.org/pdf/2002.02427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Conversational Structure Aware and Context Sensitive Topic Model for  Online Discussions <a href="https://arxiv.org/pdf/2002.02353" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Citation Data of Czech Apex Courts <a href="https://arxiv.org/pdf/2002.02224" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Related Tasks can Share! A Multi-task Framework for Affective language <a href="https://arxiv.org/pdf/2002.02154" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> A Neural Topical Expansion Framework for Unstructured Persona-oriented  Dialogue Generation <a href="https://arxiv.org/pdf/2002.02153" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Multilingual acoustic word embedding models for processing zero-resource  languages <a href="https://arxiv.org/pdf/2002.02109" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Attractive or Faithful? Popularity-Reinforced Learning for Inspired  Headline Generation <a href="https://arxiv.org/pdf/2002.02095" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Aligning the Pretraining and Finetuning Objectives of Language Models <a href="https://arxiv.org/pdf/2002.02000" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> UNCC Biomedical Semantic Question Answering Systems. BioASQ: Task-7B,  Phase-B <a href="https://arxiv.org/pdf/2002.01984" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Zero-Shot Activity Recognition with Videos <a href="https://arxiv.org/pdf/2002.02265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Understanding Car-Speak: Replacing Humans in Dealerships <a href="https://arxiv.org/pdf/2002.02070" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Stimulating Creativity with FunLines: A Case Study of Humor Generation  in Headlines <a href="https://arxiv.org/pdf/2002.02031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Irony Detection in a Multilingual Context</b>  <a href="https://arxiv.org/pdf/2002.02427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ghanem%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bilal Ghanem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Karoui%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jihen Karoui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Benamara%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Farah Benamara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rosso%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Paolo Rosso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moriceau%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Véronique Moriceau</a><br>
<font size="3">
Abstract: This paper proposes the first multilingual (French, English and Arabic) and multicultural (Indo-European languages vs. less culturally close languages) irony detection system. We employ both feature-based models and neural architectures using monolingual word representation. We compare the performance of these systems with state-of-the-art systems to identify their capabilities. We show that these monolingual models trained separately on different languages using multilingual word representation or text-based features can open the door to irony detection in languages that lack of annotated data for irony. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一个多语种（法语，英语和阿拉伯语）和多元文化（印欧语言与文化少接近语言）具有讽刺意味的检测系统。我们采用使用单语单词表示既基于特征的模型和神经结构。我们比较这些系统与国家的最先进的系统的性能，以确定自己的能力。我们发现，这些单语车型上使用多语言的单词表示或基于文本的功能，可以打开在缺乏讽刺注释数据的语言门讽刺检测不同的语言单独训练。</font>
</div>


<hr>
<div id="paper2"> <b>2. Conversational Structure Aware and Context Sensitive Topic Model for  Online Discussions</b>  <a href="https://arxiv.org/pdf/2002.02353" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yingcheng Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Loparo%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kenneth Loparo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kolacinski%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Richard Kolacinski</a><br>
<font size="3">
Abstract: Millions of online discussions are generated everyday on social media platforms. Topic modelling is an efficient way of better understanding large text datasets at scale. Conventional topic models have had limited success in online discussions, and to overcome their limitations, we use the discussion thread tree structure and propose a "popularity" metric to quantify the number of replies to a comment to extend the frequency of word occurrences, and the "transitivity" concept to characterize topic dependency among nodes in a nested discussion thread. We build a Conversational Structure Aware Topic Model (CSATM) based on popularity and transitivity to infer topics and their assignments to comments. Experiments on real forum datasets are used to demonstrate improved performance for topic extraction with six different measurements of coherence and impressive accuracy for topic assignments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：数以百万计的在线讨论的是在社会化媒体平台上产生的每一天。主题造型是在规模更好地理解大数据集文字的有效方式。传统主题模型曾在网上讨论有限的成功，并克服其局限性，我们用话题树形结构，并提出了“人气”指标，以回复的数量量化为一个注释，延长词出现的频率，和“及物”的概念来描述话题依赖嵌套话题节点之间。我们建立一个基于普及和传递来推断主题和他们的任务，以评论的会话结构感知主题模型（CSATM）。真实数据集论坛的实验来证明与连贯性和令人印象深刻的精度为主题分配六种不同的测量话题提取改进性能。</font>
</div>


<hr>
<div id="paper3"> <b>3. Citation Data of Czech Apex Courts</b>  <a href="https://arxiv.org/pdf/2002.02224" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hara%C5%A1ta%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jakub Harašta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Novotn%C3%A1%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tereza Novotná</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=%C5%A0avelka%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jaromír Šavelka</a><br>
<font size="3">
Abstract: In this paper, we introduce the citation data of the Czech apex courts (Supreme Court, Supreme Administrative Court and Constitutional Court). This dataset was automatically extracted from the corpus of texts of Czech court decisions - CzCDC 1.0. We obtained the citation data by building the natural language processing pipeline for extraction of the court decision identifiers. The pipeline included the (i) document segmentation model and the (ii) reference recognition model. Furthermore, the dataset was manually processed to achieve high-quality citation data as a base for subsequent qualitative and quantitative analyses. The dataset will be made available to the general public. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们介绍了捷克顶点法院的引用数据（最高法院，最高行政法院和宪法法院）。 CzCDC 1.0  - 这个数据集自动从捷克法院判决文本的语料库中提取。我们通过建立自然语言处理管道的法院判决标识符萃取得到的引文数据。该管道包括第（i）文件分割模型和（ⅱ）参考识别模型。此外，该数据集被人工处理，以实现高品质的引用数据作为后续定性和定量分析的位置。该数据集将提供给广大市民。</font>
</div>


<hr>
<div id="paper4"> <b>4. Related Tasks can Share! A Multi-task Framework for Affective language</b>  <a href="https://arxiv.org/pdf/2002.02154" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Deep%2C+K+S" target="_blank" rel="noopener" style="color:#0000EE;">Kumar Shikhar Deep</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Akhtar%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Md Shad Akhtar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ekbal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Asif Ekbal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bhattacharyya%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pushpak Bhattacharyya</a><br>
<font size="3">
Abstract: Expressing the polarity of sentiment as 'positive' and 'negative' usually have limited scope compared with the intensity/degree of polarity. These two tasks (i.e. sentiment classification and sentiment intensity prediction) are closely related and may offer assistance to each other during the learning process. In this paper, we propose to leverage the relatedness of multiple tasks in a multi-task learning framework. Our multi-task model is based on convolutional-Gated Recurrent Unit (GRU) framework, which is further assisted by a diverse hand-crafted feature set. Evaluation and analysis suggest that joint-learning of the related tasks in a multi-task framework can outperform each of the individual tasks in the single-task frameworks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：表达情绪的极性为“正”和“负”通常与强度/程度的极性相比具有有限的范围。这两个任务（即情感分类和情感强度预测）紧密相关，并在学习过程中可以互相提供协助。在本文中，我们提出了利用多任务的关联性在多任务学习框架。我们的多任务模式是基于卷积门控重复单元（GRU）的框架，这是一个多元化的手工制作的功能集进一步协助。评估和分析表明，联合学习在多任务框架的相关任务可以在单任务框架超越每个单独的任务。</font>
</div>


<hr>
<div id="paper5"> <b>5. A Neural Topical Expansion Framework for Unstructured Persona-oriented  Dialogue Generation</b>  <a href="https://arxiv.org/pdf/2002.02153" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minghong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piji Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haoran Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ren%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pengjie Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ren%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhaochun Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhumin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Ma</a><br>
<font size="3">
Abstract: Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated effective in generating persona consistent responses by utilizing predefined natural language user persona descriptions (e.g., "I am a vegan"). However, the predefined user persona descriptions are usually short and limited to only a few descriptive words, which makes it hard to correlate them with the dialogues. As a result, existing methods either fail to use the persona description or use them improperly when generating persona consistent responses. To address this, we propose a neural topical expansion framework, namely Persona Exploration and Exploitation (PEE), which is able to extend the predefined user persona description with semantically correlated content before utilizing them to generate dialogue responses. PEE consists of two main modules: persona exploration and persona exploitation. The former learns to extend the predefined user persona description by mining and correlating with existing dialogue corpus using a variational auto-encoder (VAE) based topic model. The latter learns to generate persona consistent responses by utilizing the predefined and extended user persona description. In order to make persona exploitation learn to utilize user persona description more properly, we also introduce two persona-oriented loss functions: Persona-oriented Matching (P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which respectively supervise persona selection in encoder and decoder. Experimental results show that our approach outperforms state-of-the-art baselines, in terms of both automatic and human evaluations. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：非结构化假面为本对话系统（UPDS）已经通过利用预定义的自然语言用户个性描述（例如，“我是素食主义者”）证明有效生成人物一致响应。然而，预定义用户的人物角色描述通常是短且仅限于一些描述性词语，这使得它很难将它们与对话相关联。其结果是，现有方法要么不能使用的人物角色描述或生成人物一致响应时不正确地使用它们。为了解决这个问题，我们提出了一个神经局部扩展的框架，即假面勘探和开采（PEE），这是能够利用它们来生成对话响应之前延长与语义相关的内容的预定义的用户角色的描述。 PEE包括两个主要模块：人物的勘探和开采的人物。前者学习到挖掘扩展预定义的用户角色的描述和使用基于主题模型，变分自动编码器（VAE）与现有的对话语料库相关。后者学会生成通过利用预定义的和扩展的用户个性描述人物一致响应。为了使人物开采学会更合理的利用用户的人物角色描述，我们还推出两款面向角色损功能：假面为本匹配（P-匹配）的损失和人物角色的导向一袋字（P-弓）损失分别在监督编码器和解码器的人物的选择。实验结果表明，我们的方法优于国家的最先进的基线，在自动和人的评估方面。</font>
</div>


<hr>
<div id="paper6"> <b>6. Multilingual acoustic word embedding models for processing zero-resource  languages</b>  <a href="https://arxiv.org/pdf/2002.02109" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kamper%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Herman Kamper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Matusevych%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yevgen Matusevych</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goldwater%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sharon Goldwater</a><br>
<font size="3">
Abstract: Acoustic word embeddings are fixed-dimensional representations of variable-length speech segments. In settings where unlabelled speech is the only available resource, such embeddings can be used in "zero-resource" speech search, indexing and discovery systems. Here we propose to train a single supervised embedding model on labelled data from multiple well-resourced languages and then apply it to unseen zero-resource languages. For this transfer learning approach, we consider two multilingual recurrent neural network models: a discriminative classifier trained on the joint vocabularies of all training languages, and a correspondence autoencoder trained to reconstruct word pairs. We test these using a word discrimination task on six target zero-resource languages. When trained on seven well-resourced languages, both models perform similarly and outperform unsupervised models trained on the zero-resource languages. With just a single training language, the second model works better, but performance depends more on the particular training--testing language pair. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：声字的嵌入被固定维可变长度的语音段的表示。在设置里未标记的讲话是唯一可用的资源，这样的嵌入可在“零资源”的声音检索，索引和发现系统中使用。在这里，我们提出培养从多个资源充足的语言标记数据的单一监督嵌入模型，然后把它应用到看不见的零资源的语言。对于这种转移的学习方法，我们考虑两个多语种回归神经网络模型：辨别分类培训了所有训练语言的词汇联合，培养重建的单词对对应的自动编码。我们这些使用上的六个标靶零资源语言文字辨别任务测试。当七，资源丰富语言的训练，这两款车型同样执行和超越训练有素的零资源语言的无监督模型。只是一个单一的语言训练，第二个模型更好地工作，但性能更依赖于特定的训练 - 测试语言对。</font>
</div>


<hr>
<div id="paper7"> <b>7. Attractive or Faithful? Popularity-Reinforced Learning for Inspired  Headline Generation</b>  <a href="https://arxiv.org/pdf/2002.02095" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun-Zhu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shuai%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hong-Han Shuai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yeh%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sung-Lin Yeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yi-Lun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ku%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lun-Wei Ku</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Peng%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wen-Chih Peng</a><br>
<font size="3">
Abstract: With the rapid proliferation of online media sources and published news, headlines have become increasingly important for attracting readers to news articles, since users may be overwhelmed with the massive information. In this paper, we generate inspired headlines that preserve the nature of news articles and catch the eye of the reader simultaneously. The task of inspired headline generation can be viewed as a specific form of Headline Generation (HG) task, with the emphasis on creating an attractive headline from a given news article. To generate inspired headlines, we propose a novel framework called POpularity-Reinforced Learning for inspired Headline Generation (PORL-HG). PORL-HG exploits the extractive-abstractive architecture with 1) Popular Topic Attention (PTA) for guiding the extractor to select the attractive sentence from the article and 2) a popularity predictor for guiding the abstractor to rewrite the attractive sentence. Moreover, since the sentence selection of the extractor is not differentiable, techniques of reinforcement learning (RL) are utilized to bridge the gap with rewards obtained from a popularity score predictor. Through quantitative and qualitative experiments, we show that the proposed PORL-HG significantly outperforms the state-of-the-art headline generation models in terms of attractiveness evaluated by both human (71.03%) and the predictor (at least 27.60%), while the faithfulness of PORL-HG is also comparable to the state-of-the-art generation model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：随着网络媒体来源和公布的消息迅速扩散，标题已成为吸引读者的新闻文章越来越重要，因为用户可能会用大量的信息所淹没。在本文中，我们产生灵感的头条新闻保持新闻报道的本质，同时吸引读者的眼球。启发标题一代人的任务，可以被看作是头条代（HG）任务的具体形式，并把重点放在建立从给定的新闻文章的标题吸引人。为了产生灵感的头条新闻，我们提出了一个所谓的流行，增强学习的启发标题代（PORL-HG）的新框架。 PORL-HG利用与1）热门话题注意（PTA）萃取-抽象体系结构用于引导所述提取器从物品和2）的流行度预测器用于引导提取器重写吸引力句子中选择有吸引力的句子。此外，由于提取的例句选择是不可微的，（RL）强化学习的技术用于桥接与从普及的分数的预测获得奖励的间隙。通过定量和定性实验，我们表明，该PORL-HG显著优于国家的最先进的标题代车型由两个人（71.03％）和预测（至少27.60％）评估吸引力方面，而PORL-HG的信实也比得上状态的最先进的生成模型。</font>
</div>


<hr>
<div id="paper8"> <b>8. Aligning the Pretraining and Finetuning Objectives of Language Models</b>  <a href="https://arxiv.org/pdf/2002.02000" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Pierse%2C+N+W" target="_blank" rel="noopener" style="color:#0000EE;">Nuo Wang Pierse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingwen Lu</a><br>
<font size="3">
Abstract: We demonstrate that explicitly aligning the pretraining objectives to the finetuning objectives in language model training significantly improves the finetuning task performance and reduces the minimum amount of finetuning examples required. The performance margin gained from objective alignment allows us to build language models with smaller sizes for tasks with less available training data. We provide empirical evidence of these claims by applying objective alignment to concept-of-interest tagging and acronym detection tasks. We found that, with objective alignment, our 768 by 3 and 512 by 3 transformer language models can reach accuracy of 83.9%/82.5% for concept-of-interest tagging and 73.8%/70.2% for acronym detection using only 200 finetuning examples per task, outperforming the 768 by 3 model pretrained without objective alignment by +4.8%/+3.4% and +9.9%/+6.3%. We name finetuning small language models in the presence of hundreds of training examples or less "Few Example learning". In practice, Few Example Learning enabled by objective alignment not only saves human labeling costs, but also makes it possible to leverage language models in more real-time applications. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们证明，明确对准训练前的目标的目标细化和微调在语言模型训练显著提高了任务细化和微调性能和降低微调所需的例子的最低金额。从客观比对所获得的性能裕量使我们能够建立语言模型尺寸较小与较少的可用训练数据的任务。我们通过将目标对准概念的兴趣标记和缩写检测任务提供这些说法的经验证据。我们发现，与目标定位，我们768 3和512 3变压器的语言模型可以达到83.9％/ 82.5％，准确度概念的兴趣标签和73.8％/ 70.2％的首字母缩写，检测只用200元细化和微调的例子任务，表现优于768由3模型由4.8％/ + 3.4％和9.9％/ + 6.3％没有客观对准预训练。我们的名字在数百个训练范例以下“几个示例学习”的存在微调小语言模型。在实践中，能够通过客观对准几个示例学习不仅节约了人工标识的成本，而且还能够利用语言模型在多个实时应用。</font>
</div>


<hr>
<div id="paper9"> <b>9. UNCC Biomedical Semantic Question Answering Systems. BioASQ: Task-7B,  Phase-B</b>  <a href="https://arxiv.org/pdf/2002.01984" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Telukuntla%2C+S+K" target="_blank" rel="noopener" style="color:#0000EE;">Sai Krishna Telukuntla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kapri%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Aditya Kapri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zadrozny%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wlodek Zadrozny</a><br>
<font size="3">
Abstract: In this paper, we detail our submission to the 2019, 7th year, BioASQ competition. We present our approach for Task-7b, Phase B, Exact Answering Task. These Question Answering (QA) tasks include Factoid, Yes/No, List Type Question answering. Our system is based on a contextual word embedding model. We have used a Bidirectional Encoder Representations from Transformers(BERT) based system, fined tuned for biomedical question answering task using BioBERT. In the third test batch set, our system achieved the highest MRR score for Factoid Question Answering task. Also, for List type question answering task our system achieved the highest recall score in the fourth test batch set. Along with our detailed approach, we present the results for our submissions, and also highlight identified downsides for our current approach and ways to improve them in our future experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们详细介绍了提交给2019年，第7年，BioASQ竞争。我们提出我们的任务-7B的方法，B相，精确应答任务。这些问题回答（QA）任务包括FACTOID，是/否，列表类型答疑。我们的系统是基于上下文的单词嵌入模型。我们使用来自变形金刚双向编码表示（BERT）的系统，罚款调整为使用BioBERT生物医学问题回答任务。在第三个试验批次设置，我们的系统取得了最高MRR得分事实型询问应答任务。另外，对于列表类型问答任务我们的系统实现了在第四一批测试集最高得分召回。随着我们的详细的方法，我们目前的结果为我们的意见，并且还强调确定了我们目前的方法和途径，以提高他们在我们未来的实验缺点。</font>
</div>


<hr>
<div id="paper10"> <b>10. Zero-Shot Activity Recognition with Videos</b>  <a href="https://arxiv.org/pdf/2002.02265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ornek%2C+E+P" target="_blank" rel="noopener" style="color:#0000EE;">Evin Pinar Ornek</a><br>
<font size="3">
Abstract: In this paper, we examined the zero-shot activity recognition task with the usage of videos. We introduce an auto-encoder based model to construct a multimodal joint embedding space between the visual and textual manifolds. On the visual side, we used activity videos and a state-of-the-art 3D convolutional action recognition network to extract the features. On the textual side, we worked with GloVe word embeddings. The zero-shot recognition results are evaluated by top-n accuracy. Then, the manifold learning ability is measured by mean Nearest Neighbor Overlap. In the end, we provide an extensive discussion over the results and the future directions. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们研究了零次活动识别任务与视频的使用。我们引入了自动编码器基于模型的构建视觉和文本歧管之间的多模式联合嵌入空间。在可视侧，我们使用活动视频和一个国家的最先进的三维卷积动作识别网络来提取特征。在文字方面，我们曾与手套字的嵌入。零射门的识别结果被顶n准确评估。然后，歧管学习能力通过平均最近邻重叠测量。最后，我们提供对结果和未来的发展方向进行了广泛讨论。</font>
</div>


<hr>
<div id="paper11"> <b>11. Understanding Car-Speak: Replacing Humans in Dealerships</b>  <a href="https://arxiv.org/pdf/2002.02070" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hooshmand%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Habeeb Hooshmand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Caverlee%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">James Caverlee</a><br>
<font size="3">
Abstract: A large portion of the car-buying experience in the United States involves interactions at a car dealership. At the dealership, the car-buyer relays their needs to a sales representative. However, most car-buyers are only have an abstract description of the vehicle they need. Therefore, they are only able to describe their ideal car in "car-speak". Car-speak is abstract language that pertains to a car's physical attributes. In this paper, we define car-speak. We also aim to curate a reasonable data set of car-speak language. Finally, we train several classifiers in order to classify car-speak. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在美国的购车体验的很大一部分涉及在汽车经销店的互动。在经销店，汽车买方中继其销售代表的需求。然而，大多数汽车购买者只拥有他们所需要的车辆的抽象描述。因此，他们只能够描述自己理想中的车“汽车说话。”租车发言是抽象的语言，涉及到汽车的物理属性。在本文中，我们定义汽车发言。我们还致力于策划的车讲的语言合理的数据集。最后，我们培养几个分类，以分类车说话。</font>
</div>


<hr>
<div id="paper12"> <b>12. Stimulating Creativity with FunLines: A Case Study of Humor Generation  in Headlines</b>  <a href="https://arxiv.org/pdf/2002.02031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hossain%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nabil Hossain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Krumm%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">John Krumm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sajed%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tanvir Sajed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kautz%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Henry Kautz</a><br>
<font size="3">
Abstract: Building datasets of creative text, such as humor, is quite challenging. We introduce FunLines, a competitive game where players edit news headlines to make them funny, and where they rate the funniness of headlines edited by others. FunLines makes the humor generation process fun, interactive, collaborative, rewarding and educational, keeping players engaged and providing humor data at a very low cost compared to traditional crowdsourcing approaches. FunLines offers useful performance feedback, assisting players in getting better over time at generating and assessing humor, as our analysis shows. This helps to further increase the quality of the generated dataset. We show the effectiveness of this data by training humor classification models that outperform a previous benchmark, and we release this dataset to the public. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：创作文本的建筑数据集，如幽默，极具挑战性。我们介绍FunLines，有竞争力的游戏，玩家编辑新闻标题，使他们逗的，在那里他们率他人编辑头条funniness。 FunLines使得幽默生成过程的乐趣，互动，合作，奖励，教育，保持玩家参与，并与传统的众包接近以非常低的成本提供幽默的数据。 FunLines提供了有用的绩效反馈，帮助玩家在发电渐入佳境随着时间的推移和评估幽默，因为我们的分析显示。这有助于进一步提高所产生的数据集的质量。我们表明，该数据由超越以前的基准培训幽默分类模型的有效性，以及我们发布这个数据集给公众。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-07</title>
    <url>/2020/02/07/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-02-07/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Reliability Validation of Learning Enabled Vehicle Tracking <a href="https://arxiv.org/pdf/2002.02424" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Lane Boundary Geometry Extraction from Satellite Imagery <a href="https://arxiv.org/pdf/2002.02362" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> Random VLAD based Deep Hashing for Efficient Image Retrieval <a href="https://arxiv.org/pdf/2002.02333" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> Fine-Grained Urban Flow Inference <a href="https://arxiv.org/pdf/2002.02318" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Person Re-identification by Contour Sketch under Moderate Clothing  Change <a href="https://arxiv.org/pdf/2002.02295" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Zero-Shot Activity Recognition with Videos <a href="https://arxiv.org/pdf/2002.02265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Looking GLAMORous: Vehicle Re-Id in Heterogeneous Cameras Networks with  Global and Local Attention <a href="https://arxiv.org/pdf/2002.02256" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Unsupervised Bidirectional Cross-Modality Adaptation via Deeply  Synergistic Image and Feature Alignment for Medical Image Segmentation <a href="https://arxiv.org/pdf/2002.02255" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> RGB-based Semantic Segmentation Using Self-Supervised Depth Pre-Training <a href="https://arxiv.org/pdf/2002.02200" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Joint Deep Learning of Facial Expression Synthesis and Recognition <a href="https://arxiv.org/pdf/2002.02194" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Pose-Aware Instance Segmentation Framework from Cone Beam CT Images for  Tooth Segmentation <a href="https://arxiv.org/pdf/2002.02143" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> An Information-rich Sampling Technique over Spatio-Temporal CNN for  Classification of Human Actions in Videos <a href="https://arxiv.org/pdf/2002.02100" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Forensic Scanner Identification Using Machine Learning <a href="https://arxiv.org/pdf/2002.02079" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Driver Gaze Estimation in the Real World: Overcoming the Eyeglass  Challenge <a href="https://arxiv.org/pdf/2002.02077" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Residual-Recursion Autoencoder for Shape Illustration Images <a href="https://arxiv.org/pdf/2002.02063" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Rotation-invariant Mixed Graphical Model Network for 2D Hand Pose  Estimation <a href="https://arxiv.org/pdf/2002.02033" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> 3DPIFCM Segmentation Algorithm for brain MRI <a href="https://arxiv.org/pdf/2002.01985" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Parallel 3DPIFCM Algorithm for Noisy Brain MRI Images <a href="https://arxiv.org/pdf/2002.01981" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> StegColNet: Steganalysis based on an ensemble colorspace approach <a href="https://arxiv.org/pdf/2002.02413" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Covering the News with (AI) Style <a href="https://arxiv.org/pdf/2002.02369" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> VGAI: A Vision-Based Decentralized Controller Learning Framework for  Robot Swarms <a href="https://arxiv.org/pdf/2002.02308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> From Data to Actions in Intelligent Transportation Systems: a  Prescription of Functional Requirements for Model Actionability <a href="https://arxiv.org/pdf/2002.02210" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Unbalanced GANs: Pre-training the Generator of Generative Adversarial  Network using Variational Autoencoder <a href="https://arxiv.org/pdf/2002.02112" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> Brain Tumor Segmentation by Cascaded Deep Neural Networks Using Multiple  Image Scales <a href="https://arxiv.org/pdf/2002.01975" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> Crowdsourcing the Perception of Machine Teaching <a href="https://arxiv.org/pdf/2002.01618" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-06</title>
    <url>/2020/02/06/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-06/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Rapid Adaptation of BERT for Information Extraction on Domain-Specific  Business Documents <a href="https://arxiv.org/pdf/2002.01861" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Automatic Location Type Classification From Social-Media Posts <a href="https://arxiv.org/pdf/2002.01846" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Discontinuous Constituent Parsing with Pointer Networks <a href="https://arxiv.org/pdf/2002.01824" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters <a href="https://arxiv.org/pdf/2002.01808" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and  Manual Correction <a href="https://arxiv.org/pdf/2002.01761" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Parsing as Pretraining <a href="https://arxiv.org/pdf/2002.01685" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Identification of Indian Languages using Ghost-VLAD pooling <a href="https://arxiv.org/pdf/2002.01664" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Lightweight Convolutional Representations for On-Device Natural Language  Processing <a href="https://arxiv.org/pdf/2002.01535" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Generalizing meanings from partners to populations: Hierarchical  inference supports convention formation on networks <a href="https://arxiv.org/pdf/2002.01510" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> If I Hear You Correctly: Building and Evaluating Interview Chatbots with  Active Listening Skills <a href="https://arxiv.org/pdf/2002.01862" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Rapid Adaptation of BERT for Information Extraction on Domain-Specific  Business Documents</b>  <a href="https://arxiv.org/pdf/2002.01861" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruixue Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luyun Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tu%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhengkai Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xie%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuqing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zihang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xie%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuhao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luchen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xiong%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kun Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jimmy Lin</a><br>
<font size="3">
Abstract: Techniques for automatically extracting important content elements from business documents such as contracts, statements, and filings have the potential to make business operations more efficient. This problem can be formulated as a sequence labeling task, and we demonstrate the adaption of BERT to two types of business documents: regulatory filings and property lease agreements. There are aspects of this problem that make it easier than "standard" information extraction tasks and other aspects that make it more difficult, but on balance we find that modest amounts of annotated data (less than 100 documents) are sufficient to achieve reasonable accuracy. We integrate our models into an end-to-end cloud platform that provides both an easy-to-use annotation interface as well as an inference interface that allows users to upload documents and inspect model outputs. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：技术的自动提取业务文档的重要内容元素，如合同，报表和申报必须让企业运营更为有效的潜力。这个问题可以配制成序列标注任务，我们证明BERT的两种类型商务文档的适应：监管机构备案和物业租赁协议。有迹象表明，使它比“标准”信息提取任务等各个方面，使之更加困难，更容易，但总的来说，我们发现，适量的注释数据（小于100个文件）的足以实现合理的准确性这个问题的各个方面。我们我们的模型集成到一个终端到终端的云平台，同时提供了一个易于使用的界面注释以及推理接口，允许用户上传文档并检查模型输出。</font>
</div>


<hr>
<div id="paper2"> <b>2. Automatic Location Type Classification From Social-Media Posts</b>  <a href="https://arxiv.org/pdf/2002.01846" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kravi%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Elad Kravi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kimelfeld%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benny Kimelfeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kanza%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yaron Kanza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Reichart%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roi Reichart</a><br>
<font size="3">
Abstract: We introduce the problem of Automatic Location Type Classification from social media posts. Our goal is to correctly associate a set of messages posted in a small radius around a given location with their corresponding location type, e.g., school, church, restaurant or museum. We provide a dataset of locations associated with tweets posted in close geographical proximity. We explore two approaches to the problem: (a) a pipeline approach where each message is first classified, and then the location associated with the message set is inferred from the individual message labels; and (b) a joint approach where the individual messages are simultaneously processed to yield the desired location type. Our results demonstrate the superiority of the joint approach. Moreover, we show that due to the unique structure of the problem, where weakly-related messages are jointly processed to yield a single final label, simpler linear classifiers outperform deep neural network alternatives that have shown superior in previous text classification tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们从社交媒体文章介绍了自动定位类型划分的问题。我们的目标是正确的一组贴在小半径围绕给定的位置，其对应的位置类型，例如，学校，教堂，餐馆或博物馆的消息联系起来。我们提供的与贴在缘相近微博相关联的位置的数据集。我们探索两种方法的问题：（1）管线方法，其中每个消息首先分类，然后与消息集相关联的位置被从单独的消息标签推断;和（b）在各个消息被同时处理的联合方法，得到所需的位置类型。我们的研究结果表明共同方法的优越性。此外，我们表明，由于问题，在弱相关的消息被联合处理，以产生一个最终标签的独特结构，简单的线性分类跑赢大盘已显示出在以前的文本分类任务优良的深神经网络的替代品。</font>
</div>


<hr>
<div id="paper3"> <b>3. Discontinuous Constituent Parsing with Pointer Networks</b>  <a href="https://arxiv.org/pdf/2002.01824" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Fern%C3%A1ndez-Gonz%C3%A1lez%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daniel Fernández-González</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=G%C3%B3mez-Rodr%C3%ADguez%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Carlos Gómez-Rodríguez</a><br>
<font size="3">
Abstract: One of the most complex syntactic representations used in computational linguistics and NLP are discontinuous constituent trees, crucial for representing all grammatical phenomena of languages such as German. Recent advances in dependency parsing have shown that Pointer Networks excel in efficiently parsing syntactic relations between words in a sentence. This kind of sequence-to-sequence models achieve outstanding accuracies in building non-projective dependency trees, but its potential has not been proved yet on a more difficult task. We propose a novel neural network architecture that, by means of Pointer Networks, is able to generate the most accurate discontinuous constituent representations to date, even without the need of Part-of-Speech tagging information. To do so, we internally model discontinuous constituent structures as augmented non-projective dependency structures. The proposed approach achieves state-of-the-art results on the two widely-used NEGRA and TIGER benchmarks, outperforming previous work by a wide margin. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：一个在计算语言学和自然语言处理中使用的最复杂的句法表征的是不连续的组成部分树木，为代表的语言的所有语法现象，如德国的关键。在依存分析的最新进展表明，指针网络高强高效地分析词与词之间句法关系的句子。这种顺序对序列模型的实现建立非投影依赖树出色的精度，但它的潜力还没有得到一个更艰巨的任务尚未证实。我们提出了一种新的神经网络结构，通过指针网络的手段，能够产生最准确的不连续的组成表示到目前为止，即使没有需要的部分，词性标注信息。要做到这一点，我们在内部不连续的成分结构建模为增强非投影依赖结构。所提出的方法实现对两种广泛使用的NEGRA和TIGER基准国家的先进成果，大幅跑赢以前的工作。</font>
</div>


<hr>
<div id="paper4"> <b>4. K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters</b>  <a href="https://arxiv.org/pdf/2002.01808" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruize Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tang%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Duyu Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nan Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhongyu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanjing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=ji%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jianshu ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cao%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cuihong Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daxin Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: We study the problem of injecting knowledge into large pre-trained models like BERT and RoBERTa. Existing methods typically update the original parameters of pre-trained models when injecting knowledge. However, when multiple kinds of knowledge are injected, they may suffer from the problem of catastrophic forgetting. To address this, we propose K-Adapter, which remains the original parameters of the pre-trained model fixed and supports continual knowledge infusion. Taking RoBERTa as the pre-trained model, K-Adapter has a neural adapter for each kind of infused knowledge, like a plug-in connected to RoBERTa. There is no information flow between different adapters, thus different adapters are efficiently trained in a distributed way. We inject two kinds of knowledge, including factual knowledge obtained from automatically aligned text-triplets on Wikipedia and Wikidata, and linguistic knowledge obtained from dependency parsing. Results on three knowledge-driven tasks (total six datasets) including relation classification, entity typing and question answering demonstrate that each adapter improves the performance, and the combination of both adapters brings further improvements. Probing experiments further show that K-Adapter captures richer factual and commonsense knowledge than RoBERTa. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们研究的知识注入到大预先训练的车型，如BERT和罗伯塔的问题。现有的方法通常注射知识时更新的预先训练模型的原始参数。然而，当多个种类的知识注入，它们可以从灾难性遗忘的问题的困扰。为了解决这个问题，我们提出了K-适配器，这仍然是预先训练模型固定和支持持续的知识灌输的原始参数。以罗伯塔作为预先训练模型，K-适配器有各种灌输的知识的神经适配器，就像连接到一个罗伯塔插件。有不同的适配器，从而不同的适配器以分布式方式有效地训练之间没有信息流。我们注入两种知识，包括自动对齐文本三联维基百科和维基数据获得的实际知识，并从依赖分析获得的语言知识。三个知识驱动型任务（共六集），包括有关分类，实体打字和答疑结果表明，每个适配器提高性能，并且这两个适配器的组合带来了进一步的改进。探测实验进一步表明，K-适配器捕捉比罗伯塔更丰富的事实和常识性知识。</font>
</div>


<hr>
<div id="paper5"> <b>5. Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and  Manual Correction</b>  <a href="https://arxiv.org/pdf/2002.01761" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mingchen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zili Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanna Wang</a><br>
<font size="3">
Abstract: Princeton WordNet (PWN) is a lexicon-semantic network based on cognitive linguistics, which promotes the development of natural language processing. Based on PWN, five Chinese wordnets have been developed to solve the problems of syntax and semantics. They include: Northeastern University Chinese WordNet (NEW), Sinica Bilingual Ontological WordNet (BOW), Southeast University Chinese WordNet (SEW), Taiwan University Chinese WordNet (CWN), Chinese Open WordNet (COW). By using them, we found that these word networks have low accuracy and coverage, and cannot completely portray the semantic network of PWN. So we decided to make a new Chinese wordnet called Multi-Fusion Chinese Wordnet (MCW) to make up those shortcomings. The key idea is to extend the SEW with the help of Oxford bilingual dictionary and Xinhua bilingual dictionary, and then correct it. More specifically, we used machine learning and manual adjustment in our corrections. Two standards were formulated to help our work. We conducted experiments on three tasks including relatedness calculation, word similarity and word sense disambiguation for the comparison of lemma's accuracy, at the same time, coverage also was compared. The results indicate that MCW can benefit from coverage and accuracy via our method. However, it still has room for improvement, especially with lemmas. In the future, we will continue to enhance the accuracy of MCW and expand the concepts in it. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：普林斯顿的WordNet（PWN）是一种基于认知语言学的词汇，语义网络，促进自然语言处理的发展。基于PWN，五个中国词汇网络已发展到解决语法和语义的问题。它们包括：东北大学中国共发现（NEW），报双语本体共发现（BOW），东南大学中国共发现（SEW），台湾大学中国共发现（CWN），中国公开赛共发现（COW）。通过使用它们，我们发现，这些字网络具有低精度和覆盖范围，并不能完全刻画PWN的语义网络。所以我们决定称为Multi-融合中国WORDNET（MCW）新中国共发现来弥补这些缺陷。其核心思想是将与牛津双解词典和新华双语词典的帮助延长SEW，然后纠正它。更具体地讲，我们用机器学习和手动调节我们的更正。两个标准配制，以帮助我们的工作。我们三个任务，包括相关性计算，词语相似度和引理的精度比较多义进行了实验，在同一时间，范围也进行了比较。结果表明，MCW可以从覆盖范围和精度通过我们的方法中受益。然而，它仍然有改进的余地，尤其是与引理。今后，我们将继续加强MCW的准确性和扩大它的概念。</font>
</div>


<hr>
<div id="paper6"> <b>6. Parsing as Pretraining</b>  <a href="https://arxiv.org/pdf/2002.01685" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Vilares%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Vilares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Strzyz%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michalina Strzyz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=S%C3%B8gaard%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anders Søgaard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=G%C3%B3mez-Rodr%C3%ADguez%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Carlos Gómez-Rodríguez</a><br>
<font size="3">
Abstract: Recent analyses suggest that encoders pretrained for language modeling capture certain morpho-syntactic structure. However, probing frameworks for word vectors still do not report results on standard setups such as constituent and dependency parsing. This paper addresses this problem and does full parsing (on English) relying only on pretraining architectures -- and no decoding. We first cast constituent and dependency parsing as sequence tagging. We then use a single feed-forward layer to directly map word vectors to labels that encode a linearized tree. This is used to: (i) see how far we can reach on syntax modelling with just pretrained encoders, and (ii) shed some light about the syntax-sensitivity of different word vectors (by freezing the weights of the pretraining network during training). For evaluation, we use bracketing F1-score and LAS, and analyze in-depth differences across representations for span lengths and dependency displacements. The overall results surpass existing sequence tagging parsers on the PTB (93.5%) and end-to-end EN-EWT UD (78.8%). </font>
<br>
<font size="2" style="line-height:30px;">
摘要：最近的分析表明预训练的语言模型捕捉特定的形态句法结构的编码器。然而，对于词矢量探测框架仍然不报告的标准设置，如成分和依存分析结果。本文将解决这个问题，不完全解析（英语）只在训练前的架构依赖 - 没有解码。首先，我们投的组成和依赖解析为序列标记。然后，我们使用一个单一的前馈层直接字矢量映射到编码的线性化树标签。这被用来：（ⅰ）见多远我们可以语法建模与刚刚预训练的编码器达到，和（ii）棚约不同字向量的语法灵敏度一些光（由训练期间冻结预训练网络的权重） 。对于评价，我们采用包围F1-得分和LAS，并分析跨表示深度的差异跨度长度和依赖位移。总的结果超过上PTB（93.5％）和端至端EN-EWT UD（78.8％）现有的序列标记的解析器。</font>
</div>


<hr>
<div id="paper7"> <b>7. Identification of Indian Languages using Ghost-VLAD pooling</b>  <a href="https://arxiv.org/pdf/2002.01664" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=N%2C+K+D" target="_blank" rel="noopener" style="color:#0000EE;">Krishna D N</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Patil%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankita Patil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Raj%2C+M+S+P" target="_blank" rel="noopener" style="color:#0000EE;">M.S.P Raj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=S%2C+S+P+H" target="_blank" rel="noopener" style="color:#0000EE;">Sai Prasad H S</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Garapati%2C+P+A" target="_blank" rel="noopener" style="color:#0000EE;">Prabhu Aashish Garapati</a><br>
<font size="3">
Abstract: In this work, we propose a new pooling strategy for language identification by considering Indian languages. The idea is to obtain utterance level features for any variable length audio for robust language recognition. We use the GhostVLAD approach to generate an utterance level feature vector for any variable length input audio by aggregating the local frame level features across time. The generated feature vector is shown to have very good language discriminative features and helps in getting state of the art results for language identification task. We conduct our experiments on 635Hrs of audio data for 7 Indian languages. Our method outperforms the previous state of the art x-vector [11] method by an absolute improvement of 1.88% in F1-score and achieves 98.43% F1-score on the held-out test data. We compare our system with various pooling approaches and show that GhostVLAD is the best pooling approach for this task. We also provide visualization of the utterance level embeddings generated using Ghost-VLAD pooling and show that this method creates embeddings which has very good language discriminative features. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在这项工作中，我们考虑印度语提出了语言识别新的合并策略。这样做是为了获得话语级功能为强大的语言识别的任何可变长度的音频。我们使用GhostVLAD方法，通过在时间上聚集所述本地帧级特征，以生成用于任何可变长度的输入音频发声水平特征向量。所生成的特征向量显示出具有很好的语言辨别功能，并获得艺术效果的语言识别任务的状态有所帮助。我们进行了对7种印度语言的音频数据的635Hrs我们的实验。我们的方法由1.88％的F1-得分的绝对改进优于现有技术的x矢量[11]的方法的先前状态，并实现所保持的输出测试数据98.43％F1-得分。我们比较了各种池系统接近，并表明GhostVLAD是这个任务的最佳方式汇集。我们还提供了使用Ghost-VLAD汇集和展示所产生的话语层面的嵌入的可视化，这种方法可以创建具有很好的语言判别特征的嵌入。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-06</title>
    <url>/2020/02/06/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-02-06/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> TPPO: A Novel Trajectory Predictor with Pseudo Oracle <a href="https://arxiv.org/pdf/2002.01852" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Analyzing the Dependency of ConvNets on Spatial Information <a href="https://arxiv.org/pdf/2002.01827" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> Geocoding of trees from street addresses and street-level images <a href="https://arxiv.org/pdf/2002.01708" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> CHAIN: Concept-harmonized Hierarchical Inference Interpretation of Deep  Convolutional Neural Networks <a href="https://arxiv.org/pdf/2002.01660" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Solving Raven's Progressive Matrices with Neural Networks <a href="https://arxiv.org/pdf/2002.01646" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Enhancing Feature Invariance with Learned Image Transformations for  Image Retrieval <a href="https://arxiv.org/pdf/2002.01642" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Illumination adaptive person reid based on teacher-student model and  adversarial training <a href="https://arxiv.org/pdf/2002.01625" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Monocular 3D Object Detection with Decoupled Structured Polygon  Estimation and Height-Guided Depth Estimation <a href="https://arxiv.org/pdf/2002.01619" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Generating Interpretable Poverty Maps using Object Detection in  Satellite Images <a href="https://arxiv.org/pdf/2002.01612" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Accelerating Object Detection by Erasing Background Activations <a href="https://arxiv.org/pdf/2002.01609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Anomaly Detection by Latent Regularized Dual Adversarial Networks <a href="https://arxiv.org/pdf/2002.01607" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Unsupervised Community Detection with a Potts Model Hamiltonian, an  Efficient Algorithmic Solution, and Applications in Digital Pathology <a href="https://arxiv.org/pdf/2002.01599" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Ego-Lane Estimation by Modelling Lanes and Sensor Failures <a href="https://arxiv.org/pdf/2002.01913" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> A neural network model that learns differences in diagnosis strategies  among radiologists has an improved area under the curve for aneurysm status  classification in magnetic resonance angiography image series <a href="https://arxiv.org/pdf/2002.01891" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Proximity Preserving Binary Code using Signed Graph-Cut <a href="https://arxiv.org/pdf/2002.01793" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Human Posture Recognition and Gesture Imitation with a Humanoid Robot <a href="https://arxiv.org/pdf/2002.01779" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Feature-map-level Online Adversarial Knowledge Distillation <a href="https://arxiv.org/pdf/2002.01775" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Entropy Minimization vs. Diversity Maximization for Domain Adaptation <a href="https://arxiv.org/pdf/2002.01690" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Concept Whitening for Interpretable Image Recognition <a href="https://arxiv.org/pdf/2002.01650" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>python 设置超时退出</title>
    <url>/2020/02/04/python-%E8%AE%BE%E7%BD%AE%E8%B6%85%E6%97%B6%E9%80%80%E5%87%BA/</url>
    <content><![CDATA[<p>使用<strong>eventlet</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> eventlet</span><br><span class="line">eventlet.monkey_patch()</span><br><span class="line"><span class="keyword">with</span> eventlet.Timeout(<span class="number">10</span>,<span class="literal">False</span>):<span class="comment">#设置超时时间为10秒</span></span><br><span class="line">	time.sleep(<span class="number">20</span>) </span><br><span class="line">	print(<span class="string">'1'</span>)</span><br><span class="line">print(<span class="string">'2'</span>)</span><br></pre></td></tr></table></figure><p>上面程序只输出</p><a id="more"></a>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-02-03</title>
    <url>/2020/02/03/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-03/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Pretrained Transformers for Simple Question Answering over Knowledge  Graphs <a href="https://arxiv.org/pdf/2001.11985" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> An efficient automated data analytics approach to large scale  computational comparative linguistics <a href="https://arxiv.org/pdf/2001.11899" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Hybrid Tiled Convolutional Neural Networks for Text Sentiment  Classification <a href="https://arxiv.org/pdf/2001.11857" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Break It Down: A Question Understanding Benchmark <a href="https://arxiv.org/pdf/2001.11770" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Teaching Machines to Converse <a href="https://arxiv.org/pdf/2001.11701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Pseudo-Bidirectional Decoding for Local Sequence Transduction <a href="https://arxiv.org/pdf/2001.11694" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Self-Adversarial Learning with Comparative Discrimination for Text  Generation <a href="https://arxiv.org/pdf/2001.11691" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Augmenting Visual Question Answering with Semantic Frame Information in  a Multitask Learning Approach <a href="https://arxiv.org/pdf/2001.11673" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Enhancement of Short Text Clustering by Iterative Classification <a href="https://arxiv.org/pdf/2001.11631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Unwanted Advances in Higher Education: Uncovering Sexual Harassment  Experiences in Academia with Text Mining <a href="https://arxiv.org/pdf/2001.11552" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Pretrained Transformers for Simple Question Answering over Knowledge  Graphs</b>  <a href="https://arxiv.org/pdf/2001.11985" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lukovnikov%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">D. Lukovnikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fischer%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">A. Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lehmann%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">J. Lehmann</a><br>
<font size="3">
Abstract: Answering simple questions over knowledge graphs is a well-studied problem in question answering. Previous approaches for this task built on recurrent and convolutional neural network based architectures that use pretrained word embeddings. It was recently shown that finetuning pretrained transformer networks (e.g. BERT) can outperform previous approaches on various natural language processing tasks. In this work, we investigate how well BERT performs on SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based models in datasparse scenarios. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在知识图回答简单的问题，在问答充分研究的问题。以前的方法完成这个任务建立在使用预训练字的嵌入复发和卷积神经网络基础架构。这是最近表明，微调预训练的变压器网络（例如BERT）可以超越各种自然语言处理任务，以前的方法。在这项工作中，我们探讨SimpleQuestions如何BERT执行和datasparse场景同时提供BERT和基于BiLSTM的模型的评估。</font>
</div>


<hr>
<div id="paper2"> <b>2. An efficient automated data analytics approach to large scale  computational comparative linguistics</b>  <a href="https://arxiv.org/pdf/2001.11899" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Mikulyte%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gabija Mikulyte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gilbert%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Gilbert</a><br>
<font size="3">
Abstract: This research project aimed to overcome the challenge of analysing human language relationships, facilitate the grouping of languages and formation of genealogical relationship between them by developing automated comparison techniques. Techniques were based on the phonetic representation of certain key words and concept. Example word sets included numbers 1-10 (curated), large database of numbers 1-10 and sheep counting numbers 1-10 (other sources), colours (curated), basic words (curated). To enable comparison within the sets the measure of Edit distance was calculated based on Levenshtein distance metric. This metric between two strings is the minimum number of single-character edits, operations including: insertions, deletions or substitutions. To explore which words exhibit more or less variation, which words are more preserved and examine how languages could be grouped based on linguistic distances within sets, several data analytics techniques were involved. Those included density evaluation, hierarchical clustering, silhouette, mean, standard deviation and Bhattacharya coefficient calculations. These techniques lead to the development of a workflow which was later implemented by combining Unix shell scripts, a developed R package and SWI Prolog. This proved to be computationally efficient and permitted the fast exploration of large language sets and their analysis. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本研究项目旨在克服分析人类语言的关系的挑战，通过开发自动比较技术促进语言和形成它们之间的关系家谱分组。技术是基于某些关键词和概念的语音表示。例如字组包括编号1-10（策划），大数据库编号1-10和羊计数编号1-10（其它来源），颜色（策划）的，基本字（策划）。为了使基于Levenshtein距离度量计算编辑距离的测量集合中的比较。两个字符串之间的度量是单字符编辑，操作，包括的最小数目：插入，缺失或取代。探讨其中的话表现出或多或少的变化，这词更保存和研究如何可以语言基于集内的语言距离进行分组，几个数据分析技术的参与。这些问题包括浓度评价，层次聚类，侧影，平均值，标准偏差和查亚系数的计算。这些技术导致后来被合并的Unix shell脚本，一个开发[R包，SWI Prolog的实现工作流的发展。事实证明，这是计算效率和许可的大型语言组和他们的分析快速探索。</font>
</div>


<hr>
<div id="paper3"> <b>3. Hybrid Tiled Convolutional Neural Networks for Text Sentiment  Classification</b>  <a href="https://arxiv.org/pdf/2001.11857" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Trusca%2C+M+M" target="_blank" rel="noopener" style="color:#0000EE;">Maria Mihaela Trusca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Spanakis%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerasimos Spanakis</a><br>
<font size="3">
Abstract: The tiled convolutional neural network (tiled CNN) has been applied only to computer vision for learning invariances. We adjust its architecture to NLP to improve the extraction of the most salient features for sentiment analysis. Knowing that the major drawback of the tiled CNN in the NLP field is its inflexible filter structure, we propose a novel architecture called hybrid tiled CNN that applies a filter only on the words that appear in the similar contexts and on their neighbor words (a necessary step for preventing the loss of some n-grams). The experiments on the datasets of IMDB movie reviews and SemEval 2017 demonstrate the efficiency of the hybrid tiled CNN that performs better than both CNN and tiled CNN. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：平铺卷积神经网络（CNN平铺）已经只适用于计算机视觉学习不变性。我们调整公司架构，以NLP提高最显着的特征为情感分析提取。明知平铺CNN在NLP领域的主要缺点是其不灵活的过滤器结构，我们提出了一种新的架构称为混合平铺CNN说，仅在出现在相似的背景和他们的邻居的话的话应用过滤器（必要步骤，用于防止一些的n-gram的损失）。对IMDB电影评论和SemEval 2017年的数据集上的实验证明了混合动力的效率平铺CNN说，比CNN都和瓷砖CNN性能更好。</font>
</div>


<hr>
<div id="paper4"> <b>4. Break It Down: A Question Understanding Benchmark</b>  <a href="https://arxiv.org/pdf/2001.11770" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wolfson%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tomer Wolfson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Geva%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mor Geva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gupta%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankit Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gardner%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matt Gardner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goldberg%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yoav Goldberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Deutch%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daniel Deutch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Berant%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jonathan Berant</a><br>
<font size="3">
Abstract: Understanding natural language questions entails the ability to break down a question into the requisite steps for computing its answer. In this work, we introduce a Question Decomposition Meaning Representation (QDMR) for questions. QDMR constitutes the ordered list of steps, expressed through natural language, that are necessary for answering a question. We develop a crowdsourcing pipeline, showing that quality QDMRs can be annotated at scale, and release the Break dataset, containing over 83K pairs of questions and their QDMRs. We demonstrate the utility of QDMR by showing that (a) it can be used to improve open-domain question answering on the HotpotQA dataset, (b) it can be deterministically converted to a pseudo-SQL formal language, which can alleviate annotation in semantic parsing applications. Last, we use Break to train a sequence-to-sequence model with copying that parses questions into QDMR structures, and show that it substantially outperforms several natural baselines. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：理解自然语言问题需要一个问题分解成用于计算其答案的必要步骤的能力。在这项工作中，我们介绍的问题一个问题分解含义表示（QDMR）。 QDMR构成的步骤，通过自然语言来表达，所必需的回答问题的有序列表。我们开发了一个众包管道，显示出质量QDMRs可以大规模进行标注，并释放中断的数据集，包含超过83K对遇到的问题进行QDMRs。我们通过展示（一），它可以被用来改善对HotpotQA数据集开放域问答，（B），可以确定性地转换成伪SQL形式语言，它可以在语义缓解标注证明QDMR的效用解析应用。最后，我们使用中断训练序列到序列模型复制，它分析问题到QDMR结构，并表明它大幅优于几种天然基线。</font>
</div>


<hr>
<div id="paper5"> <b>5. Teaching Machines to Converse</b>  <a href="https://arxiv.org/pdf/2001.11701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiwei Li</a><br>
<font size="3">
Abstract: The ability of a machine to communicate with humans has long been associated with the general success of AI. This dates back to Alan Turing's epoch-making work in the early 1950s, which proposes that a machine's intelligence can be tested by how well it, the machine, can fool a human into believing that the machine is a human through dialogue conversations. Many systems learn generation rules from a minimal set of authored rules or labels on top of hand-coded rules or templates, and thus are both expensive and difficult to extend to open-domain scenarios. Recently, the emergence of neural network models the potential to solve many of the problems in dialogue learning that earlier systems cannot tackle: the end-to-end neural frameworks offer the promise of scalability and language-independence, together with the ability to track the dialogue state and then mapping between states and dialogue actions in a way not possible with conventional systems. On the other hand, neural systems bring about new challenges: they tend to output dull and generic responses; they lack a consistent or a coherent persona; they are usually optimized through single-turn conversations and are incapable of handling the long-term success of a conversation; and they are not able to take the advantage of the interactions with humans. This dissertation attempts to tackle these challenges: Contributions are two-fold: (1) we address new challenges presented by neural network models in open-domain dialogue generation systems; (2) we develop interactive question-answering dialogue systems by (a) giving the agent the ability to ask questions and (b) training a conversation agent through interactions with humans in an online fashion, where a bot improves through communicating with humans and learning from the mistakes that it makes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：一台机器与人沟通的能力一直与AI的普遍成功有关。这可以追溯到50年代初阿兰·图灵的划时代的工作，这提出了一个机器的智能可以通过如何，将本机，可以欺骗一个人相信该机器是通过对话谈话人进行测试。许多系统学习生成规则从一组上的手工编码的规则或模板顶部撰写规则或标签最小，从而既昂贵又难以扩展到开放域场景。最近，神经网络模型的出现的可能性，解决了许多在对话学习的问题，早期的系统无法应对：终端到终端的神经框架提供的可扩展性和语言独立性的承诺，与跟踪的能力一起对话状态，并与传统的系统不可能的方式国和对话的行动之间的映射，然后。在另一方面，神经系统带来了新的挑战：他们往往输出沉闷和通用的应对措施;他们缺乏一致或连贯的角色;他们通常是通过单圈的谈话进行了优化，不能处理的对话的长期成功;他们不能够采取互动的优势与人类。本文试图解决这些挑战：捐款有两方面：（1）我们解决在开放领域对话发电系统的神经网络模型提出了新的挑战; （2）我们开发给代理提问以在线的方式，其中一个机器人通过与人类和学习交流提高训练的对话代理通过互动与人类的能力，和（b）通过互动答疑对话系统（一）从它使错误。</font>
</div>


<hr>
<div id="paper6"> <b>6. Pseudo-Bidirectional Decoding for Local Sequence Transduction</b>  <a href="https://arxiv.org/pdf/2001.11694" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wangchunshu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ge%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ke Xu</a><br>
<font size="3">
Abstract: Local sequence transduction (LST) tasks are sequence transduction tasks where there exists massive overlapping between the source and target sequences, such as Grammatical Error Correction (GEC) and spell or OCR correction. Previous work generally tackles LST tasks with standard sequence-to-sequence (seq2seq) models that generate output tokens from left to right and suffer from the issue of unbalanced outputs. Motivated by the characteristic of LST tasks, in this paper, we propose a simple but versatile approach named Pseudo-Bidirectional Decoding (PBD) for LST tasks. PBD copies the corresponding representation of source tokens to the decoder as pseudo future context to enable the decoder to attends to its bi-directional context. In addition, the bidirectional decoding scheme and the characteristic of LST tasks motivate us to share the encoder and the decoder of seq2seq models. The proposed PBD approach provides right side context information for the decoder and models the inductive bias of LST tasks, reducing the number of parameters by half and providing good regularization effects. Experimental results on several benchmark datasets show that our approach consistently improves the performance of standard seq2seq models on LST tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本地序列转导（LST）任务是在存在源和目标序列，例如语法纠错（GEC）和拼写或OCR校正之间大量重叠序列转导的任务。以前的工作通常铲球与生成输出令牌由左到右，并从非平衡输出的问题遭受标准序列对序列（seq2seq）模型LST任务。通过LST任务特性的启发，在本文中，我们提出了一个简单而通用的命名伪双向解码（PBD）为LST任务的方法。 PBD拷贝源的相应表示令牌给解码器作为伪未来上下文，以使解码器能够照顾到其双向上下文。此外，双向解码方案和LST任务的特点促使我们分享编码器和seq2seq车型的解码器。所提出的PBD方法提供了解码器和模型的LST任务归纳偏置，减少一半的参数的数量和提供良好的正规化效果右侧的上下文信息。在几个基准数据集的实验结果表明，该方法可以始终如一提高标准seq2seq车型上LST任务的性能。</font>
</div>


<hr>
<div id="paper7"> <b>7. Self-Adversarial Learning with Comparative Discrimination for Text  Generation</b>  <a href="https://arxiv.org/pdf/2001.11691" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wangchunshu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ge%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ke Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Furu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: Conventional Generative Adversarial Networks (GANs) for text generation tend to have issues of reward sparsity and mode collapse that affect the quality and diversity of generated samples. To address the issues, we propose a novel self-adversarial learning (SAL) paradigm for improving GANs' performance in text generation. In contrast to standard GANs that use a binary classifier as its discriminator to predict whether a sample is real or generated, SAL employs a comparative discriminator which is a pairwise classifier for comparing the text quality between a pair of samples. During training, SAL rewards the generator when its currently generated sentence is found to be better than its previously generated samples. This self-improvement reward mechanism allows the model to receive credits more easily and avoid collapsing towards the limited number of real samples, which not only helps alleviate the reward sparsity issue but also reduces the risk of mode collapse. Experiments on text generation benchmark datasets show that our proposed approach substantially improves both the quality and the diversity, and yields more stable performance compared to the previous GANs for text generation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：传统的生成性对抗性网络（甘斯）的文本生成往往具有影响的质量和产生的样本的多样性奖励稀疏和模式崩溃的问题。为了解决这个问题，我们提出了一个新的自我对抗学习（SAL）为提高文本生成甘斯的表现模式。与此相反使用二元分类器作为它的鉴别器以预测样品是否是真实的还是生成的标准甘斯，SAL采用比较鉴别器，其是用于在一对样品之间比较所述文本质量成对分类器。在训练期间，如果其目前产生的句子被认为比其以前生成的样本更好SAL奖励发电机。这种自强不息的奖励机制，使模型更容易获得信贷，并避免对数量有限的实际样品，这不仅有助于缓解奖励稀疏问题倒塌，但也降低了模式崩溃的风险。在文本生成基准数据集的实验表明，该方法显着提高的质量和多样性，并产生更稳定的性能相比之前的甘斯的文本生成。</font>
</div>


<hr>
<div id="paper8"> <b>8. Augmenting Visual Question Answering with Semantic Frame Information in  a Multitask Learning Approach</b>  <a href="https://arxiv.org/pdf/2001.11673" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Alizadeh%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mehrdad Alizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Di+Eugenio%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Barbara Di Eugenio</a><br>
<font size="3">
Abstract: Visual Question Answering (VQA) concerns providing answers to Natural Language questions about images. Several deep neural network approaches have been proposed to model the task in an end-to-end fashion. Whereas the task is grounded in visual processing, if the question focuses on events described by verbs, the language understanding component becomes crucial. Our hypothesis is that models should be aware of verb semantics, as expressed via semantic role labels, argument types, and/or frame elements. Unfortunately, no VQA dataset exists that includes verb semantic information. Our first contribution is a new VQA dataset (imSituVQA) that we built by taking advantage of the imSitu annotations. The imSitu dataset consists of images manually labeled with semantic frame elements, mostly taken from FrameNet. Second, we propose a multitask CNN-LSTM VQA model that learns to classify the answers as well as the semantic frame elements. Our experiments show that semantic frame element classification helps the VQA system avoid inconsistent responses and improves performance. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：视觉答疑（VQA）的担忧提供了回答有关图像自然语言问题。一些深层神经网络方法被提出来的任务结束到终端的时装模特。尽管任务是在视觉处理接地，如果问题集中在事件描述由动词，理解组件的语言变得至关重要。我们的假设是模型应该知道动词语义的，如通过语义角色标签，参数类型，和/或框架元素表示。不幸的是，没有VQA数据集存在，包括动词语义信息。我们的第一个贡献是一个新的VQA的数据集（imSituVQA），我们通过采取imSitu注释的优势构建。数据集由具有语义框架元件手动标记的图像的imSitu，大多是从框架网络服用。其次，我们提出了一个多任务CNN-LSTM VQA模型学会的答案，以及语义框架内容进行分类。我们的实验表明，语义框架元素的分类有助于VQA系统避免不一致的响应和提高性能。</font>
</div>


<hr>
<div id="paper9"> <b>9. Enhancement of Short Text Clustering by Iterative Classification</b>  <a href="https://arxiv.org/pdf/2001.11631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Rakib%2C+M+R+H" target="_blank" rel="noopener" style="color:#0000EE;">Md Rashadul Hasan Rakib</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zeh%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Norbert Zeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jankowska%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Magdalena Jankowska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Milios%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Evangelos Milios</a><br>
<font size="3">
Abstract: Short text clustering is a challenging task due to the lack of signal contained in such short texts. In this work, we propose iterative classification as a method to b o ost the clustering quality (e.g., accuracy) of short texts. Given a clustering of short texts obtained using an arbitrary clustering algorithm, iterative classification applies outlier removal to obtain outlier-free clusters. Then it trains a classification algorithm using the non-outliers based on their cluster distributions. Using the trained classification model, iterative classification reclassifies the outliers to obtain a new set of clusters. By repeating this several times, we obtain a much improved clustering of texts. Our experimental results show that the proposed clustering enhancement method not only improves the clustering quality of different clustering methods (e.g., k-means, k-means--, and hierarchical clustering) but also outperforms the state-of-the-art short text clustering methods on several short text datasets by a statistically significant margin. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：短文本聚类是一个具有挑战性的任务，由于包含在如此短的文字缺乏的信号。在这项工作中，我们提出的迭代分类为B○OST短文本的聚类质量（例如，准确度）的方法。鉴于使用任意的聚类算法获得的短文本的聚类，分类迭代适用异常值去除以获得离群-空闲簇。然后训练使用基于其集群分布的非离群的分类算法。利用训练的分类模型，迭代分类重新分类离群获得一组新的集群。通过重复几次，我们得到的文本大大改善群集。我们的实验结果表明，所提出的聚类增强方法不仅提高了的不同的聚类方法（例如，k均值，K-指：，和层次聚类）聚类质量也优于状态的最先进的短文本有统计显著保证金聚类在几个简短的文本数据集的方法。</font>
</div>


<hr>
<div id="paper10"> <b>10. Unwanted Advances in Higher Education: Uncovering Sexual Harassment  Experiences in Academia with Text Mining</b>  <a href="https://arxiv.org/pdf/2001.11552" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/physics?searchtype=author&query=Karami%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Amir Karami</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&query=White%2C+C+N" target="_blank" rel="noopener" style="color:#0000EE;">Cynthia Nicole White</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&query=Ford%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kayla Ford</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&query=Swan%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Suzanne Swan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&query=Spinel%2C+M+Y" target="_blank" rel="noopener" style="color:#0000EE;">Melek Yildiz Spinel</a><br>
<font size="3">
Abstract: Sexual harassment in academia is often a hidden problem because victims are usually reluctant to report their experiences. Recently, a web survey was developed to provide an opportunity to share thousands of sexual harassment experiences in academia. Using an efficient approach, this study collected and investigated more than 2,000 sexual harassment experiences to better understand these unwanted advances in higher education. This paper utilized text mining to disclose hidden topics and explore their weight across three variables: harasser gender, institution type, and victim's field of study. We mapped the topics on five themes drawn from the sexual harassment literature and found that more than 50% of the topics were assigned to the unwanted sexual attention theme. Fourteen percent of the topics were in the gender harassment theme, in which insulting, sexist, or degrading comments or behavior was directed towards women. Five percent of the topics involved sexual coercion (a benefit is offered in exchange for sexual favors), 5% involved sex discrimination, and 7% of the topics discussed retaliation against the victim for reporting the harassment, or for simply not complying with the harasser. Findings highlight the power differential between faculty and students, and the toll on students when professors abuse their power. While some topics did differ based on type of institution, there were no differences between the topics based on gender of harasser or field of study. This research can be beneficial to researchers in further investigation of this paper's dataset, and to policymakers in improving existing policies to create a safe and supportive environment in academia. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在学术界性骚扰往往是一个隐藏的问题，因为受害者往往不愿意报告自己的经历。最近，网络调查的开发提供共享成千上万的性骚扰经历学术界的机会。使用一种有效的方法，这项研究收集和调查2000余和性骚扰的经验，以更好地了解高等教育这些不必要的进步。本文利用文本挖掘透露隐藏的主题和跨越三个变量探索自己的体重：骚扰者性别，机构类型和研究的受害人的领域。我们映射从性骚扰文献中提取，发现的主题超过50％被分配到不必要的性关注主题五个主题的主题。的主题十四％的人在性别骚扰主题，在这种侮辱，性别歧视，或侮辱性的评论或行为针对妇女。的主题百分之五参与性胁迫（一个好处是提供以换取性方面的好处），5％涉及性别歧视，以及主题7％讨论对受害者报复举报骚扰，或者干脆不与骚扰符合。发现突出的教师和学生，以及学生的收费之间的功率差时，教授滥用职权。虽然有些题目确实有所不同根据类型的机构，有基于研究的骚扰或领域的性别主题之间没有差异。这项研究可以在本文的数据集的进一步调查研究有利，对政策制定者改善现有的政策，创造学术界安全和支持的环境。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>pip 安装提示空间不足</title>
    <url>/2020/01/21/pip-%E5%AE%89%E8%A3%85%E6%8F%90%E7%A4%BA%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3/</url>
    <content><![CDATA[<p>pip 安装提示空间不足</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Could not install packages due to an EnvironmentError: [Errno 28] No space left on device</span><br></pre></td></tr></table></figure><p>这是服务器上的/tmp空间不足，可以在自己的根目录下简历~/tmp代替 /tmp</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir ~/tmp</span><br><span class="line">export TMPDIR=$HOME/tmp</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>【arxiv论文】 Computer Vision and Pattern Recognition 2020-01-20</title>
    <url>/2020/01/20/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-01-20/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Unsupervised Learning of Camera Pose with Compositional Re-estimation <a href="https://arxiv.org/pdf/2001.06479" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Combining PRNU and noiseprint for robust and efficient device source  identification <a href="https://arxiv.org/pdf/2001.06440" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> TailorGAN: Making User-Defined Fashion Designs <a href="https://arxiv.org/pdf/2001.06427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Subjective Annotation for a Frame Interpolation Benchmark using Artifact  Amplification <a href="https://arxiv.org/pdf/2001.06409" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> GraphBGS: Background Subtraction via Recovery of Graph Signals <a href="https://arxiv.org/pdf/2001.06404" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Latency-Aware Differentiable Neural Architecture Search <a href="https://arxiv.org/pdf/2001.06392" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> BigEarthNet Deep Learning Models with A New Class-Nomenclature for  Remote Sensing Image Understanding <a href="https://arxiv.org/pdf/2001.06372" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Efficient Facial Feature Learning with Wide Ensemble-based Convolutional  Neural Networks <a href="https://arxiv.org/pdf/2001.06338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Vision Meets Drones: Past, Present and Future <a href="https://arxiv.org/pdf/2001.06303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Predicting the Physical Dynamics of Unseen 3D Objects <a href="https://arxiv.org/pdf/2001.06291" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Review: deep learning on 3D point clouds <a href="https://arxiv.org/pdf/2001.06280" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Compounding the Performance Improvements of Assembled Techniques in a  Convolutional Neural Network <a href="https://arxiv.org/pdf/2001.06268" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On <a href="https://arxiv.org/pdf/2001.06265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Two-Phase Object-Based Deep Learning for Multi-temporal SAR Image Change  Detection <a href="https://arxiv.org/pdf/2001.06252" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Registration made easy -- standalone orthopedic navigation with HoloLens <a href="https://arxiv.org/pdf/2001.06209" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for  Semi-supervised Optical Flow Estimation <a href="https://arxiv.org/pdf/2001.06171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Interpreting Galaxy Deblender GAN from the Discriminator's Perspective <a href="https://arxiv.org/pdf/2001.06151" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Learning to Augment Expressions for Few-shot Fine-grained Facial  Expression Recognition <a href="https://arxiv.org/pdf/2001.06144" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Spatio-Temporal Ranked-Attention Networks for Video Captioning <a href="https://arxiv.org/pdf/2001.06127" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Automatic Discovery of Political Meme Genres with Diverse Appearances <a href="https://arxiv.org/pdf/2001.06122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> On- Device Information Extraction from Screenshots in form of tags <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> Tracking of Micro Unmanned Aerial Vehicles: A Comparative Study <a href="https://arxiv.org/pdf/2001.06066" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Increasing the robustness of DNNs against image corruptions by playing  the Game of Noise <a href="https://arxiv.org/pdf/2001.06057" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> Modality-Balanced Models for Visual Dialogue <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> Tethered Aerial Visual Assistance <a href="https://arxiv.org/pdf/2001.06347" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<div id="title26">
<b>26.</b> DeepSUM++: Non-local Deep Neural Network for Super-Resolution of  Unregistered Multitemporal Images <a href="https://arxiv.org/pdf/2001.06342" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper26" style="color:#0000EE;">摘要</a><br></div>
<div id="title27">
<b>27.</b> Detection Method Based on Automatic Visual Shape Clustering for  Pin-Missing Defect in Transmission Lines <a href="https://arxiv.org/pdf/2001.06236" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper27" style="color:#0000EE;">摘要</a><br></div>
<div id="title28">
<b>28.</b> Sideways: Depth-Parallel Training of Video Models <a href="https://arxiv.org/pdf/2001.06232" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper28" style="color:#0000EE;">摘要</a><br></div>
<div id="title29">
<b>29.</b> FedVision: An Online Visual Object Detection Platform Powered by  Federated Learning <a href="https://arxiv.org/pdf/2001.06202" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper29" style="color:#0000EE;">摘要</a><br></div>
<div id="title30">
<b>30.</b> Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless  Approach <a href="https://arxiv.org/pdf/2001.06175" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper30" style="color:#0000EE;">摘要</a><br></div>
<div id="title31">
<b>31.</b> An adversarial learning framework for preserving users' anonymity in  face-based emotion recognition <a href="https://arxiv.org/pdf/2001.06103" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper31" style="color:#0000EE;">摘要</a><br></div>
<div id="title32">
<b>32.</b> Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for  Making a CNN Classifier Robust Against Adversarial Attacks <a href="https://arxiv.org/pdf/2001.06099" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper32" style="color:#0000EE;">摘要</a><br></div>
<div id="title33">
<b>33.</b> Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised  Learning <a href="https://arxiv.org/pdf/2001.06001" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper33" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Unsupervised Learning of Camera Pose with Compositional Re-estimation</b>  <a href="https://arxiv.org/pdf/2001.06479" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Nabavi%2C+S+S" target="_blank" rel="noopener" style="color:#0000EE;">Seyed Shahabeddin Nabavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hosseinzadeh%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mehrdad Hosseinzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fahimi%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ramin Fahimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Wang</a><br>
<font size="3">
Abstract: We consider the problem of unsupervised camera pose estimation. Given an input video sequence, our goal is to estimate the camera pose (i.e. the camera motion) between consecutive frames. Traditionally, this problem is tackled by placing strict constraints on the transformation vector or by incorporating optical flow through a complex pipeline. We propose an alternative approach that utilizes a compositional re-estimation process for camera pose estimation. Given an input, we first estimate a depth map. Our method then iteratively estimates the camera motion based on the estimated depth map. Our approach significantly improves the predicted camera motion both quantitatively and visually. Furthermore, the re-estimation resolves the problem of out-of-boundaries pixels in a novel and simple way. Another advantage of our approach is that it is adaptable to other camera pose estimation approaches. Experimental analysis on KITTI benchmark dataset demonstrates that our method outperforms existing state-of-the-art approaches in unsupervised camera ego-motion estimation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们认为监督的相机姿态估计的问题。给定的输入视频序列，我们的目标是估计连续帧之间的摄像机姿态（即，照相机运动）。传统上，这个问题是通过将严格的约束的转化载体或通过一个复杂的管道结合光流解决。我们建议，利用相机姿势估计的成分重新估计过程的替代方法。给定一个输入，我们首先估计深度图。然后，我们的迭代算法估计基于估计的深度地图上的摄像机运动。我们的方法在数量上和视觉上显著提高了预测的摄像机运动。此外，重新估计解决了一种新颖和简单的方式外的边界像素的问题。我们的方法的另一个优点是，它是适用于其他相机姿态估计方法。上KITTI基准数据集试验分析表明，我们现有的最先进的国家的方法优于在无监督照相机自运动估计方法。</font>
</div>


<hr>
<div id="paper2"> <b>2. Combining PRNU and noiseprint for robust and efficient device source  identification</b>  <a href="https://arxiv.org/pdf/2001.06440" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cozzolino%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davide Cozzolino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marra%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Francesco Marra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gragnaniello%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Diego Gragnaniello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poggi%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giovanni Poggi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Verdoliva%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luisa Verdoliva</a><br>
<font size="3">
Abstract: PRNU-based image processing is a key asset in digital multimedia forensics. It allows for reliable device identification and effective detection and localization of image forgeries, in very general conditions. However, performance impairs significantly in challenging conditions involving low quality and quantity of data. These include working on compressed and cropped images, or estimating the camera PRNU pattern based on only a few images. To boost the performance of PRNU-based analyses in such conditions we propose to leverage the image noiseprint, a recently proposed camera-model fingerprint that has proved effective for several forensic tasks. Numerical experiments on datasets widely used for source identification prove that the proposed method ensures a significant performance improvement in a wide range of challenging situations. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于PRNU图像处理是数字多媒体取证的重要资产。它允许可靠的装置识别和有效的检测和图像伪造的定位，在很一般的条件。然而，性能也妨碍显著在挑战包括低质量和数据量的条件。这些包括工作压缩和裁切图像，或估计基于只有少数图像中的相机PRNU图案。为了提高在这样的条件下基于PRNU-分析的性能，我们提出了利用图像noiseprint，已被证明有效的几个法医任务的最近提出的相机型号的指纹。上的数据集广泛用于源识别数值实验证明，该方法确保在广泛的挑战的情况一显著性能改进。</font>
</div>


<hr>
<div id="paper3"> <b>3. TailorGAN: Making User-Defined Fashion Designs</b>  <a href="https://arxiv.org/pdf/2001.06427" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lele Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Justin Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cheng-Haw Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=King%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Erh-Kan King</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kuan-Ting Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsieh%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shao-Hang Hsieh</a><br>
<font size="3">
Abstract: Attribute editing has become an important and emerging topic of computer vision. In this paper, we consider a task: given a reference garment image A and another image B with target attribute (collar/sleeve), generate a photo-realistic image which combines the texture from reference A and the new attribute from reference B. The highly convoluted attributes and the lack of paired data are the main challenges to the task. To overcome those limitations, we propose a novel self-supervised model to synthesize garment images with disentangled attributes (e.g., collar and sleeves) without paired data. Our method consists of a reconstruction learning step and an adversarial learning step. The model learns texture and location information through reconstruction learning. And, the model's capability is generalized to achieve single-attribute manipulation by adversarial learning. Meanwhile, we compose a new dataset, named GarmentSet, with annotation of landmarks of collars and sleeves on clean garment images. Extensive experiments on this dataset and real-world samples demonstrate that our method can synthesize much better results than the state-of-the-art methods in both quantitative and qualitative comparisons. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：属性编辑已经成为计算机视觉的一个重要和新兴的话题。在本文中，我们考虑一个任务：给定一个参考服装图像A和与目标属性（领/套筒）另一图像B，生成结合了从参考点A的质地和从参考B的新的属性的照片般逼真的图像高度令人费解的属性和缺乏配对数据是任务的主要挑战。为了克服这些限制，我们提出了一种新型的自监督模型以合成服装图像与解缠结的属性（例如，领子和袖子），而不配对数据。我们的方法包括一个重建学习步骤和敌对学习步骤的。该模型通过学习学习重建质地和位置信息。而且，该模型的能力是广义的对抗学习，实现单属性操作。同时，我们组成一个新的数据集，名为GarmentSet，用干净的服装图像领子和袖子的地标标注。在此数据集和真实世界的样本大量的实验表明，我们的方法可以合成比国家的最先进的方法，定量和定性的比较更好的结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. Subjective Annotation for a Frame Interpolation Benchmark using Artifact  Amplification</b>  <a href="https://arxiv.org/pdf/2001.06409" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Men%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hui Men</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hosu%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vlad Hosu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hanhe Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bruhn%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrés Bruhn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Saupe%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dietmar Saupe</a><br>
<font size="3">
Abstract: Current benchmarks for optical flow algorithms evaluate the estimation either directly by comparing the predicted flow fields with the ground truth or indirectly by using the predicted flow fields for frame interpolation and then comparing the interpolated frames with the actual frames. In the latter case, objective quality measures such as the mean squared error are typically employed. However, it is well known that for image quality assessment, the actual quality experienced by the user cannot be fully deduced from such simple measures. Hence, we conducted a subjective quality assessment crowdscouring study for the interpolated frames provided by one of the optical flow benchmarks, the Middlebury benchmark. It contains interpolated frames from 155 methods applied to each of 8 contents. We collected forced choice paired comparisons between interpolated images and corresponding ground truth. To increase the sensitivity of observers when judging minute difference in paired comparisons we introduced a new method to the field of full-reference quality assessment, called artifact amplification. From the crowdsourcing data we reconstructed absolute quality scale values according to Thurstone's model. As a result, we obtained a re-ranking of the 155 participating algorithms w.r.t. the visual quality of the interpolated frames. This re-ranking not only shows the necessity of visual quality assessment as another evaluation metric for optical flow and frame interpolation benchmarks, the results also provide the ground truth for designing novel image quality assessment (IQA) methods dedicated to perceptual quality of interpolated images. As a first step, we proposed such a new full-reference method, called WAE-IQA. By weighing the local differences between an interpolated image and its ground truth WAE-IQA performed slightly better than the currently best FR-IQA approach from the literature. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：用于光学流算法电流基准通过与地面实况地或间接地通过使用所预测的流场为帧内插，然后比较实际帧中的内插帧进行比较的预测的流场评价了估计直接。在后者的情况下，客观质量的措施，如均方误差，通常采用。但是，众所周知，对于图像质量评价，用户体验到的实际质量不能完全从这些简单的措施推出。因此，我们进行了由所述光流基准之一，所述明德基准提供的内插帧主观质量评估crowdscouring研究。它包含从施加到每个8项内容155点的方法的内插帧。我们收集了强制插入图片和相应的地面实况之间选择配对比较。为了增加观察员的灵敏度，当在配对比较判断分差，我们引入了一个新的方法来全参考质量评估领域，被称为神器放大。从众包数据，我们根据瑟斯顿模型重建质量绝对刻度值。其结果是，我们获得了155种参与算法的重新排名w.r.t.内插帧的视觉质量。这个重新排序不仅示出了视觉质量评估作为另一个评价度量光流和帧插值基准的必要性，该结果也提供了设计新的图像质量评价地面实况（IQA）的方法专用于内插图像的感知质量。作为第一步，我们提出了这样一个新的全参考方法，称为WAE-IQA。通过称重插入图像和地面实况WAE-IQA之间的局部差异不是从文献中目前最好的FR-IQA方法表现稍好。</font>
</div>


<hr>
<div id="paper5"> <b>5. GraphBGS: Background Subtraction via Recovery of Graph Signals</b>  <a href="https://arxiv.org/pdf/2001.06404" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Giraldo%2C+J+H" target="_blank" rel="noopener" style="color:#0000EE;">Jhony H. Giraldo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bouwmans%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thierry Bouwmans</a><br>
<font size="3">
Abstract: Graph-based algorithms have been successful approaching the problems of unsupervised and semi-supervised learning. Recently, the theory of graph signal processing and semi-supervised learning have been combined leading to new developments and insights in the field of machine learning. In this paper, concepts of recovery of graph signals and semi-supervised learning are introduced in the problem of background subtraction. We propose a new algorithm named GraphBGS, this method uses a Mask R-CNN for instances segmentation; temporal median filter for background initialization; motion, texture, color, and structural features for representing the nodes of a graph; k-nearest neighbors for the construction of the graph; and finally a semi-supervised method inspired from the theory of recovery of graph signals to solve the problem of background subtraction. The method is evaluated on the publicly available change detection, and scene background initialization databases. Experimental results show that GraphBGS outperforms unsupervised background subtraction algorithms in some challenges of the change detection dataset. And most significantly, this method outperforms generative adversarial networks in unseen videos in some sequences of the scene background initialization database. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于图的算法已经成功逼近无监督和半监督学习的问题。近日，图形信号处理和半监督学习的理论已被合并导致新的进展和见解，在机器学习领域。在本文中，图形信号及半监督学习的恢复的概念背景减除的问题进行了介绍。我们提出了一种新的算法命名GraphBGS，这种方法使用面膜R-CNN的情况下，分割;时间中值滤波器，用于背景初始化;运动，纹理，颜色和用于表示图中的节点的结构特征; k最近的图的构造的邻居;最后一个半监督方法从图信号的恢复的理论启发解决背景减除的问题。该方法在可公开获得的变化检测评价，并现场后台初始化数据库。实验结果表明，在变化检测数据集的一些挑战GraphBGS性能优于无人监督的背景减除算法。而最显著，这种方法优于在场景后台初始化数据库的一些序列看不见的视频生成对抗性的网络。</font>
</div>


<hr>
<div id="paper6"> <b>6. Latency-Aware Differentiable Neural Architecture Search</b>  <a href="https://arxiv.org/pdf/2001.06392" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuhui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xie%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lingxi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaopeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bowen Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qi Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xiong%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongkai Xiong</a><br>
<font size="3">
Abstract: Differentiable neural architecture search methods became popular in automated machine learning, mainly due to their low search costs and flexibility in designing the search space. However, these methods suffer the difficulty in optimizing network, so that the searched network is often unfriendly to hardware. This paper deals with this problem by adding a differentiable latency loss term into optimization, so that the search process can tradeoff between accuracy and latency with a balancing coefficient. The core of latency prediction is to encode each network architecture and feed it into a multi-layer regressor, with the training data being collected from randomly sampling a number of architectures and evaluating them on the hardware. We evaluate our approach on NVIDIA Tesla-P100 GPUs. With 100K sampled architectures (requiring a few hours), the latency prediction module arrives at a relative error of lower than 10\%. Equipped with this module, the search method can reduce the latency by 20% meanwhile preserving the accuracy. Our approach also enjoys the ability of being transplanted to a wide range of hardware platforms with very few efforts, or being used to optimizing other non-differentiable factors such as power consumption. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：微的神经结构的搜索方法成为自动化机器学习流行，主要是由于其较低的搜寻成本和设计的搜索空间的灵活性。然而，这些方法在遭受网络优化的难度，使网络搜索往往是不友好的硬件。这与这个问题论文涉及通过添加微延迟损失项为优化，使之与平衡系数精度和延迟之间的搜索过程可以权衡。延迟预测的核心是编码每个网络结构和它送入多层回归，与从随机抽样的数架构和硬件评估他们被收集训练数据。我们评估我们对NVIDIA的Tesla-P100 GPU的方法。用100K采样架构（需要几个小时），等待时间预测模块到达的低于10 \％的相对误差。配备该模块，搜索方法可以通过20％的同时保持准确度降低延迟。我们的方法也享有被移植到了广泛的硬件平台用很少的努力，或者被用来优化其它非微因素，例如功耗的能力。</font>
</div>


<hr>
<div id="paper7"> <b>7. BigEarthNet Deep Learning Models with A New Class-Nomenclature for  Remote Sensing Image Understanding</b>  <a href="https://arxiv.org/pdf/2001.06372" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Sumbul%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gencer Sumbul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kreuziger%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tristan Kreuziger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marcelino%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Filipe Marcelino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Costa%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hugo Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Benevides%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pedro Benevides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Caetano%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mario Caetano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Demir%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Begüm Demir</a><br>
<font size="3">
Abstract: Success of deep neural networks in the framework of remote sensing (RS) image analysis depends on the availability of a high number of annotated images. BigEarthNet is a new large-scale Sentinel-2 benchmark archive that has been recently introduced in RS to advance deep learning (DL) studies. Each image patch in BigEarthNet is annotated with multi-labels provided by the CORINE Land Cover (CLC) map of 2018 based on its most thematic detailed Level-3 class nomenclature. BigEarthNet has enabled data-hungry DL algorithms to reach high performance in the context of multi-label RS image retrieval and classification. However, initial research demonstrates that some CLC classes are challenging to be accurately described by considering only (single-date) Sentinel-2 images. To further increase the effectiveness of BigEarthNet, in this paper we introduce an alternative class-nomenclature to allow DL models for better learning and describing the complex spatial and spectral information content of the Sentinel-2 images. This is achieved by interpreting and arranging the CLC Level-3 nomenclature based on the properties of Sentinel-2 images in a new nomenclature of 19 classes. Then, the new class-nomenclature of BigEarthNet is used within state-of-the-art DL models (namely VGG model at the depth of 16 and 19 layers [VGG16 and VGG19] and ResNet model at the depth of 50, 101 and 152 layers [ResNet50, ResNet101, ResNet152] as well as K-Branch CNN model) in the context of multi-label classification. Experimental results show that the models trained from scratch on BigEarthNet outperform those pre-trained on ImageNet, especially in relation to some complex classes including agriculture and other vegetated and natural environments. All DL models are made publicly available, offering an important resource to guide future progress on content based image retrieval and scene classification problems in RS. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：遥感（RS）图像分析的框架深神经网络的成功取决于大量的注释的图像的可用性。 BigEarthNet是已在RS最近推出深处前进学习（DL）研究提供了新的大型哨兵-2基准存档。在BigEarthNet每个图像补丁标注有基于其最详细的专题级别3级命名的2018年CORINE土地覆盖（CLC）地图提供多标签。 BigEarthNet已使大量数据的DL算法，以达到多标签遥感影像检索和分类的情况下的高性能。然而，最初的研究表明，一些CLC类是具有挑战性的通过仅考虑（单日期）被精确地描述的Sentinel-2的图像。为了进一步提高BigEarthNet的有效性，本文介绍一种替代类的术语来允许DL模型更好的学习和描述哨兵2图像的复杂的空间和光谱信息的内容。这是通过解释和布置基于哨兵-2图像的在19类的新命名法的属性CLC 3级命名法来实现的。然后，BigEarthNet的新的类命名法是国家的最先进的DL模型（即VGG模型内以16层19的层[VGG16和VGG19]和RESNET模型的深度使用在50，101和152的深度层[ResNet50，ResNet101，ResNet152]以及K-科CNN模型）在多标签分类的上下文。实验结果表明，从头开始培训了BigEarthNet跑赢车型的预先训练上ImageNet，特别是涉及到一些复杂的类，包括农业和其他植被和自然环境。所有DL型号都公之于众，提供指导在RS基于内容的图像检索及场景分类问题未来发展的重要资源。</font>
</div>


<hr>
<div id="paper8"> <b>8. Efficient Facial Feature Learning with Wide Ensemble-based Convolutional  Neural Networks</b>  <a href="https://arxiv.org/pdf/2001.06338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Siqueira%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Henrique Siqueira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Magg%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sven Magg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wermter%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stefan Wermter</a><br>
<font size="3">
Abstract: Ensemble methods, traditionally built with independently trained de-correlated models, have proven to be efficient methods for reducing the remaining residual generalization error, which results in robust and accurate methods for real-world applications. In the context of deep learning, however, training an ensemble of deep networks is costly and generates high redundancy which is inefficient. In this paper, we present experiments on Ensembles with Shared Representations (ESRs) based on convolutional networks to demonstrate, quantitatively and qualitatively, their data processing efficiency and scalability to large-scale datasets of facial expressions. We show that redundancy and computational load can be dramatically reduced by varying the branching level of the ESR without loss of diversity and generalization power, which are both important for ensemble performance. Experiments on large-scale datasets suggest that ESRs reduce the remaining residual generalization error on the AffectNet and FER+ datasets, reach human-level performance, and outperform state-of-the-art methods on facial expression recognition in the wild using emotion and affect concepts. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：集成方法，传统上与​​独立的培训去相关模型构建，已被证明是减少残留的剩余泛化误差，有效的方法，这导致对现实世界的应用健全和准确的方法。在深学习的情况下，然而，培养深网络的集合是昂贵的，并且产生高冗余这是低效的。在本文中，我们对合奏基于卷积网络证明，定量和定性地共享交涉（的ESR）本实验中，它们的数据处理效率和可扩展性的面部表情的大规模数据集。我们发现可以通过改变ESR的无分集和概括断电分支水平，这既是对合奏表演重要的急剧减少了冗余和计算负载。在大型数据集的实验表明，的ESR减少对AffectNet和FER +数据集，达到人类水平的性能，以及使用情感上的野生面部表情识别跑赢大市的国家的最先进的方法，直接影响概念的剩余的残留泛化的错误。</font>
</div>


<hr>
<div id="paper9"> <b>9. Vision Meets Drones: Past, Present and Future</b>  <a href="https://arxiv.org/pdf/2001.06303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pengfei Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wen%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Longyin Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Du%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dawei Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bian%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiao Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinghua Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ling%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haibin Ling</a><br>
<font size="3">
Abstract: Drones, or general UAVs, equipped with cameras have been fast deployed with a wide range of applications, including agriculture, aerial photography, fast delivery, and surveillance. Consequently, automatic understanding of visual data collected from drones becomes highly demanding, bringing computer vision and drones more and more closely. To promote and track the developments of object detection and tracking algorithms, we have organized two challenge workshops in conjunction with European Conference on Computer Vision (ECCV) 2018, and IEEE International Conference on Computer Vision (ICCV) 2019, attracting more than 100 teams around the world. We provide a large-scale drone captured dataset, VisDrone, which includes four tracks, i.e., (1) image object detection, (2) video object detection, (3) single object tracking, and (4) multi-object tracking. This paper first presents a thorough review of object detection and tracking datasets and benchmarks, and discuss the challenges of collecting large-scale drone-based object detection and tracking datasets with fully manual annotations. After that, we describe our VisDrone dataset, which is captured over various urban/suburban areas of $14$ different cities across China from North to South. Being the largest such dataset ever published, VisDrone enables extensive evaluation and investigation of visual analysis algorithms on the drone platform. We provide a detailed analysis of the current state of the field of large-scale object detection and tracking on drones, and conclude the challenge as well as propose future directions and improvements. We expect the benchmark largely boost the research and development in video analysis on drone platforms. All the datasets and experimental results can be downloaded from the website: this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：无人机或者一般的无人机，配备摄像头已经迅速部署具有广泛的应用，包括农业，航空摄影，交货快，和监视。因此，从无人机采集的视频数据的自动理解变得极高，将计算机视觉和无人驾驶飞机越来越紧密。为了促进和跟踪目标检测与跟踪算法的发展，我们已经组织了一起2次挑战研讨会，欧洲会议计算机视觉（ECCV）2018，以及计算机视觉（ICCV）2019 IEEE国际会议，吸引了100多个团队世界。我们提供了一个大型雄蜂捕获数据集，VisDrone，它包括四个磁道，即，（1）图像对象检测，（2）视频对象检测，（3）单目标跟踪，和（4）的多目标跟踪。本文首先介绍目标检测与跟踪数据集和基准进行彻底审查，并讨论收集大型无人机基于体检测，并与全手动注释跟踪数据集的挑战。在那之后，我们描述了我们VisDrone数据集，这是超过$ $ 14在中国不同的城市，从南到北各个城市/郊区抓获。作为最大的此类数据集出版过的，VisDrone使广泛的评估和无人机平台上的视觉分析算法调查。我们提供大型物体检测和跟踪在无人机领域的现状进行了详细分析，并得出结论以及提出未来的发展方向和改进的挑战。我们预计恒生很大程度上提高对无人机平台在视频分析的研究和开发。此HTTPS URL：所有数据集和实验结果可以从网站上下载。</font>
</div>


<hr>
<div id="paper10"> <b>10. Predicting the Physical Dynamics of Unseen 3D Objects</b>  <a href="https://arxiv.org/pdf/2001.06291" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Rempe%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davis Rempe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sridhar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Srinath Sridhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">He Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guibas%2C+L+J" target="_blank" rel="noopener" style="color:#0000EE;">Leonidas J. Guibas</a><br>
<font size="3">
Abstract: Machines that can predict the effect of physical interactions on the dynamics of previously unseen object instances are important for creating better robots and interactive virtual worlds. In this work, we focus on predicting the dynamics of 3D objects on a plane that have just been subjected to an impulsive force. In particular, we predict the changes in state - 3D position, rotation, velocities, and stability. Different from previous work, our approach can generalize dynamics predictions to object shapes and initial conditions that were unseen during training. Our method takes the 3D object's shape as a point cloud and its initial linear and angular velocities as input. We extract shape features and use a recurrent neural network to predict the full change in state at each time step. Our model can support training with data from both a physics engine or the real world. Experiments show that we can accurately predict the changes in state for unseen object geometries and initial conditions. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机器，可以预测在以前看不见的对象实例的动态物理相互作用的作用是创造更好的机器人和互动的虚拟世界重要。在这项工作中，我们侧重于预测对刚刚经受冲击力的平面3D对象的动态。特别是，我们预测状态的变化 - 三维位置，旋转，速度和稳定性。从以前的工作不同的是，我们的方法可以概括的动态预测到物体的形状和初始条件的培训过程中看不见。我们的方法利用该3D对象的形状为点云和它的初始线速度和角速度作为输入。我们提取形状特征和使用回归神经网络在每个时间步来预测状态充满变化。我们的模型可以支持从两个物理引擎或现实世界的数据训练。实验结果表明，我们可以精确地预测为看不见的对象的几何形状和初始条件状态中的变化。</font>
</div>


<hr>
<div id="paper11"> <b>11. Review: deep learning on 3D point clouds</b>  <a href="https://arxiv.org/pdf/2001.06280" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bello%2C+S+A" target="_blank" rel="noopener" style="color:#0000EE;">Saifullahi Aminu Bello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shangshu Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cheng Wang</a><br>
<font size="3">
Abstract: Point cloud is point sets defined in 3D metric space. Point cloud has become one of the most significant data format for 3D representation. Its gaining increased popularity as a result of increased availability of acquisition devices, such as LiDAR, as well as increased application in areas such as robotics, autonomous driving, augmented and virtual reality. Deep learning is now the most powerful tool for data processing in computer vision, becoming the most preferred technique for tasks such as classification, segmentation, and detection. While deep learning techniques are mainly applied to data with a structured grid, point cloud, on the other hand, is unstructured. The unstructuredness of point clouds makes use of deep learning for its processing directly very challenging. Earlier approaches overcome this challenge by preprocessing the point cloud into a structured grid format at the cost of increased computational cost or lost of depth information. Recently, however, many state-of-the-arts deep learning techniques that directly operate on point cloud are being developed. This paper contains a survey of the recent state-of-the-art deep learning techniques that mainly focused on point cloud data. We first briefly discussed the major challenges faced when using deep learning directly on point cloud, we also briefly discussed earlier approaches which overcome the challenges by preprocessing the point cloud into a structured grid. We then give the review of the various state-of-the-art deep learning approaches that directly process point cloud in its unstructured form. We introduced the popular 3D point cloud benchmark datasets. And we also further discussed the application of deep learning in popular 3D vision tasks including classification, segmentation and detection. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：点云是3D度量空间定义的点集。点云已成为3D表示最显著数据格式之一。它获得越来越多的受欢迎程度增加采集设备，如激光雷达的可用性，以及在诸如机器人，自动驾驶等领域加强应用，增强和虚拟现实的结果。现在深学习是数据在计算机视觉处理的最有力的工具，成为任务，如分类，细分和检测的最优选的技术。虽然深学习技术主要应用于数据与结构化网格，点云，在另一方面，是非结构化的。该unstructuredness点云的利用深度学习的其直接处理非常具有挑战性。早期的方法通过预处理点云成结构化的网格格式以增加计算成本的成本或丢失的深度信息克服这一挑战。然而，最近深学习直接对点云操作的技术的许多艺术国家的正在开发中。本文件包含了一个调查国家的最先进的深得知主要集中在点云数据的技术，最近的。我们首先简要讨论了使用深直接在点云学习时所面临的重大挑战，我们还简要讨论克服通过预处理点云成结构化网格的挑战，早期的方法。然后，我们给国家的最先进的各种深学习的复习方法直接处理点云中的非结构化的形式。我们引进了当前流行的三维点云标准数据集。我们还进一步讨论在流行的3D视觉任务，包括分类，分割和检测深度学习的应用。</font>
</div>


<hr>
<div id="paper12"> <b>12. Compounding the Performance Improvements of Assembled Techniques in a  Convolutional Neural Network</b>  <a href="https://arxiv.org/pdf/2001.06268" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jungkyu Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Won%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taeryun Won</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hong%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kiho Hong</a><br>
<font size="3">
Abstract: Recent studies in image classification have demonstrated a variety of techniques for improving the performance of Convolutional Neural Networks (CNNs). However, attempts to combine existing techniques to create a practical model are still uncommon. In this study, we carry out extensive experiments to validate that carefully assembling these techniques and applying them to a basic CNN model in combination can improve the accuracy and robustness of the model while minimizing the loss of throughput. For example, our proposed ResNet-50 shows an improvement in top-1 accuracy from 76.3% to 82.78%, and an mCE improvement from 76.0% to 48.9%, on the ImageNet ILSVRC2012 validation set. With these improvements, inference throughput only decreases from 536 to 312. The resulting model significantly outperforms state-of-the-art models with similar accuracy in terms of mCE and inference throughput. To verify the performance improvement in transfer learning, fine grained classification and image retrieval tasks were tested on several open datasets and showed that the improvement to backbone network performance boosted transfer learning performance significantly. Our approach achieved 1st place in the iFood Competition Fine-Grained Visual Recognition at CVPR 2019, and the source code and trained models are available at this https URL </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在图像分类最近的研究表明多种用于改善卷积神经网络（细胞神经网络）的表现技法。不过，对现有技术结合起来，创造一个实际的模型仍屡见不鲜。在这项研究中，我们进行了广泛的实验，以验证仔细组装这些技术并将它们应用到结合的基本模式CNN能提高模型的精确度和耐用性，同时最大限度地减少产量损失。例如，我们所提出的RESNET-50示出了在顶部-1精度的提高，从76.3％到82.78％，和从76.0％的MCE改善48.9％，对ImageNet ILSVRC2012验证集。有了这些改进，推理可以通过仅降低从536到312得到的模型显著优于状态的最先进的模型具有类似的精度在MCE和推理吞吐量方面。为了验证迁移学习，细粒分类和图像检索任务的性能改进上几个开放的数据集进行了测试，结果表明，提高骨干网络的性能提升传输学习表现显著。我们的方法在iFood比赛细粒度的视觉识别在CVPR 2019获得第一名，源代码和训练的模型可在此HTTPS URL</font>
</div>


<hr>
<div id="paper13"> <b>13. SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On</b>  <a href="https://arxiv.org/pdf/2001.06265" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Jandial%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Surgan Jandial</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chopra%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ayush Chopra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ayush%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kumar Ayush</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hemani%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mayur Hemani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Abhijeet Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Krishnamurthy%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Balaji Krishnamurthy</a><br>
<font size="3">
Abstract: Image-based virtual try-on for fashion has gained considerable attention recently. The task requires trying on a clothing item on a target model image. An efficient framework for this is composed of two stages: (1) warping (transforming) the try-on cloth to align with the pose and shape of the target model, and (2) a texture transfer module to seamlessly integrate the warped try-on cloth onto the target model image. Existing methods suffer from artifacts and distortions in their try-on output. In this work, we present SieveNet, a framework for robust image-based virtual try-on. Firstly, we introduce a multi-stage coarse-to-fine warping network to better model fine-grained intricacies (while transforming the try-on cloth) and train it with a novel perceptual geometric matching loss. Next, we introduce a try-on cloth conditioned segmentation mask prior to improve the texture transfer network. Finally, we also introduce a dueling triplet loss strategy for training the texture translation network which further improves the quality of the generated try-on results. We present extensive qualitative and quantitative evaluations of each component of the proposed pipeline and show significant performance improvements against the current state-of-the-art method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于映像的虚拟试穿时装最近获得了相当大的关注。任务需要试穿的目标模型图像上的衣物。这种高效的框架由两个阶段组成：（1）翘曲（变换）的试穿布与目标模型的姿态和形状对齐，和（2）的纹理传送模块无缝集成翘曲试戴上布到目标模型图像。现有的方法从它们的试穿输出文物和扭曲痛苦。在这项工作中，我们提出SieveNet，对于稳健的基于图像的虚拟试穿的框架。首先，我们引入一个多级粗到细的翘曲网络，以更好地模型细粒度错综复杂（同时改造试穿布），并用新的知觉几何匹配损耗训练它。接下来，我们引入一个试穿改善质地传递网络之前布空调分割掩码。最后，我们还引进了决斗三重损失的策略训练纹理翻译网络，进一步提高了产生试穿结果的质量。我们提出了广泛的定性和建议的管道中各组分的定量评估，显示对当前国家的最先进的方法显著的性能改进。</font>
</div>


<hr>
<div id="paper14"> <b>14. Two-Phase Object-Based Deep Learning for Multi-temporal SAR Image Change  Detection</b>  <a href="https://arxiv.org/pdf/2001.06252" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinzheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Ce Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Atkinson%2C+P+M" target="_blank" rel="noopener" style="color:#0000EE;">Peter M Atkinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoheng Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jian%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Jian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xichuan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yongming Li</a><br>
<font size="3">
Abstract: Change detection is one of the fundamental applications of synthetic aperture radar (SAR) images. However, speckle noise presented in SAR images has a much negative effect on change detection. In this research, a novel two-phase object-based deep learning approach is proposed for multi-temporal SAR image change detection. Compared with traditional methods, the proposed approach brings two main innovations. One is to classify all pixels into three categories rather than two categories: unchanged pixels, changed pixels caused by strong speckle (false changes), and changed pixels formed by real terrain variation (real changes). The other is to group neighboring pixels into segmented into superpixel objects (from pixels) such as to exploit local spatial context. Two phases are designed in the methodology: 1) Generate objects based on the simple linear iterative clustering algorithm, and discriminate these objects into changed and unchanged classes using fuzzy c-means (FCM) clustering and a deep PCANet. The prediction of this Phase is the set of changed and unchanged superpixels. 2) Deep learning on the pixel sets over the changed superpixels only, obtained in the first phase, to discriminate real changes from false changes. SLIC is employed again to achieve new superpixels in the second phase. Low rank and sparse decomposition are applied to these new superpixels to suppress speckle noise significantly. A further clustering step is applied to these new superpixels via FCM. A new PCANet is then trained to classify two kinds of changed superpixels to achieve the final change maps. Numerical experiments demonstrate that, compared with benchmark methods, the proposed approach can distinguish real changes from false changes effectively with significantly reduced false alarm rates, and achieve up to 99.71% change detection accuracy using multi-temporal SAR imagery. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：变化检测是合成孔径雷达（SAR）图像的基本应用中的一个。然而，斑点的SAR图像噪声提出了变化检测更负面的影响。在这项研究中，一种新型的两相基于对象的深度学习方法提出了多时相SAR图像变化检测。与传统方法相比，该方法带来了两个主要的创新。一是所有像素分为三类，而不是两类：不变的像素，改变像素造成强烈的斑点（假的变化），并改变了像素的实际地形的变化（真正的变化）而形成。另一种是相邻像素到分割成超像素的对象（从像素），如以利用局部空间上下文组。两个相被设计成在该方法：1）基于该简单的线性迭代聚类算法的目的，并区分这些对象到使用模糊c均值（FCM）聚类和深PCANet变与不变类。这个阶段的预测是一组变与不变的超像素。 2）上的像素集在所述改变仅超像素，在第一阶段中获得的，深学习辨别从虚假变化的实际变化。 SLIC被再次用来实现第二阶段的新的超像素。低等级和稀疏分解的噪音显著应用到这些新的超像素来抑制斑点。进一步的聚类步骤被施加到通过FCM这些新的超像素。然后，新的PCANet被训练2种改变超级像素的分类，以实现最终的变化图。数值结果表明，与基准方法相比，该方法可以区分有效地降低了显著的误报率假的变化真正的变化，实现了利用多时相SAR影像99.71％的变化检测精度。</font>
</div>


<hr>
<div id="paper15"> <b>15. Registration made easy -- standalone orthopedic navigation with HoloLens</b>  <a href="https://arxiv.org/pdf/2001.06209" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liebmann%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Florentin Liebmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Roner%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Roner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=von+Atzigen%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marco von Atzigen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wanivenhaus%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Florian Wanivenhaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Neuhaus%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Caroline Neuhaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Spirig%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">José Spirig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Scaramuzza%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Davide Scaramuzza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sutter%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Reto Sutter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Snedeker%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jess Snedeker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Farshad%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mazda Farshad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=F%C3%BCrnstahl%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Philipp Fürnstahl</a><br>
<font size="3">
Abstract: In surgical navigation, finding correspondence between preoperative plan and intraoperative anatomy, the so-called registration task, is imperative. One promising approach is to intraoperatively digitize anatomy and register it with the preoperative plan. State-of-the-art commercial navigation systems implement such approaches for pedicle screw placement in spinal fusion surgery. Although these systems improve surgical accuracy, they are not gold standard in clinical practice. Besides economical reasons, this may be due to their difficult integration into clinical workflows and unintuitive navigation feedback. Augmented Reality has the potential to overcome these limitations. Consequently, we propose a surgical navigation approach comprising intraoperative surface digitization for registration and intuitive holographic navigation for pedicle screw placement that runs entirely on the Microsoft HoloLens. Preliminary results from phantom experiments suggest that the method may meet clinical accuracy requirements. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在手术导航，术前计划及术中解剖，所谓的注册任务之间找到对应，势在必行。一个可行的方法是手术中数字化解剖，并与术前计划注册。国家的最先进的商用导航系统实现了对脊柱融合术椎弓根螺钉放置这些方法。虽然这些系统提高手术准确性，他们不是在临床实践中的金标准。除了经济上的原因，这可能是由于他们难以融入临床工作流程和直观的导航反馈。增强现实必须克服这些局限性的潜力。因此，我们提出了一种外科手术导航的方法，包括用于登记和直观的全息术中的导航表面的数字化椎弓根螺钉放置的是完全在Microsoft HoloLens运行。从幻像实验的初步结果表明，该方法可满足临床的精度要求。</font>
</div>


<hr>
<div id="paper16"> <b>16. FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for  Semi-supervised Optical Flow Estimation</b>  <a href="https://arxiv.org/pdf/2001.06171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaolin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cuiling Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zeng%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenjun Zeng</a><br>
<font size="3">
Abstract: Optical flow estimation is an important yet challenging problem in the field of video analytics. The features of different semantics levels/layers of a convolutional neural network can provide information of different granularity. To exploit such flexible and comprehensive information, we propose a semi-supervised Feature Pyramidal Correlation and Residual Reconstruction Network (FPCR-Net) for optical flow estimation from frame pairs. It consists of two main modules: pyramid correlation mapping and residual reconstruction. The pyramid correlation mapping module takes advantage of the multi-scale correlations of global/local patches by aggregating features of different scales to form a multi-level cost volume. The residual reconstruction module aims to reconstruct the sub-band high-frequency residuals of finer optical flow in each stage. Based on the pyramid correlation mapping, we further propose a correlation-warping-normalization (CWN) module to efficiently exploit the correlation dependency. Experiment results show that the proposed scheme achieves the state-of-the-art performance, with improvement by 0.80, 1.15 and 0.10 in terms of average end-point error (AEE) against competing baseline methods - FlowNet2, LiteFlowNet and PWC-Net on the Final pass of Sintel dataset, respectively. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：光流估计是视频分析领域的一个重要而具有挑战性的问题。不同的语义等级的特征/卷积神经网络的层可提供不同粒度的信息。为了利用这种柔性和全面的信息，我们提出了从帧双光流估计一个半监督功能锥体相关和残差重建网络（FPCR-净）。它包括两个主要模块：金字塔相关映射和残差重建。金字塔相关映射模块通过聚合不同尺度的特征，以形成多级成本体积利用全局/局部贴片的多尺度相关的。将残余的重建模块目标以重建在每个阶段中更精细的光流的子带的高频残差。基于金字塔的相关性映射，我们进一步提出的相关扭曲规范化（CWN）模块，以有效地利用的相关性依赖。实验结果表明，该方案由0.80，1.15和0.10，平均终点误差（AEE）来实现国家的最先进的性能，提高同台竞技基线方法 -  FlowNet2，LiteFlowNet和PWC-Net的上辛特尔数据集的最终道次，分别。</font>
</div>


<hr>
<div id="paper17"> <b>17. Interpreting Galaxy Deblender GAN from the Discriminator's Perspective</b>  <a href="https://arxiv.org/pdf/2001.06151" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuewei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mueller%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Klaus Mueller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Xu</a><br>
<font size="3">
Abstract: Generative adversarial networks (GANs) are well known for their unsupervised learning capabilities. A recent success in the field of astronomy is deblending two overlapping galaxy images via a branched GAN model. However, it remains a significant challenge to comprehend how the network works, which is particularly difficult for non-expert users. This research focuses on behaviors of one of the network's major components, the Discriminator, which plays a vital role but is often overlooked, Specifically, we enhance the Layer-wise Relevance Propagation (LRP) scheme to generate a heatmap-based visualization. We call this technique Polarized-LRP and it consists of two parts i.e. positive contribution heatmaps for ground truth images and negative contribution heatmaps for generated images. Using the Galaxy Zoo dataset we demonstrate that our method clearly reveals attention areas of the Discriminator when differentiating generated galaxy images from ground truth images. To connect the Discriminator's impact on the Generator, we visualize the gradual changes of the Generator across the training process. An interesting result we have achieved there is the detection of a problematic data augmentation procedure that would else have remained hidden. We find that our proposed method serves as a useful visual analytical tool for a deeper understanding of GAN models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：创成对抗网络（甘斯）是众所周知的无监督的学习能力。在天文学领域最近的成功经由支GAN模型去混合两个重叠的星系图像。然而，它仍然是一个挑战显著理解如何在网络的作品，这对非专业用户特别困难。这项研究的重点是网络的主要组成部分之一的行为，鉴别，它起着至关重要的作用，但往往被忽视，特别是，我们提高了逐层关联传播（LRP）方案来生成一个基于热图可视化。我们称这种技术偏光LRP，它由两个部分组成，即积极的贡献热图的地面真理图像和生成的图像负贡献热图。利用星系动物园的数据集，我们证明了我们的方法区分从地面实况图像生成星系图像时，清楚地表明鉴别的关注的领域。要连接鉴别对发电机的影响，我们可以形象地发电机的整个训练过程中逐渐变化。我们已经实现了有一个有趣的结果是，将其他仍然隐藏着一个问题的数据增高过程的检测。我们发现，我们提出的方法作为一个有用的可视化分析工具，GAN模式有更深的了解。</font>
</div>


<hr>
<div id="paper18"> <b>18. Learning to Augment Expressions for Few-shot Fine-grained Facial  Expression Recognition</b>  <a href="https://arxiv.org/pdf/2001.06144" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenxuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanwei Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cao%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chenjie Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zheng%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Ziqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guoqiang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yu-Gang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xue%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiangyang Xue</a><br>
<font size="3">
Abstract: Affective computing and cognitive theory are widely used in modern human-computer interaction scenarios. Human faces, as the most prominent and easily accessible features, have attracted great attention from researchers. Since humans have rich emotions and developed musculature, there exist a lot of fine-grained expressions in real-world applications. However, it is extremely time-consuming to collect and annotate a large number of facial images, of which may even require psychologists to correctly categorize them. To the best of our knowledge, the existing expression datasets are only limited to several basic facial expressions, which are not sufficient to support our ambitions in developing successful human-computer interaction systems. To this end, a novel Fine-grained Facial Expression Database - F2ED is contributed in this paper, and it includes more than 200k images with 54 facial expressions from 119 persons. Considering the phenomenon of uneven data distribution and lack of samples is common in real-world scenarios, we further evaluate several tasks of few-shot expression learning by virtue of our F2ED, which are to recognize the facial expressions given only few training instances. These tasks mimic human performance to learn robust and general representation from few examples. To address such few-shot tasks, we propose a unified task-driven framework Compositional Generative Adversarial Network (Comp-GAN) learning to synthesize facial images and thus augmenting the instances of few-shot expression classes. Extensive experiments are conducted on F2ED and existing facial expression datasets, i.e., JAFFE and FER2013, to validate the efficacy of our F2ED in pre-training facial expression recognition network and the effectiveness of our proposed approach Comp-GAN to improve the performance of few-shot recognition tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：情感计算和认知理论被广泛应用于现代的人机交互场景。人脸，作为最突出和方便的特点，从研究者的高度关注。由于人类具有丰富的情感和发达的肌肉，还存在很多现实世界的应用细粒度的表情。然而，这是非常耗时的收集和注释了大量面部图像，这甚至可能需要心理学家正确分类。据我们所知，现有的表达数据仅限于几个基本的面部表情，这是不足以支持我们的野心开发成功的人机交互系统。为此，一种新的细粒度面部表情数据库 -  F2ED在本文提供的，它包括超过200K的图像与来自119分的人54个的面部表情。考虑不均匀分布数据的现象，缺乏样品是现实世界的情景一样，我们还凭借我们F2ED，这是认识到只给出几个训练实例面部表情的评价几拍表达式学习的几个任务。这些任务模拟人类的表现从几个例子学习强大和一般的表示。为了解决这样的一些次任务，我们提出了一个统一的任务驱动的框架组成剖成对抗性网络（压缩 -  GAN）学习合成面部图像，从而增强几炮表达类的实例。大量的实验是在F2ED和现有的面部表情的数据集，即JAFFE和FER2013进行，以验证我们F2ED的功效在训练前的面部表情识别网络和我们提出的方法比较-GaN的有效性，提高few-性能镜头识别任务。</font>
</div>


<hr>
<div id="paper19"> <b>19. Spatio-Temporal Ranked-Attention Networks for Video Captioning</b>  <a href="https://arxiv.org/pdf/2001.06127" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cherian%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anoop Cherian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hori%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chiori Hori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marks%2C+T+K" target="_blank" rel="noopener" style="color:#0000EE;">Tim K. Marks</a><br>
<font size="3">
Abstract: Generating video descriptions automatically is a challenging task that involves a complex interplay between spatio-temporal visual features and language models. Given that videos consist of spatial (frame-level) features and their temporal evolutions, an effective captioning model should be able to attend to these different cues selectively. To this end, we propose a Spatio-Temporal and Temporo-Spatial (STaTS) attention model which, conditioned on the language state, hierarchically combines spatial and temporal attention to videos in two different orders: (i) a spatio-temporal (ST) sub-model, which first attends to regions that have temporal evolution, then temporally pools the features from these regions; and (ii) a temporo-spatial (TS) sub-model, which first decides a single frame to attend to, then applies spatial attention within that frame. We propose a novel LSTM-based temporal ranking function, which we call ranked attention, for the ST model to capture action dynamics. Our entire framework is trained end-to-end. We provide experiments on two benchmark datasets: MSVD and MSR-VTT. Our results demonstrate the synergy between the ST and TS modules, outperforming recent state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：生成视频描述自动是一个具有挑战性的任务，涉及到时空视觉特征和语言模型之间的复杂的相互作用。鉴于影片由空间（帧级）的功能及其时间的演化，有效的字幕模型应该能够参加到这些不同的线索选择性。为此，我们提出了时空和时间空间（STATS）注意模型，该模型，条件上的语言状态，分层结合的空间和时间关注到视频中两个不同的顺序：（I）的时空（ST）子模型，该第一照顾到具有时间演变，区域然后在时间上从池这些区域的特征;和（ii）一个时间空间（TS）的子模型，该模型首先决定单个帧出席，然后应用于的帧内的空间的关注。我们提出了一个新的基于LSTM-时间排序功能，我们称之为排名的重视，对于ST模型捕捉行动力度。我们的整个框架的培训结束到终端。我们提供了两个标准数据集实验：MSVD和MSR-VTT。我们的结果证明了ST和TS模块之间的协同作用，优于国家的最先进的最近的方法。</font>
</div>


<hr>
<div id="paper20"> <b>20. Automatic Discovery of Political Meme Genres with Diverse Appearances</b>  <a href="https://arxiv.org/pdf/2001.06122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Theisen%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">William Theisen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Brogan%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Joel Brogan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Thomas%2C+P+B" target="_blank" rel="noopener" style="color:#0000EE;">Pamela Bilo Thomas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moreira%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daniel Moreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Phoa%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pascal Phoa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weninger%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tim Weninger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Scheirer%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Walter Scheirer</a><br>
<font size="3">
Abstract: Forms of human communication are not static --- we expect some evolution in the way information is conveyed over time because of advances in technology. One example of this phenomenon is the image-based meme, which has emerged as a dominant form of political messaging in the past decade. While originally used to spread jokes on social media, memes are now having an outsized impact on public perception of world events. A significant challenge in automatic meme analysis has been the development of a strategy to match memes from within a single genre when the appearances of the images vary. Such variation is especially common in memes exhibiting mimicry. For example, when voters perform a common hand gesture to signal their support for a candidate. In this paper we introduce a scalable automated visual recognition pipeline for discovering political meme genres of diverse appearance. This pipeline can ingest meme images from a social network, apply computer vision-based techniques to extract local features and index new images into a database, and then organize the memes into related genres. To validate this approach, we perform a large case study on the 2019 Indonesian Presidential Election using a new dataset of over two million images collected from Twitter and Instagram. Results show that this approach can discover new meme genres with visually diverse images that share common stylistic elements, paving the way forward for further work in semantic analysis and content attribution. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人类的沟通方式不是一成不变的---我们期待的方式获取信息的一些变化传送随着时间的推移，因为技术的进步。这种现象的一个例子是基于图像的米姆，这已经成为过去十年政治信息的主要形式。虽然原本是用来传播的笑话在社会化媒体，模因现在不得不对世界事件的公众认知的丰厚影响。在自动梅梅分析的显著挑战是一项战略，从单一的体裁内匹配模因时图像的外观变化的发展。这种变化是中模仿记因尤其常见。例如，当执行选民一个共同的手势的信号其用于候选的支持。在本文中，我们介绍了用于发现不同外观的政治米姆流派一个可扩展的自动化视觉识别管道。这条管道可以从社交网络梅梅摄取图像，应用计算机基于视觉的技术来提取局部特征和指数新的图像到一个数据库，然后整理成模因相关流派。为了验证这种方法，我们使用从Twitter和Instagram的收集超过两百万图像的新的数据集上的2019印尼总统选举的一个大案例。结果表明，该方法可以发现新的米姆风格与有着共同的风格元素在视觉上不同的图像，铺平了道路前进为语义分析和内容属性的进一步工作。</font>
</div>


<hr>
<div id="paper21"> <b>21. On- Device Information Extraction from Screenshots in form of tags</b>  <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sumit Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manoj Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Debi Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Changmai%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benu Changmai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a><br>
<font size="3">
Abstract: We propose a method to make mobile screenshots easily searchable. In this paper, we present the workflow in which we: 1) preprocessed a collection of screenshots, 2) identified script presentin image, 3) extracted unstructured text from images, 4) identifiedlanguage of the extracted text, 5) extracted keywords from the text, 6) identified tags based on image features, 7) expanded tag set by identifying related keywords, 8) inserted image tags with relevant images after ranking and indexed them to make it searchable on device. We made the pipeline which supports multiple languages and executed it on-device, which addressed privacy concerns. We developed novel architectures for components in the pipeline, optimized performance and memory for on-device computation. We observed from experimentation that the solution developed can reduce overall user effort and improve end user experience while searching, whose results are published. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们建议让移动截图易于搜索的方法。在本文中，我们提出我们在其中工作流：1）预处理截图的集合，2）识别的脚本presentin图像，3）提取从图像非结构化文本，4）提取的文本的identifiedlanguage，5）提取的关键词从文本，6）的基础上的图像特征识别的标签，7）膨胀通过识别相关的关键字标签集，8）与相关图像插入的图像标签的排名后和索引他们，使其可检索在设备上。我们做了哪些支持多种语言流水线开始执行它的设备，其中涉及隐私问题。我们开发新的架构在管线，优化的性能和内存设备上的计算组件。我们从实验观察到，解决方案开发可降低整体用户的努力和改善最终用户体验，同时搜索，其结果公布。</font>
</div>


<hr>
<div id="paper22"> <b>22. Tracking of Micro Unmanned Aerial Vehicles: A Comparative Study</b>  <a href="https://arxiv.org/pdf/2001.06066" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title22" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=G%C3%B6k%C3%A7e%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fatih Gökçe</a><br>
<font size="3">
Abstract: Micro unmanned aerial vehicles (mUAV) became very common in recent years. As a result of their widespread usage, when they are flown by hobbyists illegally, crucial risks are imposed and such mUAVs need to be sensed by security systems. Furthermore, the sensing of mUAVs are essential for also swarm robotics research where the individuals in a flock of robots require systems to sense and localize each other for coordinated operation. In order to obtain such systems, there are studies to detect mUAVs utilizing different sensing mediums, such as vision, infrared and sound signals, and small-scale radars. However, there are still challenges that awaits to be handled in this field such as integrating tracking approaches to the vision-based detection systems to enhance accuracy and computational complexity. For this reason, in this study, we combine various tracking approaches to a vision-based mUAV detection system available in the literature, in order to evaluate different tracking approaches in terms of accuracy and as well as investigate the effect of such integration to the computational cost. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：微型无人机（mUAV）在最近几年变得很普遍。由于其广泛使用的结果，当他们被非法爱好者飞行，关键的风险强加的，这样mUAVs需要通过安全系统进行检测。此外，还群机器人研究其中机器人的羊群个人要求系统意识和本地化相互协调运行mUAVs的检测是必不可少的。为了得到这样的系统，也有研究，以检测使用不同的感测介质，如视觉，红外线和声音信号，以及小规模雷达mUAVs。然而，仍然有挑战等待着在这一领域，如集成的跟踪方法，以基于视觉的检测系统，以提高精度和计算复杂性进行处理。为此，在本研究中，我们结合各种跟踪方法，以文献中的基于视觉的mUAV检测系统，以评估不同的跟踪方法在准确性方面和以及调查这种整合的计算效果成本。</font>
</div>


<hr>
<div id="paper23"> <b>23. Increasing the robustness of DNNs against image corruptions by playing  the Game of Noise</b>  <a href="https://arxiv.org/pdf/2001.06057" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title23" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Rusak%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Evgenia Rusak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schott%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lukas Schott</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zimmermann%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roland Zimmermann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bitterwolf%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julian Bitterwolf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bringmann%2C+O" target="_blank" rel="noopener" style="color:#0000EE;">Oliver Bringmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bethge%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matthias Bethge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Brendel%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wieland Brendel</a><br>
<font size="3">
Abstract: The human visual system is remarkably robust against a wide range of naturally occurring variations and corruptions like rain or snow. In contrast, the performance of modern image recognition models strongly degrades when evaluated on previously unseen corruptions. Here, we demonstrate that a simple but properly tuned training with additive Gaussian and Speckle noise generalizes surprisingly well to unseen corruptions, easily reaching the previous state of the art on the corruption benchmark ImageNet-C (with ResNet50) and on MNIST-C. We build on top of these strong baseline results and show that an adversarial training of the recognition model against uncorrelated worst-case noise distributions leads to an additional increase in performance. This regularization can be combined with previously proposed defense methods for further improvement. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人类视觉系统对宽范围的天然存在的变型和损坏等雨或雪非常健壮。相比之下，现代的图像识别模型的性能上前所未见的损坏进行评估时，强烈地下降。在这里，我们证明了一个简单的，但适当调整训练加性高斯和斑点噪声推广出奇地好于看不见的腐败，很容易达到艺术的腐败基准ImageNet-C（含ResNet50）对以前的状态和MNIST-C。我们依靠这些强大的基准结果的顶部，并表明对不相关的最坏情况下的噪声分布引线识别模型的对抗性训练，在性能上的额外增加。这正可以进一步改进先前提出的防御方法相结合。</font>
</div>


<hr>
<div id="paper24"> <b>24. Modality-Balanced Models for Visual Dialogue</b>  <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title24" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hyounghun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：可视对话任务需要一个模型，同时利用图像和会话的上下文信息来生成到对话的下一个响应。然而，通过人工分析，我们发现了大量的对话问题只能由看图像，而不到上下文历史上的任何访问来回答，而其他人还需要对话上下文来预测正确的答案。我们表明，由于这个原因，以往合资模式（史和图像）模式过分依赖，而且更容易记住的对话记录（例如，通过上下文信息提取的关键字或模式），而只有图象模型更加普及（因为他们无法记住或者从历史中提取的关键字），并在主要贴现归累计收益（NDCG）任务指标，它允许多个正确答案大幅更好地履行。因此，这种观察鼓励我们要明确地保持两种模式，即只有一个影像的模型和图像的历史关节模型，并结合它们的互补能力，为一个更加平衡的多模式模型。我们提出了这种整合两个模型的多种方法，通过与共享参数合奏和共识辍学融合。根据经验，我们的模型实现对视觉对话挑战2019（关于NDCG和整个指标高平衡等级3）强劲的业绩，并基本跑赢视觉对话框挑战2018的大多数指标的赢家。</font>
</div>


<hr>
<div id="paper25"> <b>25. Tethered Aerial Visual Assistance</b>  <a href="https://arxiv.org/pdf/2001.06347" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title25" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xiao%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuesu Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dufek%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jan Dufek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Murphy%2C+R+R" target="_blank" rel="noopener" style="color:#0000EE;">Robin R. Murphy</a><br>
<font size="3">
Abstract: In this paper, an autonomous tethered Unmanned Aerial Vehicle (UAV) is developed into a visual assistant in a marsupial co-robots team, collaborating with a tele-operated Unmanned Ground Vehicle (UGV) for robot operations in unstructured or confined environments. These environments pose extreme challenges to the remote tele-operator due to the lack of sufficient situational awareness, mostly caused by the unstructuredness and confinement, stationary and limited field-of-view and lack of depth perception from the robot's onboard cameras. To overcome these problems, a secondary tele-operated robot is used in current practices, who acts as a visual assistant and provides external viewpoints to overcome the perceptual limitations of the primary robot's onboard sensors. However, a second tele-operated robot requires extra manpower and teamwork demand between primary and secondary operators. The manually chosen viewpoints tend to be subjective and sub-optimal. Considering these intricacies, we develop an autonomous tethered aerial visual assistant in place of the secondary tele-operated robot and operator, to reduce human robot ratio from 2:2 to 1:2. Using a fundamental viewpoint quality theory, a formal risk reasoning framework, and a newly developed tethered motion suite, our visual assistant is able to autonomously navigate to good-quality viewpoints in a risk-aware manner through unstructured or confined spaces with a tether. The developed marsupial co-robots team could improve tele-operation efficiency in nuclear operations, bomb squad, disaster robots, and other domains with novel tasks or highly occluded environments, by reducing manpower and teamwork demand, and achieving better visual assistance quality with trustworthy risk-aware motion. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种自主拴无人机（UAV）的发展成为有袋动物共同的机器人团队视觉助理，具有远程操作的无人地面车辆（UGV），用于非结构化或狭窄的环境中机器人进行作业协作。这些环境造成由于缺乏足够的态势感知能力，主要由unstructuredness和约束，固定和有限领域的视图造成极端挑战远程远程操作，缺乏从机器人的车载摄像机的景深感知。为了克服这些问题，二次远程操作机器人在当前的实践，谁充当视觉辅助，并提供外部视点克服初级机器人的机载传感器的感知限制使用。然而，第二个远程操作机器人需要初级和次级运营商之间的额外的人力和团队需求。手动选择视点趋于主观和次优的。考虑到这些复杂性，我们开发代替二次远程操作机器人和操作员的一个自治系留空中视觉助理，从2减少人类机器人比为1:2至1:2。使用基本视点质量理论，正式的风险推理框架，和新开发的系绳运动套件，我们的视觉助手是能够通过与系绳非结构化或密闭空间自主导航至在风险意识的方式高质量的观点。所开发的有袋动物共同的机器人团队可以提高核作战远程操作效率，拆弹小组，灾难机器人，并与新的任务或非常闭塞的环境中，通过减少人力和团队协作需求，并实现更好的视觉援助质量值得信赖的风险其他领域知晓运动。</font>
</div>


<hr>
<div id="paper26"> <b>26. DeepSUM++: Non-local Deep Neural Network for Super-Resolution of  Unregistered Multitemporal Images</b>  <a href="https://arxiv.org/pdf/2001.06342" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title26" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Molini%2C+A+B" target="_blank" rel="noopener" style="color:#0000EE;">Andrea Bordone Molini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Valsesia%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Diego Valsesia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Fracastoro%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giulia Fracastoro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Magli%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Enrico Magli</a><br>
<font size="3">
Abstract: Deep learning methods for super-resolution of a remote sensing scene from multiple unregistered low-resolution images have recently gained attention thanks to a challenge proposed by the European Space Agency. This paper presents an evolution of the winner of the challenge, showing how incorporating non-local information in a convolutional neural network allows to exploit self-similar patterns that provide enhanced regularization of the super-resolution problem. Experiments on the dataset of the challenge show improved performance over the state-of-the-art, which does not exploit non-local information. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：超分辨率从多个未注册的低分辨率图像的遥感场景的深度学习方法最近获得了感谢关注欧洲航天局提出了挑战。本文介绍了挑战冠军，展示了如何在卷积神经网络将非本地信息的发展允许利用自相似的模式，提供了增强的超分辨率问题的正规化。对挑战的数据集实验表明在国家的最先进的，它并没有利用非本地信息更好的性能。</font>
</div>


<hr>
<div id="paper27"> <b>27. Detection Method Based on Automatic Visual Shape Clustering for  Pin-Missing Defect in Transmission Lines</b>  <a href="https://arxiv.org/pdf/2001.06236" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title27" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhenbing Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Qi%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongyu Qi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Qi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yincheng Qi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhang%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ke Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhai%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yongjie Zhai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhao%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wenqing Zhao</a><br>
<font size="3">
Abstract: Bolts are the most numerous fasteners in transmission lines and are prone to losing their split pins. How to realize the automatic pin-missing defect detection for bolts in transmission lines so as to achieve timely and efficient trouble shooting is a difficult problem and the long-term research target of power systems. In this paper, an automatic detection model called Automatic Visual Shape Clustering Network (AVSCNet) for pin-missing defect is constructed. Firstly, an unsupervised clustering method for the visual shapes of bolts is proposed and applied to construct a defect detection model which can learn the difference of visual shape. Next, three deep convolutional neural network optimization methods are used in the model: the feature enhancement, feature fusion and region feature extraction. The defect detection results are obtained by applying the regression calculation and classification to the regional features. In this paper, the object detection model of different networks is used to test the dataset of pin-missing defect constructed by the aerial images of transmission lines from multiple locations, and it is evaluated by various indicators and is fully verified. The results show that our method can achieve considerably satisfactory detection effect. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：螺栓是输电线路最众多的紧固件，而且容易失去自己的开口销。如何实现对输电线路的螺栓自动销缺失的缺陷检测，从而及时实现高效的故障排除是一个困难的问题，电力系统的长期研究目标。在本文中，一种自动检测模型称为自动视觉形状聚类网络（AVSCNet）为销缺失缺陷构造。首先，对于螺栓的视觉形状的无监督聚类方法，并应用于构建其可以学习视觉形状的差异的缺陷检测模型。接下来，在模型中使用了三个深卷积神经网络优化方法：增强功能，特征融合和区域特征提取。缺陷检测结果通过将回归计算和分类区域特征获得。在本文中，不同网络的物体检测模型用于测试的通过的从多个位置传输线架空图像构建销缺失缺陷的数据集，并且它是由各种指示器评估并且被充分验证。结果表明，我们的方法可以达到相当满意的检测效果。</font>
</div>


<hr>
<div id="paper28"> <b>28. Sideways: Depth-Parallel Training of Video Models</b>  <a href="https://arxiv.org/pdf/2001.06232" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title28" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Malinowski%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mateusz Malinowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Swirszcz%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Grzegorz Swirszcz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Carreira%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Joao Carreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Patraucean%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Viorica Patraucean</a><br>
<font size="3">
Abstract: We propose Sideways, an approximate backpropagation scheme for training video models. In standard backpropagation, the gradients and activations at every computation step through the model are temporally synchronized. The forward activations need to be stored until the backward pass is executed, preventing inter-layer (depth) parallelization. However, can we leverage smooth, redundant input streams such as videos to develop a more efficient training scheme? Here, we explore an alternative to backpropagation; we overwrite network activations whenever new ones, i.e., from new frames, become available. Such a more gradual accumulation of information from both passes breaks the precise correspondence between gradients and activations, leading to theoretically more noisy weight updates. Counter-intuitively, we show that Sideways training of deep convolutional video networks not only still converges, but can also potentially exhibit better generalization compared to standard synchronized backpropagation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出侧身，培训视频机型的大致反向传播方案。在标准反向传播，在通过所述模型中的每个计算步骤中的梯度和激活在时间上同步。正向激活需要被存储，直到执行向后通，从而防止层间（深度）并行化。然而，我们可以利用平滑，冗余输入流，如视频，开发更有效的培训计划？在这里，我们探索反向传播的替代;我们覆盖的网络激活，每当新的，即由新的框架，变得可用。这样的来自两个信息更渐进累积通断梯度和激活之间的确切的对应，从而导致理论上更嘈杂重量的更新。与直觉相反，我们表明，与标准同步反向传播侧身培训深卷积视频网络不仅仍然收敛的，但也有可能表现出较好的泛化。</font>
</div>


<hr>
<div id="paper29"> <b>29. FedVision: An Online Visual Object Detection Platform Powered by  Federated Learning</b>  <a href="https://arxiv.org/pdf/2001.06202" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title29" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anbu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luo%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">He Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youzhi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuanyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Feng%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lican Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tianjian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Yang</a><br>
<font size="3">
Abstract: Visual object detection is a computer vision-based artificial intelligence (AI) technique which has many practical applications (e.g., fire hazard monitoring). However, due to privacy concerns and the high cost of transmitting video data, it is highly challenging to build object detection models on centrally stored large training datasets following the current approach. Federated learning (FL) is a promising approach to resolve this challenge. Nevertheless, there currently lacks an easy to use tool to enable computer vision application developers who are not experts in federated learning to conveniently leverage this technology and apply it in their systems. In this paper, we report FedVision - a machine learning engineering platform to support the development of federated learning powered computer vision applications. The platform has been deployed through a collaboration between WeBank and Extreme Vision to help customers develop computer vision-based safety monitoring solutions in smart city applications. Over four months of usage, it has achieved significant efficiency improvement and cost reduction while removing the need to transmit sensitive data for three major corporate customers. To the best of our knowledge, this is the first real application of FL in computer vision-based tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：视觉对象检测是具有许多实际应用（例如，火灾监视）一个基于计算机视觉的人工智能（AI）技术。然而，由于隐私问题和传输视频数据的成本高，这是非常具有挑战性的集中存储大量训练数据构建物体检测模式下的电流的方法。联合学习（FL）是一种很有前途的方法来解决这一难题。尽管如此，目前缺乏一个易于使用的工具，使计算机视觉应用开发商谁是不是在联合学习专家能够方便地利用这一技术，并在他们的系统应用它。在本文中，我们报告FedVision  - 机器学习技术平台支持的联合学习动力的计算机视觉应用的开发。该平台已通过帮助客户WeBank和极端视觉之间的合作开发部署在智能城市应用基于计算机视觉的安全监控解决方案。四个多月的使用，它已经取得了显著提高效率和降低成本，同时消除需要发送的敏感数据有三个主要的企业客户。据我们所知，这是计算机基于视觉的任务FL的第一个真正的应用。</font>
</div>


<hr>
<div id="paper30"> <b>30. Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless  Approach</b>  <a href="https://arxiv.org/pdf/2001.06175" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title30" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Park%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chanoh Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moghadam%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Peyman Moghadam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Soohwan Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sridharan%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sridha Sridharan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fookes%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Clinton Fookes</a><br>
<font size="3">
Abstract: The demand for multimodal sensing systems for robotics is growing due to the increase in robustness, reliability and accuracy offered by these systems. These systems also need to be spatially and temporally co-registered to be effective. In this paper, we propose a targetless and structureless spatiotemporal camera-LiDAR calibration method. Our method combines a closed-form solution with a modified structureless bundle adjustment where the coarse-to-fine approach does not {require} an initial guess on the spatiotemporal parameters. Also, as 3D features (structure) are calculated from triangulation only, there is no need to have a calibration target or to match 2D features with the 3D point cloud which provides flexibility in the calibration process and sensor configuration. We demonstrate the accuracy and robustness of the proposed method through both simulation and real data experiments using multiple sensor payload configurations mounted to hand-held, aerial and legged robot systems. Also, qualitative results are given in the form of a colorized point cloud visualization. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：多传感系统对机器人的需求正在不断增长，由于这些系统提供的耐用性，可靠性和精确度的提高。这些系统还需要在空间和时间上处于同一注册是有效的。在本文中，我们提出了一个无标的和无结构的时空相机，激光雷达校准方法。我们的方法结合了改性无结构束调整，其中粗到细的方法不要求{}上的时空参数的初始猜测的闭合形式解。另外，作为三维特征（结构）从三角测量计算只，没有必要有一个校准目标或匹配2D与3D点云，其提供在校准过程和传感器配置的灵活性的特点。我们证明了该方法的准确度和鲁棒性通过使用多个传感器的有效载荷的配置模拟和实际数据实验安装到手持式，空中和腿式机器人系统。此外，定性的结果以彩色点云可视化的形式给出。</font>
</div>


<hr>
<div id="paper31"> <b>31. An adversarial learning framework for preserving users' anonymity in  face-based emotion recognition</b>  <a href="https://arxiv.org/pdf/2001.06103" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title31" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Narula%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vansh Narula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhangyang" target="_blank" rel="noopener" style="color:#0000EE;">Zhangyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang" target="_blank" rel="noopener" style="color:#0000EE;">Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chaspari%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Theodora Chaspari</a><br>
<font size="3">
Abstract: Image and video-capturing technologies have permeated our every-day life. Such technologies can continuously monitor individuals' expressions in real-life settings, affording us new insights into their emotional states and transitions, thus paving the way to novel well-being and healthcare applications. Yet, due to the strong privacy concerns, the use of such technologies is met with strong skepticism, since current face-based emotion recognition systems relying on deep learning techniques tend to preserve substantial information related to the identity of the user, apart from the emotion-specific information. This paper proposes an adversarial learning framework which relies on a convolutional neural network (CNN) architecture trained through an iterative procedure for minimizing identity-specific information and maximizing emotion-dependent information. The proposed approach is evaluated through emotion classification and face identification metrics, and is compared against two CNNs, one trained solely for emotion recognition and the other trained solely for face identification. Experiments are performed using the Yale Face Dataset and Japanese Female Facial Expression Database. Results indicate that the proposed approach can learn a convolutional transformation for preserving emotion recognition accuracy and degrading face identity recognition, providing a foundation toward privacy-aware emotion recognition technologies. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：图像和视频捕捉技术已经渗透到我们每一天的生活。这种技术可连续监测在现实生活中设置个人的表现，获得了我们新的见解他们的情感状态和转换，从而铺平了道路新的福祉和医疗应用。然而，由于强烈的隐私问题，使用这种技术时遭到强烈的怀疑态度，因为当前面为基础的情感识别系统依托深学习技术倾向于从情感保存有关用户的身份基本信息，除了-具体信息。本文提出了一种对抗性的学习框架，它依赖于通过最小化身份的具体信息，并最大限度地提高情绪相关的信息的迭代过程，培养了卷积神经网络（CNN）架构。所提出的方法是通过情感分类和面部识别指标评估，并针对两种细胞神经网络，另一个只卖情感识别训练和其他专为面部识别训练的比较。实验使用的是Yale人脸数据集和日本女性表情数据库进行。结果表明，该方法可以学习卷积转变为维护情感识别的准确性和有辱人格的脸身份识别情况，提供秘密感知情感识别技术奠定了基础。</font>
</div>


<hr>
<div id="paper32"> <b>32. Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for  Making a CNN Classifier Robust Against Adversarial Attacks</b>  <a href="https://arxiv.org/pdf/2001.06099" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title32" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Behnia%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Farnaz Behnia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mirzaeian%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ali Mirzaeian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sabokrou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohammad Sabokrou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Manoj%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sai Manoj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohsenin%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tinoosh Mohsenin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khasawneh%2C+K+N" target="_blank" rel="noopener" style="color:#0000EE;">Khaled N. Khasawneh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Liang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Homayoun%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Houman Homayoun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sasan%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Avesta Sasan</a><br>
<font size="3">
Abstract: In this paper, we propose Code-Bridged Classifier (CBC), a framework for making a Convolutional Neural Network (CNNs) robust against adversarial attacks without increasing or even by decreasing the overall models' computational complexity. More specifically, we propose a stacked encoder-convolutional model, in which the input image is first encoded by the encoder module of a denoising auto-encoder, and then the resulting latent representation (without being decoded) is fed to a reduced complexity CNN for image classification. We illustrate that this network not only is more robust to adversarial examples but also has a significantly lower computational complexity when compared to the prior art defenses. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们提出代码桥接分类（CBC），用于进行卷积神经网络（细胞神经网络）相对抗强大的攻击不增加，甚至通过降低整体模型的计算复杂性的框架。更具体地，我们提出了一种层叠的编码器卷积模型，其中，所述输入图像首先被去噪的自动编码器的编码器模块编码，然后将得到的潜表示（没有被解码）被馈送到降低复杂度的CNN为图像分类。我们表明，该网络不仅更加坚固，以对抗的例子，但也有显著较低的计算复杂性相比，现有技术抗辩。</font>
</div>


<hr>
<div id="paper33"> <b>33. Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised  Learning</b>  <a href="https://arxiv.org/pdf/2001.06001" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title33" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cascante-Bonilla%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Paola Cascante-Bonilla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fuwen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanjun Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ordonez%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vicente Ordonez</a><br>
<font size="3">
Abstract: Semi-supervised learning aims to take advantage of a large amount of unlabeled data to improve the accuracy of a model that only has access to a small number of labeled examples. We propose curriculum labeling, an approach that exploits pseudo-labeling for propagating labels to unlabeled samples in an iterative and self-paced fashion. This approach is surprisingly simple and effective and surpasses or is comparable with the best methods proposed in the recent literature across all the standard benchmarks for image classification. Notably, we obtain 94.91% accuracy on CIFAR-10 using only 4,000 labeled samples, and 88.56% top-5 accuracy on Imagenet-ILSVRC using 128,000 labeled samples. In contrast to prior works, our approach shows improvements even in a more realistic scenario that leverages out-of-distribution unlabeled data samples. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：半监督学习的目标采取了大量的未标记数据的优势，提高了一个模型，只获得了少量的标识样本的准确性。我们建议的课程标签，它利用伪标签用于在迭代和自学的方式传播标签的未标记样本的方法。这种方法是非常简单和有效，超过或者是在最近的文献在所有标准的基准图像分类提出的最佳方法相媲美。值得注意的是，我们使用128000个标记的样品获得关于Imagenet-ILSVRC上CIFAR-10 94.91％的准确度仅使用4000标记的样品，以及88.56％顶5的精度。相较于之前的作品，我们的做法显示了改善，即使在更现实的情况下，充分利用外的分布未标记的数据样本。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-20</title>
    <url>/2020/01/20/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-20/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> A Common Semantic Space for Monolingual and Cross-Lingual  Meta-Embeddings <a href="https://arxiv.org/pdf/2001.06381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Modality-Balanced Models for Visual Dialogue <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat  Groups <a href="https://arxiv.org/pdf/2001.06350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> RobBERT: a Dutch RoBERTa-based Language Model <a href="https://arxiv.org/pdf/2001.06286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue  System <a href="https://arxiv.org/pdf/2001.06206" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Plato Dialogue System: A Flexible Conversational AI Research Platform <a href="https://arxiv.org/pdf/2001.06463" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Supervised Speaker Embedding De-Mixing in Two-Speaker Environment <a href="https://arxiv.org/pdf/2001.06397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> On- Device Information Extraction from Screenshots in form of tags <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> User-in-the-loop Adaptive Intent Detection for Instructable Digital  Assistant <a href="https://arxiv.org/pdf/2001.06007" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. A Common Semantic Space for Monolingual and Cross-Lingual  Meta-Embeddings</b>  <a href="https://arxiv.org/pdf/2001.06381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Garc%C3%ADa%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Iker García</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agerri%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rodrigo Agerri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rigau%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">German Rigau</a><br>
<font size="3">
Abstract: This paper presents a new technique for creating monolingual and cross-lingual meta-embeddings. Our method integrates multiple word embeddings created from complementary techniques, textual sources, knowledge bases and languages. Existing word vectors are projected to a common semantic space using linear transformations and averaging. With our method the resulting meta-embeddings maintain the dimensionality of the original embeddings without losing information while dealing with the out-of-vocabulary problem. An extensive empirical evaluation demonstrates the effectiveness of our technique with respect to previous work on various intrinsic and extrinsic multilingual evaluations, obtaining competitive results for Semantic Textual Similarity and state-of-the-art performance for word similarity and POS tagging (English and Spanish). The resulting cross-lingual meta-embeddings also exhibit excellent cross-lingual transfer learning capabilities. In other words, we can leverage pre-trained source embeddings from a resource-rich language in order to improve the word representations for under-resourced languages. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了创建单语和跨语言间的嵌入的新技术。我们的方法整合了互补技术，文本来源，知识库和语言创建多个字的嵌入。现有字矢量投影到使用线性变换和平均共同语义空间。随着我们的方法所产生的荟萃的嵌入保持原有的嵌入的维度，而不会丢失信息，在处理外的词汇的问题。广泛的实证评价表明了我们的技术相对于各种内在和外在的多语种评估先前的工作成效，获得了语义文本相似性和国家的最先进的性能竞争的结果词语相似度和词性标注（英语和西班牙语） 。产生的跨语种元的嵌入也表现出优异的跨语言迁移学习能力。换句话说，我们可以利用从资源丰富的语言预先训练源的嵌入，以提高资源不足的语言文字表述。</font>
</div>


<hr>
<div id="paper2"> <b>2. Modality-Balanced Models for Visual Dialogue</b>  <a href="https://arxiv.org/pdf/2001.06354" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hyounghun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：可视对话任务需要一个模型，同时利用图像和会话的上下文信息来生成到对话的下一个响应。然而，通过人工分析，我们发现了大量的对话问题只能由看图像，而不到上下文历史上的任何访问来回答，而其他人还需要对话上下文来预测正确的答案。我们表明，由于这个原因，以往合资模式（史和图像）模式过分依赖，而且更容易记住的对话记录（例如，通过上下文信息提取的关键字或模式），而只有图象模型更加普及（因为他们无法记住或者从历史中提取的关键字），并在主要贴现归累计收益（NDCG）任务指标，它允许多个正确答案大幅更好地履行。因此，这种观察鼓励我们要明确地保持两种模式，即只有一个影像的模型和图像的历史关节模型，并结合它们的互补能力，为一个更加平衡的多模式模型。我们提出了这种整合两个模型的多种方法，通过与共享参数合奏和共识辍学融合。根据经验，我们的模型实现对视觉对话挑战2019（关于NDCG和整个指标高平衡等级3）强劲的业绩，并基本跑赢视觉对话框挑战2018的大多数指标的赢家。</font>
</div>


<hr>
<div id="paper3"> <b>3. A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat  Groups</b>  <a href="https://arxiv.org/pdf/2001.06350" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=de+Bayser%2C+M+G" target="_blank" rel="noopener" style="color:#0000EE;">Maira Gatti de Bayser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guerra%2C+M+A" target="_blank" rel="noopener" style="color:#0000EE;">Melina Alberio Guerra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cavalin%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Paulo Cavalin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pinhanez%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Claudio Pinhanez</a><br>
<font size="3">
Abstract: To predict the next most likely participant to interact in a multi-party conversation is a difficult problem. In a text-based chat group, the only information available is the sender, the content of the text and the dialogue history. In this paper we present our study on how these information can be used on the prediction task through a corpus and architecture that integrates turn-taking classifiers based on Maximum Likelihood Expectation (MLE), Convolutional Neural Networks (CNN) and Finite State Automata (FSA). The corpus is a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset (MultiWOZ) to a multiple travel service-based bots scenario with dialogue errors and was created to simulate user's interaction and evaluate the architecture. We present experimental results which show that the CNN approach achieves better performance than the baseline with an accuracy of 92.34%, but the integrated solution with MLE, CNN and FSA achieves performance even better, with 95.65%. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：为了预测下一个最有可能的参与者进行互动的多方通话是一个棘手的问题。在基于文本的聊天群，唯一可用的信息是发送者，文本和对话历史的内容。在本文中，我们介绍如何将这些信息可以在预测任务中使用通过语料库和架构，集成了转向回吐基于最大似然期望（MLE），卷积神经网络（CNN）和有限状态自动分类（我们的研究FSA ）。该语料库是多域向导的盎司数据集（MultiWOZ）与对话错误多个旅游服务为主的机器人场景的合成适应和创建来模拟用户的交互和评估体系结构。我们这表明，CNN方法实现比92.34％的准确度基准更好的性能，但与MLE，CNN和FSA集成的解决方案实现性能更为出色，有95.65％目前的实验结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. RobBERT: a Dutch RoBERTa-based Language Model</b>  <a href="https://arxiv.org/pdf/2001.06286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Delobelle%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pieter Delobelle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Winters%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Winters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Berendt%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bettina Berendt</a><br>
<font size="3">
Abstract: Pre-trained language models have been dominating the field of natural language processing in recent years, and have led to significant performance gains for various complex natural language tasks. One of the most prominent pre-trained language models is BERT (Bi-directional Encoders for Transformers), which was released as an English as well as a multilingual version. Although multilingual BERT performs well on many tasks, recent studies showed that BERT models trained on a single language significantly outperform the multilingual results. Training a Dutch BERT model thus has a lot of potential for a wide range of Dutch NLP tasks. While previous approaches have used earlier implementations of BERT to train their Dutch BERT, we used RoBERTa, a robustly optimized BERT approach, to train a Dutch language model called RobBERT. We show that RobBERT improves state of the art results in Dutch-specific language tasks, and also outperforms other existing Dutch BERT-based models in sentiment analysis. These results indicate that RobBERT is a powerful pre-trained model for fine-tuning for a large variety of Dutch language tasks. We publicly release this pre-trained model in hope of supporting further downstream Dutch NLP applications. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：预先训练语言模型已经主宰自然语言处理领域在最近几年，并导致显著的性能提升各种复杂的自然语言的任务。其中最突出的预先训练语言模型是BERT（变形金刚双向编码器），它被发布了作为一个英语和一个多语种的版本。虽然多语种BERT执行以及对许多任务，最近的研究显示，培训了一个单一的语言，BERT模型显著跑赢多种语言的结果。培训荷兰BERT模型因而具有广泛的荷兰NLP任务很大的潜力。虽然以前的方法已使用BERT的早期实现培养他们的荷兰BERT，我们使用了罗伯塔，一个稳健优化BERT的方法，培养所谓的RobBERT荷兰语言模型。我们发现，RobBERT改善状态荷兰人特有的语言任务的艺术效果，而且在情感分析优于其他现有的基于BERT荷模型。这些结果表明，RobBERT是微调功能强大的预先训练的模型种类繁多的荷兰语任务。我们在公开支持进一步的下游荷兰NLP应用希望释放此预先训练模式。</font>
</div>


<hr>
<div id="paper5"> <b>5. Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue  System</b>  <a href="https://arxiv.org/pdf/2001.06206" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yun-Wei Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kuan-Yen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chao-Chun Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ku%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lun-Wei Ku</a><br>
<font size="3">
Abstract: Understanding dynamic scenes and dialogue contexts in order to converse with users has been challenging for multimodal dialogue systems. The 8-th Dialog System Technology Challenge (DSTC8) proposed an Audio Visual Scene-Aware Dialog (AVSD) task, which contains multiple modalities including audio, vision, and language, to evaluate how dialogue systems understand different modalities and response to users. In this paper, we proposed a multi-step joint-modality attention network (JMAN) based on recurrent neural network (RNN) to reason on videos. Our model performs a multi-step attention mechanism and jointly considers both visual and textual representations in each reasoning process to better integrate information from the two different modalities. Compared to the baseline released by AVSD organizers, our model achieves a relative 12.1% and 22.4% improvement over the baseline on ROUGE-L score and CIDEr score. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：了解动态场景和对话的上下文，以便与用户交谈已具有挑战性的多模态对话系统。 8个对话系统技术挑战（DSTC8）提出了一个视听场景感知对话框（AVSD）任务，其中包含多种方式，包括音频，视觉和语言，以评估对话系统是如何理解不同的方式和响应用户。在本文中，我们提出了一种基于递归神经网络（RNN）一个多步骤的联合方式关注网络（JMAN）理性上的视频。我们的模型进行多步注意机制，共同考虑在每个推理过程视觉和文本表示，以更好的信息从两种不同的方式进行整合。相比于通过AVSD主办方公布的基线，我们的模型实现了对ROUGE-L分和苹果酒得分基线相对12.1％和22.4％的改善。</font>
</div>


<hr>
<div id="paper6"> <b>6. Plato Dialogue System: A Flexible Conversational AI Research Platform</b>  <a href="https://arxiv.org/pdf/2001.06463" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Papangelis%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexandros Papangelis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Namazifar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mahdi Namazifar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatri%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chandra Khatri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yi-Chia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Molino%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piero Molino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tur%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gokhan Tur</a><br>
<font size="3">
Abstract: As the field of Spoken Dialogue Systems and Conversational AI grows, so does the need for tools and environments that abstract away implementation details in order to expedite the development process, lower the barrier of entry to the field, and offer a common test-bed for new ideas. In this paper, we present Plato, a flexible Conversational AI platform written in Python that supports any kind of conversational agent architecture, from standard architectures to architectures with jointly-trained components, single- or multi-party interactions, and offline or online training of any conversational agent component. Plato has been designed to be easy to understand and debug and is agnostic to the underlying learning frameworks that train each component. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：口语对话系统和会话人工智能领域的增长，确实需要工具和环境，为了加快开发进程，降低进入该领域的障碍，并提供一个共同的测试 - 抽象掉的实施细则床上躺了新的思路。在本文中，我们目前柏拉图，灵活的对话AI平台用Python编写的，它支持任何类型的会话代理架构，从标准架构与联合训练的成分，单或多方互动，以及离线或在线培训体系任何会话代理组件。柏拉图已经被设计成易于理解和调试，并是不可知的是培养每个组件的基础学习框架。</font>
</div>


<hr>
<div id="paper7"> <b>7. Supervised Speaker Embedding De-Mixing in Two-Speaker Environment</b>  <a href="https://arxiv.org/pdf/2001.06397" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanpei Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hain%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Hain</a><br>
<font size="3">
Abstract: In this work, a speaker embedding de-mixing approach is proposed. Instead of separating two-speaker signal in signal space like speech source separation, the proposed approach separates different speaker properties from two-speaker signal in embedding space. The proposed approach contains two steps. In step one, the clean speaker embeddings are learned and collected by a residual TDNN based network. In step two, the two-speaker signal and the embedding of one of the speakers are input to a speaker embedding de-mixing network. The de-mixing network is trained to generate the embedding of the other speaker of the by reconstruction loss. Speaker identification accuracy on the de-mixed speaker embeddings is used to evaluate the quality of the obtained embeddings. Experiments are done in two kind of data: artificial augmented two-speaker data (TIMIT) and real world recording of two-speaker data (MC-WSJ). Six diffident speaker embedding de-mixing architectures are investigated. Comparing with the speaker identification accuracy on the clean speaker embeddings (98.5%), the obtained results show that one of the speaker embedding de-mixing architectures obtain close performance, reaching 96.9% test accuracy on TIMIT when the SNR between the target speaker and interfering speaker is 5 dB. More surprisingly, we found choosing a simple subtraction as the embedding de-mixing function could obtain the second best performance, reaching 95.2% test accuracy. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在这项工作中，扬声器嵌入脱混合方法提出。代替在如语音源分离的信号分离空间两个扬声器信号的，所提出的方法分离两个扬声器信号在嵌入空间中的不同扬声器的特性。所提出的方法包括两个步骤。在第一步中，清洁扬声器的嵌入被学习和由残余基于TDNN网络收集。在步骤2中，两个扬声器信号和扬声器中的一个的嵌入被输入到扬声器中嵌入解混合网络。所述去混合网络进行训练，以产生的另一个扬声器的由重建丢失的嵌入。对解混合扬声器的嵌入扬声器识别精度被用于评估所获得的嵌入的质量。实验以两种类型的数据来完成：人工增强双扬声器数据（TIMIT）和双扬声器数据的真实世界记录（MC-WSJ）。六个心虚音箱嵌入脱混合体系结构进行了研究。与在干净的扬声器的嵌入扬声器识别精度（98.5％）相比较，所获得的结果表明，该扬声器中的一个嵌入脱混合架构获得紧密的性能，上TIMIT达到96.9％测试精度当目标讲话者和干扰之间的SNR扬声器为5dB。更令人惊讶的，我们发现选择一个简单的减法作为嵌入脱混合功能可以得到第二最佳性能，达到95.2％的测试精度。</font>
</div>


<hr>
<div id="paper8"> <b>8. On- Device Information Extraction from Screenshots in form of tags</b>  <a href="https://arxiv.org/pdf/2001.06094" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sumit Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manoj Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Debi Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Changmai%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benu Changmai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a><br>
<font size="3">
Abstract: We propose a method to make mobile screenshots easily searchable. In this paper, we present the workflow in which we: 1) preprocessed a collection of screenshots, 2) identified script presentin image, 3) extracted unstructured text from images, 4) identifiedlanguage of the extracted text, 5) extracted keywords from the text, 6) identified tags based on image features, 7) expanded tag set by identifying related keywords, 8) inserted image tags with relevant images after ranking and indexed them to make it searchable on device. We made the pipeline which supports multiple languages and executed it on-device, which addressed privacy concerns. We developed novel architectures for components in the pipeline, optimized performance and memory for on-device computation. We observed from experimentation that the solution developed can reduce overall user effort and improve end user experience while searching, whose results are published. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们建议让移动截图易于搜索的方法。在本文中，我们提出我们在其中工作流：1）预处理截图的集合，2）识别的脚本presentin图像，3）提取从图像非结构化文本，4）提取的文本的identifiedlanguage，5）提取的关键词从文本，6）的基础上的图像特征识别的标签，7）膨胀通过识别相关的关键字标签集，8）与相关图像插入的图像标签的排名后和索引他们，使其可检索在设备上。我们做了哪些支持多种语言流水线开始执行它的设备，其中涉及隐私问题。我们开发新的架构在管线，优化的性能和内存设备上的计算组件。我们从实验观察到，解决方案开发可降低整体用户的努力和改善最终用户体验，同时搜索，其结果公布。</font>
</div>


<hr>
<div id="paper9"> <b>9. User-in-the-loop Adaptive Intent Detection for Instructable Digital  Assistant</b>  <a href="https://arxiv.org/pdf/2001.06007" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lair%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nicolas Lair</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Delgrange%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Clément Delgrange</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mugisha%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Mugisha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dussoux%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jean-Michel Dussoux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Oudeyer%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre-Yves Oudeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dominey%2C+P+F" target="_blank" rel="noopener" style="color:#0000EE;">Peter Ford Dominey</a><br>
<font size="3">
Abstract: People are becoming increasingly comfortable using Digital Assistants (DAs) to interact with services or connected objects. However, for non-programming users, the available possibilities for customizing their DA are limited and do not include the possibility of teaching the assistant new tasks. To make the most of the potential of DAs, users should be able to customize assistants by instructing them through Natural Language (NL). To provide such functionalities, NL interpretation in traditional assistants should be improved: (1) The intent identification system should be able to recognize new forms of known intents, and to acquire new intents as they are expressed by the user. (2) In order to be adaptive to novel intents, the Natural Language Understanding module should be sample efficient, and should not rely on a pretrained model. Rather, the system should continuously collect the training data as it learns new intents from the user. In this work, we propose AidMe (Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop adaptive intent detection framework that allows the assistant to adapt to its user by learning his intents as their interaction progresses. AidMe builds its repertoire of intents and collects data to train a model of semantic similarity evaluation that can discriminate between the learned intents and autonomously discover new forms of known intents. AidMe addresses two major issues - intent learning and user adaptation - for instructable digital assistants. We demonstrate the capabilities of AidMe as a standalone system by comparing it with a one-shot learning system and a pretrained NLU module through simulations of interactions with a user. We also show how AidMe can smoothly integrate to an existing instructable digital assistant. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人们使用数字助理（DAS）与服务或连接的对象进行交互变得越来越舒适。然而，对于非编程的用户，定制自己的DA可用的可能性是有限的，不包括教学助理新任务的可能性。为了充分利用的DA的潜力，用户应该能够通过自然语言（NL），指示他们定制的助手。为了提供这样的功能，在传统的助理NL解释应加以改进：（1）意图识别系统应该能够识别已知的意图的新形式，因为它们是由用户表达了收购意向新。 （2）为了适应新的意图，所述自然语言理解模块应该是样品高效，并且不应该依赖于预训练的模型。相反，因为它学习来自用户的新意图，系统应不断收集训练数据。在这项工作中，我们提出AidMe（在多域环境自适应意图检测），用户在半实物自适应意图检测框架，允许助手通过学习他的意图及其互进步，以适应其用户。 AidMe建立其意图和收集数据的剧目来训练语义相似性评价的模型，可以和所学意图区分自主发现已知意图的新形式。 AidMe地址两大问题 - 意向学习和适应用户 - 对于造说明数字助理。我们通过将其与一次性学习系统，并通过与用户的交互的模拟预训练NLU模块比较表明AidMe的能力，作为一个独立的系统。我们还表明AidMe如何平滑地集成到现有的造说明数字助理。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>python gtts 文本转语音</title>
    <url>/2020/01/19/python-gtts-%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3/</url>
    <content><![CDATA[<h1 id="安装gtts"><a href="#安装gtts" class="headerlink" title="安装gtts"></a>安装gtts</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install gTTS</span><br></pre></td></tr></table></figure><h1 id="文本转语音"><a href="#文本转语音" class="headerlink" title="文本转语音"></a>文本转语音</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gtts <span class="keyword">import</span> gTTS</span><br><span class="line">tts = gTTS(text=<span class="string">"Hello World"</span>, lang=<span class="string">'en'</span>)</span><br><span class="line">tts.save(<span class="string">"helloworld.mp3"</span>)</span><br></pre></td></tr></table></figure><h1 id="播放语音"><a href="#播放语音" class="headerlink" title="播放语音"></a>播放语音</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.system(<span class="string">"start helloworld.mp3"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>tts</tag>
      </tags>
  </entry>
  <entry>
    <title>python 调用谷歌翻译接口</title>
    <url>/2020/01/19/python-%E8%B0%83%E7%94%A8%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<p>googletrans 是一个封装了谷歌翻译接口的python代码库，可以通过googletrans实现免费、无限制调用谷歌翻译接口。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install googletrans</span><br></pre></td></tr></table></figure><h1 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> googletrans <span class="keyword">import</span> Translator</span><br><span class="line">translator = Translator(service_urls=[</span><br><span class="line">      <span class="string">'translate.google.cn'</span>,</span><br><span class="line">      <span class="string">'translate.google.com'</span>])</span><br><span class="line">trans=translator.translate(<span class="string">'Hello World'</span>, src=<span class="string">'en'</span>, dest=<span class="string">'zh-cn'</span>)</span><br><span class="line"><span class="comment"># 原文</span></span><br><span class="line">print(trans.origin)</span><br><span class="line"><span class="comment"># 译文</span></span><br><span class="line">print(trans.text)</span><br></pre></td></tr></table></figure><a id="more"></a>




<h1 id="语种识别"><a href="#语种识别" class="headerlink" title="语种识别"></a>语种识别</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">detection=translator.detect(<span class="string">'All with Love'</span>)</span><br><span class="line">print(detection.lang)</span><br></pre></td></tr></table></figure>

<h1 id="语种缩略表示"><a href="#语种缩略表示" class="headerlink" title="语种缩略表示"></a>语种缩略表示</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">LANGUAGES = &#123;</span><br><span class="line">    <span class="string">'af'</span>: <span class="string">'afrikaans'</span>,</span><br><span class="line">    <span class="string">'sq'</span>: <span class="string">'albanian'</span>,</span><br><span class="line">    <span class="string">'am'</span>: <span class="string">'amharic'</span>,</span><br><span class="line">    <span class="string">'ar'</span>: <span class="string">'arabic'</span>,</span><br><span class="line">    <span class="string">'hy'</span>: <span class="string">'armenian'</span>,</span><br><span class="line">    <span class="string">'az'</span>: <span class="string">'azerbaijani'</span>,</span><br><span class="line">    <span class="string">'eu'</span>: <span class="string">'basque'</span>,</span><br><span class="line">    <span class="string">'be'</span>: <span class="string">'belarusian'</span>,</span><br><span class="line">    <span class="string">'bn'</span>: <span class="string">'bengali'</span>,</span><br><span class="line">    <span class="string">'bs'</span>: <span class="string">'bosnian'</span>,</span><br><span class="line">    <span class="string">'bg'</span>: <span class="string">'bulgarian'</span>,</span><br><span class="line">    <span class="string">'ca'</span>: <span class="string">'catalan'</span>,</span><br><span class="line">    <span class="string">'ceb'</span>: <span class="string">'cebuano'</span>,</span><br><span class="line">    <span class="string">'ny'</span>: <span class="string">'chichewa'</span>,</span><br><span class="line">    <span class="string">'zh-cn'</span>: <span class="string">'chinese (simplified)'</span>,</span><br><span class="line">    <span class="string">'zh-tw'</span>: <span class="string">'chinese (traditional)'</span>,</span><br><span class="line">    <span class="string">'co'</span>: <span class="string">'corsican'</span>,</span><br><span class="line">    <span class="string">'hr'</span>: <span class="string">'croatian'</span>,</span><br><span class="line">    <span class="string">'cs'</span>: <span class="string">'czech'</span>,</span><br><span class="line">    <span class="string">'da'</span>: <span class="string">'danish'</span>,</span><br><span class="line">    <span class="string">'nl'</span>: <span class="string">'dutch'</span>,</span><br><span class="line">    <span class="string">'en'</span>: <span class="string">'english'</span>,</span><br><span class="line">    <span class="string">'eo'</span>: <span class="string">'esperanto'</span>,</span><br><span class="line">    <span class="string">'et'</span>: <span class="string">'estonian'</span>,</span><br><span class="line">    <span class="string">'tl'</span>: <span class="string">'filipino'</span>,</span><br><span class="line">    <span class="string">'fi'</span>: <span class="string">'finnish'</span>,</span><br><span class="line">    <span class="string">'fr'</span>: <span class="string">'french'</span>,</span><br><span class="line">    <span class="string">'fy'</span>: <span class="string">'frisian'</span>,</span><br><span class="line">    <span class="string">'gl'</span>: <span class="string">'galician'</span>,</span><br><span class="line">    <span class="string">'ka'</span>: <span class="string">'georgian'</span>,</span><br><span class="line">    <span class="string">'de'</span>: <span class="string">'german'</span>,</span><br><span class="line">    <span class="string">'el'</span>: <span class="string">'greek'</span>,</span><br><span class="line">    <span class="string">'gu'</span>: <span class="string">'gujarati'</span>,</span><br><span class="line">    <span class="string">'ht'</span>: <span class="string">'haitian creole'</span>,</span><br><span class="line">    <span class="string">'ha'</span>: <span class="string">'hausa'</span>,</span><br><span class="line">    <span class="string">'haw'</span>: <span class="string">'hawaiian'</span>,</span><br><span class="line">    <span class="string">'iw'</span>: <span class="string">'hebrew'</span>,</span><br><span class="line">    <span class="string">'hi'</span>: <span class="string">'hindi'</span>,</span><br><span class="line">    <span class="string">'hmn'</span>: <span class="string">'hmong'</span>,</span><br><span class="line">    <span class="string">'hu'</span>: <span class="string">'hungarian'</span>,</span><br><span class="line">    <span class="string">'is'</span>: <span class="string">'icelandic'</span>,</span><br><span class="line">    <span class="string">'ig'</span>: <span class="string">'igbo'</span>,</span><br><span class="line">    <span class="string">'id'</span>: <span class="string">'indonesian'</span>,</span><br><span class="line">    <span class="string">'ga'</span>: <span class="string">'irish'</span>,</span><br><span class="line">    <span class="string">'it'</span>: <span class="string">'italian'</span>,</span><br><span class="line">    <span class="string">'ja'</span>: <span class="string">'japanese'</span>,</span><br><span class="line">    <span class="string">'jw'</span>: <span class="string">'javanese'</span>,</span><br><span class="line">    <span class="string">'kn'</span>: <span class="string">'kannada'</span>,</span><br><span class="line">    <span class="string">'kk'</span>: <span class="string">'kazakh'</span>,</span><br><span class="line">    <span class="string">'km'</span>: <span class="string">'khmer'</span>,</span><br><span class="line">    <span class="string">'ko'</span>: <span class="string">'korean'</span>,</span><br><span class="line">    <span class="string">'ku'</span>: <span class="string">'kurdish (kurmanji)'</span>,</span><br><span class="line">    <span class="string">'ky'</span>: <span class="string">'kyrgyz'</span>,</span><br><span class="line">    <span class="string">'lo'</span>: <span class="string">'lao'</span>,</span><br><span class="line">    <span class="string">'la'</span>: <span class="string">'latin'</span>,</span><br><span class="line">    <span class="string">'lv'</span>: <span class="string">'latvian'</span>,</span><br><span class="line">    <span class="string">'lt'</span>: <span class="string">'lithuanian'</span>,</span><br><span class="line">    <span class="string">'lb'</span>: <span class="string">'luxembourgish'</span>,</span><br><span class="line">    <span class="string">'mk'</span>: <span class="string">'macedonian'</span>,</span><br><span class="line">    <span class="string">'mg'</span>: <span class="string">'malagasy'</span>,</span><br><span class="line">    <span class="string">'ms'</span>: <span class="string">'malay'</span>,</span><br><span class="line">    <span class="string">'ml'</span>: <span class="string">'malayalam'</span>,</span><br><span class="line">    <span class="string">'mt'</span>: <span class="string">'maltese'</span>,</span><br><span class="line">    <span class="string">'mi'</span>: <span class="string">'maori'</span>,</span><br><span class="line">    <span class="string">'mr'</span>: <span class="string">'marathi'</span>,</span><br><span class="line">    <span class="string">'mn'</span>: <span class="string">'mongolian'</span>,</span><br><span class="line">    <span class="string">'my'</span>: <span class="string">'myanmar (burmese)'</span>,</span><br><span class="line">    <span class="string">'ne'</span>: <span class="string">'nepali'</span>,</span><br><span class="line">    <span class="string">'no'</span>: <span class="string">'norwegian'</span>,</span><br><span class="line">    <span class="string">'ps'</span>: <span class="string">'pashto'</span>,</span><br><span class="line">    <span class="string">'fa'</span>: <span class="string">'persian'</span>,</span><br><span class="line">    <span class="string">'pl'</span>: <span class="string">'polish'</span>,</span><br><span class="line">    <span class="string">'pt'</span>: <span class="string">'portuguese'</span>,</span><br><span class="line">    <span class="string">'pa'</span>: <span class="string">'punjabi'</span>,</span><br><span class="line">    <span class="string">'ro'</span>: <span class="string">'romanian'</span>,</span><br><span class="line">    <span class="string">'ru'</span>: <span class="string">'russian'</span>,</span><br><span class="line">    <span class="string">'sm'</span>: <span class="string">'samoan'</span>,</span><br><span class="line">    <span class="string">'gd'</span>: <span class="string">'scots gaelic'</span>,</span><br><span class="line">    <span class="string">'sr'</span>: <span class="string">'serbian'</span>,</span><br><span class="line">    <span class="string">'st'</span>: <span class="string">'sesotho'</span>,</span><br><span class="line">    <span class="string">'sn'</span>: <span class="string">'shona'</span>,</span><br><span class="line">    <span class="string">'sd'</span>: <span class="string">'sindhi'</span>,</span><br><span class="line">    <span class="string">'si'</span>: <span class="string">'sinhala'</span>,</span><br><span class="line">    <span class="string">'sk'</span>: <span class="string">'slovak'</span>,</span><br><span class="line">    <span class="string">'sl'</span>: <span class="string">'slovenian'</span>,</span><br><span class="line">    <span class="string">'so'</span>: <span class="string">'somali'</span>,</span><br><span class="line">    <span class="string">'es'</span>: <span class="string">'spanish'</span>,</span><br><span class="line">    <span class="string">'su'</span>: <span class="string">'sundanese'</span>,</span><br><span class="line">    <span class="string">'sw'</span>: <span class="string">'swahili'</span>,</span><br><span class="line">    <span class="string">'sv'</span>: <span class="string">'swedish'</span>,</span><br><span class="line">    <span class="string">'tg'</span>: <span class="string">'tajik'</span>,</span><br><span class="line">    <span class="string">'ta'</span>: <span class="string">'tamil'</span>,</span><br><span class="line">    <span class="string">'te'</span>: <span class="string">'telugu'</span>,</span><br><span class="line">    <span class="string">'th'</span>: <span class="string">'thai'</span>,</span><br><span class="line">    <span class="string">'tr'</span>: <span class="string">'turkish'</span>,</span><br><span class="line">    <span class="string">'uk'</span>: <span class="string">'ukrainian'</span>,</span><br><span class="line">    <span class="string">'ur'</span>: <span class="string">'urdu'</span>,</span><br><span class="line">    <span class="string">'uz'</span>: <span class="string">'uzbek'</span>,</span><br><span class="line">    <span class="string">'vi'</span>: <span class="string">'vietnamese'</span>,</span><br><span class="line">    <span class="string">'cy'</span>: <span class="string">'welsh'</span>,</span><br><span class="line">    <span class="string">'xh'</span>: <span class="string">'xhosa'</span>,</span><br><span class="line">    <span class="string">'yi'</span>: <span class="string">'yiddish'</span>,</span><br><span class="line">    <span class="string">'yo'</span>: <span class="string">'yoruba'</span>,</span><br><span class="line">    <span class="string">'zu'</span>: <span class="string">'zulu'</span>,</span><br><span class="line">    <span class="string">'fil'</span>: <span class="string">'Filipino'</span>,</span><br><span class="line">    <span class="string">'he'</span>: <span class="string">'Hebrew'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>官方手册: <a href="https://py-googletrans.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://py-googletrans.readthedocs.io/en/latest/</a></p>
]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>谷歌翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-17</title>
    <url>/2020/01/18/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-17/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Lexical Sememe Prediction using Dictionary Definitions by Capturing  Local Semantic Correspondence <a href="https://arxiv.org/pdf/2001.05954" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Speech Emotion Recognition Based on Multi-feature and Multi-lingual  Fusion <a href="https://arxiv.org/pdf/2001.05908" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Comparing Rule-based, Feature-based and Deep Neural Methods for  De-identification of Dutch Medical Records <a href="https://arxiv.org/pdf/2001.05714" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> A Pilot Study on Multiple Choice Machine Reading Comprehension for  Vietnamese Texts <a href="https://arxiv.org/pdf/2001.05687" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> AandP: Utilizing Prolog for converting between active sentence and  passive sentence with three-steps conversion <a href="https://arxiv.org/pdf/2001.05672" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Schema2QA: Answering Complex Queries on the Structured Web with a Neural  Model <a href="https://arxiv.org/pdf/2001.05609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Stereotypical Bias Removal for Hate Speech Detection Task using  Knowledge-based Generalizations <a href="https://arxiv.org/pdf/2001.05495" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> AggressionNet: Generalised Multi-Modal Deep Temporal and Sequential  Learning for Aggression Identification <a href="https://arxiv.org/pdf/2001.05493" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> #MeToo on Campus: Studying College Sexual Assault at Scale Using Data  Reported on Social Media <a href="https://arxiv.org/pdf/2001.05970" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Show, Recall, and Tell: Image Captioning with Recall Mechanism <a href="https://arxiv.org/pdf/2001.05876" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> "Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials  for Humans <a href="https://arxiv.org/pdf/2001.05871" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Ensemble based discriminative models for Visual Dialog Challenge 2018 <a href="https://arxiv.org/pdf/2001.05865" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Discoverability in Satellite Imagery: A Good Sentence is Worth a  Thousand Pictures <a href="https://arxiv.org/pdf/2001.05839" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Document Network Projection in Pretrained Word Embedding Space <a href="https://arxiv.org/pdf/2001.05727" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Delving Deeper into the Decoder for Video Captioning <a href="https://arxiv.org/pdf/2001.05614" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Insertion-Deletion Transformer <a href="https://arxiv.org/pdf/2001.05540" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Lexical Sememe Prediction using Dictionary Definitions by Capturing  Local Semantic Correspondence</b>  <a href="https://arxiv.org/pdf/2001.05954" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Du%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiaju Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fanchao Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maosong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhiyuan Liu</a><br>
<font size="3">
Abstract: Sememes, defined as the minimum semantic units of human languages in linguistics, have been proven useful in many NLP tasks. Since manual construction and update of sememe knowledge bases (KBs) are costly, the task of automatic sememe prediction has been proposed to assist sememe annotation. In this paper, we explore the approach of applying dictionary definitions to predicting sememes for unannotated words. We find that sememes of each word are usually semantically matched to different words in its dictionary definition, and we name this matching relationship local semantic correspondence. Accordingly, we propose a Sememe Correspondence Pooling (SCorP) model, which is able to capture this kind of matching to predict sememes. We evaluate our model and baseline methods on a famous sememe KB HowNet and find that our model achieves state-of-the-art performance. Moreover, further quantitative analysis shows that our model can properly learn the local semantic correspondence between sememes and words in dictionary definitions, which explains the effectiveness of our model. The source codes of this paper can be obtained from this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：义位，定义为语言学人类语言的语义的最小单位，已在许多自然语言处理的任务被证明是有用的。由于人工建设和义素知识库（KBS）更新是昂贵的，自动义原预测的任务已经提出，以协助义原注释。在本文中，我们将探讨采用字典的定义为预测未注释词义位的方法。我们发现，每个词的义位通常是在语义上在其字典上的定义匹配不同的话，我们命名此匹配关系当地语义对应。因此，我们提出了一个义位对应池（SCORP）模型，它能够捕捉到这种匹配预测义原。我们评估在一个著名的义原KB知网我们的模型和基线的方法和发现，我们的模型实现了国家的最先进的性能。此外，进一步的定量分析表明，我们的模型能够正确地学习字典定义义位与词之间的本地语义对应，这说明我们的模型的有效性。本文的源代码可以从该HTTPS URL来获得。</font>
</div>


<hr>
<div id="paper2"> <b>2. Speech Emotion Recognition Based on Multi-feature and Multi-lingual  Fusion</b>  <a href="https://arxiv.org/pdf/2001.05908" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chunyi Wang</a><br>
<font size="3">
Abstract: A speech emotion recognition algorithm based on multi-feature and Multi-lingual fusion is proposed in order to resolve low recognition accuracy caused by lack of large speech dataset and low robustness of acoustic features in the recognition of speech emotion. First, handcrafted and deep automatic features are extracted from existing data in Chinese and English speech emotions. Then, the various features are fused respectively. Finally, the fused features of different languages are fused again and trained in a classification model. Distinguishing the fused features with the unfused ones, the results manifest that the fused features significantly enhance the accuracy of speech emotion recognition algorithm. The proposed solution is evaluated on the two Chinese corpus and two English corpus, and is shown to provide more accurate predictions compared to original solution. As a result of this study, the multi-feature and Multi-lingual fusion algorithm can significantly improve the speech emotion recognition accuracy when the dataset is small. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于多特征和多语种的融合语音情感识别算法是为了解决由于缺乏大型数据集的讲话和在识别语音情感的声学特征低稳健的低识别精度提出。首先，手工和自动深特征在中国和英语演讲情绪现有的数据中提取。于是，各种功能都融合分别。最后，不同语言的熔断特性再次融合，并在分类模型训练。判定，非融合的，结果清单中的融合功能，融合功能显著增强语音情感识别算法的精度。提出的解决方案是在两名中国语料库和两个英语语料库进行评估，并显示相对于原来的解决方案，以提供更精确的预测。作为这项研究的结果是，多特征和多语种的融合算法可以显著提高语音情感识别的准确性如果数据集小。</font>
</div>


<hr>
<div id="paper3"> <b>3. Comparing Rule-based, Feature-based and Deep Neural Methods for  De-identification of Dutch Medical Records</b>  <a href="https://arxiv.org/pdf/2001.05714" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Trienes%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jan Trienes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Trieschnigg%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dolf Trieschnigg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Seifert%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christin Seifert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hiemstra%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Djoerd Hiemstra</a><br>
<font size="3">
Abstract: Unstructured information in electronic health records provide an invaluable resource for medical research. To protect the confidentiality of patients and to conform to privacy regulations, de-identification methods automatically remove personally identifying information from these medical records. However, due to the unavailability of labeled data, most existing research is constrained to English medical text and little is known about the generalizability of de-identification methods across languages and domains. In this study, we construct a varied dataset consisting of the medical records of 1260 patients by sampling data from 9 institutes and three domains of Dutch healthcare. We test the generalizability of three de-identification methods across languages and domains. Our experiments show that an existing rule-based method specifically developed for the Dutch language fails to generalize to this new data. Furthermore, a state-of-the-art neural architecture performs strongly across languages and domains, even with limited training data. Compared to feature-based and rule-based methods the neural method requires significantly less configuration effort and domain-knowledge. We make all code and pre-trained de-identification models available to the research community, allowing practitioners to apply them to their datasets and to enable future benchmarks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在电子健康记录的非结构化信息提供医学研究的宝贵资源。为了保护病人的保密性和符合隐私法规，去识别方法自动删除的个人识别这些医疗记录信息。然而，由于标签的数据，大多数现有的研究被限制在英国的医疗文本和小的不可有人知道的跨语言和领域去识别方法的普遍性。在这项研究中，我们构建了一个不同的数据集从9个院所和荷兰医疗保健的三个域采样数据组成的1260例患者的医疗记录。我们测试的跨语言，跨域三个去识别方法的普遍性。我们的实验表明，专门为荷兰语言开发现有的基于规则的方法不能推广到这个新的数据。此外，一个国家的最先进的神经结构进行强烈跨语言和域，即使在有限的训练数据。相比于基于规则的基于特征和方法，神经方法需要显著较少配置工作和领域的知识。我们让所有的代码和预先训练去标识模型提供给研究界，让从业者将它们应用到自己的数据集，以使未来的基准。</font>
</div>


<hr>
<div id="paper4"> <b>4. A Pilot Study on Multiple Choice Machine Reading Comprehension for  Vietnamese Texts</b>  <a href="https://arxiv.org/pdf/2001.05687" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Van+Nguyen%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kiet Van Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tran%2C+K+V" target="_blank" rel="noopener" style="color:#0000EE;">Khiem Vinh Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luu%2C+S+T" target="_blank" rel="noopener" style="color:#0000EE;">Son T. Luu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nguyen%2C+A+G" target="_blank" rel="noopener" style="color:#0000EE;">Anh Gia-Tuan Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nguyen%2C+N+L" target="_blank" rel="noopener" style="color:#0000EE;">Ngan Luu-Thuy Nguyen</a><br>
<font size="3">
Abstract: Machine Reading Comprehension (MRC) is the task of natural language processing which studies the ability to read and understand unstructured texts and then find the correct answers for questions. Until now, we have not yet had any MRC dataset for such a low-resource language as Vietnamese. In this paper, we introduce ViMMRC, a challenging machine comprehension corpus with multiple-choice questions, intended for research on the machine comprehension of Vietnamese text. This corpus includes 2,783 multiple-choice questions and answers based on a set of 417 Vietnamese texts used for teaching reading comprehension for 1st to 5th graders. Answers may be extracted from the contents of single or multiple sentences in the corresponding reading text. A thorough analysis of the corpus and experimental results in this paper illustrate that our corpus ViMMRC demands reasoning abilities beyond simple word matching. We proposed the method of Boosted Sliding Window (BSW) that improves 5.51% in accuracy over the best baseline method. We also measured human performance on the corpus and compared it to our MRC models. The performance gap between humans and our best experimental model indicates that significant progress can be made on Vietnamese machine reading comprehension in further research. The corpus is freely available at our website for research purposes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机阅读理解（MRC）是自然语言处理的哪些研究阅读和理解非结构化的文本，然后找到问题的正确答案的能力的任务。到现在为止，我们还没有过任何MRC数据集这样的低资源语言越南。在本文中，我们介绍ViMMRC，一个具有挑战性的机器理解语料库与多项选择题，供越南文本的机器理解研究。该文集包括基于一套用于教学阅读理解的1日至5年级学生417个越南文2783多项选择题及答案。答案可以从在相应的阅读文本单个或多个句子的内容被提取。本文的语料和实验结果的深入分析表明我们的语料库ViMMRC要求超出了简单的词语匹配的推理能力。我们提出的提振推拉窗（BSW）的，超过最佳基线法提高了精度5.51％的方法。我们还测量了语料库人的表现和它相比，我们的MRC模型。人类和我们最好的实验模型之间的性能差距表明，显著的进展可以在进一步研究越南机器阅读理解进行。该语料库是免费提供的，在我们的网站用于研究目的。</font>
</div>


<hr>
<div id="paper5"> <b>5. AandP: Utilizing Prolog for converting between active sentence and  passive sentence with three-steps conversion</b>  <a href="https://arxiv.org/pdf/2001.05672" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Tran%2C+T+Q" target="_blank" rel="noopener" style="color:#0000EE;">Trung Q. Tran</a><br>
<font size="3">
Abstract: I introduce a simple but efficient method to solve one of the critical aspects of English grammar which is the relationship between active sentence and passive sentence. In fact, an active sentence and its corresponding passive sentence express the same meaning, but their structure is different. I utilized Prolog [4] along with Definite Clause Grammars (DCG) [5] for doing the conversion between active sentence and passive sentence. Some advanced techniques were also used such as Extra Arguments, Extra Goals, Lexicon, etc. I tried to solve a variety of cases of active and passive sentences such as 12 English tenses, modal verbs, negative form, etc. More details and my contributions will be presented in the following sections. The source code is available at this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我介绍一个简单的，但要解决的英语语法的关键方面是主动句和被动句之间的关系的一个有效的方法。事实上，一个主动句和其对应的被动句表达同一个意思，但它们的结构是不同的。我使用的Prolog [4]与定条款文法（DCG）[5]这样做主动句和被动句子之间的转换沿。一些先进的技术，还使用了诸如额外的参数，额外的目标，词汇，等我试图解决各种主动和被动句等12个英文时态，情态动词，否定形式等更多细节和我的贡献的情况下将在下面的章节中介绍。源代码可在此HTTPS URL。</font>
</div>


<hr>
<div id="paper6"> <b>6. Schema2QA: Answering Complex Queries on the Structured Web with a Neural  Model</b>  <a href="https://arxiv.org/pdf/2001.05609" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Silei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Campagna%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Giovanni Campagna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Monica S. Lam</a><br>
<font size="3">
Abstract: Virtual assistants today require every website to submit skills individually into their proprietary repositories. The skill consists of a fixed set of supported commands and the formal representation of each command. The assistants use the contributed data to create a proprietary linguistic interface, typically using an intent classifier. This paper proposes an open-source toolkit, called Schema2QA, that leverages the this http URL markup found in many websites to automatically build skills. Schema2QA has several advantages: (1) Schema2QA handles compositional queries involving multiple fields automatically, such as "find the Italian restaurant around here with the most reviews", or "what W3C employees on LinkedIn went to Oxford"; (2) Schema2QA translates natural language into executable queries on the up-to-date data from the website; (3) natural language training can be applied to one domain at a time to handle multiple websites using the same this http URL representations. We apply Schema2QA to two different domains, showing that the skills we built can answer useful queries with little manual effort. Our skills achieve an overall accuracy between 74% and 78%, and can answer questions that span three or more properties with 65% accuracy. We also show that a new domain can be supported by transferring knowledge. The open-source Schema2QA lets each website create and own its linguistic interface. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：虚拟助理都要求每一个网站提交技巧单独为他们的专利库。技能由一组固定的支持的命令和各命令的正式表示。助手用提供的数据以创建一个专有的语言接口，通常使用的意图分类器。本文提出了一种开放源代码工具包，叫做Schema2QA，即利用了这个在很多网站上找到的自动构建技术HTTP URL标记。 Schema2QA有以下几个优点：（1）Schema2QA自动处理涉及多个领域组成的查询，如“找到意大利餐厅这里与大多数评论围绕”或“去牛津大学在LinkedIn什么W3C员工”; （2）Schema2QA转换自然语言转换为可执行的查询从网站上的最新数据; （3）自然语言培训可以同时被应用到一个域中使用相同的这个HTTP URL交涉处理多个网站。我们应用Schema2QA于两个不同的领域，显示出我们建立了技能可以回答很少的手动工作有用的查询。我们的技能达到74％和78％之间的整体精度，并能回答这个跨越65％的准确率三个或更多的性能问题。我们还表明，一个新的域可以通过知识转移的支持。开源Schema2QA让每个网站创建和拥有自己的语言界面。</font>
</div>


<hr>
<div id="paper7"> <b>7. Stereotypical Bias Removal for Hate Speech Detection Task using  Knowledge-based Generalizations</b>  <a href="https://arxiv.org/pdf/2001.05495" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Badjatiya%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pinkesh Badjatiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gupta%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Manish Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Varma%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vasudeva Varma</a><br>
<font size="3">
Abstract: With the ever-increasing cases of hate spread on social media platforms, it is critical to design abuse detection mechanisms to proactively avoid and control such incidents. While there exist methods for hate speech detection, they stereotype words and hence suffer from inherently biased training. Bias removal has been traditionally studied for structured datasets, but we aim at bias mitigation from unstructured text data. In this paper, we make two important contributions. First, we systematically design methods to quantify the bias for any model and propose algorithms for identifying the set of words which the model stereotypes. Second, we propose novel methods leveraging knowledge-based generalizations for bias-free learning. Knowledge-based generalization provides an effective way to encode knowledge because the abstraction they provide not only generalizes content but also facilitates retraction of information from the hate speech detection classifier, thereby reducing the imbalance. We experiment with multiple knowledge generalization policies and analyze their effect on general performance and in mitigating bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages dataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that the use of knowledge-based generalizations results in better performance by forcing the classifier to learn from generalized content. Our methods utilize existing knowledge-bases and can easily be extended to other tasks </font>
<br>
<font size="2" style="line-height:30px;">
摘要：随着不断增加的社会化媒体平台上传播仇恨的情况下，它是设计滥用检测手段，积极主动规避和控制此类事件的关键。虽然存在仇恨言论的检测方法，他们刻板印象的话，因此从本质上偏向训练受到影响。偏置消除历来被研究了结构化数据集，但我们的目标是从非结构化的文本数据缓解偏差。在本文中，我们提出两个重要的贡献。首先，我们系统的设计方法，以量化的任何模型的偏差，提出的算法识别词集该模型定型。第二，我们提出了新的方法利用知识为基础的概括为无偏差的学习。基于知识的推广提供了一个有效的方式来编码知识，因为他们提供的不只是抽象概括的内容，但也有利于信息回缩从仇恨言论检测分类，从而减少不平衡。我们与多个知识推广政策实验和分析整体性能和减轻他们的偏见的影响。我们有两个现实世界的尺寸〜96K的数据集，维基百科对话页数据集（WikiDetox）和大小的Twitter的数据集〜24K，表明通过强制分类在更好的性能使用基于知识的概括的结果，从学习实验广义的内容。我们的方法利用现有的知识基地，可以很容易地扩展到其他任务</font>
</div>


<hr>
<div id="paper8"> <b>8. AggressionNet: Generalised Multi-Modal Deep Temporal and Sequential  Learning for Aggression Identification</b>  <a href="https://arxiv.org/pdf/2001.05493" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Khandelwal%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anant Khandelwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Niraj Kumar</a><br>
<font size="3">
Abstract: Wide usage of social media platforms has increased the risk of aggression, which results in mental stress and affects the lives of people negatively like psychological agony, fighting behavior, and disrespect to others. Majority of such conversations contains code-mixed languages[28]. Additionally, the way used to express thought or communication style also changes from one social media plat-form to another platform (e.g., communication styles are different in twitter and Facebook). These all have increased the complexity of the problem. To solve these problems, we have introduced a unified and robust multi-modal deep learning architecture which works for English code-mixed dataset and uni-lingual English dataset both.The devised system, uses psycho-linguistic features and very ba-sic linguistic features. Our multi-modal deep learning architecture contains, Deep Pyramid CNN, Pooled BiLSTM, and Disconnected RNN(with Glove and FastText embedding, both). Finally, the system takes the decision based on model averaging. We evaluated our system on English Code-Mixed TRAC 2018 dataset and uni-lingual English dataset obtained from Kaggle. Experimental results show that our proposed system outperforms all the previous approaches on English code-mixed dataset and uni-lingual English dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：社会化媒体平台，用途广泛增加侵略的风险，这会导致精神压力和负面影响的人们的生活就像心理上的痛苦，战斗行为，和不尊重他人。这样的对话的大多数包含代码混合语言[28]。此外，该方法用来表达思想或沟通方式也从一个社交媒体平台，改变到另一个平台（例如，沟通方式是在Twitter和Facebook有所不同）。这些都增加了问题的复杂性。为了解决这些问题，我们引入了一个统一和强大的多模态深度学习架构，适用于英语代码混合数据集和单语种英语数据集both.The设计系统，采用心理语言特征和非常BA-SIC语言特征。我们的多模态深度学习架构包含，深金字塔CNN，汇集BiLSTM，并断开RNN（带手套和FastText嵌入，两者）。最后，该系统采用基于模型平均的决定。我们评估了英语代码混合TRAC 2018数据集，并从Kaggle获得单语种英语数据集我们的系统。实验结果表明，该系统优于所有英语代码混合数据集和单语种英语数据集以前的方法。</font>
</div>


<hr>
<div id="paper9"> <b>9. #MeToo on Campus: Studying College Sexual Assault at Scale Using Data  Reported on Social Media</b>  <a href="https://arxiv.org/pdf/2001.05970" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Duong%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Viet Duong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pham%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Phu Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bose%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ritwik Bose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Luo%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiebo Luo</a><br>
<font size="3">
Abstract: Recently, the emergence of the #MeToo trend on social media has empowered thousands of people to share their own sexual harassment experiences. This viral trend, in conjunction with the massive personal information and content available on Twitter, presents a promising opportunity to extract data driven insights to complement the ongoing survey based studies about sexual harassment in college. In this paper, we analyze the influence of the #MeToo trend on a pool of college followers. The results show that the majority of topics embedded in those #MeToo tweets detail sexual harassment stories, and there exists a significant correlation between the prevalence of this trend and official reports on several major geographical regions. Furthermore, we discover the outstanding sentiments of the #MeToo tweets using deep semantic meaning representations and their implications on the affected users experiencing different types of sexual harassment. We hope this study can raise further awareness regarding sexual misconduct in academia. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近日，在社会化媒体的#MeToo趋势的出现已经授权成千上万的人分享自己的性骚扰经历。这种病毒发展趋势，结合大量的个人信息，并在Twitter上可用内容，提出了一个有前途的机会抽取数据的深入分析，以补充有关大学性骚扰正在进行的调查为基础的研究。在本文中，我们分析了对高校追随者池#MeToo趋势的影响。结果显示，大部分嵌入在这些#MeToo主题的鸣叫细节性骚扰的故事，并且存在几大地理区域这一趋势，官方报告的患病率之间的相关性显著。此外，我们发现使用深层语义表述及其对受影响的用户体验不同类型的性骚扰影响的#MeToo鸣叫的优秀情绪。我们希望这项研究能提高公众对学术界的性行为不端进一步的认识。</font>
</div>


<hr>
<div id="paper10"> <b>10. Show, Recall, and Tell: Image Captioning with Recall Mechanism</b>  <a href="https://arxiv.org/pdf/2001.05876" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Li Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bai%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zechen Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yonghua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongtao Lu</a><br>
<font size="3">
Abstract: Generating natural and accurate descriptions in image cap-tioning has always been a challenge. In this paper, we pro-pose a novel recall mechanism to imitate the way human con-duct captioning. There are three parts in our recall mecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS). Recall unit is a text-retrieval module designedto retrieve recalled words for images. SG and RWS are de-signed for the best use of recalled words. SG branch cangenerate a recalled context, which can guide the process ofgenerating caption. RWS branch is responsible for copyingrecalled words to the caption. Inspired by pointing mecha-nism in text summarization, we adopt a soft switch to balancethe generated-word probabilities between SG and RWS. Inthe CIDEr optimization step, we also introduce an individualrecalled-word reward (WR) to boost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr / SPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 / 22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the results of other state-of-the-artmethods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：生成自然和图像帽tioning准确的描述一直是一个挑战。在本文中，我们亲姿势模仿的方式人类CON-管字幕一种新的召回机制。有三个部分在我们的回忆机甲-NISM：召回单位，语义指南（SG），并回顾-wordslot（RWS）。召回单元是文本的检索模块designedto检索图像召回的话。 SG和RWS被解签订了最好的使用被召回的话。 SG分支cangenerate一个回顾上下文，其可以引导过程ofgenerating字幕。 RWS分公司负责copyingrecalled字标题。通过指向文本摘要机甲-NISM启发，我们采用软切换至SG和RWS之间balancethe产生字概率。在矿井苹果酒优化步骤，我们还引入individualrecalled字奖励（WR），以提升培训。我们的proposedmethods（SG + RWS + WR）实现BLEU-4 /苹果酒/ 36.6 / 116.9 / 21.3与交叉熵损失和38.7 /129.1 /苹果酒优化上MSCOCO Karpathytest分裂22.4，这超越其他状态 - 的结果SPICEscores的最artmethods。</font>
</div>


<hr>
<div id="paper11"> <b>11. "Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials  for Humans</b>  <a href="https://arxiv.org/pdf/2001.05871" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lai%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vivian Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chenhao Tan</a><br>
<font size="3">
Abstract: To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a training phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：为支持与机器学习模型人的决策，我们经常需要嵌入是unsalient的，未知的，或者违反直觉的人类模型阐发模式。虽然现有的方法重点讲解机器的预测具有实时援助，我们探讨模型驱动的教程，以帮助人们了解一个训练阶段这些模式。我们认为，从科学论文，类似于科学传播的现行做法，并从解释训练数据自动选择的例子准则都教程。我们使用欺骗性的审查检测作为测试平台，并进行大规模，随机人体学科实验来检验这种教程的效果。我们发现，确实教程改善人类的性能，使用和不使用实时的援助。特别是，虽然深度学习不是简单的模型，教程和简单模型的解释提供了卓越的预测性能对人体更有益。我们的工作提出了以人为本对人类和人工智能之间的协同作用的教程和说明未来的发展方向。</font>
</div>


<hr>
<div id="paper12"> <b>12. Ensemble based discriminative models for Visual Dialog Challenge 2018</b>  <a href="https://arxiv.org/pdf/2001.05865" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shubham Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goyal%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Raghav Goyal</a><br>
<font size="3">
Abstract: This manuscript describes our approach for the Visual Dialog Challenge 2018. We use an ensemble of three discriminative models with different encoders and decoders for our final submission. Our best performing model on 'test-std' split achieves the NDCG score of 55.46 and the MRR value of 63.77, securing third position in the challenge. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本稿件描述了我们的视觉对话挑战2018年我们使用三种判别模型不同的编码器和解码器为我们最后提交的集成方法。在“测试-STD”分裂我们的最佳表现模型达到NDCG得分55.46和63.77的MRR的价值，确保在挑战第三的位置。</font>
</div>


<hr>
<div id="paper13"> <b>13. Discoverability in Satellite Imagery: A Good Sentence is Worth a  Thousand Pictures</b>  <a href="https://arxiv.org/pdf/2001.05839" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Noever%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Noever</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Regian%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wes Regian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ciolino%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Matt Ciolino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kalin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Josh Kalin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hambrick%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dom Hambrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Blankenship%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kaye Blankenship</a><br>
<font size="3">
Abstract: Small satellite constellations provide daily global coverage of the earth's landmass, but image enrichment relies on automating key tasks like change detection or feature searches. For example, to extract text annotations from raw pixels requires two dependent machine learning models, one to analyze the overhead image and the other to generate a descriptive caption. We evaluate seven models on the previously largest benchmark for satellite image captions. We extend the labeled image samples five-fold, then augment, correct and prune the vocabulary to approach a rough min-max (minimum word, maximum description). This outcome compares favorably to previous work with large pre-trained image models but offers a hundred-fold reduction in model size without sacrificing overall accuracy (when measured with log entropy loss). These smaller models provide new deployment opportunities, particularly when pushed to edge processors, on-board satellites, or distributed ground stations. To quantify a caption's descriptiveness, we introduce a novel multi-class confusion or error matrix to score both human-labeled test data and never-labeled images that include bounding box detection but lack full sentence captions. This work suggests future captioning strategies, particularly ones that can enrich the class coverage beyond land use applications and that lessen color-centered and adjacency adjectives ("green", "near", "between", etc.). Many modern language transformers present novel and exploitable models with world knowledge gleaned from training from their vast online corpus. One interesting, but easy example might learn the word association between wind and waves, thus enriching a beach scene with more than just color descriptions that otherwise might be accessed from raw pixels without text annotation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：小卫星星座提供地球陆地面积的每日全球覆盖，但图像富集依赖于自动化样改变检测或功能的搜索关键任务。例如，为了从原始像素提取文本注释需要两个依赖机器学习模型，一个分析俯视图像和其他，以产生描述性标题。我们评估对卫星图片说明以前最大的基准七款车型。我们扩展了标记图像样本五倍，然后扩充的，正确的和修剪词汇接近粗糙最小 - 最大（最小字，最大的描述）。这一结果相比毫不逊色与大预先训练的图像模型，但提供的模型大小百倍还原之前的工作不牺牲整体精度（当日志熵损失测量）。这些小模型提供了新的部署机会，特别是当推到边缘处理器，板载卫星，或分布式地面站。为了量化标题的描述性，我们引入了一个新的多类混淆或错误矩阵得分人类标记的测试数据，而不会标记的图像，包括边框检测，但缺乏完整的句子标题。这项工作表明未来字幕战略，特别是那些能充实类覆盖率超过土地使用的应用程序和减轻色心和邻接的形容词（“绿色”，“近”，“间”等）。许多现代语言的变压器存在新颖性和与世界的知识利用的模型从训练中收集来自其庞大的在线语料库。一个有趣的，但简单的例子可以学习乘风破浪的词语联想，从而丰富海滩场景比，否则可能从原始像素进行访问，而不文本注释只是颜色的描述更多。</font>
</div>


<hr>
<div id="paper14"> <b>14. Document Network Projection in Pretrained Word Embedding Space</b>  <a href="https://arxiv.org/pdf/2001.05727" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gourru%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Antoine Gourru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guille%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adrien Guille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Velcin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Velcin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jacques%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Jacques</a><br>
<font size="3">
Abstract: We present Regularized Linear Embedding (RLE), a novel method that projects a collection of linked documents (e.g. citation network) into a pretrained word embedding space. In addition to the textual content, we leverage a matrix of pairwise similarities providing complementary information (e.g., the network proximity of two documents in a citation graph). We first build a simple word vector average for each document, and we use the similarities to alter this average representation. The document representations can help to solve many information retrieval tasks, such as recommendation, classification and clustering. We demonstrate that our approach outperforms or matches existing document network embedding methods on node classification and link prediction tasks. Furthermore, we show that it helps identifying relevant keywords to describe document classes. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出正则线性嵌入（RLE），一种新型的方法，其项目链接的文档（例如引网络）的集合到一个预训练的字嵌入空间。除了文本内容，我们利用成对的相似性提供补充信息（例如，在引用图两个文件的网络接近）的基质中。我们首先建立每个文档的简单词汇向量平均，而我们使用的相似改变这种平均表示。该文件表示可以帮助解决许多信息检索任务，如推荐，分类和聚类。我们证明我们的方法比或匹配现有的文档嵌入网络节点上的分类和链接预测任务的方法。此外，我们表明，它可以帮助识别相关关键字来描述文档类。</font>
</div>


<hr>
<div id="paper15"> <b>15. Delving Deeper into the Decoder for Video Captioning</b>  <a href="https://arxiv.org/pdf/2001.05614" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haoran Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jianmin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaolin Hu</a><br>
<font size="3">
Abstract: Video captioning is an advanced multi-modal task which aims to describe a video clip using a natural language sentence. The encoder-decoder framework is the most popular paradigm for this task in recent years. However, there still exist some non-negligible problems in the decoder of a video captioning model. We make a thorough investigation into the decoder and adopt three techniques to improve the performance of the model. First of all, a combination of variational dropout and layer normalization is embedded into a recurrent unit to alleviate the problem of overfitting. Secondly, a new method is proposed to evaluate the performance of a model on a validation set so as to select the best checkpoint for testing. Finally, a new training strategy called \textit{professional learning} is proposed which develops the strong points of a captioning model and bypasses its weaknesses. It is demonstrated in the experiments on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to Text (MSR-VTT) datasets that our model has achieved the best results evaluated by BLEU, CIDEr, METEOR and ROUGE-L metrics with significant gains of up to 11.7% on MSVD and 5% on MSR-VTT compared with the previous state-of-the-art models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：视频字幕是一种先进的多模态的任务，目的是描述使用自然语言句子的视频剪辑。编码器，解码器框架是在最近几年，这一任务最流行的范例。但是，仍然存在着一个视频字幕模型的解码器的一些不可忽视的问题。我们做一个彻底的调查，解码器，并采用三种技术来提高模型的性能。首先，变差和层正常化的组合被嵌入到一个重复单元，以减轻过拟合问题。其次，新方法，提出了在验证集评估模型的性能，以便选择最佳的检查点进行测试。最后，新的培训战略称为\ textit {专业学习}，提出了开发一个字幕模型的长处，避开其弱点。它证明了在微软研究院的视频描述语料库（MSVD）和MSR视频的实验文本（MSR-VTT）的数据集，我们的模型已经实现由BLEU，苹果酒，流星和ROUGE-L指标评估了显著收益最好的结果高达11.7％的MSVD和5％的MSR-VTT与以前国家的最先进的机型相比。</font>
</div>


<hr>
<div id="paper16"> <b>16. Insertion-Deletion Transformer</b>  <a href="https://arxiv.org/pdf/2001.05540" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ruis%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Laura Ruis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Stern%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mitchell Stern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Proskurnia%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julia Proskurnia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">William Chan</a><br>
<font size="3">
Abstract: We propose the Insertion-Deletion Transformer, a novel transformer-based neural architecture and training method for sequence generation. The model consists of two phases that are executed iteratively, 1) an insertion phase and 2) a deletion phase. The insertion phase parameterizes a distribution of insertions on the current output hypothesis, while the deletion phase parameterizes a distribution of deletions over the current output hypothesis. The training method is a principled and simple algorithm, where the deletion model obtains its signal directly on-policy from the insertion model output. We demonstrate the effectiveness of our Insertion-Deletion Transformer on synthetic translation tasks, obtaining significant BLEU score improvement over an insertion-only model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出的插入缺失变压器，一种新型的基于变压器的神经结构和序列生成训练方法。该模型由被迭代执行两个阶段：1）的插入相位和2）的删除相。插入阶段参数化对电流输出假设插入的分布，而删除相位参数化缺失的过电流输出假设的分布。该训练方法是一个原则性和简单的算法，其中该删除模型直接获得关于策略从插入模型输出它的信号。我们证明我们的插入缺失变压器上合成翻译任务的有效性，通过一个只有插入模型取得显著BLEU评分改善。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>一些公司及高校在线翻译系统</title>
    <url>/2020/01/17/%E4%B8%80%E4%BA%9B%E5%85%AC%E5%8F%B8%E5%8F%8A%E9%AB%98%E6%A0%A1%E5%9C%A8%E7%BA%BF%E7%BF%BB%E8%AF%91%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="公司在线翻译系统"><a href="#公司在线翻译系统" class="headerlink" title="公司在线翻译系统"></a>公司在线翻译系统</h1><ul>
<li><a href="https://fanyi.baidu.com/" target="_blank" rel="noopener">百度翻译</a></li>
<li><a href="https://translate.google.cn/" target="_blank" rel="noopener">谷歌翻译</a></li>
<li><a href="http://fanyi.youdao.com/" target="_blank" rel="noopener">有道翻译</a></li>
<li><a href="https://fanyi.qq.com/" target="_blank" rel="noopener">腾讯翻译君</a></li>
<li><a href="https://fanyi.sogou.com/" target="_blank" rel="noopener">搜狗翻译</a></li>
<li><a href="https://niutrans.vip/trans" target="_blank" rel="noopener">小牛翻译</a></li>
<li><a href="https://cloudtranslation.com/online/" target="_blank" rel="noopener">云译</a></li>
</ul><h1 id="高校在线翻译系统"><a href="#高校在线翻译系统" class="headerlink" title="高校在线翻译系统"></a>高校在线翻译系统</h1><ul>
<li><a href="http://nmt.xmu.edu.cn/" target="_blank" rel="noopener">厦门大学</a></li>
</ul>]]></content>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-16</title>
    <url>/2020/01/17/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-16/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses <a href="https://arxiv.org/pdf/2001.05467" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> A BERT based Sentiment Analysis and Key Entity Detection Approach for  Online Financial Texts <a href="https://arxiv.org/pdf/2001.05326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Authorship Attribution in Bangla literature using Character-level CNN <a href="https://arxiv.org/pdf/2001.05316" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> A Continuous Space Neural Language Model for Bengali Language <a href="https://arxiv.org/pdf/2001.05315" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Embedding Compression with Isotropic Iterative Quantization <a href="https://arxiv.org/pdf/2001.05314" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Tensor Graph Convolutional Networks for Text Classification <a href="https://arxiv.org/pdf/2001.05313" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process  Approach to Linguistic Relationships <a href="https://arxiv.org/pdf/2001.05297" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Urdu-English Machine Transliteration using Neural Networks <a href="https://arxiv.org/pdf/2001.05296" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Language Models Are An Effective Patient Representation Learning  Technique For Electronic Health Record Data <a href="https://arxiv.org/pdf/2001.05295" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> The empirical structure of word frequency distributions <a href="https://arxiv.org/pdf/2001.05292" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Exploring and Improving Robustness of Multi Task Deep Neural Networks  via Domain Agnostic Defenses <a href="https://arxiv.org/pdf/2001.05286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Detecting New Word Meanings: A Comparison of Word Embedding Models in  Spanish <a href="https://arxiv.org/pdf/2001.05285" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Improving Spoken Language Understanding By Exploiting ASR N-best  Hypotheses <a href="https://arxiv.org/pdf/2001.05284" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> FGN: Fusion Glyph Network for Chinese Named Entity Recognition <a href="https://arxiv.org/pdf/2001.05272" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation <a href="https://arxiv.org/pdf/2001.05139" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Parallel Machine Translation with Disentangled Context Transformer <a href="https://arxiv.org/pdf/2001.05136" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Robust Speaker Recognition Using Speech Enhancement And Attention Model <a href="https://arxiv.org/pdf/2001.05031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> A Tree Adjoining Grammar Representation for Models Of Stochastic  Dynamical Systems <a href="https://arxiv.org/pdf/2001.05320" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Auto Completion of User Interface Layout Design Using Transformer-Based  Tree Decoders <a href="https://arxiv.org/pdf/2001.05308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Teddy: A System for Interactive Review Analysis <a href="https://arxiv.org/pdf/2001.05171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Modeling Product Search Relevance in e-Commerce <a href="https://arxiv.org/pdf/2001.04980" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses</b>  <a href="https://arxiv.org/pdf/2001.05467" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Niu%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tong Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: Many sequence-to-sequence dialogue models tend to generate safe, uninformative responses. There have been various useful efforts on trying to eliminate them. However, these approaches either improve decoding algorithms during inference, rely on hand-crafted features, or employ complex models. In our work, we build dialogue models that are dynamically aware of what utterances or tokens are dull without any feature-engineering. Specifically, we start with a simple yet effective automatic metric, AvgOut, which calculates the average output probability distribution of all time steps on the decoder side during training. This metric directly estimates which tokens are more likely to be generated, thus making it a faithful evaluation of the model diversity (i.e., for diverse models, the token probabilities should be more evenly distributed rather than peaked at a few dull tokens). We then leverage this novel metric to propose three models that promote diversity without losing relevance. The first model, MinAvgOut, directly maximizes the diversity score through the output distributions of each batch; the second model, Label Fine-Tuning (LFT), prepends to the source sequence a label continuously scaled by the diversity score to control the diversity level; the third model, RL, adopts Reinforcement Learning and treats the diversity score as a reward signal. Moreover, we experiment with a hybrid model by combining the loss terms of MinAvgOut and RL. All four models outperform their base LSTM-RNN model on both diversity and relevance by a large margin, and are comparable to or better than competitive baselines (also verified via human evaluation). Moreover, our approaches are orthogonal to the base model, making them applicable as an add-on to other emerging better dialogue models in the future. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：许多序列对序列的对话模式容易产生安全，无信息的响应。已经有上试图消除他们各种有用的努力。然而，这些方法或者改进的推理过程中的解码算法，依靠手工制作的功能，或采用复杂的模型。在我们的工作，我们建立对话模型是动态意识到什么话语或令牌是没有任何功能的工程平淡。具体而言，我们先从一个简单而有效的自动度量，AvgOut，其在训练期间计算出的解码器侧的所有时间步长的平均输出概率分布。该指标直接估计令牌更容易产生，从而使得它的型号多样的忠实评价（即，对于不同的车型，令牌的概率应该是更均匀地分布，而不是在几个沉闷的令牌见顶）。然后，我们利用这一新的指标，提出促进多样性不失相关性三种模式。第一种模式，MinAvgOut，直接通过最大化每批的输出分布的分集比分;第二个模型，标签微调（LFT），前置到源序列通过分集比分来控制分集电平连续缩放的标签;第三种模式，RL，采用强化学习和对待多样性分数作为奖励信号。此外，我们结合MinAvgOut和RL的损失方面与混合动力模型试验。所有这四种型号跑赢上都多样性和实用性大幅度的基地LSTM-RNN模型，并比竞争基准（也可以通过人工评估验证）相当或更好。此外，我们的方法是正交的示范基地，使它们适用于作为一个附加在未来其他新兴更好的对话模式。</font>
</div>


<hr>
<div id="paper2"> <b>2. A BERT based Sentiment Analysis and Key Entity Detection Approach for  Online Financial Texts</b>  <a href="https://arxiv.org/pdf/2001.05326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lingyun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zheng%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinhao Zheng</a><br>
<font size="3">
Abstract: The emergence and rapid progress of the Internet have brought ever-increasing impact on financial domain. How to rapidly and accurately mine the key information from the massive negative financial texts has become one of the key issues for investors and decision makers. Aiming at the issue, we propose a sentiment analysis and key entity detection approach based on BERT, which is applied in online financial text mining and public opinion analysis in social media. By using pre-train model, we first study sentiment analysis, and then we consider key entity detection as a sentence matching or Machine Reading Comprehension (MRC) task in different granularity. Among them, we mainly focus on negative sentimental information. We detect the specific entity by using our approach, which is different from traditional Named Entity Recognition (NER). In addition, we also use ensemble learning to improve the performance of proposed approach. Experimental results show that the performance of our approach is generally higher than SVM, LR, NBM, and BERT for two financial sentiment analysis and key entity detection datasets. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：出现和互联网的飞速进步也带来了金融领域不断增加的影响。如何快速，准确地矿从大量负面财务文本的关键信息已成为投资者和决策者的关键问题之一。针对这个问题，我们提出了一个情感分析和基于BERT，这是在网上金融文本挖掘和舆情分析社交媒体应用的关键实体检测方法。通过使用预火车模型，我们首先研究情感分析，然后我们考虑的关键实体检测在不同粒度的句子匹配或机器阅读理解（MRC）的任务。其中，我们主要集中在负感伤的信息。我们发现，通过使用我们的方法，这是从传统的命名实体识别（NER）不同的特定实体。此外，我们还可以使用集成学习，以提高该方法的性能。实验结果表明，我们的方法的性能一般比SVM，LR，NBM，和BERT较高的两个财务情绪分析和关键实体检测数据集。</font>
</div>


<hr>
<div id="paper3"> <b>3. Authorship Attribution in Bangla literature using Character-level CNN</b>  <a href="https://arxiv.org/pdf/2001.05316" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatun%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Aisha Khatun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rahman%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anisur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Islam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Md. Saiful Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Marium-E-Jannat" target="_blank" rel="noopener" style="color:#0000EE;">Marium-E-Jannat</a><br>
<font size="3">
Abstract: Characters are the smallest unit of text that can extract stylometric signals to determine the author of a text. In this paper, we investigate the effectiveness of character-level signals in Authorship Attribution of Bangla Literature and show that the results are promising but improvable. The time and memory efficiency of the proposed model is much higher than the word level counterparts but accuracy is 2-5% less than the best performing word-level models. Comparison of various word-based models is performed and shown that the proposed model performs increasingly better with larger datasets. We also analyze the effect of pre-training character embedding of diverse Bangla character set in authorship attribution. It is seen that the performance is improved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors, balancing them before training and compare the results. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：字符是文本，可以提取stylometric信号来确定文本的作者的最小单位。在本文中，我们研究了字符级信号的孟加拉文学著作权归属的有效性，并表明其结果是有希望的，但改善的。该模型的时间和内存效率比字级同行高得多，但精度比表现最好的字级车型少2-5％。执行并显示各种基于词的模型比较，该模型执行越来越多地与更大的数据集更好。我们还分析了前培训字符著作权归属不同孟加拉字符集的嵌入的效果。可以看出，性能高达10％的预培训提高。我们使用的数据集2的6至14作家，训练前平衡他们并比较结果。</font>
</div>


<hr>
<div id="paper4"> <b>4. A Continuous Space Neural Language Model for Bengali Language</b>  <a href="https://arxiv.org/pdf/2001.05315" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chowdhury%2C+H+A" target="_blank" rel="noopener" style="color:#0000EE;">Hemayet Ahmed Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Imon%2C+M+A+H" target="_blank" rel="noopener" style="color:#0000EE;">Md. Azizul Haque Imon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rahman%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anisur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Khatun%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Aisha Khatun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Islam%2C+M+S" target="_blank" rel="noopener" style="color:#0000EE;">Md. Saiful Islam</a><br>
<font size="3">
Abstract: Language models are generally employed to estimate the probability distribution of various linguistic units, making them one of the fundamental parts of natural language processing. Applications of language models include a wide spectrum of tasks such as text summarization, translation and classification. For a low resource language like Bengali, the research in this area so far can be considered to be narrow at the very least, with some traditional count based models being proposed. This paper attempts to address the issue and proposes a continuous-space neural language model, or more specifically an ASGD weight dropped LSTM language model, along with techniques to efficiently train it for Bengali Language. The performance analysis with some currently existing count based models illustrated in this paper also shows that the proposed architecture outperforms its counterparts by achieving an inference perplexity as low as 51.2 on the held out data set for Bengali. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言模型通常用来估计各种语言单位的概率分布，使其自然语言处理的基本组成部分之一。语言模型的应用包括任务，如文本摘要，翻译和分类的广泛。对于像孟加拉低资源的语言，在这方面至今也算是研究是起码狭窄，而提出了一些传统的基于计数模式。本文试图解决这个问题，并提出了一个连续的空间神经语言模型，或者更准确地说是ASGD体重也下降LSTM语言模型，用技术来有效地训练它的孟加拉语一起。本文所示还显示了一些目前存在的以计数为基础的模型的性能分析，提出的架构通过实现一个推论困惑低至51.2对孟加拉的伸出数据集优于其同行。</font>
</div>


<hr>
<div id="paper5"> <b>5. Embedding Compression with Isotropic Iterative Quantization</b>  <a href="https://arxiv.org/pdf/2001.05314" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liao%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Siyu Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanzhi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qinru Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yuan%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bo Yuan</a><br>
<font size="3">
Abstract: Continuous representation of words is a standard component in deep learning-based NLP models. However, representing a large vocabulary requires significant memory, which can cause problems, particularly on resource-constrained platforms. Therefore, in this paper we propose an isotropic iterative quantization (IIQ) approach for compressing embedding vectors into binary ones, leveraging the iterative quantization technique well established for image retrieval, while satisfying the desired isotropic property of PMI based models. Experiments with pre-trained embeddings (i.e., GloVe and HDC) demonstrate a more than thirty-fold compression ratio with comparable and sometimes even improved performance over the original real-valued embedding vectors. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：词的连续表示是基于深学习NLP车型的标准组件。然而，较大量的词汇需要显著的内存，这可能会导致问题，特别是在资源受限的平台。因此，在本文中，我们提出了压缩嵌入矢量成二进制的，利用图像检索完善的迭代量化技术，同时满足基于PMI模型所需的各向同性各向同性迭代量化（IIQ）的方法。与预训练的嵌入（即，手套和HDC）实验证实与在原始实值嵌入矢量可比有时甚至改善性能超过30倍的压缩比。</font>
</div>


<hr>
<div id="paper6"> <b>6. Tensor Graph Convolutional Networks for Text Classification</b>  <a href="https://arxiv.org/pdf/2001.05313" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xien Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=You%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinxin You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Ji Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lv%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Ping Lv</a><br>
<font size="3">
Abstract: Compared to sequential learning models, graph-based neural networks exhibit some excellent properties, such as ability capturing global information. In this paper, we investigate graph-based neural networks for text classification problem. A new framework TensorGCN (tensor graph convolutional networks), is presented for this task. A text graph tensor is firstly constructed to describe semantic, syntactic, and sequential contextual information. Then, two kinds of propagation learning perform on the text graph tensor. The first is intra-graph propagation used for aggregating information from neighborhood nodes in a single graph. The second is inter-graph propagation used for harmonizing heterogeneous information between graphs. Extensive experiments are conducted on benchmark datasets, and the results illustrate the effectiveness of our proposed framework. Our proposed TensorGCN presents an effective way to harmonize and integrate heterogeneous information from different kinds of graphs. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：相比于连续的学习模式，基于图形的神经网络表现出一些优异的性能，如能力捕捉全球信息。在本文中，我们研究了文本分类问题，基于图形的神经网络。一个新的框架TensorGCN（图张卷积网络），提出了这一任务。文本图形张量首先被构造来描述语义，语法，和顺序的上下文信息。然后，有两种传播学习上的文字图形张量执行。第一种是用于在单个图表聚集来自邻近节点的信息，图形的帧内传播。第二个是用于协调图之间异构信息曲线图间传播。大量的实验是在基准数据集进行，其结果说明我们提出的框架的有效性。我们提出的TensorGCN礼物协调和异构信息从不同类型的图形整合的有效途径。</font>
</div>


<hr>
<div id="paper7"> <b>7. Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process  Approach to Linguistic Relationships</b>  <a href="https://arxiv.org/pdf/2001.05297" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Cathcart%2C+C+A" target="_blank" rel="noopener" style="color:#0000EE;">Chundra Aroor Cathcart</a><br>
<font size="3">
Abstract: This paper addresses a series of complex and unresolved issues in the historical phonology of West Iranian languages. The West Iranian languages (Persian, Kurdish, Balochi, and other languages) display a high degree of non-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to language contact; we argue, however, that an oversimplified view of the processes at work has prevailed in the literature on West Iranian dialectology, with specialists assuming that deviations from an expected outcome in a given non-Persian language are due to lexical borrowing from some chronological stage of Persian. It is demonstrated that this qualitative approach yields at times problematic conclusions stemming from the lack of explicit probabilistic inferences regarding the distribution of the data: Persian may not be the sole donor language; additionally, borrowing at the lexical level is not always the mechanism that introduces irregularity. In many cases, the possibility that West Iranian languages show different reflexes in different conditioning environments remains under-explored. We employ a novel Bayesian approach designed to overcome these problems and tease apart the different determinants of irregularity in patterns of West Iranian sound change. Our methodology allows us to provisionally resolve a number of outstanding questions in the literature on West Iranian dialectology concerning the dialectal affiliation of certain sound changes. We outline future directions for work of this sort. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文地址了一系列西伊朗语支的历史音韵复杂和悬而未决的问题。西伊朗语支（波斯，库尔德人，俾路支语等语种）表现出高度的非Lautgesetzlich行为。大多数这种不规则的无疑是由于语言接触;我们认为，但是，在工作流程的一个过于简单化的观点在西方的伊朗方言的文学盛行，与由于从一些时间阶段的词汇借用专家假设从给定的非波斯语的预期结果偏差波斯语。据证实，这种定性方法的产量有时有问题的结论，因为缺乏有关数据的分布概率明确推论的词干：波斯可能不是唯一的供体语言;另外，在词汇水平借用并不总是机制引入了不规则性。在许多情况下，西伊朗的语言说明了在不同的环境条件不同反射的可能性仍然充分开发。我们采用设计来克服这些问题，并梳理出不规则的西伊朗声音的变化模式的不同决定一种新的贝叶斯方法。我们的方法可以让我们暂时解决了许多文献对西方的伊朗方言有关的某些声音的变化方言隶属关系悬而未决的问题。我们为这种工作勾勒未来的发展方向。</font>
</div>


<hr>
<div id="paper8"> <b>8. Urdu-English Machine Transliteration using Neural Networks</b>  <a href="https://arxiv.org/pdf/2001.05296" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Din%2C+U+M+u" target="_blank" rel="noopener" style="color:#0000EE;">Usman Mohy ud Din</a><br>
<font size="3">
Abstract: Machine translation has gained much attention in recent years. It is a sub-field of computational linguistic which focus on translating text from one language to other language. Among different translation techniques, neural network currently leading the domain with its capabilities of providing a single large neural network with attention mechanism, sequence-to-sequence and long-short term modelling. Despite significant progress in domain of machine translation, translation of out-of-vocabulary words(OOV) which include technical terms, named-entities, foreign words are still a challenge for current state-of-art translation systems, and this situation becomes even worse while translating between low resource languages or languages having different structures. Due to morphological richness of a language, a word may have different meninges in different context. In such scenarios, translation of word is not only enough in order provide the correct/quality translation. Transliteration is a way to consider the context of word/sentence during translation. For low resource language like Urdu, it is very difficult to have/find parallel corpus for transliteration which is large enough to train the system. In this work, we presented transliteration technique based on Expectation Maximization (EM) which is un-supervised and language independent. Systems learns the pattern and out-of-vocabulary (OOV) words from parallel corpus and there is no need to train it on transliteration corpus explicitly. This approach is tested on three models of statistical machine translation (SMT) which include phrasebased, hierarchical phrase-based and factor based models and two models of neural machine translation which include LSTM and transformer model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：机器翻译已经获得了广泛关注，近年来。这是着眼于从一种语言到另一种语言翻译文本计算语言学的子领域。在不同的翻译技术，目前主导其提供与注意机制，序列对序列和长短期建模一个大的神经网络的功能域的神经网络。尽管在机器翻译，出词汇的词（OOV），其中包括技术术语，命名实体翻译的领域显著进步，外来词仍然是国家的最先进的电流转换系统的挑战，而且这种情况变得更而具有不同结构的低资源语言或语言之间的转换变得更糟。由于语言的形态丰富，一个字可以有不同的上下文不同的脑膜。在这种情况下，文字的翻译不仅足以为了提供正确的/翻译质量。音译是考虑在翻译过程中字/句子的上下文的方式。对于像乌尔都语低资源语言，它是很难有/找到音译平行语料库是足够大的训练系统。在这项工作中，我们提出了基于期望最大化（EM）的音译技术，它是无监督和语言无关。系统学习的模式，从平行语料库超出词汇（OOV）的话，也没有必要训练它音译语料库明确。这种方法是在三个模型的统计机器翻译（SMT），其中包括phrasebased的测试，分层phrasebased和基于因子模型和神经机器翻译的两款车型，其中包括LSTM和变压器模型。</font>
</div>


<hr>
<div id="paper9"> <b>9. Language Models Are An Effective Patient Representation Learning  Technique For Electronic Health Record Data</b>  <a href="https://arxiv.org/pdf/2001.05295" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Steinberg%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Ethan Steinberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jung%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Ken Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Fries%2C+J+A" target="_blank" rel="noopener" style="color:#0000EE;">Jason A. Fries</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Corbin%2C+C+K" target="_blank" rel="noopener" style="color:#0000EE;">Conor K. Corbin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pfohl%2C+S+R" target="_blank" rel="noopener" style="color:#0000EE;">Stephen R. Pfohl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shah%2C+N+H" target="_blank" rel="noopener" style="color:#0000EE;">Nigam H. Shah</a><br>
<font size="3">
Abstract: Widespread adoption of electronic health records (EHRs) has fueled development of clinical outcome models using machine learning. However, patient EHR data are complex, and how to optimally represent them is an open question. This complexity, along with often small training set sizes available to train these clinical outcome models, are two core challenges for training high quality models. In this paper, we demonstrate that learning generic representations from the data of all the patients in the EHR enables better performing prediction models for clinical outcomes, allowing for these challenges to be overcome. We adapt common representation learning techniques used in other domains and find that representations inspired by language models enable a 3.5% mean improvement in AUROC on five clinical outcomes compared to standard baselines, with the average improvement rising to 19% when only a small number of patients are available for training a prediction model for a given clinical outcome. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：广泛采用的电子健康记录（电子病历）具有利用机器学习临床结果模型的燃料的发展。然而，患者的电子病历数据是复杂的，如何最优地表示他们是一个悬而未决的问题。这种复杂性，经常与小的训练集以及尺寸，以训练这些临床结果的模型，是培养高素质模型两个核心挑战。在本文中，我们证明了学习所有的患者在电子病历的数据一般表示为临床结果可以实现更好的进行预测模型，从而不必在克服这些挑战。我们采用通用表示学习其他领域使用的技术，并找到语言模型的启发是表示能够在AUROC五个临床结果3.5％的平均改善比标准的基线，平均提高上升到19％时，只有少数患者可用于训练预测模型对于给定的临床结果。</font>
</div>


<hr>
<div id="paper10"> <b>10. The empirical structure of word frequency distributions</b>  <a href="https://arxiv.org/pdf/2001.05292" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramscar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michael Ramscar</a><br>
<font size="3">
Abstract: The frequencies at which individual words occur across languages follow power law distributions, a pattern of findings known as Zipf's law. A vast literature argues over whether this serves to optimize the efficiency of human communication, however this claim is necessarily post hoc, and it has been suggested that Zipf's law may in fact describe mixtures of other distributions. From this perspective, recent findings that Sinosphere first (family) names are geometrically distributed are notable, because this is actually consistent with information theoretic predictions regarding optimal coding. First names form natural communicative distributions in most languages, and I show that when analyzed in relation to the communities in which they are used, first name distributions across a diverse set of languages are both geometric and, historically, remarkably similar, with power law distributions only emerging when empirical distributions are aggregated. I then show this pattern of findings replicates in communicative distributions of English nouns and verbs. These results indicate that if lexical distributions support efficient communication, they do so because their functional structures directly satisfy the constraints described by information theory, and not because of Zipf's law. Understanding the function of these information structures is likely to be key to explaining humankind's remarkable communicative capacities. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在发生个别单词跨语言服从幂律分布的频率，被称为齐普夫定律发现的模式。大量文献论证了，这是否用于优化人力沟通的效率，但这种说法必然是事后，这已经表明齐普夫定律，实际上可能描述的其他分布的混合。从这个角度来看，最近的调查结果Sinosphere第一（家庭）名称几何分布是显着的，因为这是关于最优编码信息理论预测实际上是一致的。名字形成大多数语言自然交际分布，我表明，在关系分析，在一组不同的语言中使用它们的社区，第一个名称发行时都是几何和，从历史上看，非常相似，幂律分布只有当经验分布聚集出现。然后我显示英语名词和动词的交际分布发现重复的这种模式。这些结果表明，如果词汇分布支持有效的沟通，他们这样做是因为他们的功能结构直接满足信息理论中描述的约束，并没有因为齐普夫定律。了解这些信息结构的功能很可能是关键，解释人类的非凡能力，交际。</font>
</div>


<hr>
<div id="paper11"> <b>11. Exploring and Improving Robustness of Multi Task Deep Neural Networks  via Domain Agnostic Defenses</b>  <a href="https://arxiv.org/pdf/2001.05286" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Murali%2C+K+C" target="_blank" rel="noopener" style="color:#0000EE;">Kashyap Coimbatore Murali</a><br>
<font size="3">
Abstract: In this paper, we explore the robustness of the Multi-Task Deep Neural Networks (MT-DNN) against non-targeted adversarial attacks across Natural Language Understanding (NLU) tasks as well as some possible ways to defend against them. Liu et al., have shown that the Multi-Task Deep Neural Network, due to the regularization effect produced when training as a result of its cross task data, is more robust than a vanilla BERT model trained only on one task (1.1%-1.5% absolute difference). We further show that although the MT-DNN has generalized better, making it easily transferable across domains and tasks, it can still be compromised as after only 2 attacks (1-character and 2-character) the accuracy drops by 42.05% and 32.24% for the SNLI and SciTail tasks. Finally, we propose a domain agnostic defense which restores the model's accuracy (36.75% and 25.94% respectively) as opposed to a general-purpose defense or an off-the-shelf spell checker. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们探索了多任务深层神经网络（MT-DNN）的稳健性对整个自然语言理解（NLU）任务以及一些可能的方式来抵御这些非目标对抗性攻击。 Liu等人，已经表明，多任务深层的神经网络中，由于正规化效应产生当训练作为其横任务数据的结果是，比只在一个任务（1.1％培养了香草BERT模型更健壮 - 1.5％的绝对差）。进一步的研究表明，虽然MT-DNN具有更好的推广，使得它很容易跨域和任务转让的，它仍然可以作出妥协，只有2次攻击（1个字符和2个字符）的准确度42.05％和32.24％，下降后对于SNLI和SciTail任务。最后，我们提出了一个未知的领域国防其恢复模型的精确度（36.75％和25.94分别％），而不是通用的防守还是关闭的，现成的拼写检查器。</font>
</div>


<hr>
<div id="paper12"> <b>12. Detecting New Word Meanings: A Comparison of Word Embedding Models in  Spanish</b>  <a href="https://arxiv.org/pdf/2001.05285" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Torres-Rivera%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrés Torres-Rivera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Torres-Moreno%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Juan-Manuel Torres-Moreno</a><br>
<font size="3">
Abstract: Semantic neologisms (SN) are defined as words that acquire a new word meaning while maintaining their form. Given the nature of this kind of neologisms, the task of identifying these new word meanings is currently performed manually by specialists at observatories of neology. To detect SN in a semi-automatic way, we developed a system that implements a combination of the following strategies: topic modeling, keyword extraction, and word sense disambiguation. The role of topic modeling is to detect the themes that are treated in the input text. Themes within a text give clues about the particular meaning of the words that are used, for example: viral has one meaning in the context of computer science (CS) and another when talking about health. To extract keywords, we used TextRank with POS tag filtering. With this method, we can obtain relevant words that are already part of the Spanish lexicon. We use a deep learning model to determine if a given keyword could have a new meaning. Embeddings that are different from all the known meanings (or topics) indicate that a word might be a valid SN candidate. In this study, we examine the following word embedding models: Word2Vec, Sense2Vec, and FastText. The models were trained with equivalent parameters using Wikipedia in Spanish as corpora. Then we used a list of words and their concordances (obtained from our database of neologisms) to show the different embeddings that each model yields. Finally, we present a comparison of these outcomes with the concordances of each word to show how we can determine if a word could be a valid candidate for SN. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语义新词（SN）被定义为获得一个新词，同时保持其形式意义的话。鉴于这种新词的性质，目前手动专家在旧词新的天文台进行识别这些新词的意义的任务。为了检测SN以半自动化的方式，我们开发了一个系统，该系统实现了以下策略的组合：主题建模，关键词提取，以及词义消歧。主题建模的作用是检测在输入文本处理的主题。文本中的主题提供有关的被使用，例如词的特殊含义的线索：病毒只有一种含义在计算机科学（CS）和其他的方面讲卫生的时候。要提取的关键字，我们使用TextRank与POS标签过滤。通过这种方法，我们可以得到与已是西班牙词汇的一部分相关的词。我们使用了深刻的学习模式，以确定是否一个给定的关键字可能有新的意义。嵌入物是所有已知的含义（或主题）不同的指示词可能是一个有效的SN候选人。在这项研究中，我们考察以下单词嵌入型号：Word2Vec，Sense2Vec和FastText。模特们在西班牙使用维基百科语料库等效参数训练。然后我们使用的单词的列表和他们的语词（从我们的新词的数据库中获得）来显示不同的嵌入每个型号的产量。最后，我们提出这些结果与每个单词的词汇索引的比较，以显示我们如何确定一个词可能是SN有效候选人。</font>
</div>


<hr>
<div id="paper13"> <b>13. Improving Spoken Language Understanding By Exploiting ASR N-best  Hypotheses</b>  <a href="https://arxiv.org/pdf/2001.05284" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mingda Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ruan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weitong Ruan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xinyue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soldaini%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luca Soldaini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hamza%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wael Hamza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Su%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chengwei Su</a><br>
<font size="3">
Abstract: In a modern spoken language understanding (SLU) system, the natural language understanding (NLU) module takes interpretations of a speech from the automatic speech recognition (ASR) module as the input. The NLU module usually uses the first best interpretation of a given speech in downstream tasks such as domain and intent classification. However, the ASR module might misrecognize some speeches and the first best interpretation could be erroneous and noisy. Solely relying on the first best interpretation could make the performance of downstream tasks non-optimal. To address this issue, we introduce a series of simple yet efficient models for improving the understanding of semantics of the input speeches by collectively exploiting the n-best speech interpretations from the ASR module. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在现代口语理解（SLU）系统，自然语言理解（NLU）模块需要一个讲话的解释从自动语音识别（ASR）模块的输入。该NLU模块通常使用一个给定的讲话在下游任务，如域名和意图分类第一最好的诠释。然而，ASR模块可能误识别的一些讲话和第一最好的诠释可能是错误的和嘈杂。仅仅依靠第一最好的诠释可以使下游任务的性能最优的。为了解决这个问题，我们引入了一系列简单而有效的模型，通过集体从ASR模块利用N条最佳演讲诠释提高输入演讲的语义的理解。</font>
</div>


<hr>
<div id="paper14"> <b>14. FGN: Fusion Glyph Network for Chinese Named Entity Recognition</b>  <a href="https://arxiv.org/pdf/2001.05272" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xuan%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhenyu Xuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bao%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rui Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chuyu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shengyi Jiang</a><br>
<font size="3">
Abstract: Chinese NER is a challenging task. As pictographs, Chinese characters contain latent glyph information, which is often overlooked. We propose the FGN, Fusion Glyph Network for Chinese NER. This method may offer glyph information for fusion representation learning with BERT. The major innovations of FGN include: (1) a novel CNN structure called CGS-CNN is proposed to capture glyph information from both character graphs and their neighboring graphs. (2) we provide a method with sliding window and Slice-Attention to extract interactive information between BERT representation and glyph representation. Experiments are conducted on four NER datasets, showing that FGN with LSTM-CRF as tagger achieves new state-of-the-arts performance for Chinese NER. Further, more experiments are conducted to investigate the influences of various components and settings in FGN. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：中国NER是一个具有挑战性的任务。作为象形文字，中国字符包含潜在的字形信息，这些信息往往被忽视。我们提出了FGN，融合雕文网中国ER。这种方法可以提供融合表示学习与BERT字形信息。 FGN的主要创新点包括：（1）所谓的CGS-CNN一种新颖的CNN结构，提出从两个字符图和其周边图形捕获字形信息。 （2）我们提供具有滑动窗口和切片-注意提取BERT表示和字形表示之间的交互信息的方法。实验是在四个NER数据集进行，显示为恶搞实现国家的最艺术的新的性能为中国NER与LSTM-CRF是FGN。此外，更多的实验以调查FGN的各种组件和设置的影响。</font>
</div>


<hr>
<div id="paper15"> <b>15. A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation</b>  <a href="https://arxiv.org/pdf/2001.05139" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Guan%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhihao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoyan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minlie Huang</a><br>
<font size="3">
Abstract: Story generation, namely generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling fluency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difficulty of associating relevant commonsense knowledge, understanding the causal relationships, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize commonsense knowledge from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we employ multi-task learning which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：故事的产生，即产生从一个领先的情况下合理的故事，是一个重要而艰巨的任务。尽管在模拟的流畅性和局部连贯，现有的神经语言生成模型的成功（例如，GPT-2）仍从重复，逻辑冲突受到影响，并且缺乏长程的在产生的故事的连贯性。我们推测，这是因为关联相关常识的知识，理解因果关系，并计划实体和事件的适当时间顺序的难度。在本文中，我们设计了常识性的故事，一代知识强化训练前的模式。我们建议利用来自外部的知识基础常识知识产生合理的故事。为了进一步捕获的因果关系，并在合理的故事句子之间的时间相关性，我们采用多任务学习相结合的具有区分客观区分微调过程中真实和虚假的故事。自动和手动评估表明，我们的模型能够产生更合理的故事，比国家的最先进的基线，特别是在逻辑和全球协调方面。</font>
</div>


<hr>
<div id="paper16"> <b>16. Parallel Machine Translation with Disentangled Context Transformer</b>  <a href="https://arxiv.org/pdf/2001.05136" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kasai%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jungo Kasai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cross%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">James Cross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ghazvininejad%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marjan Ghazvininejad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiatao Gu</a><br>
<font size="3">
Abstract: State-of-the-art neural machine translation models generate a translation from left to right and every step is conditioned on the previously generated tokens. The sequential nature of this generation process causes fundamental latency in inference since we cannot generate multiple tokens in each sentence in parallel. We propose an attention-masking based model, called Disentangled Context (DisCo) transformer, that simultaneously generates all tokens given different contexts. The DisCo transformer is trained to predict every output token given an arbitrary subset of the other reference tokens. We also develop the parallel easy-first inference algorithm, which iteratively refines every token in parallel and reduces the number of required iterations. Our extensive experiments on 7 directions with varying data sizes demonstrate that our model achieves competitive, if not better, performance compared to the state of the art in non-autoregressive machine translation while significantly reducing decoding time on average. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：国家的最先进的从左至右和每一步的前提是之前生成的令牌神经机器翻译模型生成翻译。这个生成过程的有序性导致的推论根本延迟，因为我们不能生成并行每个句子多个令牌。我们建议注意的遮蔽基于模型，称为迎刃而解上下文（迪斯科）变压器，能够同时生成给出不同的上下文中的所有令牌。迪斯科变压器训练以预测每个输出令牌给出的其它参考标记的任意子集。我们还开发并行易先推理算法，反复细化每个令牌并行，减少了所需的迭代次数。我们对7点的方向具有不同大小的数据大量的实验证明，如果没有更好的，性能比现有技术中的非自回归机器翻译的状态，而显著减少平均解码时间我们的模型实现了有竞争力的。</font>
</div>


<hr>
<div id="paper17"> <b>17. Robust Speaker Recognition Using Speech Enhancement And Attention Model</b>  <a href="https://arxiv.org/pdf/2001.05031" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanpei Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hain%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thomas Hain</a><br>
<font size="3">
Abstract: In this paper, a novel architecture for speaker recognition is proposed by cascading speech enhancement and speaker processing. Its aim is to improve speaker recognition performance when speech signals are corrupted by noise. Instead of individually processing speech enhancement and speaker recognition, the two modules are integrated into one framework by a joint optimisation using deep neural networks. Furthermore, to increase robustness against noise, a multi-stage attention mechanism is employed to highlight the speaker related features learned from context information in time and frequency domain. To evaluate speaker identification and verification performance of the proposed approach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark datasets. Moreover, the robustness of our proposed approach is also tested on VoxCeleb1 data when being corrupted by three types of interferences, general noise, music, and babble, at different signal-to-noise ratio (SNR) levels. The obtained results show that the proposed approach using speech enhancement and multi-stage attention models outperforms two strong baselines not using them in most acoustic conditions in our experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文对说话人识别一个新颖的架构通过级联语音增强和扬声器的处理建议。其目的是为了提高说话人识别性能时，语音信号被噪声干扰。而不是单独处理语音增强和说话人识别，这两个模块是通过使用深层神经网络的联合优化集成到一个框架。此外，为了增加可以有效抵抗噪声，采用多级注意机制，突出显示上下文信息在时间和频域学会了说话者相关的功能。为了评价说话人识别和建议的方法验证性能，我们测试它VoxCeleb1，大多采用标准数据集之一的数据集。此外，我们的建议的方法的稳健性上VoxCeleb1数据还测试由三种类型的干扰，一般噪声，音乐和多路重合，在不同的信噪比（SNR）水平被损坏时。得到的结果表明，该方法使用语音增强和多级车型的关注性能优于两周强的基线没有在我们的实验中最声学条件下使用它们。</font>
</div>


<hr>
<div id="paper18"> <b>18. A Tree Adjoining Grammar Representation for Models Of Stochastic  Dynamical Systems</b>  <a href="https://arxiv.org/pdf/2001.05320" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Khandelwal%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dhruv Khandelwal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Schoukens%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maarten Schoukens</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=T%C3%B3th%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roland Tóth</a><br>
<font size="3">
Abstract: Model structure and complexity selection remains a challenging problem in system identification, especially for parametric non-linear models. Many Evolutionary Algorithm (EA) based methods have been proposed in the literature for estimating model structure and complexity. In most cases, the proposed methods are devised for estimating structure and complexity within a specified model class and hence these methods do not extend to other model structures without significant changes. In this paper, we propose a Tree Adjoining Grammar (TAG) for stochastic parametric models. TAGs can be used to generate models in an EA framework while imposing desirable structural constraints and incorporating prior knowledge. In this paper, we propose a TAG that can systematically generate models ranging from FIRs to polynomial NARMAX models. Furthermore, we demonstrate that TAGs can be easily extended to more general model classes, such as the non-linear Box-Jenkins model class, enabling the realization of flexible and automatic model structure and complexity selection via EA. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：模型的结构和复杂的选择仍然在系统识别一个具有挑战性的问题，尤其是对于参数非线性模型。许多进化算法（EA）为基础的方法在文献中已经提出了用于估计模型结构和复杂性。在大多数情况下，所提出的方法被设计为在指定模型类内估计结构和复杂性，并因此这些方法不延伸到其他模型结构而不显著变化。在本文中，我们提出了一个树连接语法（TAG）为随机参数模型。标签可以用于在EA框架来生成模型，同时施加理想的结构约束和结合先验知识。在本文中，我们提出了一个标记，可以系统地生成模型，从FIR的多项式NARMAX模型。此外，我们证明，标签可以容易地扩展到更一般的模型类，诸如非线性箱Jenkins模型类，可实现灵活和自动模型结构和复杂选择经由EA实现。</font>
</div>


<hr>
<div id="paper19"> <b>19. Auto Completion of User Interface Layout Design Using Transformer-Based  Tree Decoders</b>  <a href="https://arxiv.org/pdf/2001.05308" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Amelot%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Amelot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bengio%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Samy Bengio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Si%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Si Si</a><br>
<font size="3">
Abstract: It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：一直在该领域越来越多的关注，开发自动机器方便的设计过程。在本文中，我们侧重于帮助图形用户界面（UI）布局设计，在应用发展的重要任务。鉴于部分的布局，设计师已经进入，我们的模型学会通过预测与正确的位置和尺寸，其余的UI元素以及分层结构完成全国布局。这样的自动化将显著缓解UI设计师和开发人员的努力。虽然我们专注于界面布局的预测，我们的模型可以普遍适用于涉及树形结构和二维展示位置等布局预报问题。特别是，我们设计了基于变压器的树解码器的两个版本：指针和递归变压器，并与公共数据集，这些模型进行试验。我们还提出几个指标，用于测量树预测的准确性，并在用户体验领域地这些指标。这些贡献了新的任务和方法，深度学习研究。</font>
</div>


<hr>
<div id="paper20"> <b>20. Teddy: A System for Interactive Review Analysis</b>  <a href="https://arxiv.org/pdf/2001.05171" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Engel%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jonathan Engel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Evensen%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sara Evensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Demiralp%2C+%C3%87" target="_blank" rel="noopener" style="color:#0000EE;">Çağatay Demiralp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tan%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wang-Chiew Tan</a><br>
<font size="3">
Abstract: Reviews are integral to e-commerce services and products. They contain a wealth of information about the opinions and experiences of users, which can help better understand consumer decisions and improve user experience with products and services. Today, data scientists analyze reviews by developing rules and models to extract, aggregate, and understand information embedded in the review text. However, working with thousands of reviews, which are typically noisy incomplete text, can be daunting without proper tools. Here we first contribute results from an interview study that we conducted with fifteen data scientists who work with review text, providing insights into their practices and challenges. Results suggest data scientists need interactive systems for many review analysis tasks. In response we introduce Teddy, an interactive system that enables data scientists to quickly obtain insights from reviews and improve their extraction and modeling pipelines. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：评论是不可或缺的电子商务服务和产品。它们包含了大量关于用户的意见和经验，这有助于更好地了解消费者的决策和提高产品和服务的用户体验信息。如今，科学家数据分析通过制定规则和模型来提取，汇总评价，并了解嵌入在审查文本信息。然而，成千上万的评论，这是典型的吵不完整的文本工作，可没有合适的工具望而生畏。在这里，我们首先从访谈研究，我们具有十五数据科学家谁的工作与评论文本进行，提供洞察到他们的做法和挑战作出贡献的结果。结果表明数据科学家需要对很多的评论分析任务的交互系统。在回应我们介绍泰迪，一个互动系统，使数据科学家能够迅速从审查获得洞察力和改善他们的提取和建模管道。</font>
</div>


<hr>
<div id="paper21"> <b>21. Modeling Product Search Relevance in e-Commerce</b>  <a href="https://arxiv.org/pdf/2001.04980" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Iyer%2C+R+R" target="_blank" rel="noopener" style="color:#0000EE;">Rahul Radhakrishnan Iyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kohli%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rohan Kohli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Prabhumoye%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shrimai Prabhumoye</a><br>
<font size="3">
Abstract: With the rapid growth of e-Commerce, online product search has emerged as a popular and effective paradigm for customers to find desired products and engage in online shopping. However, there is still a big gap between the products that customers really desire to purchase and relevance of products that are suggested in response to a query from the customer. In this paper, we propose a robust way of predicting relevance scores given a search query and a product, using techniques involving machine learning, natural language processing and information retrieval. We compare conventional information retrieval models such as BM25 and Indri with deep learning models such as word2vec, sentence2vec and paragraph2vec. We share some of our insights and findings from our experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：随着电子商务的快速发展，在线产品搜索已经成为一种流行和有效的模式，为客户找到所需的产品和从事网上购物。然而，仍然有客户真正渴望的产品的购买和相关性被提出以响应来自客户的查询产品之间有很大的差距。在本文中，我们提出了预测给定的搜索查询和产品的相关性分值，使用涉及机器学习，自然语言处理和信息检索技术的可靠方式。我们比较传统的信息检索模型如BM25和大狐猴与深度学习模式，如word2vec，sentence2vec和paragraph2vec。我们分享我们的一些见解和研究结果，从我们的实验。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-15</title>
    <url>/2020/01/16/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-15/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning <a href="https://arxiv.org/pdf/2001.04935" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Balancing the composition of word embeddings across heterogenous data  sets <a href="https://arxiv.org/pdf/2001.04693" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> Bi-Decoder Augmented Network for Neural Machine Translation <a href="https://arxiv.org/pdf/2001.04586" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> On the Replicability of Combining Word Embeddings and Retrieval Models <a href="https://arxiv.org/pdf/2001.04484" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Detecting depression in dyadic conversations with multimodal narratives  and visualizations <a href="https://arxiv.org/pdf/2001.04809" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> A (Simplified) Supreme Being Necessarily Exists -- Says the Computer! <a href="https://arxiv.org/pdf/2001.04701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Improved Robust ASR for Social Robots in Public Spaces <a href="https://arxiv.org/pdf/2001.04619" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Faster Transformer Decoding: N-gram Masked Self-Attention <a href="https://arxiv.org/pdf/2001.04589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning</b>  <a href="https://arxiv.org/pdf/2001.04935" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Schuster%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Roei Schuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schuster%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tal Schuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Meri%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yoav Meri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shmatikov%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vitaly Shmatikov</a><br>
<font size="3">
Abstract: Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word "meaning" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks. Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the "meaning" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another. An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：字的嵌入，即，低维向量表示，如手套和SGNS，编码字在这个意义上，词语向量之间的距离对应于它们的语义接近“意思是”。这使语义的迁移学习的各种自然语言处理任务。 Word中的嵌入通常是受过训练的大型公共语料库，如维基百科或Twitter。我们表明，攻击者谁可以修改其嵌入训练可以通过改变空间嵌入它们的位置控制的新的和现有的词“意义”的语料库。我们开发了语料库的特点，可作为单词之间距离的代理明确的表达，并建立自己的价值观和嵌入的距离之间的因果关系。然后，我们展示了如何使用两个敌对目标的这种关系：（1）做一个字一个字的世界排名第一的邻居，和（2）从一个语义集群移动一个字到另一个。在嵌入的攻击会影响不同的下游任务，这表明首次数据传输学习情境中毒的力量。我们使用这种攻击来操纵信息检索系统，如简历搜索查询扩展，使某些名字命名实体识别模型或多或少可见，并造成新词被翻译成特定的目标词无论使用什么语言。最后，我们展示了攻击者如何产生语言上可能语料库修改，从而欺骗试图难以置信的句子从使用语言模型的语料库过滤防御。</font>
</div>


<hr>
<div id="paper2"> <b>2. Balancing the composition of word embeddings across heterogenous data  sets</b>  <a href="https://arxiv.org/pdf/2001.04693" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Brandl%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stephanie Brandl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lassner%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Lassner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Alber%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Maximilian Alber</a><br>
<font size="3">
Abstract: Word embeddings capture semantic relationships based on contextual information and are the basis for a wide variety of natural language processing applications. Notably these relationships are solely learned from the data and subsequently the data composition impacts the semantic of embeddings which arguably can lead to biased word vectors. Given qualitatively different data subsets, we aim to align the influence of single subsets on the resulting word vectors, while retaining their quality. In this regard we propose a criteria to measure the shift towards a single data subset and develop approaches to meet both objectives. We find that a weighted average of the two subset embeddings balances the influence of those subsets while word similarity performance decreases. We further propose a promising optimization approach to balance influences and quality of word embeddings. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：基于上下文信息的嵌入Word中捕捉语义关系，并且是各种各样的自然语言处理应用的基础。值得注意的是这些关系仅由数据并随后将数据组合物影响的语义的嵌入可论证可导致偏置字矢量的教训。考虑到质的不同数据子集，我们的目标是一致的最终的字向量单亚群的影响力，同时保持它们的质量。在这方面，我们提出了一个标准来衡量一个单一的数据子集的转变和发展途径，以满足这两个目标。我们发现，两个子集的嵌入的加权平均余额部分数据的影响，而单词类似性能降低。我们进一步提出了一个有前途的优化方法来平衡影响和字的嵌入质量。</font>
</div>


<hr>
<div id="paper3"> <b>3. Bi-Decoder Augmented Network for Neural Machine Translation</b>  <a href="https://arxiv.org/pdf/2001.04586" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Pan%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Boyuan Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yazheng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhou Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhuang%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yueting Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cai%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Deng Cai</a><br>
<font size="3">
Abstract: Neural Machine Translation (NMT) has become a popular technology in recent years, and the encoder-decoder framework is the mainstream among all the methods. It's obvious that the quality of the semantic representations from encoding is very crucial and can significantly affect the performance of the model. However, existing unidirectional source-to-target architectures may hardly produce a language-independent representation of the text because they rely heavily on the specific relations of the given language pairs. To alleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented Network (BiDAN) for the neural machine translation task. Besides the original decoder which generates the target language sequence, we add an auxiliary decoder to generate back the source language sequence at the training time. Since each decoder transforms the representations of the input text into its corresponding language, jointly training with two target ends can make the shared encoder has the potential to produce a language-independent semantic space. We conduct extensive experiments on several NMT benchmark datasets and the results demonstrate the effectiveness of our proposed approach. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：神经机器翻译（NMT）已经成为一种流行的技术，近年来，和编码器，解码器的结构与第方法中所有的主流。很明显，从编码语义表示的质量是非常重要的，可以显著影响模型的性能。但是，现有的单向源到目标架构可以几乎不产生文本的语言无关的表示，因为他们在很大程度上依赖于特定的语言对的特定关系。为了缓解这一问题，在本文中，我们提出了一个新颖的双解码器增强网络（毕单）的神经机器翻译的任务。除了生成目标语言序列原有解码器，我们添加辅助解码器，以生成回到了训练时间的源语言序列。因为每个解码器将输入的文本的表示成其相应的语言，共同具有两个靶的端部的训练可以使共享编码器具有以产生独立于语言的语义空间的潜力。我们几个NMT基准数据集进行了广泛的实验，结果证明我们提出的方法的有效性。</font>
</div>


<hr>
<div id="paper4"> <b>4. On the Replicability of Combining Word Embeddings and Retrieval Models</b>  <a href="https://arxiv.org/pdf/2001.04484" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Papariello%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Luca Papariello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bampoulidis%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alexandros Bampoulidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lupu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mihai Lupu</a><br>
<font size="3">
Abstract: We replicate recent experiments attempting to demonstrate an attractive hypothesis about the use of the Fisher kernel framework and mixture models for aggregating word embeddings towards document representations and the use of these representations in document classification, clustering, and retrieval. Specifically, the hypothesis was that the use of a mixture model of von Mises-Fisher (VMF) distributions instead of Gaussian distributions would be beneficial because of the focus on cosine distances of both VMF and the vector space model traditionally used in information retrieval. Previous experiments had validated this hypothesis. Our replication was not able to validate it, despite a large parameter scan space. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近期重复实验，试图证明有关使用费的内核架构和混合模型的聚集对文档表示字的嵌入和使用文档分类，聚类和检索这些表象的一个有吸引力的假说。具体而言，假设是使用冯米塞斯-Fisher分析（VMF）的混合物模型的分布，而不是高斯分布将是因为聚焦在两个VMF和信息检索传统上使用向量空间模型的余弦距离的有益的。以前的实验已经证实了这一假设。我们的复制无法验证它，尽管大的参数扫描空间。</font>
</div>


<hr>
<div id="paper5"> <b>5. Detecting depression in dyadic conversations with multimodal narratives  and visualizations</b>  <a href="https://arxiv.org/pdf/2001.04809" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+J+Y" target="_blank" rel="noopener" style="color:#0000EE;">Joshua Y. Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+G+Y" target="_blank" rel="noopener" style="color:#0000EE;">Greyson Y. Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yacef%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kalina Yacef</a><br>
<font size="3">
Abstract: Conversations contain a wide spectrum of multimodal information that gives us hints about the emotions and moods of the speaker. In this paper, we developed a system that supports humans to analyze conversations. Our main contribution is the identification of appropriate multimodal features and the integration of such features into verbatim conversation transcripts. We demonstrate the ability of our system to take in a wide range of multimodal information and automatically generated a prediction score for the depression state of the individual. Our experiments showed that this approach yielded better performance than the baseline model. Furthermore, the multimodal narrative approach makes it easy to integrate learnings from other disciplines, such as conversational analysis and psychology. Lastly, this interdisciplinary and automated approach is a step towards emulating how practitioners record the course of treatment as well as emulating how conversational analysts have been analyzing conversations by hand. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话包含的多模式信息范围广泛，让我们有预兆说话者的情绪和心情。在本文中，我们开发了一个系统，支持人类分析的对话。我们的主要贡献是适当的多模式特征的识别和整合这些功能集成到逐字谈话笔录。我们证明我们的系统采取广泛的多模式信息，并自动生成个人的抑郁状态的预测得分的能力。我们的实验表明，这种方法取得了比基线模型更好的性能。此外，多模式的叙事方法，可以轻松集成到其他学科，如会话分析和心理学的学习收获。最后，这种跨学科的和自动化的方法是对模拟从业者如何记录治疗过程，以及如何模拟对话分析家一直用手分析对话的一个步骤。</font>
</div>


<hr>
<div id="paper6"> <b>6. A (Simplified) Supreme Being Necessarily Exists -- Says the Computer!</b>  <a href="https://arxiv.org/pdf/2001.04701" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Benzm%C3%BCller%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Christoph Benzmüller</a><br>
<font size="3">
Abstract: A simplified variant of Kurt Gödel's modal ontological argument is presented. Some of Gödel's, resp. Scott's, premises are modified, others are dropped, and modal collapse is avoided. The emended argument is shown valid already in quantified modal logic K. The presented simplifications have been computationally explored utilising latest knowledge representation and reasoning technology based on higher-order logic. The paper thus illustrates how modern symbolic AI technology can contribute new knowledge to formal philosophy and theology. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：哥德尔的模式本体论的简化变体显示。有些哥德尔，RESP的。斯科特的，房屋被修改，其他被丢弃，避免了模态崩溃。在仔细的校勘参数显示有效的已量化模态逻辑K.所提出的简化了计算研究利用最新的知识表示和基于高阶逻辑推理技术。因此，阐述了象征性的AI技术如何现代可以促进新知识的正式哲学和神学。</font>
</div>


<hr>
<div id="paper7"> <b>7. Improved Robust ASR for Social Robots in Public Spaces</b>  <a href="https://arxiv.org/pdf/2001.04619" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Jankowski%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Charles Jankowski</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mruthyunjaya%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vishwas Mruthyunjaya</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Lin%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruixi Lin</a><br>
<font size="3">
Abstract: Social robots deployed in public spaces present a challenging task for ASR because of a variety of factors, including noise SNR of 20 to 5 dB. Existing ASR models perform well for higher SNRs in this range, but degrade considerably with more noise. This work explores methods for providing improved ASR performance in such conditions. We use the AiShell-1 Chinese speech corpus and the Kaldi ASR toolkit for evaluations. We were able to exceed state-of-the-art ASR performance with SNR lower than 20 dB, demonstrating the feasibility of achieving relatively high performing ASR with open-source toolkits and hundreds of hours of training data, which is commonly available. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：部署在公共场所的社交机器人目前由于多种因素的影响，其中包括20至5分贝的噪音信噪比ASR一项艰巨的任务。现有ASR模型表现良好在这个范围内的较高的信噪比，但更多的噪音大大降低。这项工作探索提供在这样的条件下改善ASR性能的方法。我们使用AiShell-1中国语料库和Kaldi ASR工具包的评估。我们能够超过信噪比国家的最先进的ASR性能大于20dB低，表明达到比较高的用开源工具包和数以百计的训练数据，这是通常可以利用的时间来完成ASR的可行性。</font>
</div>


<hr>
<div id="paper8"> <b>8. Faster Transformer Decoding: N-gram Masked Self-Attention</b>  <a href="https://arxiv.org/pdf/2001.04589" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chelba%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Ciprian Chelba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mia Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bapna%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Ankur Bapna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shazeer%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Noam Shazeer</a><br>
<font size="3">
Abstract: Motivated by the fact that most of the information relevant to the prediction of target tokens is drawn from the source sentence $S=s_1, \ldots, s_S$, we propose truncating the target-side window used for computing self-attention by making an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show that the $N$-gram masked self-attention model loses very little in BLEU score for $N$ values in the range $4, \ldots, 8$, depending on the task. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：事实上，大多数的相关目标令牌的预测信息从源句子$ S = S_1，\ ldots，S_S $绘制的启发，我们建议截断用于通过计算自我关注的目标侧窗做一个$ N $ -gram假设。在WMT恩德和EnFr数据集上的实验表明，$ N $ -gram掩盖自我注意模型的BLEU分数$ N $值的范围在$ 4 \ ldots，$ 8，根据任务非常小的损失。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-14</title>
    <url>/2020/01/15/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-14/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Multi-Source Domain Adaptation for Text Classification via  DistanceNet-Bandits <a href="https://arxiv.org/pdf/2001.04362" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark  for Chinese <a href="https://arxiv.org/pdf/2001.04351" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>

<div id="title3">
<b>3.</b> AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural  Architecture Search <a href="https://arxiv.org/pdf/2001.04246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Mining customer product reviews for product development: A summarization  process <a href="https://arxiv.org/pdf/2001.04200" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Joint Reasoning for Multi-Faceted Commonsense Knowledge <a href="https://arxiv.org/pdf/2001.04170" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> ProphetNet: Predicting Future N-gram for Sequence-to-Sequence  Pre-training <a href="https://arxiv.org/pdf/2001.04063" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Stochastic Natural Language Generation Using Dependency Information <a href="https://arxiv.org/pdf/2001.03897" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Rethinking Generalization of Neural Models: A Named Entity Recognition  Case Study <a href="https://arxiv.org/pdf/2001.03844" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Revisiting Challenges in Data-to-Text Generation with Fact Grounding <a href="https://arxiv.org/pdf/2001.03830" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Learning Cross-Context Entity Representations from Text <a href="https://arxiv.org/pdf/2001.03765" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> PatentTransformer-2: Controlling Patent Text Generation by Structural  Metadata <a href="https://arxiv.org/pdf/2001.03708" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Does syntax need to grow on trees? Sources of hierarchical inductive  bias in sequence-to-sequence networks <a href="https://arxiv.org/pdf/2001.03632" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Reformer: The Efficient Transformer <a href="https://arxiv.org/pdf/2001.04451" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured  Prediction <a href="https://arxiv.org/pdf/2001.04437" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Negative Statements Considered Useful <a href="https://arxiv.org/pdf/2001.04425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Asymmetrical Hierarchical Networks with Attentive Interactions for  Interpretable Review-Based Recommendation <a href="https://arxiv.org/pdf/2001.04346" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Shareable Representations for Search Query Understanding <a href="https://arxiv.org/pdf/2001.04345" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> Improving Dysarthric Speech Intelligibility Using Cycle-consistent  Adversarial Training <a href="https://arxiv.org/pdf/2001.04260" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Structural Decompositions of Epistemic Logic Programs <a href="https://arxiv.org/pdf/2001.04219" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> A logic-based relational learning approach to relation extraction: The  OntoILPER system <a href="https://arxiv.org/pdf/2001.04192" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for  Language Grounding Tasks in Street View <a href="https://arxiv.org/pdf/2001.03671" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Multi-Source Domain Adaptation for Text Classification via  DistanceNet-Bandits</b>  <a href="https://arxiv.org/pdf/2001.04362" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Guo%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pasunuru%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ramakanth Pasunuru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bansal%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mohit Bansal</a><br>
<font size="3">
Abstract: Domain adaptation performance of a learning algorithm on a target domain is a function of its source domain error and a divergence measure between the data distribution of these two domains. We present a study of various distance-based measures in the context of NLP tasks, that characterize the dissimilarity between domains based on sample estimates. We first conduct analysis experiments to show which of these distance measures can best differentiate samples from same versus different domains, and are correlated with empirical results. Next, we develop a DistanceNet model which uses these distance measures, or a mixture of these distance measures, as an additional loss function to be minimized jointly with the task's loss function, so as to achieve better unsupervised domain adaptation. Finally, we extend this model to a novel DistanceNet-Bandit model, which employs a multi-armed bandit controller to dynamically switch between multiple source domains and allow the model to learn an optimal trajectory and mixture of domains for transfer to the low-resource target domain. We conduct experiments on popular sentiment analysis datasets with several diverse domains and show that our DistanceNet model, as well as its dynamic bandit variant, can outperform competitive baselines in the context of unsupervised domain adaptation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对目标域学习算法的域自适应性能是它的源域误差的函数和这两个结构域的数据分布之间的偏差度量。我们提出的在NLP任务范围内各种基于距离的测量，表征根据样本估计域间的差异性进行了研究。我们首先进行分析实验表明其中的这些距离措施最好的分化样本相同与不同的域，并与实验结果是相关的。接下来，我们开发出使用这些距离的措施，或者这些距离测量的混合物DistanceNet模型，作为额外的损失函数要与任务的损失函数共同最小化，从而达到更好的无监督的领域适应性。最后，我们扩展该模型以一种新颖的DistanceNet匪模型，其采用多臂老虎控制器到多个源域之间动态开关和允许模型学习域的最佳轨迹和混合物，然后转移到低资源目标域。我们进行了对流行的情感分析数据集实验与多个不同领域，并表明我们的模型DistanceNet，以及它的动态强盗变种，可以在无人监督的领域适应性的背景下跑赢大市的竞争基准。</font>
</div>


<hr>
<div id="paper2"> <b>2. CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark  for Chinese</b>  <a href="https://arxiv.org/pdf/2001.04351" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Liang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qianqian Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Cong Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tian%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yin Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weitang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanwei Zhang</a><br>
<font size="3">
Abstract: In this paper, we introduce the NER dataset from CLUE organization (CLUENER2020), a well-defined fine-grained dataset for named entity recognition in Chinese. CLUENER2020 contains 10 categories. Apart from common labels like person, organization, and location, it contains more diverse categories. It is more challenging than current other Chinese NER datasets and could better reflect real-world applications. For comparison, we implement several state-of-the-art baselines as sequence labeling tasks and report human performance, as well as its analysis. To facilitate future work on fine-grained NER for Chinese, we release our dataset, baselines, and leader-board. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们将介绍从CLUE组织NER数据集（CLUENER2020），一个明确的细粒度数据集在中国命名实体识别。 CLUENER2020包含10个类别。除了像个人，组织和位置共同的标签，它包含了更多样化的类别。它比目前的其他中国NER数据集更具挑战性，更能反映现实世界的应用。为了便于比较，我们实现国家的最先进的一些基线为序列标注任务和报告人的表现，以及它的分析。为了方便日后对中国细粒度NER的工作，我们发布的数据集，基线和领袖板。</font>
</div>


<hr>
<div id="paper3"> <b>3. AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural  Architecture Search</b>  <a href="https://arxiv.org/pdf/2001.04246" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Daoyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yaliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minghui Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bofang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ding%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bolin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Deng%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongbo Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingren Zhou</a><br>
<font size="3">
Abstract: Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大型预训练的语言模型，如BERT表明它们在不同的自然语言处理任务的有效性。然而，巨大的参数尺寸使得它们很难在需要快速推断资源有限的实时应用进行部署。现有的方法压缩BERT为小机型，而这种压缩是任务无关，即对所有不同的下游任务相同的压缩BERT。由必要性和面向任务的BERT压缩的好处的启发，我们提出了一种新的压缩方法，AdaBERT，它利用微神经结构的搜索自动压缩成BERT任务自适应小型号为特定的任务。我们结合了面向任务的知识蒸馏损失提供搜索提示和效率意识的损失，搜索约束，这使得任务自适应BERT压缩一个很好的权衡效率和效益之间。我们评估几个NLP任务AdaBERT，结果表明，这些任务自适应压缩模型12.7倍至29.3x比推理时间和11.5倍BERT更快17.0x参数规模而言较小，而相当的性能得以维持。</font>
</div>


<hr>
<div id="paper4"> <b>4. Mining customer product reviews for product development: A summarization  process</b>  <a href="https://arxiv.org/pdf/2001.04200" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hou%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tianjun Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yannou%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bernard Yannou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Leroy%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yann Leroy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Poirson%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emilie Poirson</a><br>
<font size="3">
Abstract: This research set out to identify and structure from online reviews the words and expressions related to customers' likes and dislikes to guide product development. Previous methods were mainly focused on product features. However, reviewers express their preference not only on product features. In this paper, based on an extensive literature review in design science, the authors propose a summarization model containing multiples aspects of user preference, such as product affordances, emotions, usage conditions. Meanwhile, the linguistic patterns describing these aspects of preference are discovered and drafted as annotation guidelines. A case study demonstrates that with the proposed model and the annotation guidelines, human annotators can structure the online reviews with high inter-agreement. As high inter-agreement human annotation results are essential for automatizing the online review summarization process with the natural language processing, this study provides materials for the future study of automatization. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本研究着手从网上评论识别和结构关系到客户的好恶词语来指导产品的开发。先前的方法主要集中在产品功能。然而，评论家表达自己的喜好，不仅在产品功能。在本文的基础上，设计科学的全面的文献，作​​者提出了一个包含用户偏好的倍数方面，如产品的可供性，情绪，利用状况的总结模式。同时，描述偏好这些方面的语言模式被发现并起草作为注解的指导方针。案例研究表明，与所提出的模型和注释指引，人工注释就可以构建高之间的协议网上审查。由于采用协议间的人类标注的结果是与自然语言处理automatizing在线审核汇总过程中必不可少的，这项研究提供了自动化的未来学习材料。</font>
</div>


<hr>
<div id="paper5"> <b>5. Joint Reasoning for Multi-Faceted Commonsense Knowledge</b>  <a href="https://arxiv.org/pdf/2001.04170" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chalier%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yohan Chalier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Razniewski%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Razniewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weikum%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerhard Weikum</a><br>
<font size="3">
Abstract: Commonsense knowledge (CSK) supports a variety of AI applications, from visual understanding to chatbots. Prior works on acquiring CSK, such as ConceptNet, have compiled statements that associate concepts, like everyday objects or activities, with properties that hold for most or some instances of the concept. Each concept is treated in isolation from other concepts, and the only quantitative measure (or ranking) of properties is a confidence score that the statement is valid. This paper aims to overcome these limitations by introducing a multi-faceted model of CSK statements and methods for joint reasoning over sets of inter-related statements. Our model captures four different dimensions of CSK statements: plausibility, typicality, remarkability and salience, with scoring and ranking along each dimension. For example, hyenas drinking water is typical but not salient, whereas hyenas eating carcasses is salient. For reasoning and ranking, we develop a method with soft constraints, to couple the inference over concepts that are related in in a taxonomic hierarchy. The reasoning is cast into an integer linear programming (ILP), and we leverage the theory of reduction costs of a relaxed LP to compute informative rankings. This methodology is applied to several large CSK collections. Our evaluation shows that we can consolidate these inputs into much cleaner and more expressive knowledge. Results are available at this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：常识知识（CSK）支持多种AI应用，从视觉理解聊天机器人。在获取CSK之前的作品，如ConceptNet，编译语句关联的概念，像日常生活中的物体或活动，性质搁置了大部分或概念的若干实例。每个概念隔离治疗与其他概念和属性的唯一定量测量（或排序）是置信得分的声明是有效的。本文旨在通过引入CSK语句和方法的多面模型在台相互关联的语句联合推理来克服这些限制。我们的模型捕获CSK报表的四个维度：合理性，典型性，remarkability和显着性，与得分和沿每个维度的排名。例如，鬣狗饮用水是典型的但不显着，而鬣狗吃尸体是显着的。推理和排名，我们开发了一个方法与软约束，耦合，而忽视了在一个分类层次结构相关的概念推理。推理铸造成整数线性规划（ILP），和我们利用的轻松LP的降低成本的理论来计算信息排名。这种方法适用于几个大的CSK集合。我们的评估显示，我们可以整合这些投入更清洁，更富有表现力的知识。结果可在此HTTPS URL。</font>
</div>


<hr>
<div id="paper6"> <b>6. ProphetNet: Predicting Future N-gram for Sequence-to-Sequence  Pre-training</b>  <a href="https://arxiv.org/pdf/2001.04063" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yan%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yu Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Qi%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weizhen Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gong%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yeyun Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dayiheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nan Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jiusheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Ruofei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: In this paper, we present a new sequence-to-sequence pre-training model called ProphetNet, which introduces a novel self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism.Instead of the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time step.The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale dataset (160GB) respectively. Experimental results show ProphetNet achieves the best performance on both abstractive summarization and question generation tasks compared to the models using the same base scale pre-training dataset. For the large scale dataset pre-training, ProphetNet achieves new state-of-the-art results on Gigaword and comparable results on CNN/DailyMail using only about 1/5 pre-training epochs of the previous model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们提出名为ProphetNet一个新的序列到序列前的训练模式，它引入了一个新的自我监督的目标命名为将来的n-gram预测和建议的N流的自我关注的mechanism.Instead在传统的序列到序列模型中的一个步骤的提前预测的优化，ProphetNet由n-领先一步预测该预测下一个n各自时间step.The将来的n-gram在预测令牌同时基于先前上下文令牌明确地优化鼓励模型来规划未来的令牌，并防止过度拟合强大的本地相关性。我们使用碱规模的数据集（16GB）和分别大规模数据集（160GB）预列车ProphetNet。实验结果表明ProphetNet达到上相比，使用相同的基本预分训练数据集模型既抽象总结和询问生成任务的最佳性能。对于大规模数据集前培训，ProphetNet实现国家的最先进的新的Gigaword和使用CNN /每日邮报以前的型号只有约1/5前的训练时期比较的结果的结果。</font>
</div>


<hr>
<div id="paper7"> <b>7. Stochastic Natural Language Generation Using Dependency Information</b>  <a href="https://arxiv.org/pdf/2001.03897" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Seifossadat%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Elham Seifossadat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sameti%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hossein Sameti</a><br>
<font size="3">
Abstract: This article presents a stochastic corpus-based model for generating natural language text. Our model first encodes dependency relations from training data through a feature set, then concatenates these features to produce a new dependency tree for a given meaning representation, and finally generates a natural language utterance from the produced dependency tree. We test our model on nine domains from tabular, dialogue act and RDF format. Our model outperforms the corpus-based state-of-the-art methods trained on tabular datasets and also achieves comparable results with neural network-based approaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR evaluation metrics. Also, by reporting Human Evaluation results, we show that our model produces high-quality utterances in aspects of informativeness and naturalness as well as quality. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文介绍了生成自然语言文本随机基于语料库的模型。我们的模式首先编码的依赖性和通过功能训练数据集的关系，然后连接这些特征来产生一个给定的意思表示一个新的依赖关系树，最后产生从产生依赖关系树的自然语言语句。我们测试我们从表格，对话行为和RDF格式9个域模型。我们的模型优于训练有素的表格数据集基于语料库的国家的最先进的方法和也实现了比较的结果神经网络的基础上对话行为，E2E和WebNLG数据集的BLEU和ERR评价指标办法训练。此外，通过报告人的评价结果​​，我们表明，我们的模型在信息量和自然，以及质量方面的生产高品质的话语。</font>
</div>


<hr>
<div id="paper8"> <b>8. Rethinking Generalization of Neural Models: A Named Entity Recognition  Case Study</b>  <a href="https://arxiv.org/pdf/2001.03844" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Fu%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jinlan Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pengfei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanjing Huang</a><br>
<font size="3">
Abstract: While neural network-based models have achieved impressive performance on a large body of NLP tasks, the generalization behavior of different models remains poorly understood: Does this excellent performance imply a perfect generalization model, or are there still some limitations? In this paper, we take the NER task as a testbed to analyze the generalization behavior of existing models from different perspectives and characterize the differences of their generalization abilities through the lens of our proposed measures, which guides us to better design models and training methods. Experiments with in-depth analyses diagnose the bottleneck of existing neural NER models in terms of breakdown performance analysis, annotation errors, dataset bias, and category relationships, which suggest directions for improvement. We have released the datasets: (ReCoNLL, PLONER) for the future research at our project page: this http URL. As a by-product of this paper, we have open-sourced a project that involves a comprehensive summary of recent NER papers and classifies them into different research topics: this https URL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：尽管基于神经网络的模型已在大机构的NLP任务，取得了骄人的业绩，不同型号的遗体推广行为知之甚少：这是否出色表现意味着一个完美的泛化模型，还是有仍有一定的局限性？在本文中，我们采取了NER任务作为测试平台，分析从不同的角度现有车型的推广行为，并通过我们的建议措施的镜头，是指导我们更好地设计模型和训练方法表征其泛化能力的差异。在深入分析实验诊断现有的神经NER模型的瓶颈在击穿性能分析，标注错误，数据集偏见和类别的关系，其提出改进方向的术语。我们已经发布了数据集：（ReCoNLL，PLONER）对未来的研究，在我们的项目页面：这个HTTP URL。作为本文的副产品，我们有开源的，涉及到的最近NER文件，并将其分类，全面总结成不同的研究课题项目：该HTTPS URL。</font>
</div>


<hr>
<div id="paper9"> <b>9. Revisiting Challenges in Data-to-Text Generation with Fact Grounding</b>  <a href="https://arxiv.org/pdf/2001.03830" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hongmin Wang</a><br>
<font size="3">
Abstract: Data-to-text generation models face challenges in ensuring data fidelity by referring to the correct input source. To inspire studies in this area, Wiseman et al. (2017) introduced the RotoWire corpus on generating NBA game summaries from the box- and line-score tables. However, limited attempts have been made in this direction and the challenges remain. We observe a prominent bottleneck in the corpus where only about 60% of the summary contents can be grounded to the boxscore records. Such information deficiency tends to misguide a conditioned language model to produce unconditioned random facts and thus leads to factual hallucinations. In this work, we restore the information balance and revamp this task to focus on fact-grounded data-to-text generation. We introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding), with 50% more data from the year 2017-19 and enriched input tables, hoping to attract more research focuses in this direction. Moreover, we achieve improved data fidelity over the state-of-the-art models by integrating a new form of table reconstruction as an auxiliary task to boost the generation quality. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：数据到文本代车型面临参照正确的输入源，确保数据的保真度的挑战。在这方面，怀斯曼等激励研究。 （2017）介绍了从箱 - 和线路得分表中生成的NBA比赛的摘要语料库RotoWire。然而，有限的尝试已在这方面取得和挑战依然存在。我们观察到，其中的总结内容只有约60％可以接地的技术统计记录的语料库一个突出的瓶颈。这样的信息不足往往误导了条件语言模型制作无条件随机的事实，从而导致实际的幻觉。在这项工作中，我们恢复信息平衡和改造这个任务专注于事实接地数据到文本生成。我们引进一个纯化和大规模数据集，RotoWire-FG（实况接地），从今年2017年覆盖和丰富的输入表50％以上的数据，希望能吸引更多的研究集中在这个方向。此外，我们通过表重建的一种新形式的积分作为辅助任务，以提高生成质量实现对国家的最先进的模型改进的数据的保真度。</font>
</div>


<hr>
<div id="paper10"> <b>10. Learning Cross-Context Entity Representations from Text</b>  <a href="https://arxiv.org/pdf/2001.03765" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Ling%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jeffrey Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=FitzGerald%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nicholas FitzGerald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shan%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zifei Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soares%2C+L+B" target="_blank" rel="noopener" style="color:#0000EE;">Livio Baldini Soares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=F%C3%A9vry%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thibault Févry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weiss%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">David Weiss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kwiatkowski%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tom Kwiatkowski</a><br>
<font size="3">
Abstract: Language modeling tasks, in which words, or word-pieces, are predicted on the basis of a local context, have been very effective for learning word embeddings and context dependent representations of phrases. Motivated by the observation that efforts to code world knowledge into machine readable knowledge bases or human readable encyclopedias tend to be entity-centric, we investigate the use of a fill-in-the-blank task to learn context independent representations of entities from the text contexts in which those entities were mentioned. We show that large scale training of neural models allows us to learn high quality entity representations, and we demonstrate successful results on four domains: (1) existing entity-level typing benchmarks, including a 64% error reduction over previous work on TypeNet (Murty et al., 2018); (2) a novel few-shot category reconstruction task; (3) existing entity linking benchmarks, where we match the state-of-the-art on CoNLL-Aida without linking-specific features and obtain a score of 89.8% on TAC-KBP 2010 without using any alias table, external knowledge base or in domain training data and (4) answering trivia questions, which uniquely identify entities. Our global entity representations encode fine-grained type categories, such as Scottish footballers, and can answer trivia questions such as: Who was the last inmate of Spandau jail in Berlin? </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言建模任务，其中词或字块，在本地范围内的基础上预测，一直是学习的嵌入词和短语的背景有关的表示是非常有效的。通过观察该努力的代码世界知识转化为机器可读的知识基础或人类可读的百科全书往往是实体为中心的推动下，我们研究使用填充式的空白任务的学习实体的情况下独立表示从文本在这些实体中提到的上下文。我们展示的神经模型的规模大的培训，让我们了解高品质实体交涉，我们证明在四个主要领域成功的结果：（1）现有的实体层面打字的基准，其中包括64％的误差减少了以前的工作在键入net（穆尔蒂。等人，2018）; （2）一种新的几拍重建类别任务; （3）现有的实体连接的基准，在那里我们匹配状态的最先进的上CoNLL-阿依无需关联的特定功能，将获得于2010年05 TAC-KBP得分为89.8％，而无需使用任何别名表，外部知识库或在域训练数据和（4）回答琐事问题，唯一标识实体。我们的全球实体表示编码细粒度类型类别，如苏格兰足球运动员，并且可以回答小问题，如：谁是施潘道监狱在柏林的最后一个犯人？</font>
</div>


<hr>
<div id="paper11"> <b>11. PatentTransformer-2: Controlling Patent Text Generation by Structural  Metadata</b>  <a href="https://arxiv.org/pdf/2001.03708" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jieh-Sheng Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hsiang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jieh Hsiang</a><br>
<font size="3">
Abstract: PatentTransformer is our codename for patent text generation based on Transformer-based models. Our goal is "Augmented Inventing." In this second version, we leverage more of the structural metadata in patents. The structural metadata includes patent title, abstract, and dependent claim, in addition to independent claim previously. Metadata controls what kind of patent text for the model to generate. Also, we leverage the relation between metadata to build a text-to-text generation flow, for example, from a few words to a title, the title to an abstract, the abstract to an independent claim, and the independent claim to multiple dependent claims. The text flow can go backward because the relation is trained bidirectionally. We release our GPT-2 models trained from scratch and our code for inference so that readers can verify and generate patent text on their own. As for generation quality, we measure it by both ROUGE and Google Universal Sentence Encoder. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：PatentTransformer是我们基于基于变压器的新型专利文本生成代号。我们的目标是“增强发明了。”在第二个版本中，我们利用更多的结构性元数据的专利。结构元数据包括专利标题，摘要，以及从属权利要求中，除了独立权利要求先前。元数据控制什么样的专利文本为模型来生成。此外，我们利用的元数据之间的关系，以建立一个文本到文本生成流，例如，从几话标题，标题为抽象，抽象到一个独立的权利要求，以及在独立权利要求到多个从属索赔。因为关系是双向训练文本流可以去落后。我们发布我们从头开始训练的GPT-2机型和我们推断代码，使读者可以验证并产生自己的专利文本。至于代的品质，我们双方ROUGE和谷歌万能句子编码器测量。</font>
</div>


<hr>
<div id="paper12"> <b>12. Does syntax need to grow on trees? Sources of hierarchical inductive  bias in sequence-to-sequence networks</b>  <a href="https://arxiv.org/pdf/2001.03632" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=McCoy%2C+R+T" target="_blank" rel="noopener" style="color:#0000EE;">R. Thomas McCoy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Frank%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Robert Frank</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Linzen%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tal Linzen</a><br>
<font size="3">
Abstract: Learners that are exposed to the same training data might generalize differently due to differing inductive biases. In neural network models, inductive biases could in theory arise from any aspect of the model architecture. We investigate which architectural factors affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection. For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order. All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a tree-structured model rather than a model with sequential recurrence, suggesting that human-like syntactic generalization requires architectural syntactic structure. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：暴露在同样的训练数据学习者可以概括不同，由于不同的感性偏见。在神经网络模型，感性的偏见在理论上可以从模型架构的任何方面引起的。我们调查其建筑因素影响训练的两个句法任务，英语问题的形成和英语时态reinflection神经序列到序列模型的推广行为。对于这两个任务，训练集是基于层次结构和基于线性顺序的推广泛化一致。所有的建筑因素，我们调查定性的影响模型如何推广，其中包括没有明确的连接层次结构的因素。例如，LSTMs越冬和显示本质上不同的感应偏压。然而，持续推动整个任务的分层偏见的唯一因素是使用一个树形结构的模型，而不是连续的复发模型，这表明类似人类的语法概括要求的建筑句法结构。</font>
</div>


<hr>
<div id="paper13"> <b>13. Reformer: The Efficient Transformer</b>  <a href="https://arxiv.org/pdf/2001.04451" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kitaev%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nikita Kitaev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kaiser%2C+%C5%81" target="_blank" rel="noopener" style="color:#0000EE;">Łukasz Kaiser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Levskaya%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anselm Levskaya</a><br>
<font size="3">
Abstract: Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：大型变压器模型通常实现多项任务的国家的最先进的成果，但训练这些模型可能极其昂贵的，特别是在长序列。我们介绍了两种技术来提高变压器的效率。首先，我们通过一个使用局部性敏感散列，从O（$ L ^ 2 $）至O（$ L \材L $），其中$ L $是的长度改变其复杂性替代点积关注顺序。此外，我们使用可逆残渣层而不是标准的残差，其允许在训练过程中，而不是$ N $倍，其中$ N $是层的数目仅一次存储激活。将得到的模型，重整器，而被更内存效率和长序列快得多与Transformer模型看齐进行。</font>
</div>


<hr>
<div id="paper14"> <b>14. LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured  Prediction</b>  <a href="https://arxiv.org/pdf/2001.04437" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Niculae%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vlad Niculae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Martins%2C+A+F+T" target="_blank" rel="noopener" style="color:#0000EE;">André F. T. Martins</a><br>
<font size="3">
Abstract: Structured prediction requires manipulating a large number of combinatorial structures, e.g., dependency trees or alignments, either as latent or output variables. Recently, the SparseMAP method has been proposed as a differentiable, sparse alternative to maximum a posteriori (MAP) and marginal inference. SparseMAP returns a combination of a small number of structures, a desirable property in some downstream applications. However, SparseMAP requires a tractable MAP inference oracle. This excludes, e.g., loopy graphical models or factor graphs with logic constraints, which generally require approximate inference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP that addresses this limitation via a local polytope relaxation. LP-SparseMAP uses the flexible and powerful domain specific language of factor graphs for defining and backpropagating through arbitrary hidden structure, supporting coarse decompositions, hard logic constraints, and higher-order correlations. We derive the forward and backward algorithms needed for using LP-SparseMAP as a hidden or output layer. Experiments in three structured prediction tasks show benefits compared to SparseMAP and Structured SVM. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：结构化预测需要操纵大量组合结构，例如，依赖树木或比对，无论是作为潜在的或输出变量。最近，SparseMAP方法已经被提出作为一个微的，稀疏替代最大后验（MAP）和边际推理。 SparseMAP返回少量的结构，在一些下游应用的期望特性的组合。然而，SparseMAP需要一个听话的地图推断预言。这不包括，例如，多圈图形模型或因子图与逻辑约束，这通常需要近似推断。在本文中，我们介绍了LP-SparseMAP，SparseMAP的扩展，地址通过本地多面体放松这一限制。 LP-SparseMAP使用用于定义和通过任意隐藏结构backpropagating，支撑粗分解，硬逻辑约束，和更高阶的相关性因子图的灵活和强大的域专用语言。我们推导需要使用LP-SparseMAP作为隐藏或输出层中的向前和向后的算法。在三个结构预测任务实验表明相比SparseMAP和结构化SVM的好处。</font>
</div>


<hr>
<div id="paper15"> <b>15. Negative Statements Considered Useful</b>  <a href="https://arxiv.org/pdf/2001.04425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Arnaout%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hiba Arnaout</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Razniewski%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Simon Razniewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weikum%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerhard Weikum</a><br>
<font size="3">
Abstract: Knowledge bases (KBs), pragmatic collections of knowledge about notable entities, are an important asset in applications such as search, question answering and dialogue. Rooted in a long tradition in knowledge representation, all popular KBs only store positive information, while they abstain from taking any stance towards statements not contained in them. In this paper, we make the case for explicitly stating interesting statements which are not true. Negative statements would be important to overcome current limitations of question answering, yet due to their potential abundance, any effort towards compiling them needs a tight coupling with ranking. We introduce two approaches towards compiling negative statements. (i) In peer-based statistical inferences, we compare entities with highly related entities in order to derive potential negative statements, which we then rank using supervised and unsupervised features. (ii) In query-log-based text extraction, we use a pattern-based approach for harvesting search engine query logs. Experimental results show that both approaches hold promising and complementary potential. Along with this paper, we publish the first datasets on interesting negative information, containing over 1.1M statements for 100K popular Wikidata entities. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：知识库（KBS），约著名的实体知识务实的集合，是在应用程序，如搜索，问答和对话的重要资产。在知识表示有着悠久的传统根深蒂固，所有流行的知识库系统只保存正面信息，而他们从迈出不包含在他们陈述的任何立场弃权。在本文中，我们做出明确说明有趣的声明不属实的情况。克服答疑的电流限制否定陈述将是重要的，但由于其潜在的丰富，对编译他们的任何努力，需要与排名的紧密耦合。我们引入对编译否定陈述两种方法。 （一）在对等的统计推断，我们比较具有高度相关实体的实体，以得出潜在的负面陈述，然后我们使用级监督和无监督的功能。 （二）在查询日志基于文本的提取，我们用收获的搜索引擎查询日志基于模式的方法。实验结果表明，这两种方法保持承诺和互补的潜力。除了本文中，我们公布有趣的负面信息的第一数据集，包含100K流行的维基数据实体超过1.1M的语句。</font>
</div>


<hr>
<div id="paper16"> <b>16. Asymmetrical Hierarchical Networks with Attentive Interactions for  Interpretable Review-Based Recommendation</b>  <a href="https://arxiv.org/pdf/2001.04346" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ni%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingchao Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cheng%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhengzhang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zong%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bo Zong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Song%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dongjin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yanchi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haifeng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=de+Melo%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gerard de Melo</a><br>
<font size="3">
Abstract: Recently, recommender systems have been able to emit substantially improved recommendations by leveraging user-provided reviews. Existing methods typically merge all reviews of a given user or item into a long document, and then process user and item documents in the same manner. In practice, however, these two sets of reviews are notably different: users' reviews reflect a variety of items that they have bought and are hence very heterogeneous in their topics, while an item's reviews pertain only to that single item and are thus topically homogeneous. In this work, we develop a novel neural network model that properly accounts for this important difference by means of asymmetric attentive modules. The user module learns to attend to only those signals that are relevant with respect to the target item, whereas the item module learns to extract the most salient contents with regard to properties of the item. Our multi-hierarchical paradigm accounts for the fact that neither are all reviews equally useful, nor are all sentences within each review equally pertinent. Extensive experimental results on a variety of real datasets demonstrate the effectiveness of our method. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近日，推荐系统已经能够通过利用用户提供的评论发出显着改善的建议。现有的方法通常合并给定用户或项目的所有评价为长的文档，然后处理以同样的方式用户和项目的文件。然而在实践中，这两组的评论是显着不同：用户的评价反映的各种物品，他们已经买了，并因此在其主题非常庞杂，而项目的审查只涉及到单个项目，因此是局部均匀。在这项工作中，我们开发了妥善占不对称周到模块的方式这一重要区别一个新的神经网络模型。用户模块学会照顾只有那些相关的相对于目标项目的信号，而项目模块学会了关于该项目的属性提取最突出的内容。我们的多层次模式考虑的事实是，无论是全部评论同样有用，也不是每个评论中的所有语句同样相关。在各种真实数据集的大量实验结果证明了该方法的有效性。</font>
</div>


<hr>
<div id="paper17"> <b>17. Shareable Representations for Search Query Understanding</b>  <a href="https://arxiv.org/pdf/2001.04345" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mukul Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Youna Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Headden%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Will Headden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Goutam%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rahul Goutam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Heran Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yin%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bing Yin</a><br>
<font size="3">
Abstract: Understanding search queries is critical for shopping search engines to deliver a satisfying customer experience. Popular shopping search engines receive billions of unique queries yearly, each of which can depict any of hundreds of user preferences or intents. In order to get the right results to customers it must be known queries like "inexpensive prom dresses" are intended to not only surface results of a certain product type but also products with a low price. Referred to as query intents, examples also include preferences for author, brand, age group, or simply a need for customer service. Recent works such as BERT have demonstrated the success of a large transformer encoder architecture with language model pre-training on a variety of NLP tasks. We adapt such an architecture to learn intents for search queries and describe methods to account for the noisiness and sparseness of search query data. We also describe cost effective ways of hosting transformer encoder models in context with low latency requirements. With the right domain-specific training we can build a shareable deep learning model whose internal representation can be reused for a variety of query understanding tasks including query intent identification. Model sharing allows for fewer large models needed to be served at inference time and provides a platform to quickly build and roll out new search query classifiers. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：了解搜索查询是购物搜索引擎提供一个满意的客户体验至关重要。流行的购物搜索引擎获得数十亿年唯一的查询，每一个都可以描绘出任何数百个用户的偏好或意图的。为了得到正确的结果，必须知道像“便宜的舞会礼服”旨在不仅是某个产品类型的表面效果，也具有价格低的产品查询客户。称为查询意图，例子还包括作者，品牌，年龄组或只是需要为客户服务的偏好。最近的作品如BERT都展现了大型变压器编码器架构，拥有对各种NLP任务语言模型前培训的成功。我们采用这样的架构，以学习为搜索查询意图和描述的是占搜索查询数据的吵闹和稀疏。我们还描述在低延迟要求的背景下举办的变压器编码器模型的经济有效的方式。有了正确的特定领域的培训，我们可以建立其内部表示可以为多种查询理解任务，包括查询意图识别重复使用一个共享的深度学习模式。模型共享允许在需要推理时间送达较少的大型模型，并提供了一个平台快速构建并推出新的搜索查询的分类。</font>
</div>


<hr>
<div id="paper18"> <b>18. Improving Dysarthric Speech Intelligibility Using Cycle-consistent  Adversarial Training</b>  <a href="https://arxiv.org/pdf/2001.04260" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Yang%2C+S+H" target="_blank" rel="noopener" style="color:#0000EE;">Seung Hee Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Chung%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minhwa Chung</a><br>
<font size="3">
Abstract: Dysarthria is a motor speech impairment affecting millions of people. Dysarthric speech can be far less intelligible than those of non-dysarthric speakers, causing significant communication difficulties. The goal of our work is to develop a model for dysarthric to healthy speech conversion using Cycle-consistent GAN. Using 18,700 dysarthric and 8,610 healthy control Korean utterances that were recorded for the purpose of automatic recognition of voice keyboard in a previous study, the generator is trained to transform dysarthric to healthy speech in the spectral domain, which is then converted back to speech. Objective evaluation using automatic speech recognition of the generated utterance on a held-out test set shows that the recognition performance is improved compared with the original dysarthic speech after performing adversarial training, as the absolute WER has been lowered by 33.4%. It demonstrates that the proposed GAN-based conversion method is useful for improving dysarthric speech intelligibility. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：构音障碍是影响数百万人的电机语言障碍。构音障碍的言语可以比那些非构音障碍的扬声器远不如理解，造成显著沟通困难。我们工作的目标是开发用于构音障碍的使用周期一致甘健康语音转换模型。使用18700构音障碍，并且记录在先前的研究中自动识别语音键盘的目的8,610健康控制朝鲜的言论，发电机被训练在频域中，然后将其转换回语音转换构音障碍的健康讲话。客观评价使用上的保持输出测试组示出了识别性能与执行对抗性训练后的原始dysarthic语音相比得到改善，作为绝对WER已经被降低了33.4％的产生的话语的自动语音识别。这表明，所提出的基于GaN的转换方法是提高构音障碍的语音清晰度非常有用。</font>
</div>


<hr>
<div id="paper19"> <b>19. Structural Decompositions of Epistemic Logic Programs</b>  <a href="https://arxiv.org/pdf/2001.04219" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hecher%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Markus Hecher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Morak%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Michael Morak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Woltran%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stefan Woltran</a><br>
<font size="3">
Abstract: Epistemic logic programs (ELPs) are a popular generalization of standard Answer Set Programming (ASP) providing means for reasoning over answer sets within the language. This richer formalism comes at the price of higher computational complexity reaching up to the fourth level of the polynomial hierarchy. However, in contrast to standard ASP, dedicated investigations towards tractability have not been undertaken yet. In this paper, we give first results in this direction and show that central ELP problems can be solved in linear time for ELPs exhibiting structural properties in terms of bounded treewidth. We also provide a full dynamic programming algorithm that adheres to these bounds. Finally, we show that applying treewidth to a novel dependency structure---given in terms of epistemic literals---allows to bound the number of ASP solver calls in typical ELP solving procedures. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：认知逻辑程序（电子学习）是标准的回答集编程（ASP）提供用于在语言中的推理在结果集的流行推广。这更丰富的形式主义来以较高的计算复杂性达到最高多项式层次的第四级的价格。然而，相对于标准的ASP，朝易处理专用的调查还没有进行呢。在本文中，我们让在这个方向的第一结果和表明中央ELP问题可以在线性时间内解决了在有界树宽的方面表现出结构性质电子学习。我们还提供一个完整的动态规划算法了符合这些界限。最后，我们表明，将树宽以一种新颖的依赖结构---在认识文字的形式给出---允许的ASP求解器的典型ELP解决过程的调用绑定的号码。</font>
</div>


<hr>
<div id="paper20"> <b>20. A logic-based relational learning approach to relation extraction: The  OntoILPER system</b>  <a href="https://arxiv.org/pdf/2001.04192" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Lima%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rinaldo Lima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Espinasse%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bernard Espinasse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Freitas%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Fred Freitas</a><br>
<font size="3">
Abstract: Relation Extraction (RE), the task of detecting and characterizing semantic relations between entities in text, has gained much importance in the last two decades, mainly in the biomedical domain. Many papers have been published on Relation Extraction using supervised machine learning techniques. Most of these techniques rely on statistical methods, such as feature-based and tree-kernels-based methods. Such statistical learning techniques are usually based on a propositional hypothesis space for representing examples, i.e., they employ an attribute-value representation of features. This kind of representation has some drawbacks, particularly in the extraction of complex relations which demand more contextual information about the involving instances, i.e., it is not able to effectively capture structural information from parse trees without loss of information. In this work, we present OntoILPER, a logic-based relational learning approach to Relation Extraction that uses Inductive Logic Programming for generating extraction models in the form of symbolic extraction rules. OntoILPER takes profit of a rich relational representation of examples, which can alleviate the aforementioned drawbacks. The proposed relational approach seems to be more suitable for Relation Extraction than statistical ones for several reasons that we argue. Moreover, OntoILPER uses a domain ontology that guides the background knowledge generation process and is used for storing the extracted relation instances. The induced extraction rules were evaluated on three protein-protein interaction datasets from the biomedical domain. The performance of OntoILPER extraction models was compared with other state-of-the-art RE systems. The encouraging results seem to demonstrate the effectiveness of the proposed solution. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：关系抽取（RE），检测和文本中的实体之间的表征语义关系的任务，获得了巨大的重要性在过去的二十年中，主要是在生物医学领域。许多论文已使用监督机器学习技术发表了关系抽取。这些技术大部分依赖于统计方法，如基于树的内核基于特征和方法。这样的统计学习的技术通常是基于用于表示实施例中，即一个命题假设空间，他们采用的特征的属性 - 值表示。这种表示法存在一些缺陷，特别是在复杂的关系，其中要求对涉及的情况下，即更多的上下文信息的提取，它不能有效地捕捉解析树结构信息不会丢失信息。在这项工作中，我们目前OntoILPER，一种基于逻辑的关系学习方法关系抽取使用归纳逻辑程序设计中的象征提取规则的形式产生的提取模式。 OntoILPER需要的例子丰富的关系表示，这可以减轻上述缺点的利润。拟议的关系的方式似乎更适合关系抽取比统计的人有几个原因，我们认为。此外，OntoILPER使用领域本体引导的背景知识生成处理，用于存储提取的关系实例。从生物医学域中的三个蛋白质 - 蛋白质相互作用数据集的感应提取规则进行评价。 OntoILPER提取模型的性能与国家的最先进的其它可再生能源系统进行了比较。令人鼓舞的结果似乎证明了该解决方案的有效性。</font>
</div>


<hr>
<div id="paper21"> <b>21. Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for  Language Grounding Tasks in Street View</b>  <a href="https://arxiv.org/pdf/2001.03671" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Mehta%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Harsh Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Artzi%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yoav Artzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Baldridge%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jason Baldridge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ie%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eugene Ie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mirowski%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Piotr Mirowski</a><br>
<font size="3">
Abstract: The Touchdown dataset (Chen et al., 2019) provides instructions by human annotators for navigation through New York City streets and for resolving spatial descriptions at a given location. To enable the wider research community to work effectively with the Touchdown tasks, we are publicly releasing the 29k raw Street View panoramas needed for Touchdown. We follow the process used for the StreetLearn data release (Mirowski et al., 2019) to check panoramas for personally identifiable information and blur them as necessary. These have been added to the StreetLearn dataset and can be obtained via the same process as used previously for StreetLearn. We also provide a reference implementation for both of the Touchdown tasks: vision and language navigation (VLN) and spatial description resolution (SDR). We compare our model results to those given in Chen et al. (2019) and show that the panoramas we have added to StreetLearn fully support both Touchdown tasks and can be used effectively for further research and comparison. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：（Chen等，2019）着陆数据集由通过纽约市的街道导航人工注释，并在给定的位置，解决空间的描述提供了说明。为了使更广泛的研究团体与着陆任务有效地开展工作，我们公开发布的29K原街景全景图所需的触地得分。我们遵循用于StreetLearn数据发布过程（Mirowski等，2019），以检查全景的个人身份信息，模糊它们是必要的。这些已被添加到所述数据集StreetLearn并如前面对StreetLearn使用可以通过相同的过程来获得。我们还为双方的着陆任务提供一个参考实现：视觉和语言导航（VLN）和空间分辨率描述（SDR）。我们比较我们的模型结果与陈等人给出的。 （2019），并表明我们已经添加到StreetLearn全景图完全支持着陆任务，可以进一步研究和比较有效地使用。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【arxiv论文】 Computation and Language 2020-01-13</title>
    <url>/2020/01/14/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-01-13/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><p><font size="4"><div id="title1"><br><b>1.</b> Towards Minimal Supervision BERT-based Grammar Error Correction <a href="https://arxiv.org/pdf/2001.03521" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div></font></p><div id="title2">
<b>2.</b> Co-evolution of language and agents in referential games <a href="https://arxiv.org/pdf/2001.03361" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div><div id="title3">
<b>3.</b> Machine Learning Approaches for Amharic Parts-of-speech Tagging <a href="https://arxiv.org/pdf/2001.03324" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div><a id="more"></a>


<div id="title4">
<b>4.</b> Learning to Multi-Task Learn for Better Neural Machine Translation <a href="https://arxiv.org/pdf/2001.03294" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> A Scalable Chatbot Platform Leveraging Online Community Posts: A  Proof-of-Concept Study <a href="https://arxiv.org/pdf/2001.03278" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Simulating Lexical Semantic Change from Sense-Annotated Data <a href="https://arxiv.org/pdf/2001.03216" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Debate Dynamics for Human-comprehensible Fact-checking on Knowledge  Graphs <a href="https://arxiv.org/pdf/2001.03436" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Inductive Document Network Embedding with Topic-Word Attention <a href="https://arxiv.org/pdf/2001.03369" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Linking Social Media Posts to News with Siamese Transformers <a href="https://arxiv.org/pdf/2001.03303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<font><p></p>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Towards Minimal Supervision BERT-based Grammar Error Correction</b>  <a href="https://arxiv.org/pdf/2001.03521" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yiyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Anastasopoulos%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Antonios Anastasopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Black%2C+A+W" target="_blank" rel="noopener" style="color:#0000EE;">Alan W Black</a><br>
<font size="3">
Abstract: Current grammatical error correction (GEC) models typically consider the task as sequence generation, which requires large amounts of annotated data and limit the applications in data-limited settings. We try to incorporate contextual information from pre-trained language model to leverage annotation and benefit multilingual scenarios. Results show strong potential of Bidirectional Encoder Representations from Transformers (BERT) in grammatical error correction task. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：当前语法纠错（GEC）模型通常考虑的任务，因为序列产生，这需要大量的注释数据，并限制在数据有限的情况下的应用程序。我们尝试从预先训练语言模型来杠杆注释结合上下文信息，有利于多语言情景。结果表明，从变形金刚（BERT）的语法纠错任务双向编码器交涉的巨大潜力。</font>
</div>


<hr>
<div id="paper2"> <b>2. Co-evolution of language and agents in referential games</b>  <a href="https://arxiv.org/pdf/2001.03361" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Dagan%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gautier Dagan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hupkes%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dieuwke Hupkes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bruni%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Elia Bruni</a><br>
<font size="3">
Abstract: Referential games offer a grounded learning environment for neural agents, that accounts for the functional aspects of language. However, they fail to account for another fundamental aspect of human language: Because languages are transmitted from generation to generation, they have to be learnable by new language users, which makes them subject to cultural evolution. Recent work has shown that incorporating cultural evolution in referential game results in considerable improvements in the properties of the languages that emerge in the game. In this work, we first substantiate this claim with a different data set and a wider array of evaluation metrics. Then, drawing inspiration from linguistic theories of human language evolution, we consider a scenario in which not only cultural but also genetic evolution is integrated. As our core contribution, we introduce the Language Transmission Engine, in which cultural evolution of the language is combined with genetic evolution of the agents' architecture. We show that this co-evolution scenario leads to across-the-board improvements on all considered metrics. These results stress that cultural evolution is important for language emergence studies, but also the suitability of the architecture itself should be considered. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：参照游戏提供接地的学习环境，为神经剂，这占了语言的功能方面。然而，他们无法解释人类语言的另一个重要方面：由于语言从代代相传，他们必须通过新的语言的用户，这使得他们受到文化的演变可以学习的。最近的研究显示，在纳入参考的比赛结果在在游戏中出现的语言的性质相当大的改善文化的演变。在这项工作中，我们首先证实这一要求与不同的数据集和评价度量的更广泛的阵列。然后，从人类语言进化的语言学理论中汲取灵感，我们认为这不仅是文化，而且基因进化集成的场景。作为我们的核心贡献，我们介绍了语言传输引擎，其中语言文化演进与代理的架构的遗传进化相结合。我们表明，这种协同进化的情况导致对所有考虑的指标，全面的板的改进。这些结果强调的是文化进化是语言出现的研究很重要，而且建筑本身的适用性应予以考虑。</font>
</div>


<hr>
<div id="paper3"> <b>3. Machine Learning Approaches for Amharic Parts-of-speech Tagging</b>  <a href="https://arxiv.org/pdf/2001.03324" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gashaw%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Ibrahim Gashaw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shashirekha%2C+H+L" target="_blank" rel="noopener" style="color:#0000EE;">H L. Shashirekha</a><br>
<font size="3">
Abstract: Part-of-speech (POS) tagging is considered as one of the basic but necessary tools which are required for many Natural Language Processing (NLP) applications such as word sense disambiguation, information retrieval, information processing, parsing, question answering, and machine translation. Performance of the current POS taggers in Amharic is not as good as that of the contemporary POS taggers available for English and other European languages. The aim of this work is to improve POS tagging performance for the Amharic language, which was never above 91%. Usage of morphological knowledge, an extension of the existing annotated data, feature extraction, parameter tuning by applying grid search and the tagging algorithms have been examined and obtained significant performance difference from the previous works. We have used three different datasets for POS experiments. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：部分的词类（POS）标记被认为是其所需的许多自然语言处理（NLP）的应用，如词义消歧，信息检索，信息处理，分析，问题解答基本而必要的工具之一，和机器翻译。在阿姆哈拉语当前POS标注器的性能还不如说可用于英语和其他欧洲语言的当代POS标注器的。这项工作的目的是为了改进为阿姆哈拉语，这是从来没有91％以上的词性标注的性能。形态的知识，现有的注解数据的扩展，特征提取，参数整定运用网格搜索和标记算法的使用已经被检查，并从以前的作品获得显著的性能差异。我们使用了三种不同的数据集用于POS实验。</font>
</div>


<hr>
<div id="paper4"> <b>4. Learning to Multi-Task Learn for Better Neural Machine Translation</b>  <a href="https://arxiv.org/pdf/2001.03294" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zaremoodi%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Poorya Zaremoodi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Haffari%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gholamreza Haffari</a><br>
<font size="3">
Abstract: Scarcity of parallel sentence pairs is a major challenge for training high quality neural machine translation (NMT) models in bilingually low-resource scenarios, as NMT is data-hungry. Multi-task learning is an elegant approach to inject linguistic-related inductive biases into NMT, using auxiliary syntactic and semantic tasks, to improve generalisation. The challenge, however, is to devise effective training schedules, prescribing when to make use of the auxiliary tasks during the training process to fill the knowledge gaps of the main translation task, a setting referred to as biased-MTL. Current approaches for the training schedule are based on hand-engineering heuristics, whose effectiveness vary in different MTL settings. We propose a novel framework for learning the training schedule, ie learning to multi-task learn, for the MTL setting of interest. We formulate the training schedule as a Markov decision process which paves the way to employ policy learning methods to learn the scheduling policy. We effectively and efficiently learn the training schedule policy within the imitation learning framework using an oracle policy algorithm that dynamically sets the importance weights of auxiliary tasks based on their contributions to the generalisability of the main NMT task. Experiments on low-resource NMT settings show the resulting automatically learned training schedulers are competitive with the best heuristics, and lead to up to +1.1 BLEU score improvements. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：平行句对稀缺是在双语低资源方案培养高素质神经机器翻译（NMT）车型的一大挑战，因为NMT是大量数据的。多任务学习是注入语言相关的感性偏见到NMT，利用辅助句法和语义的任务，以提高泛化一个优雅的方法。我们面临的挑战，但是，是制定有效的培训计划，开处方时，在训练过程中使用的辅助任务，填补了主要翻译任务的知识差距，设定被称为偏压MTL。对于训练计划目前的做法是基于手工工程启发式，其有效性在不同MTL设置而异。我们提出了学习培训计划，即学习多任务学习，感兴趣的MTL设置一个新的框架。我们制定的训练计划为马尔可夫决策过程，铺平了道路雇用政策的学习方法来学习调度策略。我们有效地学习使用Oracle策略算法，动态设置的基础上他们的主要任务NMT的普适性贡献辅助任务的重要性权重模仿学习框架内的培训计划政策。在低资源NMT设置实验表明所产生的自动学习训练调度与最好的启发式竞争力，并导致高达+1.​​1 BLEU得分的改善。</font>
</div>


<hr>
<div id="paper5"> <b>5. A Scalable Chatbot Platform Leveraging Online Community Posts: A  Proof-of-Concept Study</b>  <a href="https://arxiv.org/pdf/2001.03278" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Jo%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sihyeon Jo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Im%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sangwon Im</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Han%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">SangWook Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+S+H" target="_blank" rel="noopener" style="color:#0000EE;">Seung Hee Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hee-Eun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Seong-Woo Kim</a><br>
<font size="3">
Abstract: The development of natural language processing algorithms and the explosive growth of conversational data are encouraging researches on the human-computer conversation. Still, getting qualified conversational data on a large scale is difficult and expensive. In this paper, we verify the feasibility of constructing a data-driven chatbot with processed online community posts by using them as pseudo-conversational data. We argue that chatbots for various purposes can be built extensively through the pipeline exploiting the common structure of community posts. Our experiment demonstrates that chatbots created along the pipeline can yield the proper responses. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：自然语言处理算法的开发和会话数据的爆炸性增长是令人鼓舞的人机对话的研究。尽管如此，越来越大规模合格的会话数据难，看病贵。在本文中，我们核实使用它们作为伪会话数据建设有处理在线社区的帖子一个数据驱动的聊天机器人的可行性。我们认为，出于各种目的聊天机器人，可以通过管道利用社区帖子的共同结构广泛建立。我们的实验表明，沿管道创建聊天机器人能得到适当的回应。</font>
</div>


<hr>
<div id="paper6"> <b>6. Simulating Lexical Semantic Change from Sense-Annotated Data</b>  <a href="https://arxiv.org/pdf/2001.03216" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Schlechtweg%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dominik Schlechtweg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Walde%2C+S+S+i" target="_blank" rel="noopener" style="color:#0000EE;">Sabine Schulte im Walde</a><br>
<font size="3">
Abstract: We present a novel procedure to simulate lexical semantic change from synchronic sense-annotated data, and demonstrate its usefulness for assessing lexical semantic change detection models. The induced dataset represents a stronger correspondence to empirically observed lexical semantic change than previous synthetic datasets, because it exploits the intimate relationship between synchronic polysemy and diachronic change. We publish the data and provide the first large-scale evaluation gold standard for LSC detection models. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了一种新的方法来模拟从共时性意义标注的数据词汇语义变化，并展示其评估词汇语义变化检测模型有效性。感应数据集表示更强的对应于比以前的合成数据集经验观察词汇语义变化，因为它利用共时多义性和历时变化之间的亲密关系。我们发布的数据，并提供了LSC检测模型的首次大规模评估的黄金标准。</font>
</div>


<hr>
<div id="paper7"> <b>7. Debate Dynamics for Human-comprehensible Fact-checking on Knowledge  Graphs</b>  <a href="https://arxiv.org/pdf/2001.03436" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Hildebrandt%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Marcel Hildebrandt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Serna%2C+J+A+Q" target="_blank" rel="noopener" style="color:#0000EE;">Jorge Andres Quintero Serna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yunpu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ringsquandl%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Martin Ringsquandl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Joblin%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mitchell Joblin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Tresp%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Volker Tresp</a><br>
<font size="3">
Abstract: We propose a novel method for fact-checking on knowledge graphs based on debate dynamics. The underlying idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments -- paths in the knowledge graph -- with the goal to justify the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, referred to as the judge, decides whether the fact is true or false. The two agents can be considered as sparse feature extractors that present interpretable evidence for either the thesis or the antithesis. In contrast to black-box methods, the arguments enable the user to gain an understanding for the decision of the judge. Moreover, our method allows for interactive reasoning on knowledge graphs where the users can raise additional arguments or evaluate the debate taking common sense reasoning and external information into account. Such interactive systems can increase the acceptance of various AI applications based on knowledge graphs and can further lead to higher efficiency, robustness, and fairness. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了基于辩论动力学知识图其实检查的新方法。其基本思想是将框架三重分类的任务，两个加强学习剂，其提取参数之间辩论的游戏 - 在知识图上的路径 - 用进球来证明的事实是真实的（论文）或事实是假的（对立面），分别。根据这些参数，一个二元分类，简称判断，决定是否其实是真还是假。这两种药剂可以看作是稀疏的特征提取，对于无论是论文或对立面目前可解释的证据。相较于黑箱方法，参数使用户获得了法官的决定的理解。此外，我们的方法允许对知识图，其中用户可以提出额外的参数或评估的辩论采取常识推理和外部信息纳入考虑交互推理。这样的交互系统可以增加接受的基于知识的图表各种AI应用，并进一步导致更高的效率，稳健性和公平性。</font>
</div>


<hr>
<div id="paper8"> <b>8. Inductive Document Network Embedding with Topic-Word Attention</b>  <a href="https://arxiv.org/pdf/2001.03369" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Brochier%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Robin Brochier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Guille%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adrien Guille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Velcin%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Julien Velcin</a><br>
<font size="3">
Abstract: Document network embedding aims at learning representations for a structured text corpus i.e. when documents are linked to each other. Recent algorithms extend network embedding approaches by incorporating the text content associated with the nodes in their formulations. In most cases, it is hard to interpret the learned representations. Moreover, little importance is given to the generalization to new documents that are not observed within the network. In this paper, we propose an interpretable and inductive document network embedding method. We introduce a novel mechanism, the Topic-Word Attention (TWA), that generates document representations based on the interplay between word and topic representations. We train these word and topic vectors through our general model, Inductive Document Network Embedding (IDNE), by leveraging the connections in the document network. Quantitative evaluations show that our approach achieves state-of-the-art performance on various networks and we qualitatively show that our model produces meaningful and interpretable representations of the words, topics and documents. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：文档在网络学习表示了结构化文本语料库即当文档相互链接嵌入目标。最近算法扩展网络嵌入通过将在它们的制剂中的节点相关联的文本内容接近。在大多数情况下，这是很难解释学表示。此外，小的重要性是考虑到泛化到未在网络内观察到新文档。在本文中，我们提出了一个解释和归纳文档网络嵌入方法。我们引入新的机制，主题字注意（TWA），其基于字和主题陈述之间的相互文档表示。我们培养这些词和话题载体通过我们的一般模型，归纳文档网络嵌入（IDNE），通过利用文档网络中的连接。定量评估表明，我们的方法实现了各种网络上的国家的最先进的性能和我们定性地表明，我们的模型产生的话，主题和文件有意义的，可解释的表示。</font>
</div>


<hr>
<div id="paper9"> <b>9. Linking Social Media Posts to News with Siamese Transformers</b>  <a href="https://arxiv.org/pdf/2001.03303" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Danovitch%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jacob Danovitch</a><br>
<font size="3">
Abstract: Many computational social science projects examine online discourse surrounding a specific trending topic. These works often involve the acquisition of large-scale corpora relevant to the event in question to analyze aspects of the response to the event. Keyword searches present a precision-recall trade-off and crowd-sourced annotations, while effective, are costly. This work aims to enable automatic and accurate ad-hoc retrieval of comments discussing a trending topic from a large corpus, using only a handful of seed news articles. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：许多计算社会科学的研究项目围绕特定热门话题的在线话语。这些作品往往涉及收购有关问题的情况下大规模语料库的分析应对事件的各个方面。关键字搜索呈现精密召回权衡和人群来源的注解，而有效的，是昂贵的。这项工作的目的在于使的意见，从大语料库讨论一个热门话题自动精确的ad-hoc检索，仅使用种子的新闻报道屈指可数。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>
</font>]]></content>
      <categories>
        <category>arxiv</category>
        <category>CL</category>
      </categories>
  </entry>
  <entry>
    <title>【论文笔记】Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</title>
    <url>/2020/01/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Task-Oriented-Dialog-Systems-that-Consider-Multiple-Appropriate-Responses-under-the-Same-Context/</url>
    <content><![CDATA[<p><strong>Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</strong>. Yichi Zhang, Zhijian Ou, Zhou Yu. <a href="https://arxiv.org/abs/1911.10484" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p><img src="/images/DADL1.jpg" alt></p><p><img src="/images/DADL2.jpg" alt></p><p>在对话中，对于同一句话，可以有多种回复。但是，现有模型往往趋于生成出现概率最高的回复，而忽视了概率较低的回复。本文通过数据增强的方法，使得模型具备生成多样化回复的能力。</p><a id="more"></a>



<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p><img src="/images/DADL4.jpg" alt><br>在数据预处理阶段，在整个数据集中，找出所有的dialogue state相同的system actions，作为ground truth的补充增强。</p>
<h2 id="整体方法"><a href="#整体方法" class="headerlink" title="整体方法"></a>整体方法</h2><p><img src="/images/DADL3.jpg" alt><br>训练过程中，所有可能的回复概率都要最大，而不只需要ground truth概率最大。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>1 encoder + 3 decoder<br><img src="/images/DADL5.jpg" alt></p>
<p>作者认为通过这样训练，模型就具备了生成多样性回复的能力，在测试的时候可以通过multi beam search、top-k等方式生成多样性回复。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者本次实验主要在数据集MultiWoZ进行。<br><img src="/images/DADL7.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Dialog System</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Integrating Relation Constraints with Neural Relation Extractors</title>
    <url>/2020/01/08/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Integrating-Relation-Constraints-with-Neural-Relation-Extractors/</url>
    <content><![CDATA[<p><strong>Integrating Relation Constraints with Neural Relation Extractors</strong>. Yuan Ye, Yansong Feng, Bingfeng Luo, Yuxuan Lai, Dongyan Zhao. AAAI 2020. <a href="https://arxiv.org/abs/1911.11493" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>在关系抽取任务中，<strong>某个关系的所有subject或者object属于同一种类型</strong>（如：在“母校”的所有subject都属于“人”），或者<strong>多个关系之间往往存在依赖关系</strong>（如“城市”和“地区”的subject都是地名），但是现有模型都没有考虑这个约束，只是单独考虑每一个关系。本文工作利用这种约束以提升关系抽取任务的效果。</p><a id="more"></a>

<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文从Coherent和Semantic两个角度出发，提出两种方法。</p>
<h2 id="Coherent"><a href="#Coherent" class="headerlink" title="Coherent"></a>Coherent</h2><p>一致性：满足约束的两个关系，预测概率要同时高。</p>
<p><img src="/images/IER1.jpg" alt></p>
<p>矩阵v表示关系约束C,如果关系i和关系j满足约束，则v_ij=1。</p>
<h2 id="Semantic"><a href="#Semantic" class="headerlink" title="Semantic"></a>Semantic</h2><p>语义性：符合约束中某个规则的两个实例，至少有一个实例满足规则中的某个关系。</p>
<p><img src="/images/IER2.jpg" alt></p>
<p>矩阵u表示约束C,如果关系j和关系k满足约束i，则v_ij=1,v_ik=1.</p>
<p>最后loss由两部分构成，Lo为原始的loss，Lc为约束loss。<br><img src="/images/IER3.jpg" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在ACNN和APCNN两个模型上进行验证，均获得了提升。<br><img src="/images/IER4.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Neural Relation Extraction</tag>
        <tag>Relation Constraints</tag>
      </tags>
  </entry>
  <entry>
    <title>智源社区2019年大会PPT分享 </title>
    <url>/2020/01/08/%E6%99%BA%E6%BA%90%E7%A4%BE%E5%8C%BA2019%E5%B9%B4%E5%A4%A7%E4%BC%9APPT%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p>获取方式 <a href="https://mp.weixin.qq.com/s/zqqQVwr16EhqA2zxYUQSWQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/zqqQVwr16EhqA2zxYUQSWQ</a></p>
<a id="more"></a>

<p><img src="/images/zhiyuan2019-1.jpg" alt=""></p>
<p><img src="/images/zhiyuan2019-2.jpg" alt=""></p>
]]></content>
  </entry>
  <entry>
    <title>【shell】批量删除除了某个文件外的其他所有文件</title>
    <url>/2020/01/08/%E3%80%90shell%E3%80%91%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E9%99%A4%E4%BA%86%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%96%E7%9A%84%E5%85%B6%E4%BB%96%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -f !(no_delete_file1|no_delete_file2)</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls |grep -v no_delete_file |xargs rm -f</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>批量删除</tag>
      </tags>
  </entry>
  <entry>
    <title>AAAI2020 预讲会</title>
    <url>/2019/12/22/AAAI2020-%E9%A2%84%E8%AE%B2%E4%BC%9A/</url>
    <content><![CDATA[<p>AAAI2020 预讲会翻译对话与文本生成、文本分析与内容挖掘两个Session比较有意思的论文。</p><ul>
<li><p>Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation <a href="https://arxiv.org/abs/1911.09320" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N2-%E9%82%B5%E6%99%A8%E6%B3%BD-%E4%B8%AD%E7%A7%91%E9%99%A2%E8%AE%A1%E7%AE%97%E6%89%80.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Modeling Fluency and Faithfulness for Diverse Neural Machine Translation <a href="https://arxiv.org/abs/1912.00178" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N1-%E8%B0%A2%E5%A9%89%E8%8E%B9-%E4%B8%AD%E7%A7%91%E9%99%A2%E8%AE%A1%E7%AE%97%E6%89%80.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Task-Oriented Dialog Systems that Consider Multiple Appropriate Response under the Same Context <a href="https://arxiv.org/abs/1911.10484" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N3-%E5%BC%A0%E4%BA%A6%E5%BC%9B-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Neural Machine Translation with Joint Representation <a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S1N8-%E6%9D%8E%E7%82%8E%E6%B4%8B-%E4%B8%9C%E5%8C%97%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Multi-Scale Self-Attention for Text Classification <a href="https://arxiv.org/abs/1912.00544" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S2N1-%E9%83%AD%E7%90%A6%E9%B9%8F-%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Intergrating Relation Constraints with Neural Relation Extractors <a href="https://arxiv.org/abs/1911.11493" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/procjx/procjx.github.io/blob/master/files/AAAI2020-PRE/%E3%80%90%E7%BB%88%E7%A8%BF%E3%80%91S2N5-%E5%8F%B6%E5%85%83-%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6.pdf" target="_blank" rel="noopener">[Slide]</a></p>
</li>
<li><p>Cross-Lingual Natural Language Generation via Pre-Training <a href="https://arxiv.org/abs/1909.10481" target="_blank" rel="noopener">[PDF]</a></p>
</li>
</ul>]]></content>
      <categories>
        <category>论文列表</category>
      </categories>
      <tags>
        <tag>AAAI</tag>
      </tags>
  </entry>
  <entry>
    <title>国内一些NLP实验室及老师主页</title>
    <url>/2019/12/21/%E5%9B%BD%E5%86%85%E4%B8%80%E4%BA%9BNLP%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8F%8A%E8%80%81%E5%B8%88%E4%B8%BB%E9%A1%B5/</url>
    <content><![CDATA[<p>以下列表只是我个人整理，随意排序，欢迎大家补充与指正。</p>
<ul>
<li><p><a href="http://nlp.csai.tsinghua.edu.cn/site2/" target="_blank" rel="noopener">清华大学自然语言处理与社会人文计算实验室</a></p>
<p><a href="http://www.cs.tsinghua.edu.cn/publish/cs/4616/2013/20130424103737386785027/20130424103737386785027_.html" target="_blank" rel="noopener">孙茂松</a> <a href="http://nlp.csai.tsinghua.edu.cn/~ly/index_cn.html" target="_blank" rel="noopener">刘洋</a> <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/" target="_blank" rel="noopener">刘知远</a></p>
</li>
<li><p><a href="http://www.wict.pku.edu.cn/" target="_blank" rel="noopener">北京大学王选计算机研究所</a></p>
<p><a href="http://www.icst.pku.edu.cn/xztd/xztd_01/1222625.htm" target="_blank" rel="noopener">万小军</a> <a href="http://www.icst.pku.edu.cn/xztd/xztd_01/1222614.htm" target="_blank" rel="noopener">严睿</a> <a href="http://www.wict.pku.edu.cn/zhaodongyan/" target="_blank" rel="noopener">赵东岩</a> <a href="https://sites.google.com/site/ysfeng/home" target="_blank" rel="noopener">冯岩松</a> <a href="https://www.cs.uic.edu/~liub/" target="_blank" rel="noopener">刘兵</a></p>
</li>
<li><p><a href="http://www.cs.tsinghua.edu.cn/publish/cs/index.html" target="_blank" rel="noopener">清华大学计算机科学与技术系</a></p>
<p><a href="http://coai.cs.tsinghua.edu.cn/hml/" target="_blank" rel="noopener">黄民烈</a></p>
</li>
</ul>
<a id="more"></a>

<ul>
<li><p><a href="http://www.icip.org.cn/zh/homepage/" target="_blank" rel="noopener">中国科学院软件研究所中文信息处理实验室</a></p>
<p><a href="http://www.icip.org.cn/team/sunle/" target="_blank" rel="noopener">孙乐</a> <a href="http://www.icip.org.cn/team/hanxianpei/" target="_blank" rel="noopener">韩先培</a></p>
</li>
<li><p><a href="http://iip.ict.ac.cn/" target="_blank" rel="noopener">中国科学院计算技术研究所智能信息处理重点实验室</a></p>
<p><a href="http://sourcedb.ict.cas.cn/cn/jssrck/201709/t20170910_4857722.html" target="_blank" rel="noopener">冯洋</a></p>
</li>
<li><p><a href="http://www.nlplab.com/niuplan/niutrans.ch.html" target="_blank" rel="noopener">东北大学自然语言处理实验室</a></p>
<p><a href="http://www.nlplab.com/members/zhujingbo.html" target="_blank" rel="noopener">朱靖波</a> <a href="http://www.nlplab.com/members/xiaotong.html" target="_blank" rel="noopener">肖桐</a></p>
</li>
<li><p><a href="http://www.cs.fudan.edu.cn/" target="_blank" rel="noopener">复旦大学计算机科学技术学院</a></p>
<p><a href="https://xpqiu.github.io/" target="_blank" rel="noopener">邱锡鹏</a></p>
</li>
<li><p><a href="http://cs.tju.edu.cn/csweb/" target="_blank" rel="noopener">天津大学计算机科学与技术学院</a></p>
<p><a href="https://zhangmeishan.github.io/chn.html" target="_blank" rel="noopener">张梅山</a> <a href="http://cs.tju.edu.cn/csweb/admin_teacher/view?id=232" target="_blank" rel="noopener">熊德意</a></p>
</li>
<li><p><a href="http://nlp.xmu.edu.cn/index.html" target="_blank" rel="noopener">厦门大学自然语言处理实验室</a></p>
<p><a href="http://121.192.180.171:8080/" target="_blank" rel="noopener">史晓东</a></p>
</li>
<li><p><a href="https://cdmc.xmu.edu.cn/index.htm" target="_blank" rel="noopener">厦门大学数字媒体计算研究中心</a></p>
<p><a href="https://cdmc.xmu.edu.cn/info/1010/1054.htm" target="_blank" rel="noopener">苏劲松</a></p>
</li>
<li><p><a href="http://bcmi.sjtu.edu.cn/index.cn.html" target="_blank" rel="noopener">上海交通大学BCMI实验室</a></p>
<p><a href="http://bcmi.sjtu.edu.cn/~zhaohai/" target="_blank" rel="noopener">赵海</a></p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>写作助手</title>
    <url>/2019/12/21/%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://www.overleaf.com/" target="_blank" rel="noopener">Overleaf</a><br>在线编辑Latex。</p>
</li>
<li><p><a href="https://www.grammarly.com/" target="_blank" rel="noopener">Grammarly</a><br>自动检测语法。</p>
</li>
<li><p><a href="http://www.esoda.org/" target="_blank" rel="noopener">易搜搭</a><br>词语搭配。</p>
</li>
</ul>
<a id="more"></a>]]></content>
      <tags>
        <tag>写作助手</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Improved Document Modelling with a Neural Discourse Parser</title>
    <url>/2019/12/21/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Improved-Document-Modelling-with-a-Neural-Discourse-Parser/</url>
    <content><![CDATA[<p><strong>Improved Document Modelling with a Neural Discourse Parser</strong>.Fajri Koto, Jey Han Lau, Timothy Baldwin. ArXiv 1911.<a href="https://arxiv.org/abs/1911.06919" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>使用篇章结构信息提高篇章建模。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>文章的关键有两点，篇章结构是什么？如何利用篇章结构？</p><a id="more"></a>


<h2 id="篇章结构是什么？"><a href="#篇章结构是什么？" class="headerlink" title="篇章结构是什么？"></a>篇章结构是什么？</h2><p><img src="/images/DMDP1.jpg" alt></p>
<p>本篇文章的篇章结构由RST分析得到，首先将篇章切分成EDU，然后再EDU基础上建立篇章分析树，树上的叶子结点为EDU，非叶子结点为其两个子节点的篇章关系，树上的边为对应子节点在该关系中的重要性。（具体可以去了解一下RST官网介绍和相关论文）</p>
<h2 id="如何利用篇章结构？"><a href="#如何利用篇章结构？" class="headerlink" title="如何利用篇章结构？"></a>如何利用篇章结构？</h2><p>如何利用篇章结构，首先是如何编码篇章结构，也就是如何抽取篇章分析树的特征。针对每个树根节点到每个叶子结点的路径，作者设计两类特征：Shallow Discourse Features 和 Latent Discourse Features。</p>
<h3 id="Shallow-Discourse-Features"><a href="#Shallow-Discourse-Features" class="headerlink" title="Shallow Discourse Features"></a>Shallow Discourse Features</h3><ul>
<li>叶子结点重要性分数</li>
</ul>
<p><img src="/images/DMDP2.jpg" alt></p>
<p>统计路径上Nucleus的比例，h(root)为根节点高度。</p>
<ul>
<li>关系重要性分数</li>
</ul>
<p><img src="/images/DMDP3.jpg" alt></p>
<p>统计路径上每个关系的加权比例，h(x)为节点x的高度。</p>
<ul>
<li><p>结点类别</p>
<p>  Nucleus or satellite</p>
<ul>
<li>兄弟结点</li>
</ul>
<h3 id="Latent-Discourse-Features"><a href="#Latent-Discourse-Features" class="headerlink" title="Latent Discourse Features"></a>Latent Discourse Features</h3></li>
</ul>
<p><img src="/images/DMDP6.jpg" alt></p>
<p>使用两个Bi-LSTM分别编码词序列和句法特征序列，avg-pool，然后拼接。</p>
<p><img src="/images/DMDP4.jpg" alt></p>
<p>拼接后的序列再过一个Bi-LSTM得到最终特征表示。</p>
<p><img src="/images/DMDP5.jpg" alt></p>
<h3 id="如何利用篇章特征"><a href="#如何利用篇章特征" class="headerlink" title="如何利用篇章特征"></a>如何利用篇章特征</h3><p> 得到两类特征后，要如何利用呢？本文提出了三种方法。</p>
<ul>
<li><p>拼接word embedding</p>
<p><img src="/images/DMDP7.jpg" alt></p>
</li>
<li><p>加一层Bi-LSTM</p>
<p><img src="/images/DMDP8.jpg" alt></p>
</li>
<li><p>作为解码attention的一个额外输入</p>
<p><img src="/images/DMDP9.jpg" alt></p>
</li>
</ul>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="Document-Summarizatoin"><a href="#Document-Summarizatoin" class="headerlink" title="Document Summarizatoin"></a>Document Summarizatoin</h2><p>  <img src="/images/DMDP10.jpg" alt></p>
<p>  第一种和第二种方法较好。</p>
<h2 id="Petition-Popularity-Prediction"><a href="#Petition-Popularity-Prediction" class="headerlink" title="Petition Popularity Prediction"></a>Petition Popularity Prediction</h2><p>  <img src="/images/DMDP11.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Summarization</tag>
        <tag>Discourse</tag>
        <tag>RST</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】linux批量杀死进程</title>
    <url>/2019/12/21/%E3%80%90shell%E3%80%91linux%E6%89%B9%E9%87%8F%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>批量杀死包含关键字“keyword1”但不包含“keyword2”的进程。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef|grep keyword1|grep -v keyword2|cut -c 9-15|xargs kill -9</span><br></pre></td></tr></table></figure><ul>
<li><strong>“ps -ef”</strong> ——查看所有进程</li>
<li><strong>“grep keyword1”</strong> ——列出所有含有关键字”keyword1”的进程</li>
<li><strong>“grep -v keyword2”</strong> ——在列出的进程中去除含有关键字”keyword2”的进程</li>
<li><strong>“cut -c 9-15″</strong> ——截取输入行的第9个字符到第15个字符，而这正好是进程号PID</li>
<li><strong>“xargs kill -9″</strong> ——xargs 命令是用来把前面命令的输出结果(PID)作为”kill -9″命令的参数，并执行该命令。”kill -9″会强行杀掉指定进程。</li>
</ul>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>批量</tag>
        <tag>杀死进程</tag>
      </tags>
  </entry>
  <entry>
    <title>好的研究想法从哪里来</title>
    <url>/2019/12/03/%E5%A5%BD%E7%9A%84%E7%A0%94%E7%A9%B6%E6%83%B3%E6%B3%95%E4%BB%8E%E5%93%AA%E9%87%8C%E6%9D%A5/</url>
    <content><![CDATA[<p>转载自：知乎专栏 NLP日知录 <a href="https://zhuanlan.zhihu.com/p/93765082" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/93765082</a></p><p>作者：刘知远 </p><p>背景说明：临近ACL 2020投稿截止时间，跟同学密集讨论，争论哪些研究想法适合投到ACL有机会命中。从自己十多年研究经历来看，如何判断一个研究想法好不好，以及这些研究想法从哪里来，对于初学者而言的确是个难题。所以，简单攒了这篇小短文，分享一些经验和想法，希望对刚进入NLP领域的新同学有用。多有舛误请指正。</p><a id="more"></a>


<p>王家卫的电影《一代宗师》中有段经典的比武桥段，宫会长对叶问说“今天我们不比武术，比想法”。其实，好的点子或者想法（idea），也是一篇优秀研究成果的灵魂。而计算机领域流行着一句话“IDEA is cheap, show me the code”，也说明对于重视实践的计算机学科而言，想法的好坏还取决于它的实际效能。这里就来谈下好的研究想法从哪里来。</p>
<h1 id="什么算是好的想法"><a href="#什么算是好的想法" class="headerlink" title="什么算是好的想法"></a>什么算是好的想法</h1><p>2015年，我在微博上写过一个调侃的小段子：</p>
<blockquote>
<p>ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。</p>
</blockquote>
<p>到了2018年，我又续了一小段：</p>
<blockquote>
<p>不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门，曰注意，曰记忆，曰对抗，曰增强。经ImageNet一役威震武林，豢Alpha犬一匹无人可近。一时家家筑丹炉，人人炼丹忙，门徒云集，依附者众，有一统江湖之势。有童谣为证：左手大数据，右手英伟达，每逢顶会炼丹忙。</p>
</blockquote>
<p>这里面提到的图模型加圈、神经网络加层、优化目标加正则，神经网络中的门、注意、记忆等，都是一些改进模型性能的创新思路，被各大NLP任务广泛使用并发表论文，也许就是因为被不同NLP任务的重复使用和发表，多少有些审美疲劳而缺少更深的创新思想，被有些网友和学者诟为“灌水”，似乎都不算好的想法。</p>
<p>那么什么才是好的想法呢？我理解这个”好“字，至少有两个层面的意义。</p>
<h2 id="学科发展角度的“好”"><a href="#学科发展角度的“好”" class="headerlink" title="学科发展角度的“好”"></a>学科发展角度的“好”</h2><p>学术研究本质是对未知领域的探索，是对开放问题的答案的追寻。所以从推动学科发展的角度，评判什么是好的研究想法的标准，首先就在一个<strong>“新”</strong>字。</p>
<p>过去有个说法，人工智能学科有个魔咒，凡是人工智能被解决（或者有解决方案）的部分，就不再被认为代表“人类智能”。计算机视觉、自然语言处理、机器学习、机器人之所以还被列为人工智能主要方向，也许正是因为它们尚未被解决，尚能代表“人类智能”的尊严。而我们要开展创新研究，就是要提出新的想法解决这些问题。这其中的”新“字，可以体现在提出新的问题和任务，探索新的解决思路，提出新的算法技术，实现新的工具系统等。</p>
<p>在保证”新“的基础上，研究想法好不好，那就看它<strong>对推动学科发展的助力有多大</strong>。深度学习之所以拥有如此显赫的影响力，就在于它对于人工智能自然语言处理、语音识别、计算机视觉等各重要方向都产生了革命性的影响，彻底改变了对无结构信号（语音、图像、文本）的语义表示的技术路线。</p>
<h2 id="研究实践角度的”好“"><a href="#研究实践角度的”好“" class="headerlink" title="研究实践角度的”好“"></a>研究实践角度的”好“</h2><p>那是不是想法只要够”新“就好呢？是不是越新越好呢？我认为应该还不是。因为，只有<strong>能做得出来的想法</strong>才有资格被分析好不好。所以，从研究实践角度，还需要考虑研究想法的<strong>可实现性</strong>和<strong>可验证性</strong>。</p>
<p>可实现性，体现在该想法是否有足够的数学或机器学习工具支持实现。可验证性，体现在该想法是否有合适的数据集合和广泛接受的评价标准。很多民间科学家的想法之所以得不到学术界的认同，就是因为这些想法往往缺乏可实现性和可验证性，只停留在天马行空的纸面，只是些虚无缥缈的理念。</p>
<h1 id="好的研究想法从哪里来"><a href="#好的研究想法从哪里来" class="headerlink" title="好的研究想法从哪里来"></a>好的研究想法从哪里来</h1><p>想法好还是不好，并不是非黑即白的二分问题，而是像光谱一样呈连续分布，因时而异，因人而宜。计算机科技领域的发展既有积累的过程，也有跃迁的奇点，积累量变才会产生质变，吃第三个馒头饱了，也是因为前面两个馒头打底。</p>
<p>现在的学术研究已经成为高度专业化的职业，有庞大的研究者群体。”Publish or Perish“，是从事学术职业（如教授、研究员、研究生）的人必须做好平衡的事情，不能要求研究者的每份工作都是“诺贝尔奖”或“图灵奖”级的才值得发表。只要对研究领域的发展有所助力，就值得发表出来，帮助同行前进。鲁迅说：天才并不是自生自长在深林荒野里的怪物，是由可以使天才生长的民众产生，长育出来的，所以没有这种民众，就没有天才。这个庞大研究者群体正是天才成长的群众基础。同时，学术新人也是在开展创新研究训练中，不断磨砺寻找好想法能力，鲁迅也说：即使天才，在生下来的时候的第一声啼哭，也和平常的儿童的一样，决不会就是一首好诗。</p>
<p>那么，好的研究想法从哪里来呢？我总结，首先要有区分研究想法好与不好的能力，这需要<strong>深入全面了解所在研究方向的历史与现状</strong>，具体就是对学科文献的全面掌握。人是最善于学习的动物，完全可以将既有文献中不同时期研究工作的想法作为学习对象，通过了解它们提出后对学科发展的影响——具体体现在论文引用、学术评价情况等各方面——建立对研究想法好与不好的评价模型。我们很难条分缕析完美地列出区分好与不好想法的所有特征向量，但人脑强大的学习能力，只要给予足够的输入数据，就可以在神经网络中自动学习建立判别的模型，鉴古知今，见微知著，这也许就是常说的学术洞察力。</p>
<p>做过一些研究的同学会有感受，仅阅读自己研究方向的文献，新想法还是不会特别多。这是因为，读到的都是该研究问题已经完成时的想法，它们本身无法启发新的想法。如何产生新的想法呢？我总结有三种可行的基本途径：</p>
<p><strong>实践法</strong>。即在研究任务上实现已有最好的算法，通过分析实验结果，例如发现这些算法计算复杂度特别高、训练收敛特别慢，或者发现该算法的错误样例呈现明显的规律，都可以启发你改进已有算法的思路。现在很多自然语言处理任务的Leaderboard上的最新算法，就是通过分析错误样例来有针对性改进算法的 [1]。</p>
<p><strong>类比法</strong>。即将研究问题与其他任务建立类比联系，调研其他相似任务上最新的有效思想、算法或工具，通过合理的转换迁移，运用到当前的研究问题上来。例如，当初注意力机制在神经网络机器翻译中大获成功，当时主要是在词级别建立注意力，后来我们课题组的林衍凯和沈世奇提出建立句子级别的注意力解决关系抽取的远程监督训练数据的标注噪音问题 [2]，这就是一种类比的做法。</p>
<p><strong>组合法</strong>。即将新的研究问题分解为若干已被较好解决的子问题，通过有机地组合这些子问题上的最好做法，建立对新的研究问题的解决方案。例如，我们提出的融合知识图谱的预训练语言模型，就是将BERT和TransE等已有算法融合起来建立的新模型 [3]。</p>
<p>正如武侠中的最高境界是无招胜有招，好的研究想法并不拘泥于以上的路径，很多时候是在研究者对研究问题深刻认知的基础上，综合丰富的研究阅历和聪明才智产生”顿悟“的结果。这对初学者而言恐怕还很难一窥门径，需要从基本功做起，经过大量科研实践训练后，才能有登堂入室之感。</p>
<p>在科研实践过程中，除了通过大量文献阅读了解历史，通过深入思考总结产生洞察力外，还有一项必不可少的工作，那就是主动开放的学术交流和合作意识。不同研究领域思想和成果交流碰撞，既为创新思想提供了新的来源，也为”类比“和”顿悟“提供了机会。了解一下历史就可以知晓，人工智能的提出，就是数学、计算机科学、控制论、信息论、脑科学等学科交叉融合的产物。而当红的深度学习的起源，1980年代的Parallel Distributed Processing （PDP），也是计算机科学、脑认知科学、心理学、生物学等领域研究者通力合作的产物。下面是1986年出版的名著《Parallel Distributed Processing: Explorations in the Microstructure of Cognition》第一卷的封面。</p>
<p><img src="https://pic2.zhimg.com/80/v2-a8d3f6e553f9f279cdafea5a3e218701_hd.jpg" alt></p>
<p>作者在前言中是这么讲他们的合作过程的，在最初长达六个月的时间里，它们每周见面交流两次讨论研究进展。</p>
<blockquote>
<p>We expected the project to take about six months. We began in January 1982 by bringing a number of our colleagues together to form a discussion group on these topics. During the first six months we met twice weekly and laid the foundation for most of the work presented in these volumes.</p>
</blockquote>
<p>而书中提供的PDP研究组的成员名单，40年后的今天仍让我惊叹其高度的跨机构、跨学科的交叉特点。所以，特别建议同学们在科研训练中，在专注研究问题的前提下，保持主动的学术交流意识，无论是听讲座报告，参加学术会议，还是选修课程，都有意识地扩宽学术交流的广度，不仅与小同行打成一片，更有看似八竿子打不着的研究领域的学术伙伴。随着研究经历的丰富，会越来越强烈地感受到，越是大跨度交叉的学术报告，越让你受到更大的启发，产生更多让自己兴奋的研究想法。</p>
<p><img src="https://pic2.zhimg.com/80/v2-404a752001300a69baabd40fb3d78b99_hd.jpg" alt></p>
<h1 id="初学者应该怎么做"><a href="#初学者应该怎么做" class="headerlink" title="初学者应该怎么做"></a>初学者应该怎么做</h1><p>与阅读论文、撰写论文、设计实验等环节相比，如何产生好的研究想法，是一个不太有章可循的环节，很难总结出固定的范式可供遵循。像小马过河，需要通过大量训练实践，来积累自己的研究经验。不过，对于初学者而言，仍然有几个简单可行的原则可以参考。</p>
<p><strong>一篇论文的可发表价值，取决于它与已有最直接相关工作间的Delta</strong>。我们大部分研究工作都是站在前人工作的基础上推进的。牛顿说：如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。在我看来，评判一篇论文研究想法的价值，就是看它站在了哪个或哪些巨人的肩膀上，以及在此基础上又向上走了多远。反过来，在准备开始一项研究工作之前，在形成研究想法的时候，也许要首先明确准备站在哪个巨人的肩膀上，以及计划通过什么方式走得更远。与已有最直接相关工作之间的Delta，决定了这个研究想法的价值有多大。</p>
<p><strong>兼顾摘果子和啃骨头</strong>。人们一般把比较容易想到的研究想法，叫做Low Hanging Fruit（低垂果实）。低垂果实容易摘，但同时摘的人也多，选择摘果子就容易受到想法撞车的困扰。例如，2018年以BERT为首的预训练语言模型取得重大突破，2019年中就出现大量改进工作，其中以跨模态预训练模型为例，短短几个月里<a href="http://arxiv.org上挂出了超过六个来自不同团队的图像与文本融合的预训练模型" target="_blank" rel="noopener">http://arxiv.org上挂出了超过六个来自不同团队的图像与文本融合的预训练模型</a> [4]。设身处地去想，进行跨模态预训练模型研究，就是一个比较容易想到的方向，你一定需要有预判能力，知道世界上肯定会有很多团队也同时开展这方面研究，这时你如果选择入场，就一定要做得更深入更有特色，有自己独特的贡献才行。相对而言，那些困难的问题，愿意碰的人就少，潜下心来啃硬骨头，也是不错的选择，当然同时就会面临做不出来的风险，或者做出来也得不到太多关注的风险。同学需要根据自身特点、经验和需求，兼顾摘果子和啃骨头两种类型的研究想法。</p>
<p><img src="https://pic1.zhimg.com/80/v2-d71aaf2b86116e3ea1e891bf9230a2c4_hd.jpg" alt></p>
<p><strong>注意多项研究工作的主题连贯性</strong>。同学的研究训练往往持续数年，需要注意前后多项研究工作的主题连贯性，保证内在逻辑统一。需要考虑，在个人简历上，在出国申请Personal Statement中，或者在各类评奖展示中，能够将这些研究成果汇总在一起，讲出自己开展这些研究工作的总目标、总设想。客观上讲，人工智能领域研究节奏很快，技术更新换代快，所以成果发表也倾向于小型化、短平快。我有商学院、社科的朋友，他们一项研究工作往往需要持续一年甚至数年以上；高性能计算、计算机网络方向的研究周期也相对较长。人工智能这种小步快跑的特点，决定了很多同学即使本科毕业时，也会有多篇论文发表，更不用说硕士生、博士生。在这种情况下，就格外需要在研究选题时，注意前后工作的连贯性和照应关系。几项研究工作放在一起，到底是互相割裂说不上话，还是在为一个统一的大目标而努力，格外反映研究的大局意识和布局能力。例如，下图是我们课题组涂存超博士2018年毕业时博士论文《面向社会计算的网络表示学习》的章节设置，整体来看就比《社会计算的若干重要问题研究》等没有内在关联的写法要更让人信服一些。当然，对于初学者而言，一开始就想清楚五年的研究计划，根本不可能。但想，还是不去想，结果还是不同的。</p>
<p><img src="https://pic1.zhimg.com/80/v2-9fbee2d16f9c05fa1cb1ec86a27d265c_hd.jpg" alt></p>
<p><strong>注意总结和把握研究动态和趋势，因时而动</strong>。2019年在知乎上有这样一个问题：”2019年在NLP领域，资源有限的个人/团队能做哪些有价值有希望的工作？“ 我当时的回答如下：</p>
<blockquote>
<p>我感觉，产业界开始集团化搞的问题，说明其中主要的开放性难题已经被解决得差不多了，如语言识别、人脸识别等，在过去20年里面都陆续被广泛商业应用。看最近的BERT、GPT-2，我理解更多的是将深度学习对大规模数据拟合的能力发挥到极致，在深度学习技术路线基本成熟的前提下，大公司有强大计算能力支持，自然可以数据用得更多，模型做得更大，效果拟合更好。<br>成熟高新技术进入商用竞争，就大致会符合摩尔定律的发展规律。现在BERT等训练看似遥不可及，但随着计算能力等因素的发展普及，说不定再过几年，人人都能轻易训练BERT和GPT-2，大家又会在同一个起跑线上，把目光转移到下一个挑战性难题上。<br>所以不如提前考虑，哪些问题是纯数据驱动技术无法解决的。NLP和AI中的困难任务，如常识和知识推理，复杂语境和跨模态理解，可解释智能，都还没有可行的解决方案，我个人也不看好数据驱动方法能够彻底解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些正是有远见的研究者们应该开始关注的方向。</p>
</blockquote>
<p>需要看到，不同时期的研究动态和趋势不同。把握这些动态和趋势，就能够做出研究社区感兴趣的成果。不然的话，即使研究成果没有变化，只是简单早几年或晚几年投稿，结果也会大不相同。例如，2013年word2vec发表，在2014-2016年之间开展词表示学习研究，就相对比较容易得到ACL、EMNLP等会议的录用；但到了2017-2018年，ACL等会议上的词表示学习的相关工作就比较少见了。</p>
<h1 id="最后的补充"><a href="#最后的补充" class="headerlink" title="最后的补充"></a>最后的补充</h1><p>这篇短文，主要是希望面向初学者，介绍一些求新过程中的经验和注意事项，希望大家少走一些弯路。但阅读文献，深入思考，接收拒稿不断改进的苦，该吃的还是要吃。学术研究和论文发表，对个人而言也许意味着高薪资和奖学金，但其最终的目的还是真正的推动学科的发展。所以，要做经得起考验的学术研究，关键就在”真“与”新“，需要我们始终恪守和孜孜以求。</p>
<p>著名历史学家、清华校友何炳棣先生曾在自传《读史阅世六十年》中提及著名数学家林家翘的一句嘱咐：“要紧的是不管搞哪一行，千万不要做第二等的题目。” 具体到每个领域，什么是一等的题目本身见仁见智，其实更指向内心“求真”的态度。</p>
<p>参考文献<br>[1] <a href="https://paperswithcode.com/" target="_blank" rel="noopener">https://paperswithcode.com/</a> &amp; <a href="http://nlpprogress.com/" target="_blank" rel="noopener">http://nlpprogress.com/</a></p>
<p>[2] Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, Maosong Sun. Neural Relation Extraction with Selective Attention over Instances. The 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016).</p>
<p>[3] Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu. ERNIE: Enhanced Language Representation with Informative Entities. The 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019).</p>
<p>[4] <a href="https://github.com/thunlp/PLMpapers" target="_blank" rel="noopener">https://github.com/thunlp/PLMpapers</a></p>
]]></content>
  </entry>
  <entry>
    <title>Keyphrase Generation任务综述</title>
    <url>/2019/12/02/Keyphrase-Generation%E4%BB%BB%E5%8A%A1%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="任务简介"><a href="#任务简介" class="headerlink" title="任务简介"></a>任务简介</h1><p>A <strong>keyphrase</strong> or keyword is a piece of short, summative content that expresses the main semantic meaning of a longer text. The typical use of a keyphrase or keyword is in scientific publications to provide the core information of a paper. </p><a id="more"></a>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><ul>
<li>F1@5</li>
<li>F1@10</li>
</ul>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><ul>
<li>KP20K</li>
<li>SemEval</li>
<li>NUS</li>
<li>Krapivin</li>
<li>Inspec</li>
</ul>
<h1 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h1><ul>
<li>2019-06-13 <strong>Title-Guided Encoding for Keyphrase Generation</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="center">Dataset</th>
<th align="center">F1@5</th>
<th align="center">F1@10</th>
</tr>
</thead>
<tbody><tr>
<td align="center">KP20K</td>
<td align="center">0.372</td>
<td align="center">0.315</td>
</tr>
</tbody></table>
<h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><ul>
<li><p><strong>Deep Keyphrase Generation</strong>. Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky, Yu Chi. ACL 2017. <a href="https://aclweb.org/anthology/papers/P/P17/P17-1054/" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/memray/seq2seq-keyphrase" target="_blank" rel="noopener">[code]</a><br>Keyphrase Generation的第一篇paper，主要框架是 seq2seq + copy.</p>
</li>
<li><p><strong>Semi-Supervised Learning for Neural Keyphrase Generation</strong>. Hai Ye, Lu Wang. EMNLP 2018. <a href="https://aclweb.org/anthology/papers/D/D18/D18-1447/" target="_blank" rel="noopener">[pdf]</a><br>解决资源不足问题，提出两个策略：<br>（1）微调，通过keyphrase extraction方式人为构造大量数据预训练模型，再通过已有数据微调；<br>（2）多任务框架，生成keyphrase的同时生成title。</p>
</li>
<li><p><strong>Title-Guided Encoding for Keyphrase Generation</strong>. Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, Michael R. Lyu1. AAAI 2019. <a href="https://arxiv.org/abs/1808.08575" target="_blank" rel="noopener">[pdf]</a><br>本文认为标题包含了文章的主要信息，通过标题来引导摘要的建模已提升模型性能。</p>
</li>
<li><p><strong>Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</strong>. Hou Pong Chan, Wang Chen, Lu Wang, Irwin King. ACL 2019. <a href="https://arxiv.org/abs/1906.04106" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/kenchan0226/keyphrase-generation-rl" target="_blank" rel="noopener">[code]</a></p>
</li>
</ul>
<ul>
<li><strong>Topic-Aware Neural Keyphrase Generation for Social Media Language. Yue Wang</strong>. Jing Li, Hou Pong Chan, Irwin King, Michael R. Lyu, Shuming Shi. ACL 2019. <a href="https://arxiv.org/abs/1906.03889" target="_blank" rel="noopener">[pdf]</a> <a href="https://github.com/yuewang-cuhk/TAKG" target="_blank" rel="noopener">[code]</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【shell】截断字符串</title>
    <url>/2019/11/29/%E3%80%90shell%E3%80%91%E6%88%AA%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/fengbohello/p/5954895.html" target="_blank" rel="noopener">https://www.cnblogs.com/fengbohello/p/5954895.html</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">line='abcd&lt;SEG&gt;efg'</span><br><span class="line">newline=$&#123;line#*&lt;SEG&gt;&#125;</span><br><span class="line">echo $newline # efg</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】判断字符串是否包含子串</title>
    <url>/2019/11/29/%E3%80%90shell%E3%80%91%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/iamlihongwei/article/details/59484029" target="_blank" rel="noopener">https://blog.csdn.net/iamlihongwei/article/details/59484029</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [[ $line =~ "&lt;BEGIN&gt;" ]] </span><br><span class="line">then</span><br><span class="line">	echo "包含&lt;BEGIN&gt;"</span><br><span class="line">elif [[ $line =~ "&lt;SEG&gt;" ]]</span><br><span class="line">then</span><br><span class="line">	echo "包含&lt;SEG&gt;"</span><br><span class="line">else</span><br><span class="line">	echo "都不包含"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>使用python发送免费短信</title>
    <url>/2019/11/27/%E4%BD%BF%E7%94%A8python%E5%8F%91%E9%80%81%E5%85%8D%E8%B4%B9%E7%9F%AD%E4%BF%A1/</url>
    <content><![CDATA[<p>首先在 <a href="https://www.twilio.com/" target="_blank" rel="noopener">twilio</a> 上注册帐号，并申请一个 twilio 手机号，并认证自己的手机号，twilio只能给认证过的手机号发送短信。</p><p>使用 python 发送短信</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> twilio.rest <span class="keyword">import</span> Client</span><br><span class="line"></span><br><span class="line">account_sid = &lt;your account sid&gt;</span><br><span class="line">auth_token = &lt;your auth token&gt;</span><br><span class="line">client = Client(account_sid, auth_token)</span><br><span class="line"></span><br><span class="line">message=client.messages.create(</span><br><span class="line">	from_=&lt;your twilio phone num&gt;,</span><br><span class="line">	body=&lt;your message&gt;,</span><br><span class="line">	to=&lt;your phone num&gt;</span><br><span class="line">)</span><br><span class="line">print(message.sid)</span><br></pre></td></tr></table></figure><a id="more"></a>



<p>注：试用版免费次数有限。</p>
]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>【论文笔记】Context-Aware Learning for Neural Machine Translation</title>
    <url>/2019/11/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Context-Aware-Learning-for-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Context-Aware Learning for Neural Machine Translation</strong>. Sébastien Jean, Kyunghyun Cho. ArXiv 1903. <a href="https://arxiv.org/pdf/1903.04715.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文提出一个正则化项，鼓励模型利用上下文信息，从而提高篇章翻译结果。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>人们认为使用上下文可以提高篇章翻译，也就是使用上下文信息后译文翻译概率会更高。</p><a id="more"></a>


<p><img src="/images/context-aware1.png" alt></p>
<p>这个不等式在token、sentence、data三个层次上都成立</p>
<p><img src="/images/context-aware2.png" alt></p>
<p>本文在损失函数中加入一个正则化项，正则化项由三个max margin组成。</p>
<p><img src="/images/context-aware3.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="/images/context-aware4.png" alt></p>
<p>（a）句子级别翻译，不利用上下信息</p>
<p>（b）利用随机上下文，随机上下文的期望跟不利用上下文的期望一样，所以使用上下文没有提升</p>
<p>（c）利用前文上下文，对比随机上下文有提升，并且跟没有利用上下文相差0.4</p>
<p>（d）鼓励利用前文上下文，跟没有利用上下文相差3.74，并且比（c）有提升</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Pretrained Language Models for Document-Level Neural Machine Translation</title>
    <url>/2019/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Pretrained-Language-Models-for-Document-Level-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Pretrained Language Models for Document-Level Neural Machine Translation</strong>. Liangyou Li, Xin Jiang, Qun Liu. ArXiv. <a href="https://arxiv.org/pdf/1911.03110.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>现有篇章翻译工作大都只能有限的上下文（前面3句话），当利用更长上下文时，由于训练不稳定模型效果反而下降。理论上来说更长的上下文可以提供更多信息，更有助于翻译。本文就是希望能够在篇章翻译中利用更长的上下文。</p><a id="more"></a>

<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="BERT初始化"><a href="#BERT初始化" class="headerlink" title="BERT初始化"></a>BERT初始化</h2><p>现有有些篇章翻译工作先利用大量平行句对预训练（有些只有利用篇章语料的平行句对预训练），然后再利用平行篇章语料微调。本文不再使用平行句对预训练，而是使用别人训练好的BERT来初始化模型参数。（BERT是在大量单语篇章语料上训练得到的）</p>
<h2 id="利用上下文"><a href="#利用上下文" class="headerlink" title="利用上下文"></a>利用上下文</h2><p>本文使用的上下文为前面512个词。将上下文和当前句子拼接起来，中间有个分隔符，但是如果直接使用Encoder对拼接后的句子进行编码，生成的译文反而更差（训练不稳定）。</p>
<p><img src="/images/mlmdoc.png" alt></p>
<p>本文提出了三个改进方法：</p>
<ul>
<li><p><strong>Segment Embeddings</strong>:<br>用来标记每个词是属于当前要翻译句子，还是属于上下文。</p>
</li>
<li><p><strong>Reverse Position Embeddings</strong>:<br>先对当前要翻译句子进行编号，再对上下文进行编号。</p>
</li>
<li><p><strong>Context Masks</strong>:<br>经过编码器后，当前句子已经包含了上下文信息，对上下文的隐状态加 mask，使得解码器更加关注当前句子。（不加mask，训练不稳定）</p>
</li>
</ul>
<h2 id="多任务"><a href="#多任务" class="headerlink" title="多任务"></a>多任务</h2><p>本文引入了Mask Language Model</p>
<p><img src="/images/mlmdoc1.png" alt></p>
<p>X: 源端当前句子</p>
<p>C: 源端上下文</p>
<p>Y: 目标端当前句子</p>
<p>S: X 和 C 的拼接</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><img src="/images/mlmdoc2.png" alt></p>
<p>可以训12层encoder还是比较 NB 的。<br><font color="#FF0000">我认为作者可以补充一个只加BERT的实验结果。</font></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础】Dropout</title>
    <url>/2019/11/15/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E3%80%91Dropout/</url>
    <content><![CDATA[<p>** Improving neural networks by preventing co-adaptation of feature detectors**. Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R. Salakhutdinov. arXiv 1207.0580. <a href="https://arxiv.org/abs/1207.0580" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="一些博客"><a href="#一些博客" class="headerlink" title="一些博客"></a>一些博客</h1><ul>
<li><a href="https://www.zhihu.com/question/61751133" target="_blank" rel="noopener">神经网络Dropout层中为什么dropout后还需要进行rescale？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/66337970" target="_blank" rel="noopener">Dropout的前世与今生</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【git 使用】分支合并</title>
    <url>/2019/11/12/%E3%80%90git-%E4%BD%BF%E7%94%A8%E3%80%91%E5%88%86%E6%94%AF%E5%90%88%E5%B9%B6/</url>
    <content><![CDATA[<ul>
<li>master发生改变，同步到feature branch</li>
</ul><p>merge master into feature branch</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout &lt;feature branch&gt;</span><br><span class="line">git merge master</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>ArXiv 论文 2019/11/2-2019/11/8</title>
    <url>/2019/11/10/ArXiv-%E8%AE%BA%E6%96%87-2019-11-2-2019-11-8/</url>
    <content><![CDATA[<ul>
<li><a href="https://arxiv.org/abs/1911.00492" target="_blank" rel="noopener">Reasoning Over Paths via Knowledge Base Completion</a></li>
<li><a href="https://arxiv.org/abs/1911.00069" target="_blank" rel="noopener">Neural Cross-Lingual Relation Extraction Based on Bilingual Word Embedding Mapping</a></li>
<li><a href="https://arxiv.org/abs/1911.00133" target="_blank" rel="noopener">Dreaddit: A Reddit Dataset for Stress Analysis in Social Media</a></li>
<li><a href="https://arxiv.org/abs/1911.00176" target="_blank" rel="noopener"><strong>Sequence Modeling with Unconstrained Generation Order</strong></a></li>
<li><a href="https://arxiv.org/abs/1911.00317" target="_blank" rel="noopener">On the Linguistic Representational Power of Neural Machine Translation Models</a></li>
<li><a href="https://arxiv.org/abs/1911.00473" target="_blank" rel="noopener">BERT Goes to Law School: Quantifying the Competitive Advantage of Access to Large Legal Corpora in Contract Understanding</a><a id="more"></a></li>
<li><a href="https://arxiv.org/abs/1911.00484" target="_blank" rel="noopener">Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents</a></li>
<li><a href="https://arxiv.org/abs/1911.00225" target="_blank" rel="noopener">When Choosing Plausible Alternatives, Clever Hans can be Clever</a></li>
<li><a href="https://arxiv.org/abs/1911.00269" target="_blank" rel="noopener">A Robust Data-Driven Approach for Dialogue State Tracking of Unseen Slot Values</a></li>
<li><a href="https://arxiv.org/abs/1911.00274" target="_blank" rel="noopener">Kernelized Bayesian Softmax for Text Generation</a></li>
<li><a href="https://arxiv.org/abs/1911.00359" target="_blank" rel="noopener">CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data</a></li>
</ul>
]]></content>
      <categories>
        <category>arxiv</category>
      </categories>
      <tags>
        <tag>ArXiv</tag>
      </tags>
  </entry>
  <entry>
    <title>【git 使用】clone、branch、add、commit、push</title>
    <url>/2019/11/08/%E3%80%90git-%E4%BD%BF%E7%94%A8%E3%80%91clone%E3%80%81branch%E3%80%81add%E3%80%81commit%E3%80%81push/</url>
    <content><![CDATA[<h1 id="克隆仓库"><a href="#克隆仓库" class="headerlink" title="克隆仓库"></a>克隆仓库</h1><ul>
<li>普通</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@xxx.git</span><br></pre></td></tr></table></figure><ul>
<li>指定branch</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@xxx.git -b &lt;branchname&gt;</span><br></pre></td></tr></table></figure><h1 id="提交修改"><a href="#提交修改" class="headerlink" title="提交修改"></a>提交修改</h1><ul>
<li>提交某个文件</li>
</ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add &lt;path to file&gt;</span><br><span class="line">git commit -m '&lt;message&gt;'</span><br><span class="line">git push origin &lt;branchname&gt;</span><br></pre></td></tr></table></figure><a id="more"></a>








<ul>
<li>提交多个文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add --all</span><br><span class="line">git commit -m '&lt;message&gt;'</span><br><span class="line">git push origin &lt;branchname&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>【shell】alias设置指令别名</title>
    <url>/2019/11/08/%E3%80%90shell%E3%80%91alias%E8%AE%BE%E7%BD%AE%E6%8C%87%E4%BB%A4%E5%88%AB%E5%90%8D/</url>
    <content><![CDATA[<p>alias 可以用来将一些较长的指令进行简化，使用alias时，用户必须使用单引号’’将原来的命令引起来，防止特殊字符导致错误。</p><h1 id="alias基本使用"><a href="#alias基本使用" class="headerlink" title="alias基本使用"></a>alias基本使用</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias 新指令=‘原指令 -选项/参数’</span><br></pre></td></tr></table></figure><p>如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias myscp='scp admin@192.168.72.77'</span><br></pre></td></tr></table></figure><h1 id="查看永久已设置别名"><a href="#查看永久已设置别名" class="headerlink" title="查看永久已设置别名"></a>查看永久已设置别名</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alias -p</span><br></pre></td></tr></table></figure><a id="more"></a>







<h1 id="设置永久别名"><a href="#设置永久别名" class="headerlink" title="设置永久别名"></a>设置永久别名</h1><p>修改<code>~/.bashrc</code>文件</p>
<p>参考：<a href="https://man.linuxde.net/alias" target="_blank" rel="noopener">https://man.linuxde.net/alias</a></p>
]]></content>
      <categories>
        <category>技术杂谈</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>alias</tag>
      </tags>
  </entry>
  <entry>
    <title>ArXiv 论文 2019/10/28-2019/11/1</title>
    <url>/2019/11/02/ArXiv-%E8%AE%BA%E6%96%87-2019-10-28-2019-11-1/</url>
    <content><![CDATA[<ul>
<li><a href="https://arxiv.org/abs/1910.13461" target="_blank" rel="noopener">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></li>
<li><a href="https://arxiv.org/abs/1910.14659" target="_blank" rel="noopener">Pseudolikelihood Reranking with Masked Language Models</a></li>
<li><a href="https://arxiv.org/abs/1910.14549" target="_blank" rel="noopener">Positional Attention-based Frame Identification with BERT: A Deep Learning Approach to Target Disambiguation and Semantic Frame Selection</a></li>
<li><a href="https://arxiv.org/abs/1910.14192" target="_blank" rel="noopener">Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</a></li>
<li><a href="https://arxiv.org/abs/1910.14176" target="_blank" rel="noopener">Predicting Discourse Structure using Distant Supervision from Sentiment</a><a id="more"></a></li>
<li><a href="https://arxiv.org/abs/1910.14142" target="_blank" rel="noopener">Discourse-Aware Neural Extractive Model for Text Summarization</a></li>
<li><a href="https://arxiv.org/abs/1910.14075" target="_blank" rel="noopener">Fill in the Blanks: Imputing Missing Sentences for Larger-Context Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.14613" target="_blank" rel="noopener">Neural Assistant: Joint Action Prediction, Response Generation, and Latent Knowledge Reasoning</a></li>
<li><a href="https://arxiv.org/abs/1910.14208" target="_blank" rel="noopener">Hidden State Guidance: Improving Image Captioning using An Image Conditioned Autoencoder</a></li>
<li><a href="https://arxiv.org/abs/1910.13890" target="_blank" rel="noopener">A Latent Morphology Model for Open-Vocabulary Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.13794" target="_blank" rel="noopener">Let Me Know What to Ask: Interrogative-Word-Aware Question Generation</a></li>
<li><a href="https://arxiv.org/abs/1910.13466" target="_blank" rel="noopener">Ordered Memory</a></li>
<li><a href="https://arxiv.org/abs/1910.13106" target="_blank" rel="noopener">Incorporating Interlocutor-Aware Context into Response Generation on Multi-Party Chatbots</a></li>
<li><a href="https://arxiv.org/abs/1910.13267" target="_blank" rel="noopener">BPE-Dropout: Simple and Effective Subword Regularization</a></li>
<li><a href="https://arxiv.org/abs/1910.13294" target="_blank" rel="noopener">Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control</a></li>
<li><a href="https://arxiv.org/abs/1910.13437" target="_blank" rel="noopener">An Empirical Study of Generation Order for Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1910.12708" target="_blank" rel="noopener">Evaluating Lottery Tickets Under Distributional Shifts</a></li>
<li><a href="https://arxiv.org/abs/1910.12702" target="_blank" rel="noopener">Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect Morphological Modeling</a></li>
<li><a href="https://arxiv.org/abs/1910.12698" target="_blank" rel="noopener">Adaptive Ensembling: Unsupervised Domain Adaptation for Political Document Analysis</a></li>
<li><a href="https://arxiv.org/abs/1910.12527" target="_blank" rel="noopener">RPM-Oriented Query Rewriting Framework for E-commerce Keyword-Based Sponsored Search</a></li>
<li><a href="https://arxiv.org/abs/1910.12391" target="_blank" rel="noopener">What does BERT Learn from Multiple-Choice Reading Comprehension Datasets?</a></li>
<li><a href="https://arxiv.org/abs/1910.12197" target="_blank" rel="noopener">Look-up and Adapt: A One-shot Semantic Parser</a></li>
<li><a href="https://arxiv.org/abs/1910.12196" target="_blank" rel="noopener">Open the Boxes of Words: Incorporating Sememes into Textual Adversarial Attack</a></li>
<li><a href="https://arxiv.org/abs/1910.11966" target="_blank" rel="noopener">Yall should read this! Identifying Plurality in Second-Person Personal Pronouns in English Texts</a></li>
<li><a href="https://arxiv.org/abs/1910.12038" target="_blank" rel="noopener">Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word Embeddings and Layered Attention</a></li>
<li><a href="https://arxiv.org/abs/1910.11959" target="_blank" rel="noopener">FineText: Text Classification via Attention-based Language Model Fine-tuning</a></li>
<li><a href="https://arxiv.org/abs/1910.12094" target="_blank" rel="noopener">Meta Learning for End-to-End Low-Resource Speech Recognition</a></li>
<li><a href="https://arxiv.org/abs/1910.11491" target="_blank" rel="noopener">Attention Optimization for Abstractive Document Summarization</a></li>
<li><a href="https://arxiv.org/abs/1910.11471" target="_blank" rel="noopener">Machine Translation from Natural Language to Code using Long-Short Term Memory</a></li>
<li><a href="https://arxiv.org/abs/1910.11470" target="_blank" rel="noopener">A Survey on Recent Advances in Named Entity Recognition from Deep Learning models</a></li>
<li><a href="https://arxiv.org/abs/1910.11411" target="_blank" rel="noopener">Multi-Document Summarization with Determinantal Point Processes and Contextualized Representations</a></li>
<li><a href="https://arxiv.org/abs/1910.11399" target="_blank" rel="noopener">Comparison of Quality Indicators in User-generated Content Using Social Media and Scholarly Text</a></li>
<li><a href="https://arxiv.org/abs/1910.11494" target="_blank" rel="noopener">Fast and Accurate Knowledge-Aware Document Representation Enhancement for News Recommendations</a></li>
<li><a href="https://arxiv.org/abs/1910.11455" target="_blank" rel="noopener">Recognizing long-form speech using streaming end-to-end models</a></li>
</ul>
]]></content>
      <categories>
        <category>arxiv</category>
      </categories>
      <tags>
        <tag>ArXiv</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Discourse-Aware Neural Extractive Model for Text Summarization</title>
    <url>/2019/11/02/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Discourse-Aware-Neural-Extractive-Model-for-Text-Summarization/</url>
    <content><![CDATA[<p><strong>Discourse-Aware Neural Extractive Model for Text Summarization</strong>. Jiacheng Xu, Zhe Gan, Yu Cheng, Jingjing Liu. ArXiv 1910.14142.<a href="https://arxiv.org/pdf/1910.14142.pdf" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>作者分析认为现有抽取式文档摘要存在以下两个不足：</p><a id="more"></a>

<ul>
<li>抽取式文档摘要都是以句子级别进行抽取，导致结果包含冗余或者没有用的信息。</li>
<li>BERT常被SOTA文档摘要模型用在文档编码器，但是BERT是再句对上预训练的，不能很好捕捉长距离的句间依赖关系。</li>
</ul>
<p>针对以上两个不足，作者提出了两个解决方法：</p>
<ul>
<li>按EDU进行抽取 （EDU是RST中的基本单元，具体可以去了解discourse parsing）</li>
<li>构造RST Graph和Coreference Graph建模长距离句间依赖关系。</li>
</ul>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>Discourse Segmentation: sequence to EDU</p>
<p>Discourse Parsing: EDU to RST tree</p>
<h2 id="RST-Graph"><a href="#RST-Graph" class="headerlink" title="RST Graph"></a>RST Graph</h2><p>通过篇章分析，可以在篇章上构造得到一棵树，树的叶子节点是EDU，树上的边代表的是对应子节点的重要性程度，N代表主要，S代表次要，可以认为S是N的补充。相邻两个子节点可以有三种关系，N-N,N-S,S-N。</p>
<p>作者提出假设：S依赖N,所以存在一条路径从S指向N；如果两个节点都是N，就认为是右N依赖做N。</p>
<p>根据这个假设，可以将RST discourse tree转成成RST dependence graph。</p>
<p><img src="/images/discbert1.jpg" alt></p>
<p>注：论文原图中没有标N和S，为了好理解我标了N和S。</p>
<p>如果存在一条从第i个EDU指向第j个EDU的路径，则设GR[i][j]=1，否则为0,这样就可以将RST Graph转化成GR矩阵。</p>
<p><img src="/images/discbert2.jpg" alt></p>
<h2 id="Coreference-Graph"><a href="#Coreference-Graph" class="headerlink" title="Coreference Graph"></a>Coreference Graph</h2><p>通过斯坦福的CoreNLP工具，可以得到多个共指簇（coreference clusters），每个簇中的EDU都指向同一个实体。指向同一个实体的EDU存在联系，所以同一个簇中的所有EDU之间（包括自己跟自己）存在一条边。基于这个原则，作者设计一个构造coreference graph的算法，遍历所有簇，簇中每个EDU之间存在一个边。也就得到了共指矩阵GC。</p>
<p><img src="/images/discbert3.jpg" alt></p>
<h2 id="模型框架"><a href="#模型框架" class="headerlink" title="模型框架"></a>模型框架</h2><p><img src="/images/discbert4.jpg" alt></p>
<p>首先使用BERT编码整个篇章，使用BERT得到的隐状态表示，每个EDU内部做self-attention得到EDU的表示，由得到的EDU表示和两个矩阵表示GR和GC，做GCN得到EDU新的表示，通过MLP预测EDU是否被抽取出来做EDU（0-1序列标注）。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在两个数据集上进行验证，并得到了SOTA结果。</p>
<p><img src="/images/discbert5.jpg" alt></p>
<p><img src="/images/discbert6.jpg" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Discourse Structure</tag>
        <tag>Extractive</tag>
        <tag>Summarization</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Document-level Neural Machine Translation with Inter-Sentence Attention</title>
    <url>/2019/11/02/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Document-level-Neural-Machine-Translation-with-Inter-Sentence-Attention/</url>
    <content><![CDATA[<p><strong>Document-level Neural Machine Translation with Inter-Sentence Attention</strong>. Shu Jiang, Rui Wang, Zuchao Li, Masao Utiyama, Kehai Chen, Eiichiro Sumita, Hai Zhao, Bao-liang Lu. ArXiv 1910.14528. <a href="https://arxiv.org/pdf/1910.14528.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文认为大部分篇章翻译只是引入大体的篇章上下文信息，但不是所有的上下文信息都对当前句子翻译有效，本文希望对上下文信息进行筛选。于是本文提出一个associated memory network（AMN）考虑句间关系，建模更加相关的上下文。(<em>其实 SAN 和 QCN 都有对上下文进行筛选</em>)</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><img src="/images/camn.jpg" alt></p>
<p>（1）使用RNN对previous sentences（cj）进行编码，得到每个词的隐状态表示<font color="#FF0000">(<em>不是很懂为什么要用RNN，不直接使用transformer，并且当前句子x也不用像c一样使用RNN编码</em>)</font></p>
<p>（2）MultiHead Self-Attention更新每个句子的表示<br><img src="/images/camn1.jpg" alt><br><img src="/images/camn2.jpg" alt></p>
<p>（3）当前句子x的每个词和前面每个句子cj中的每个词算一个相似度分数<br><img src="/images/camn3.jpg" alt></p>
<p>（4）对相似性分数按行做softmax作为最终的相似性分数<br><img src="/images/camn4.jpg" alt></p>
<p>（5）得到句子级别上下文表示<br><img src="/images/camn5.jpg" alt></p>
<p>（6）建模每个句子的权重<br><img src="/images/camn6.jpg" alt></p>
<p>（7）得到篇章级别上下文<br><img src="/images/camn7.jpg" alt></p>
<p>（8）在transformer encoder中融入篇章级别上下文信息<br><img src="/images/camn8.jpg" alt><br><img src="/images/camn9.jpg" alt></p>
<p><font color="#FF0000">整体上来说，这种方法略显粗暴。</font></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者在TED Talks, Subtitles, News三个数据集上验证了自己的模型有效性。</p>
<p><img src="/images/camn10.jpg" alt></p>
<font color="#FF0000">
  我认为实验还是存在一些不足：（1）没有跟SAN、QCN等工作进行对比（2）按照HAN公开代码，HAN是没有做BPE的，但是本文有做BPE，而本文中报的结果是HAN中报的没有做BPE的结果。
</font>]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>NMT</tag>
        <tag>Document NMT</tag>
        <tag>Inter-Sentence</tag>
      </tags>
  </entry>
  <entry>
    <title>Accepted Papers List</title>
    <url>/2019/11/01/Accepted-Papers-List/</url>
    <content><![CDATA[<h1 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h1><ul>
<li><a href="">AAAI</a></li>
<li><a href="https://openreview.net/group?id=ICLR.cc/2020/Conference" target="_blank" rel="noopener">ICLR</a></li>
</ul>
<h1 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h1><ul>
<li><a href="https://dblp.org/db/conf/aaai/aaai2019" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2019/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2019.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://www.aclweb.org/anthology/events/emnlp-2019/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://openreview.net/group?id=ICLR.cc/2019/Conference" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai19.org/accepted-papers.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2019/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2019/Schedule?type=Poster" target="_blank" rel="noopener">NeurIPS</a></li>
</ul>
<a id="more"></a>

<h1 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h1><ul>
<li><a href="https://dblp.org/db/conf/aaai/aaai2018" target="_blank" rel="noopener">AAAI</a></li>
<li><a href="https://aclweb.org/anthology/events/acl-2018/" target="_blank" rel="noopener">ACL</a></li>
<li><a href="http://openaccess.thecvf.com/CVPR2018.py" target="_blank" rel="noopener">CVPR</a></li>
<li><a href="https://aclweb.org/anthology/events/emnlp-2018/" target="_blank" rel="noopener">EMNLP</a></li>
<li><a href="https://iclr.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICLR</a></li>
<li><a href="https://icml.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">ICML</a></li>
<li><a href="https://www.ijcai-18.org/accepted-papers/index.html" target="_blank" rel="noopener">IJCAI</a></li>
<li><a href="https://aclweb.org/anthology/events/naacl-2018/" target="_blank" rel="noopener">NAACL</a></li>
<li><a href="https://nips.cc/Conferences/2018/Schedule?type=Poster" target="_blank" rel="noopener">NeurIPS</a></li>
</ul>
]]></content>
      <categories>
        <category>论文列表</category>
      </categories>
      <tags>
        <tag>AAAI</tag>
        <tag>Accepted Papers</tag>
        <tag>ACL</tag>
        <tag>CVPR</tag>
        <tag>EMNLP</tag>
        <tag>ICLR</tag>
        <tag>ICML</tag>
        <tag>IJCAI</tag>
        <tag>NAACL</tag>
        <tag>NIPS</tag>
      </tags>
  </entry>
  <entry>
    <title>公开课推荐</title>
    <url>/2019/10/31/%E5%85%AC%E5%BC%80%E8%AF%BE%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h1 id="机器学习（斯坦福大学）"><a href="#机器学习（斯坦福大学）" class="headerlink" title="机器学习（斯坦福大学）"></a>机器学习（斯坦福大学）</h1><p>机器学习是一门研究在非特定编程条件下让计算机采取行动的学科。最近二十年，机器学习为我们带来了自动驾驶汽车、实用的语音识别、高效的网络搜索，让我们对人类基因的解读能力大大提高。当今机器学习技术已经非常普遍，您很可能在毫无察觉情况下每天使用几十次。许多研究者还认为机器学习是人工智能（AI）取得进展的最有效途径。</p><a id="more"></a>
<p>本课程将广泛介绍机器学习、数据挖掘和统计模式识别。相关主题包括：(i) 监督式学习（参数和非参数算法、支持向量机、核函数和神经网络）。(ii) 无监督学习（集群、降维、推荐系统和深度学习）。(iii) 机器学习实例（偏见/方差理论；机器学习和AI领域的创新）。课程将引用很多案例和应用，您还需要学习如何在不同领域应用学习算法，例如智能机器人（感知和控制）、文本理解（网络搜索和垃圾邮件过滤）、计算机视觉、医学信息学、音频、数据库挖掘等领域。</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera</a></li>
<li><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="noopener">网易公开课</a></li>
</ul>
<hr>
<h1 id="CS231n（斯坦福大学）"><a href="#CS231n（斯坦福大学）" class="headerlink" title="CS231n（斯坦福大学）"></a>CS231n（斯坦福大学）</h1><p>计算机视觉已经在我们的社会中无处不在，在搜索，图像理解，应用程序，测绘，医药，无人驾驶飞机和自动驾驶汽车中的应用。许多这些应用程序的核心是视觉识别任务，如图像分类，定位和检测。神经网络（又名“深度学习”）方法的最新发展极大地提高了这些最先进的视觉识别系统的性能。本课程深入探讨深度学习架构的细节，重点是学习这些任务的端到端模型，尤其是图像分类。在为期10周的课程中，学生将学习实施，训练和调试自己的神经网络，并获得对计算机视觉尖端研究的详细了解。最后的任务将涉及培训一个数百万参数卷积神经网络，并将其应用于最大的图像分类数据集（ImageNet）。我们将着重教授如何设置图像识别问题，学习算法（例如反向传播），用于训练和微调网络的实际工程技巧，并引导学生通过实践任务和最终课程项目。本课程的大部分背景和材料都将从ImageNet挑战中吸取。</p>
<h2 id="链接-1"><a href="#链接-1" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS20SI（斯坦福大学）"><a href="#CS20SI（斯坦福大学）" class="headerlink" title="CS20SI（斯坦福大学）"></a>CS20SI（斯坦福大学）</h1><p>Tensorflow是Google Brain研究人员开发的一个功能强大的机器学习开源软件库。它具有许多预建功能，可以简化构建不同神经网络的任务。 Tensorflow允许在不同计算机之间分配计算，以及在一台机器中分配多个CPU和GPU。 TensorFlow提供了一个Python API，以及一个较少记录的C ++ API。对于本课程，我们将使用Python。</p>
<p>本课程将涵盖深入学习研究的Tensorflow图书馆的基本原理和当代用法。帮助学生理解Tensorflow的图形计算模型，探索其提供的功能，并学习如何构建和构建最适合深度学习项目的模型。通过本课程，学生将使用Tensorflow建立不同复杂度的模型，从简单的线性/逻辑回归到卷积神经网络和带有LSTM的递归神经网络，以解决词嵌入，翻译，光学字符识别等任务。学生还将学习最佳实践来构建模型并管理研究实验。</p>
<h2 id="链接-2"><a href="#链接-2" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://web.stanford.edu/class/cs20si/" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<hr>
<h1 id="CS224d（斯坦福大学）"><a href="#CS224d（斯坦福大学）" class="headerlink" title="CS224d（斯坦福大学）"></a>CS224d（斯坦福大学）</h1><p>自然语言处理（NLP）是信息时代最重要的技术之一。理解复杂的语言也是人工智能的重要组成部分。 NLP的应用无处不在，因为人们用语言沟通大多数事物：网络搜索，广告，电子邮件，客户服务，语言翻译，放射学报告等等。NLP应用背后有大量的基础任务和机器学习模型。最近，深度学习方法在许多不同的NLP任务中获得了非常高的性能。这些模型通常可以通过单一的端到端模型进行培训，而且不需要传统的，特定于任务的特征工程。在这个冬季的季度课程中，学生将学习实施，培训，调试，可视化和创造自己的神经网络模型。本课程深入介绍了深入学习NLP的前沿研究。在模型方面，我们将介绍词向量表示，基于窗口的神经网络，递归神经网络，长期 - 短期记忆模型，递归神经网络，卷积神经网络以及一些涉及存储器组件的最新模型。通过讲座和编程作业，学生将学习使神经网络适应实际问题的必要工程技巧。</p>
<h2 id="链接-3"><a href="#链接-3" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-" target="_blank" rel="noopener">课程主页</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6" target="_blank" rel="noopener">YouTube</a></li>
</ul>
]]></content>
      <categories>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>CS231n</tag>
        <tag>CS20SI</tag>
        <tag>CS224d</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Hierarchical-Modeling-of-Global-Context-for-Document-Level-Neural-Machine-Translation/</url>
    <content><![CDATA[<p><strong>Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation</strong>. Xin Tan, Longyin Zhang, Deyi Xiong, Guodong Zhou. EMNLP 2019. <a href="https://www.aclweb.org/anthology/D19-1168.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文觉得现有篇章翻译工作基于pre-context的方法存在两个不足：</p>
<p>（1）只利用一边（one-sidedness）的上下文可能还不够</p>
<p>（2）不正确的pre-context（translation bias propagation caused by improper pre-context）可能会导致翻译错误，所以本文想要利用整个篇章建模全局上下文（global context）来提升篇章翻译。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="使用层次结构建模全局上下文"><a href="#使用层次结构建模全局上下文" class="headerlink" title="使用层次结构建模全局上下文"></a>使用层次结构建模全局上下文</h2><p><img src="/images/HM-GDC.png" alt></p>
<p>A. Sentence Encoder</p>
<p>首先对句子进行编码得到每个词的隐状态表示，</p>
<p><img src="/images/h1.png" alt></p>
<p>求和得到整个句子的表示，</p>
<p><img src="/images/h21.png" alt></p>
<p>B. Document Encoder</p>
<p>对篇章所有句子进行编码，得到拥有篇章信息的句子表示（sentence-level global context）</p>
<p><img src="/images/h22.png" alt></p>
<p>C. Backpropagation of global context</p>
<p>由sentence-level global context得到word-level global context</p>
<p><img src="/images/h3.png" alt></p>
<h2 id="将全局上下文结合到NMT中"><a href="#将全局上下文结合到NMT中" class="headerlink" title="将全局上下文结合到NMT中"></a>将全局上下文结合到NMT中</h2><p>像其他工作一样，这个global context既结合在编码阶段，也可以结合在解码阶段。</p>
<p>A. 结合在编码阶段</p>
<p>使用word-level global context更新每个词的表示，P表示残差dropout，这里为0.1。</p>
<p><img src="/images/h5.png" alt></p>
<p>B. 结合在解码阶段</p>
<p><img src="/images/h4.png" alt></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>本文实验在中英和德英两个数据集上进行。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>A. 中英</p>
<p>句子级别数据（用于预训练）：2.8M news corpora (LDC 2003E14, LDC2004T07, LDC2005T06, LDC2005T10, LDC2004T08)</p>
<p>篇章级别数据: IWSLT 2017 TED (1906个文档，226K个句对 )</p>
<p>B. 德英</p>
<p>(不进行预训练，没有句子级别数据)</p>
<p>篇章级别数据：IWSLT 2014 TED (1361个文档，172个句对)</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>EMNLP</tag>
        <tag>NMT</tag>
        <tag>Context</tag>
        <tag>Document NMT</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Cross-Lingual-BERT-Transformation-for-Zero-Shot-Dependency-Parsing/</url>
    <content><![CDATA[<p><strong>Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</strong>. Yuxuan Wang, Wanxiang Che, Jiang Guo, Yijia Liu, Ting Liu. EMNLP 2019 <a href="https://arxiv.org/abs/1909.06775" target="_blank" rel="noopener">[PDF]</a>（短文）</p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前大部分cross-lingual word embedding技术存在的问题：</p><a id="more"></a>

<p>（1）依赖大量跨语言数据</p>
<p>（2）需要大量计算资源和训练时间</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文提出一种简单快捷的离线cross-lingual BERT线性映射方法：</p>
<p>（1）通过无监督词对齐方法获得上下文对齐次对（context-level，非词典）</p>
<p>（2）通过预训练好的BERT模型得到上下文对齐次对（x,y）中x,y的上下文表示</p>
<p>（3）通过SVD(奇异值分解)、GD(梯度下降)的方式求得两个表示的线性映射</p>
<p><img src="https://img-blog.csdnimg.cn/2019100320530798.png" alt></p>
<p>作者将获得的跨语言上下文词向量应用到zero-shot依存分析任务上，并获得了目前最好结果。并与XLM(利用跨语言数据重新训练BERT的方法)进行了对比，实验表明该方法在取得与XLM相近结果的情况下，需要的计算资源更少，训练速度也更快。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>EMNLP</tag>
        <tag>Cross Lingual</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Neural-Keyphrase-Generation-via-Reinforcement-Learning-with-Adaptive-Rewards/</url>
    <content><![CDATA[<p><strong>Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</strong>. Hou Pong Chan, Wang Chen, Lu Wang, Irwin King. ACL 2019. <a href="https://arxiv.org/abs/1906.04106" target="_blank" rel="noopener">[PDF]</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本篇论文主要解决目前keyphrase generation任务中存在的两个不足：</p><a id="more"></a>

<p>（1）模型生成的keyphrase比真实的keyphrase个数少</p>
<p>（2）已有评价标准依赖词的完成匹配（不完全匹配就算错，如真实keyphrase为SVM，模型生成的keyphrase为support vector machine也算错）</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>keyphrase根据是否在原文中是否出现分present和absent，这里将一个document的所有keyphrase拼接成一个序列，present在前absent在后，并通过利用seq2seq编码document来生成所有的keyphrase。<br><img src="https://img-blog.csdnimg.cn/20190620092517159.png" width="55%" height="55%"></p>
<p>针对第一个不足，作者使用了reinforcement learning，</p>
<p>sample policy：<br><img src="https://img-blog.csdnimg.cn/20190620092800754.png" alt></p>
<p>reward function: RF1<br><img src="https://img-blog.csdnimg.cn/20190620091404860.png" alt></p>
<p>N为目前已生成的keyphrase个数，G为真实keyphrase个数。作者认为当生成keyphrase的个数还少于真实keyphrase个数时，应该鼓励模型去生成更多的keyphrase，所以用recall作为reward；当个数足够时，除了要求个数也要要求正确性，所以用的F1。看到这里可能也有人会有疑问，为什么前面只重视个数而忽视正确性呢？为什么不改变个数和正确性的权重呢（可以认为是F1的变形）？在这里我个人认为作者可能是实验驱动，只用recall就有效果了；如果没有效果作者可能会去设计吧。。。</p>
<p>presen keyphrase 和 absent keyphrase分别计算reward:<br><img src="https://img-blog.csdnimg.cn/20190620093050519.png" width="55%" height="55%"></p>
<p>针对第二个不足，思路也很容易理解，就是找keyphrase的各种形式，作者这里主要有三个方法</p>
<p>（1）Acronyms in the ground-truths</p>
<p>（2）Wikipedia entity titles</p>
<p>（3）Wikipedia disambiguation pages</p>
<p>然后作者在四个baseline基础上分别验证了方法的有效性，并且对生成的keyphrase的个数、RF1进行了分析。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>ACL</tag>
        <tag>Keyphrase Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 教程</title>
    <url>/2019/10/31/Hexo-%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<ul>
<li><a href="https://hexo-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">hexo指南</a></li>
<li><a href="https://ahh666.com/posts/blog_gitalk_about.html" target="_blank" rel="noopener">添加gitalk评论</a></li>
<li><a href="https://blog.yleao.com/2018/0901/hexo-next%E4%B8%BB%E9%A2%98%E4%B8%8B%E7%9A%84%E7%BE%8E%E5%8C%96.html" target="_blank" rel="noopener">hexo-next主题下的美化</a></li>
<li><a href="https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/MATH.md" target="_blank" rel="noopener">hexo-next使用公式</a></li>
<li><a href="https://io-oi.me/tech/hexo-next-optimization/" target="_blank" rel="noopener">打造个性超赞博客 Hexo + NexT + GitHub Pages 的超深度优化</a></li>
<li><a href="https://muse.theme-next.org/" target="_blank" rel="noopener">Next官方文档</a></li>
<li><a href="https://fontawesome.com/v4.7.0/icons/" target="_blank" rel="noopener">图标</a></li>
</ul>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</title>
    <url>/2019/10/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91Unsupervised%20Neural%20Single-Document%20Summarization%20of%20Reviews%20via/</url>
    <content><![CDATA[<p><strong>Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</strong>. Masaru Isonuma, Junichiro Mori, Ichiro Sakata. ACL 2019. <a href="https://arxiv.org/pdf/1906.05691.pdf" target="_blank" rel="noopener">[PDF]</a></p><a id="more"></a>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>本文认为，评论（review）可以当作一个棵篇章树，树的根节点是其摘要，表示该评论的整体意思; 树的其他节点是对其父节点的细化。 也就是说这棵篇章树由摘要（根节点）与评论中所有句子（非根节点，每个非根节点代表一个句子）组成。于是本文通过学习构造这个隐式篇章树来建模得到评论摘要，并提出一种排序（rank）算法选择对生成摘要更加重要的句子。</p>
<p><img src="/images/strsum.png" alt></p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="模型整体方法"><a href="#模型整体方法" class="headerlink" title="模型整体方法"></a>模型整体方法</h2><p>（1）双向GRU+maxpooling 建模得到每个句子表示</p>
<p>（2）建模 父节点-子节点 对应关系权重（权重代表了树的关系）</p>
<p>（3）加权求和所有子节点表示，生成父节点（本文假设：子节点能够还原父节点，因为子节点包含了比父节点更多的信息。）</p>
<p>目标函数就是所有父节点生成概率最大。</p>
<p><img src="/images/strsum2.png" alt></p>
<h2 id="父节点-子节点-对应关系权重建模方法"><a href="#父节点-子节点-对应关系权重建模方法" class="headerlink" title="父节点-子节点 对应关系权重建模方法"></a>父节点-子节点 对应关系权重建模方法</h2><p>初始建模：边界概率（Marginal Probability of Dependency）</p>
<p><img src="/images/strsum3.png" alt></p>
<p>归一化（公式推导不是很懂）</p>
<p><img src="/images/strsum4.png" alt></p>
<p>调整：篇章排序（DiscourseRank）</p>
<p>受PageRank算法启发，更重要的句子有更多后代，迭代更新权重矩阵。<br><img src="/images/strsum5.png" alt></p>
<p><img src="/images/strsum6.png" alt></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>ACL</tag>
        <tag>Discourse Structure</tag>
        <tag>Discourse Ranking</tag>
      </tags>
  </entry>
</search>
